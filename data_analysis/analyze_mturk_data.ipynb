{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mturk csv file to analyze\n",
    "mturk_csv_path = './data_files/mturk/moderation0.csv'\n",
    "\n",
    "# read contents into dataframe\n",
    "mturk_df = pd.read_csv(mturk_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate worker accuracy\n",
    "def calc_accuracy():\n",
    "    # get expert labels\n",
    "    with open('../image_processing/labels.json') as handle:\n",
    "        expert_labels = json.load(handle)\n",
    "        handle.close()\n",
    "\n",
    "    # evaluate accuracy wrt. individual categories and overall\n",
    "    num_total_correct_category = 0\n",
    "    num_total_category = 0\n",
    "    num_error = 0\n",
    "    num_other = 0\n",
    "\n",
    "    num_sexnudity_correct = 0\n",
    "    num_sexnudity_incorrect = 0\n",
    "\n",
    "    num_graphic_correct = 0\n",
    "    num_graphic_incorrect = 0\n",
    "\n",
    "    num_safe_correct = 0\n",
    "    num_safe_incorrect = 0\n",
    "\n",
    "    # evaluate accuracy wrt. individual types and overall\n",
    "    num_total_correct_type = 0\n",
    "    num_total_type = 0\n",
    "\n",
    "    num_realistic_correct = 0\n",
    "    num_realistic_incorrect = 0\n",
    "\n",
    "    num_synthetic_correct = 0\n",
    "    num_synthetic_incorrect = 0\n",
    "\n",
    "    # evaluate accuracy wrt. both category and type\n",
    "    num_total_correct = 0\n",
    "    num_total = 0\n",
    "\n",
    "    # iterate through worker submissions\n",
    "    for row in mturk_df.itertuples():\n",
    "        labels = getattr(row, 'labels')\n",
    "        worker_labels = json.loads(labels)\n",
    "\n",
    "        # iterate through worker annotations for each image\n",
    "        for image, annotation in worker_labels.items():\n",
    "            # skip if no annotations for this image\n",
    "            if annotation == 'error':\n",
    "                num_error += 1\n",
    "                continue\n",
    "\n",
    "            worker_category = annotation['category']\n",
    "            worker_type = annotation['type']\n",
    "            worker_label_type = worker_category + '_' + worker_type\n",
    "\n",
    "            expert_annotation = expert_labels[image]\n",
    "            expert_category = expert_annotation['category']\n",
    "            expert_type = expert_annotation['type']\n",
    "            expert_label_type = expert_annotation['label_type']\n",
    "\n",
    "            # evaluate accuracy wrt. category\n",
    "            if worker_category == 'other':\n",
    "                num_other += 1\n",
    "            else:\n",
    "                if worker_category == expert_category:\n",
    "                    if expert_category == 'sex_nudity':\n",
    "                        num_sexnudity_correct += 1\n",
    "                    elif expert_category == 'graphic':\n",
    "                        num_graphic_correct += 1\n",
    "                    else:\n",
    "                        num_safe_correct += 1\n",
    "                    num_total_correct_category += 1\n",
    "                else:\n",
    "                    if expert_category == 'sex_nudity':\n",
    "                        num_sexnudity_incorrect += 1\n",
    "                    elif expert_category == 'graphic':\n",
    "                        num_graphic_incorrect += 1\n",
    "                    else:\n",
    "                        num_safe_incorrect += 1    \n",
    "                num_total_category += 1\n",
    "\n",
    "            # evaluate wrt. type\n",
    "            if worker_type == expert_type:\n",
    "                if expert_type == 'realistic':\n",
    "                    num_realistic_correct += 1\n",
    "                else:\n",
    "                    num_synthetic_correct += 1\n",
    "                num_total_correct_type += 1\n",
    "            else:\n",
    "                if expert_type == 'realistic':\n",
    "                    num_realistic_incorrect += 1\n",
    "                else:\n",
    "                    num_synthetic_incorrect += 1\n",
    "            num_total_type += 1\n",
    "\n",
    "            # evaluate wrt. both category and type\n",
    "            if worker_category == 'other':\n",
    "                pass\n",
    "            else:\n",
    "                num_total += 1\n",
    "                if worker_label_type == expert_label_type:\n",
    "                    num_total_correct += 1\n",
    "\n",
    "    # calculate and print results wrt. categories\n",
    "    print('Category accuracy:')\n",
    "    print('\\tOverall detection:\\t{}'.format(num_total_correct_category / num_total_category))\n",
    "    if num_sexnudity_correct + num_sexnudity_incorrect:\n",
    "        print('\\tSex and nudity detection:\\t{}'.format(num_sexnudity_correct / (num_sexnudity_correct + num_sexnudity_incorrect)))\n",
    "    if num_graphic_correct + num_graphic_incorrect:\n",
    "        print('\\tGraphic content detection:\\t{}'.format(num_graphic_correct / (num_graphic_correct + num_graphic_incorrect)))\n",
    "    if num_safe_correct + num_safe_incorrect:\n",
    "        print('\\tSafe content detection:\\t{}'.format(num_safe_correct / (num_safe_correct + num_safe_incorrect)))\n",
    "    print('\\n')\n",
    "\n",
    "    # calculate and print results wrt. types\n",
    "    print('Type accuracy:')\n",
    "    print('\\tOverall detection:\\t{}'.format(num_total_correct_type / num_total_type))\n",
    "    if num_realistic_correct + num_realistic_incorrect:\n",
    "        print('\\tRealistic detection:\\t{}'.format(num_realistic_correct / (num_realistic_correct + num_realistic_incorrect)))\n",
    "    if num_synthetic_correct + num_synthetic_incorrect:\n",
    "        print('\\tSynthetic detection:\\t{}'.format(num_synthetic_correct / (num_synthetic_correct + num_synthetic_incorrect)))\n",
    "    print('\\n')\n",
    "\n",
    "    # calculate and print results wrt. both category and type\n",
    "    print('Category and type accuracy:')\n",
    "    print('\\tOverall detection:\\t{}'.format(num_total_correct / num_total))\n",
    "    print('\\n')\n",
    "\n",
    "    # print number of 'other' category annotations and number of 'errors' reported\n",
    "    print('Number of images skipped:')\n",
    "    print('\\tNumber of errored images:\\t\\t{}'.format(num_error))\n",
    "    print('\\tNumber of \"other\" categorizations:\\t{}'.format(num_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate worker confidence statistics\n",
    "def calc_confidence():\n",
    "    confidences = []\n",
    "\n",
    "    # iterate through worker submissions\n",
    "    for row in mturk_df.itertuples():\n",
    "        labels = getattr(row, 'labels')\n",
    "        worker_labels = json.loads(labels)\n",
    "\n",
    "        # iterate through worker annotations for each image\n",
    "        for image, annotation in worker_labels.items():\n",
    "            # skip if no annotations for this image\n",
    "            if annotation == 'error':\n",
    "                continue\n",
    "\n",
    "            confidences.append(annotation['confidence'])\n",
    "\n",
    "    # convert list to np array\n",
    "    confidences = np.asarray(confidences, dtype=np.float64)\n",
    "\n",
    "    # calculate and print statistics\n",
    "    print('Confidence statistics:')\n",
    "    print('\\tAverage:\\t{}'.format(np.mean(confidences)))\n",
    "    print('\\tStandard dev:\\t{}'.format(np.std(confidences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate worker behavioral statistics\n",
    "def calc_behavioral():\n",
    "    # calculate and print clicks_total statistics\n",
    "    clicks_total = mturk_df['clicks_total']\n",
    "    print('Clicks total:')\n",
    "    print('\\tAverage:\\t{}'.format(np.mean(clicks_total)))\n",
    "    print('\\tStandard dev:\\t{}'.format(np.std(clicks_total)))\n",
    "    print('\\n')\n",
    "\n",
    "    # calculate and print mousemove_total statistics\n",
    "    mousemoves_total = mturk_df['mousemoves_total']\n",
    "    print('Mousemoves total:')\n",
    "    print('\\tAverage:\\t{}'.format(np.mean(mousemoves_total)))\n",
    "    print('\\tStandard dev:\\t{}'.format(np.std(mousemoves_total)))\n",
    "    print('\\n')\n",
    "\n",
    "    # calculate and print completion_time statistics\n",
    "    completion_time = mturk_df['completion_time']\n",
    "    print('Completion time:')\n",
    "    print('\\tAverage:\\t{}'.format(np.mean(completion_time)))\n",
    "    print('\\tStandard dev:\\t{}'.format(np.std(completion_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category accuracy:\n",
      "\tOverall detection:\t0.9158878504672897\n",
      "\tSafe content detection:\t0.9158878504672897\n",
      "\n",
      "\n",
      "Type accuracy:\n",
      "\tOverall detection:\t0.8909090909090909\n",
      "\tRealistic detection:\t0.975\n",
      "\tSynthetic detection:\t0.8428571428571429\n",
      "\n",
      "\n",
      "Category and type accuracy:\n",
      "\tOverall detection:\t0.8130841121495327\n",
      "\n",
      "\n",
      "Number of images skipped:\n",
      "\tNumber of errored images:\t\t0\n",
      "\tNumber of \"other\" categorizations:\t3\n"
     ]
    }
   ],
   "source": [
    "calc_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence statistics:\n",
      "\tAverage:\t4.6909090909090905\n",
      "\tStandard dev:\t0.4813891743590446\n"
     ]
    }
   ],
   "source": [
    "calc_confidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicks total:\n",
      "\tAverage:\t85.54545454545455\n",
      "\tStandard dev:\t17.132444692950994\n",
      "\n",
      "\n",
      "Mousemoves total:\n",
      "\tAverage:\t92.0\n",
      "\tStandard dev:\t35.009089728759925\n",
      "\n",
      "\n",
      "Completion time:\n",
      "\tAverage:\t181343.63636363635\n",
      "\tStandard dev:\t57932.5320418231\n"
     ]
    }
   ],
   "source": [
    "calc_behavioral()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
