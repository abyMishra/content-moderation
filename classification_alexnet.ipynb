{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set up Python environment: numpy for numerical routines, and matplotlib for plotting\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The caffe module needs to be on the Python path;\n",
    "#  we'll add it here explicitly.\n",
    "import sys\n",
    "caffe_root = '/home/ambika/caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaffeNet found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
    "    print 'CaffeNet found.'\n",
    "else:\n",
    "    print 'Downloading pre-trained CaffeNet model...'\n",
    "    !../scripts/download_model_binary.py ../models/bvlc_reference_caffenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()\n",
    "\n",
    "model_def = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "model_weights = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n"
     ]
    }
   ],
   "source": [
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set the size of the input (we can skip this if we're happy\n",
    "#  with the default; we can also change it later, e.g., for different batch sizes)\n",
    "net.blobs['data'].reshape(50,        # batch size\n",
    "                          3,         # 3-channel (BGR) images\n",
    "                          227, 227)  # image size is 227x227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "for filename in glob.glob('/home/ambika/Downloads/CrowdSourcing-Project-master/samples/*.jpg'): \n",
    "    #im=Image.open(filename)\n",
    "    image_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class is: 611\n",
      "output label: n03598930 jigsaw puzzle\n",
      "probabilities and labels:\n",
      "[(0.50360048, 'n03598930 jigsaw puzzle'), (0.10029279, 'n02980441 castle'), (0.085219562, 'n06785654 crossword puzzle, crossword'), (0.044029515, 'n02793495 barn'), (0.034406442, 'n03877845 palace')]\n",
      "predicted class is: 339\n",
      "output label: n02389026 sorrel\n",
      "probabilities and labels:\n",
      "[(0.16089933, 'n02389026 sorrel'), (0.14502063, 'n02093428 American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier'), (0.10857349, 'n02093256 Staffordshire bullterrier, Staffordshire bull terrier'), (0.087770343, 'n02108089 boxer'), (0.0828095, 'n02109047 Great Dane')]\n",
      "predicted class is: 15\n",
      "output label: n01558993 robin, American robin, Turdus migratorius\n",
      "probabilities and labels:\n",
      "[(0.94511968, 'n01558993 robin, American robin, Turdus migratorius'), (0.03295581, 'n01530575 brambling, Fringilla montifringilla'), (0.0039031084, 'n01560419 bulbul'), (0.003902744, 'n01807496 partridge'), (0.0034882226, 'n01824575 coucal')]\n",
      "predicted class is: 850\n",
      "output label: n04399382 teddy, teddy bear\n",
      "probabilities and labels:\n",
      "[(0.40974206, 'n04399382 teddy, teddy bear'), (0.25389957, \"n03590841 jack-o'-lantern\"), (0.075689554, 'n03720891 maraca'), (0.038207658, 'n04162706 seat belt, seatbelt'), (0.015083597, 'n02787622 banjo')]\n",
      "predicted class is: 795\n",
      "output label: n04228054 ski\n",
      "probabilities and labels:\n",
      "[(0.27688962, 'n04228054 ski'), (0.23241538, 'n03404251 fur coat'), (0.071876399, 'n02113799 standard poodle'), (0.045011304, 'n04509417 unicycle, monocycle'), (0.042202853, 'n02102973 Irish water spaniel')]\n",
      "predicted class is: 779\n",
      "output label: n04146614 school bus\n",
      "probabilities and labels:\n",
      "[(0.047185775, 'n04146614 school bus'), (0.038059384, 'n02930766 cab, hack, taxi, taxicab'), (0.036635522, 'n02364673 guinea pig, Cavia cobaya'), (0.032967836, 'n06874185 traffic light, traffic signal, stoplight'), (0.023260064, 'n03908714 pencil sharpener')]\n",
      "predicted class is: 495\n",
      "output label: n03018349 china cabinet, china closet\n",
      "probabilities and labels:\n",
      "[(0.39145291, 'n03018349 china cabinet, china closet'), (0.092866823, 'n03290653 entertainment center'), (0.085023507, 'n03529860 home theater, home theatre'), (0.06194789, 'n04239074 sliding door'), (0.040710486, 'n03661043 library')]\n",
      "predicted class is: 223\n",
      "output label: n02104365 schipperke\n",
      "probabilities and labels:\n",
      "[(0.2664018, 'n02104365 schipperke'), (0.077487051, 'n03179701 desk'), (0.054531664, 'n02105056 groenendael'), (0.052244514, 'n04265275 space heater'), (0.039357007, 'n02790996 barbell')]\n",
      "predicted class is: 178\n",
      "output label: n02092339 Weimaraner\n",
      "probabilities and labels:\n",
      "[(0.28704444, 'n02092339 Weimaraner'), (0.11744082, 'n02091032 Italian greyhound'), (0.1024552, 'n02090379 redbone'), (0.066436186, 'n02099849 Chesapeake Bay retriever'), (0.054498196, 'n02099712 Labrador retriever')]\n",
      "predicted class is: 579\n",
      "output label: n03452741 grand piano, grand\n",
      "probabilities and labels:\n",
      "[(0.063039273, 'n03452741 grand piano, grand'), (0.059535559, 'n03942813 ping-pong ball'), (0.052050967, 'n04239074 sliding door'), (0.02670436, 'n04201297 shoji'), (0.025554547, 'n03376595 folding chair')]\n"
     ]
    }
   ],
   "source": [
    "#image = caffe.io.load_image(caffe_root + 'examples/images/cat.jpg')\n",
    "# load ImageNet labels\n",
    "labels_file = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "if not os.path.exists(labels_file):\n",
    "    !../data/ilsvrc12/get_ilsvrc_aux.sh\n",
    "    \n",
    "labels = np.loadtxt(labels_file, str, delimiter='\\t')\n",
    "filename='test_labels.txt'\n",
    "b = open(filename, 'wb') \n",
    "a = csv.writer(b)\n",
    "\n",
    "for i in range(0,10):\n",
    "    #image = caffe.io.load_image('/home/ambika/INF_project/data/dog/166995.jpg')\n",
    "    image = caffe.io.load_image(image_list[i])\n",
    "    transformed_image = transformer.preprocess('data', image)\n",
    "    #copy the image data into the memory allocated for the net\n",
    "    net.blobs['data'].data[...] = transformed_image\n",
    "\n",
    "    ### perform classification\n",
    "    output = net.forward()\n",
    "\n",
    "    output_prob = output['prob'][0]  # the output probability vector for the first image in the batch\n",
    "\n",
    "    print 'predicted class is:', output_prob.argmax()\n",
    "    print 'output label:', labels[output_prob.argmax()]\n",
    "    # sort top five predictions from softmax output\n",
    "    top_inds = output_prob.argsort()[::-1][:5]  # reverse sort and take five largest items\n",
    "\n",
    "    print 'probabilities and labels:'\n",
    "    print zip(output_prob[top_inds], labels[top_inds])\n",
    "    \n",
    "    \n",
    "    data=str(output_prob[top_inds[0]])+'\\t'+labels[top_inds[0]]+'\\t'+str(output_prob[top_inds[1]])+'\\t'+labels[top_inds[1]]+'\\t'+str(output_prob[top_inds[2]])+'\\t'+labels[top_inds[2]]+'\\t'+str(output_prob[top_inds[3]])+'\\t'+labels[top_inds[3]]+'\\t'+str(output_prob[top_inds[4]])+'\\t'+labels[top_inds[4]]\n",
    "    new_data=[[image_list[i]+'\\t'+data]]\n",
    "    a.writerows(new_data)\n",
    "    #plt.imshow(image)\n",
    "    \n",
    "b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ambika/Downloads/CrowdSourcing-Project-master/samples/26201.jpg\t0.0630393\tn03452741 grand piano, grand\n"
     ]
    }
   ],
   "source": [
    "print image_list[0]+'\\t'+str(output_prob[top_inds[0]])+'\\t'+ labels[top_inds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0630393\tn03452741 grand piano, grand\n"
     ]
    }
   ],
   "source": [
    "print str(output_prob[top_inds[0]])+'\\t'+labels[top_inds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
