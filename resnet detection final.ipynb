{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 02:42:28.959839 24436 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 02:42:28.959861 24436 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 02:42:28.959863 24436 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 02:42:28.961028 24436 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 02:42:28.961129 24436 layer_factory.hpp:77] Creating layer data\n",
      "I0430 02:42:28.961138 24436 net.cpp:86] Creating Layer data\n",
      "I0430 02:42:28.961148 24436 net.cpp:382] data -> data\n",
      "I0430 02:42:28.961166 24436 net.cpp:124] Setting up data\n",
      "I0430 02:42:28.961174 24436 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 02:42:28.961175 24436 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 02:42:28.961179 24436 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 02:42:28.961185 24436 net.cpp:86] Creating Layer conv1\n",
      "I0430 02:42:28.961189 24436 net.cpp:408] conv1 <- data\n",
      "I0430 02:42:28.961194 24436 net.cpp:382] conv1 -> conv1\n",
      "I0430 02:42:28.961263 24436 net.cpp:124] Setting up conv1\n",
      "I0430 02:42:28.961269 24436 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:42:28.961274 24436 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 02:42:28.961287 24436 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 02:42:28.961297 24436 net.cpp:86] Creating Layer relu1\n",
      "I0430 02:42:28.961299 24436 net.cpp:408] relu1 <- conv1\n",
      "I0430 02:42:28.961303 24436 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 02:42:28.961308 24436 net.cpp:124] Setting up relu1\n",
      "I0430 02:42:28.961310 24436 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:42:28.961311 24436 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 02:42:28.961313 24436 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 02:42:28.961316 24436 net.cpp:86] Creating Layer pool1\n",
      "I0430 02:42:28.961318 24436 net.cpp:408] pool1 <- conv1\n",
      "I0430 02:42:28.961321 24436 net.cpp:382] pool1 -> pool1\n",
      "I0430 02:42:28.961328 24436 net.cpp:124] Setting up pool1\n",
      "I0430 02:42:28.961330 24436 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:42:28.961333 24436 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 02:42:28.961335 24436 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 02:42:28.961338 24436 net.cpp:86] Creating Layer norm1\n",
      "I0430 02:42:28.961340 24436 net.cpp:408] norm1 <- pool1\n",
      "I0430 02:42:28.961344 24436 net.cpp:382] norm1 -> norm1\n",
      "I0430 02:42:28.961347 24436 net.cpp:124] Setting up norm1\n",
      "I0430 02:42:28.961351 24436 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:42:28.961352 24436 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 02:42:28.961355 24436 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 02:42:28.961359 24436 net.cpp:86] Creating Layer conv2\n",
      "I0430 02:42:28.961360 24436 net.cpp:408] conv2 <- norm1\n",
      "I0430 02:42:28.961364 24436 net.cpp:382] conv2 -> conv2\n",
      "I0430 02:42:28.961735 24436 net.cpp:124] Setting up conv2\n",
      "I0430 02:42:28.961748 24436 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:42:28.961750 24436 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 02:42:28.961757 24436 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 02:42:28.961762 24436 net.cpp:86] Creating Layer relu2\n",
      "I0430 02:42:28.961765 24436 net.cpp:408] relu2 <- conv2\n",
      "I0430 02:42:28.961769 24436 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 02:42:28.961774 24436 net.cpp:124] Setting up relu2\n",
      "I0430 02:42:28.961777 24436 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:42:28.961779 24436 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 02:42:28.961782 24436 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 02:42:28.961787 24436 net.cpp:86] Creating Layer pool2\n",
      "I0430 02:42:28.961791 24436 net.cpp:408] pool2 <- conv2\n",
      "I0430 02:42:28.961793 24436 net.cpp:382] pool2 -> pool2\n",
      "I0430 02:42:28.961799 24436 net.cpp:124] Setting up pool2\n",
      "I0430 02:42:28.961803 24436 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:42:28.961805 24436 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 02:42:28.961808 24436 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 02:42:28.961813 24436 net.cpp:86] Creating Layer norm2\n",
      "I0430 02:42:28.961815 24436 net.cpp:408] norm2 <- pool2\n",
      "I0430 02:42:28.961819 24436 net.cpp:382] norm2 -> norm2\n",
      "I0430 02:42:28.961823 24436 net.cpp:124] Setting up norm2\n",
      "I0430 02:42:28.961827 24436 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:42:28.961829 24436 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 02:42:28.961833 24436 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 02:42:28.961838 24436 net.cpp:86] Creating Layer conv3\n",
      "I0430 02:42:28.961841 24436 net.cpp:408] conv3 <- norm2\n",
      "I0430 02:42:28.961845 24436 net.cpp:382] conv3 -> conv3\n",
      "I0430 02:42:28.962815 24436 net.cpp:124] Setting up conv3\n",
      "I0430 02:42:28.962827 24436 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:42:28.962829 24436 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 02:42:28.962836 24436 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 02:42:28.962841 24436 net.cpp:86] Creating Layer relu3\n",
      "I0430 02:42:28.962842 24436 net.cpp:408] relu3 <- conv3\n",
      "I0430 02:42:28.962846 24436 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 02:42:28.962851 24436 net.cpp:124] Setting up relu3\n",
      "I0430 02:42:28.962852 24436 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:42:28.962854 24436 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 02:42:28.962857 24436 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 02:42:28.962864 24436 net.cpp:86] Creating Layer conv4\n",
      "I0430 02:42:28.962867 24436 net.cpp:408] conv4 <- conv3\n",
      "I0430 02:42:28.962869 24436 net.cpp:382] conv4 -> conv4\n",
      "I0430 02:42:28.963327 24436 net.cpp:124] Setting up conv4\n",
      "I0430 02:42:28.963338 24436 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:42:28.963341 24436 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 02:42:28.963351 24436 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 02:42:28.963364 24436 net.cpp:86] Creating Layer relu4\n",
      "I0430 02:42:28.963372 24436 net.cpp:408] relu4 <- conv4\n",
      "I0430 02:42:28.963377 24436 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 02:42:28.963382 24436 net.cpp:124] Setting up relu4\n",
      "I0430 02:42:28.963385 24436 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:42:28.963387 24436 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 02:42:28.963390 24436 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 02:42:28.963397 24436 net.cpp:86] Creating Layer conv5\n",
      "I0430 02:42:28.963399 24436 net.cpp:408] conv5 <- conv4\n",
      "I0430 02:42:28.963403 24436 net.cpp:382] conv5 -> conv5\n",
      "I0430 02:42:28.963882 24436 net.cpp:124] Setting up conv5\n",
      "I0430 02:42:28.963891 24436 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:42:28.963893 24436 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 02:42:28.963902 24436 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 02:42:28.963907 24436 net.cpp:86] Creating Layer relu5\n",
      "I0430 02:42:28.963910 24436 net.cpp:408] relu5 <- conv5\n",
      "I0430 02:42:28.963912 24436 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 02:42:28.963917 24436 net.cpp:124] Setting up relu5\n",
      "I0430 02:42:28.963919 24436 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:42:28.963920 24436 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 02:42:28.963922 24436 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 02:42:28.963927 24436 net.cpp:86] Creating Layer pool5\n",
      "I0430 02:42:28.963929 24436 net.cpp:408] pool5 <- conv5\n",
      "I0430 02:42:28.963932 24436 net.cpp:382] pool5 -> pool5\n",
      "I0430 02:42:28.963938 24436 net.cpp:124] Setting up pool5\n",
      "I0430 02:42:28.963942 24436 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 02:42:28.963943 24436 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 02:42:28.963945 24436 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 02:42:28.963951 24436 net.cpp:86] Creating Layer fc6\n",
      "I0430 02:42:28.963953 24436 net.cpp:408] fc6 <- pool5\n",
      "I0430 02:42:28.963958 24436 net.cpp:382] fc6 -> fc6\n",
      "I0430 02:42:28.986737 24436 net.cpp:124] Setting up fc6\n",
      "I0430 02:42:28.986758 24436 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:42:28.986760 24436 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 02:42:28.986768 24436 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 02:42:28.986773 24436 net.cpp:86] Creating Layer relu6\n",
      "I0430 02:42:28.986775 24436 net.cpp:408] relu6 <- fc6\n",
      "I0430 02:42:28.986781 24436 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 02:42:28.986788 24436 net.cpp:124] Setting up relu6\n",
      "I0430 02:42:28.986789 24436 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:42:28.986791 24436 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 02:42:28.986793 24436 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 02:42:28.986801 24436 net.cpp:86] Creating Layer drop6\n",
      "I0430 02:42:28.986817 24436 net.cpp:408] drop6 <- fc6\n",
      "I0430 02:42:28.986821 24436 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 02:42:28.986827 24436 net.cpp:124] Setting up drop6\n",
      "I0430 02:42:28.986831 24436 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:42:28.986836 24436 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 02:42:28.986840 24436 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 02:42:28.986845 24436 net.cpp:86] Creating Layer fc7\n",
      "I0430 02:42:28.986847 24436 net.cpp:408] fc7 <- fc6\n",
      "I0430 02:42:28.986851 24436 net.cpp:382] fc7 -> fc7\n",
      "I0430 02:42:29.000640 24436 net.cpp:124] Setting up fc7\n",
      "I0430 02:42:29.000697 24436 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:42:29.000700 24436 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 02:42:29.000731 24436 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 02:42:29.000751 24436 net.cpp:86] Creating Layer relu7\n",
      "I0430 02:42:29.000763 24436 net.cpp:408] relu7 <- fc7\n",
      "I0430 02:42:29.000771 24436 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 02:42:29.000785 24436 net.cpp:124] Setting up relu7\n",
      "I0430 02:42:29.000790 24436 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:42:29.000792 24436 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 02:42:29.000795 24436 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 02:42:29.000803 24436 net.cpp:86] Creating Layer drop7\n",
      "I0430 02:42:29.000808 24436 net.cpp:408] drop7 <- fc7\n",
      "I0430 02:42:29.000814 24436 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 02:42:29.000823 24436 net.cpp:124] Setting up drop7\n",
      "I0430 02:42:29.000825 24436 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:42:29.000829 24436 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 02:42:29.000831 24436 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 02:42:29.000838 24436 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 02:42:29.000841 24436 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 02:42:29.000845 24436 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 02:42:29.002058 24436 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 02:42:29.002074 24436 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 02:42:29.002075 24436 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 02:42:29.002081 24436 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 02:42:29.002086 24436 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 02:42:29.002089 24436 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 02:42:29.002091 24436 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 02:42:29.002094 24436 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 02:42:29.002095 24436 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 02:42:29.002099 24436 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 02:42:29.002100 24436 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 02:42:29.002102 24436 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 02:42:29.002104 24436 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 02:42:29.002106 24436 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 02:42:29.002109 24436 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 02:42:29.002111 24436 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 02:42:29.002113 24436 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 02:42:29.002116 24436 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 02:42:29.002120 24436 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 02:42:29.002121 24436 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 02:42:29.002123 24436 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 02:42:29.002125 24436 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 02:42:29.002127 24436 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 02:42:29.002130 24436 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 02:42:29.002132 24436 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 02:42:29.002135 24436 net.cpp:202] data does not need backward computation.\n",
      "I0430 02:42:29.002136 24436 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 02:42:29.002146 24436 net.cpp:257] Network initialization done.\n",
      "I0430 02:42:29.100111 24436 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:42:29.253852 24436 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 02:42:29.254662 24436 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:42:29.254669 24436 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 02:42:29.254672 24436 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/144114.jpg'}, '/tmp/tmpgv_R6F.mat')\n",
      "Processed 438 windows in 58.280 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.027 s.\n",
      "prediction    [-2.41563, 1.57993, -1.86066, -2.15003, -1.900...\n",
      "ymin                                                        152\n",
      "xmin                                                         75\n",
      "ymax                                                        288\n",
      "xmax                                                        345\n",
      "Name: /home/ambika/INF_project/data/airplane/144114.jpg, dtype: object\n",
      "prediction    [-2.07331, 0.93291, -1.88672, -1.96276, -1.427...\n",
      "ymin                                                        151\n",
      "xmin                                                         20\n",
      "ymax                                                        285\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/airplane/144114.jpg, dtype: object\n",
      "airplane\n",
      "75\t152\t345\t288\n",
      "ski\n",
      "20\t151\t500\t285\n",
      "144114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ambika/.local/lib/python2.7/site-packages/ipykernel/__main__.py:37: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/home/ambika/.local/lib/python2.7/site-packages/ipykernel/__main__.py:42: FutureWarning: sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n",
      "/home/ambika/.local/lib/python2.7/site-packages/ipykernel/__main__.py:59: FutureWarning: order is deprecated, use sort_values(...)\n",
      "/home/ambika/.local/lib/python2.7/site-packages/ipykernel/__main__.py:69: FutureWarning: order is deprecated, use sort_values(...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 02:43:29.060906 24542 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 02:43:29.060920 24542 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 02:43:29.060923 24542 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 02:43:29.062038 24542 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 02:43:29.062222 24542 layer_factory.hpp:77] Creating layer data\n",
      "I0430 02:43:29.062232 24542 net.cpp:86] Creating Layer data\n",
      "I0430 02:43:29.062237 24542 net.cpp:382] data -> data\n",
      "I0430 02:43:29.062252 24542 net.cpp:124] Setting up data\n",
      "I0430 02:43:29.062258 24542 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 02:43:29.062260 24542 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 02:43:29.062264 24542 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 02:43:29.062271 24542 net.cpp:86] Creating Layer conv1\n",
      "I0430 02:43:29.062275 24542 net.cpp:408] conv1 <- data\n",
      "I0430 02:43:29.062280 24542 net.cpp:382] conv1 -> conv1\n",
      "I0430 02:43:29.062352 24542 net.cpp:124] Setting up conv1\n",
      "I0430 02:43:29.062358 24542 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:43:29.062361 24542 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 02:43:29.062367 24542 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 02:43:29.062371 24542 net.cpp:86] Creating Layer relu1\n",
      "I0430 02:43:29.062373 24542 net.cpp:408] relu1 <- conv1\n",
      "I0430 02:43:29.062376 24542 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 02:43:29.062381 24542 net.cpp:124] Setting up relu1\n",
      "I0430 02:43:29.062383 24542 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:43:29.062384 24542 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 02:43:29.062386 24542 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 02:43:29.062389 24542 net.cpp:86] Creating Layer pool1\n",
      "I0430 02:43:29.062392 24542 net.cpp:408] pool1 <- conv1\n",
      "I0430 02:43:29.062397 24542 net.cpp:382] pool1 -> pool1\n",
      "I0430 02:43:29.062403 24542 net.cpp:124] Setting up pool1\n",
      "I0430 02:43:29.062407 24542 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:43:29.062408 24542 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 02:43:29.062410 24542 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 02:43:29.062414 24542 net.cpp:86] Creating Layer norm1\n",
      "I0430 02:43:29.062417 24542 net.cpp:408] norm1 <- pool1\n",
      "I0430 02:43:29.062420 24542 net.cpp:382] norm1 -> norm1\n",
      "I0430 02:43:29.062425 24542 net.cpp:124] Setting up norm1\n",
      "I0430 02:43:29.062428 24542 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:43:29.062430 24542 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 02:43:29.062433 24542 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 02:43:29.062438 24542 net.cpp:86] Creating Layer conv2\n",
      "I0430 02:43:29.062439 24542 net.cpp:408] conv2 <- norm1\n",
      "I0430 02:43:29.062443 24542 net.cpp:382] conv2 -> conv2\n",
      "I0430 02:43:29.062814 24542 net.cpp:124] Setting up conv2\n",
      "I0430 02:43:29.062822 24542 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:43:29.062824 24542 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 02:43:29.062830 24542 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 02:43:29.062835 24542 net.cpp:86] Creating Layer relu2\n",
      "I0430 02:43:29.062837 24542 net.cpp:408] relu2 <- conv2\n",
      "I0430 02:43:29.062841 24542 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 02:43:29.062846 24542 net.cpp:124] Setting up relu2\n",
      "I0430 02:43:29.062849 24542 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:43:29.062851 24542 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 02:43:29.062855 24542 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 02:43:29.062858 24542 net.cpp:86] Creating Layer pool2\n",
      "I0430 02:43:29.062862 24542 net.cpp:408] pool2 <- conv2\n",
      "I0430 02:43:29.062868 24542 net.cpp:382] pool2 -> pool2\n",
      "I0430 02:43:29.062876 24542 net.cpp:124] Setting up pool2\n",
      "I0430 02:43:29.062882 24542 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:43:29.062886 24542 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 02:43:29.062889 24542 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 02:43:29.062896 24542 net.cpp:86] Creating Layer norm2\n",
      "I0430 02:43:29.062899 24542 net.cpp:408] norm2 <- pool2\n",
      "I0430 02:43:29.062902 24542 net.cpp:382] norm2 -> norm2\n",
      "I0430 02:43:29.062907 24542 net.cpp:124] Setting up norm2\n",
      "I0430 02:43:29.062911 24542 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:43:29.062913 24542 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 02:43:29.062916 24542 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 02:43:29.062922 24542 net.cpp:86] Creating Layer conv3\n",
      "I0430 02:43:29.062923 24542 net.cpp:408] conv3 <- norm2\n",
      "I0430 02:43:29.062927 24542 net.cpp:382] conv3 -> conv3\n",
      "I0430 02:43:29.063649 24542 net.cpp:124] Setting up conv3\n",
      "I0430 02:43:29.063660 24542 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:43:29.063664 24542 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 02:43:29.063675 24542 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 02:43:29.063683 24542 net.cpp:86] Creating Layer relu3\n",
      "I0430 02:43:29.063685 24542 net.cpp:408] relu3 <- conv3\n",
      "I0430 02:43:29.063689 24542 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 02:43:29.063695 24542 net.cpp:124] Setting up relu3\n",
      "I0430 02:43:29.063699 24542 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:43:29.063700 24542 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 02:43:29.063704 24542 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 02:43:29.063709 24542 net.cpp:86] Creating Layer conv4\n",
      "I0430 02:43:29.063712 24542 net.cpp:408] conv4 <- conv3\n",
      "I0430 02:43:29.063716 24542 net.cpp:382] conv4 -> conv4\n",
      "I0430 02:43:29.064426 24542 net.cpp:124] Setting up conv4\n",
      "I0430 02:43:29.064435 24542 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:43:29.064440 24542 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 02:43:29.064446 24542 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 02:43:29.064452 24542 net.cpp:86] Creating Layer relu4\n",
      "I0430 02:43:29.064455 24542 net.cpp:408] relu4 <- conv4\n",
      "I0430 02:43:29.064462 24542 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 02:43:29.064467 24542 net.cpp:124] Setting up relu4\n",
      "I0430 02:43:29.064471 24542 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:43:29.064473 24542 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 02:43:29.064476 24542 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 02:43:29.064481 24542 net.cpp:86] Creating Layer conv5\n",
      "I0430 02:43:29.064483 24542 net.cpp:408] conv5 <- conv4\n",
      "I0430 02:43:29.064486 24542 net.cpp:382] conv5 -> conv5\n",
      "I0430 02:43:29.064998 24542 net.cpp:124] Setting up conv5\n",
      "I0430 02:43:29.065006 24542 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:43:29.065009 24542 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 02:43:29.065021 24542 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 02:43:29.065026 24542 net.cpp:86] Creating Layer relu5\n",
      "I0430 02:43:29.065028 24542 net.cpp:408] relu5 <- conv5\n",
      "I0430 02:43:29.065032 24542 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 02:43:29.065037 24542 net.cpp:124] Setting up relu5\n",
      "I0430 02:43:29.065040 24542 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:43:29.065042 24542 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 02:43:29.065044 24542 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 02:43:29.065048 24542 net.cpp:86] Creating Layer pool5\n",
      "I0430 02:43:29.065052 24542 net.cpp:408] pool5 <- conv5\n",
      "I0430 02:43:29.065054 24542 net.cpp:382] pool5 -> pool5\n",
      "I0430 02:43:29.065062 24542 net.cpp:124] Setting up pool5\n",
      "I0430 02:43:29.065064 24542 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 02:43:29.065066 24542 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 02:43:29.065069 24542 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 02:43:29.065076 24542 net.cpp:86] Creating Layer fc6\n",
      "I0430 02:43:29.065078 24542 net.cpp:408] fc6 <- pool5\n",
      "I0430 02:43:29.065083 24542 net.cpp:382] fc6 -> fc6\n",
      "I0430 02:43:29.091506 24542 net.cpp:124] Setting up fc6\n",
      "I0430 02:43:29.091527 24542 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:43:29.091531 24542 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 02:43:29.091540 24542 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 02:43:29.091549 24542 net.cpp:86] Creating Layer relu6\n",
      "I0430 02:43:29.091552 24542 net.cpp:408] relu6 <- fc6\n",
      "I0430 02:43:29.091557 24542 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 02:43:29.091562 24542 net.cpp:124] Setting up relu6\n",
      "I0430 02:43:29.091565 24542 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:43:29.091567 24542 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 02:43:29.091568 24542 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 02:43:29.091572 24542 net.cpp:86] Creating Layer drop6\n",
      "I0430 02:43:29.091574 24542 net.cpp:408] drop6 <- fc6\n",
      "I0430 02:43:29.091576 24542 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 02:43:29.091583 24542 net.cpp:124] Setting up drop6\n",
      "I0430 02:43:29.091585 24542 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:43:29.091588 24542 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 02:43:29.091590 24542 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 02:43:29.091594 24542 net.cpp:86] Creating Layer fc7\n",
      "I0430 02:43:29.091596 24542 net.cpp:408] fc7 <- fc6\n",
      "I0430 02:43:29.091601 24542 net.cpp:382] fc7 -> fc7\n",
      "I0430 02:43:29.101289 24542 net.cpp:124] Setting up fc7\n",
      "I0430 02:43:29.101312 24542 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:43:29.101317 24542 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 02:43:29.101330 24542 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 02:43:29.101341 24542 net.cpp:86] Creating Layer relu7\n",
      "I0430 02:43:29.101346 24542 net.cpp:408] relu7 <- fc7\n",
      "I0430 02:43:29.101352 24542 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 02:43:29.101361 24542 net.cpp:124] Setting up relu7\n",
      "I0430 02:43:29.101364 24542 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:43:29.101366 24542 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 02:43:29.101371 24542 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 02:43:29.101377 24542 net.cpp:86] Creating Layer drop7\n",
      "I0430 02:43:29.101380 24542 net.cpp:408] drop7 <- fc7\n",
      "I0430 02:43:29.101387 24542 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 02:43:29.101393 24542 net.cpp:124] Setting up drop7\n",
      "I0430 02:43:29.101398 24542 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:43:29.101402 24542 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 02:43:29.101405 24542 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 02:43:29.101411 24542 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 02:43:29.101415 24542 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 02:43:29.101419 24542 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 02:43:29.102550 24542 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 02:43:29.102576 24542 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 02:43:29.102581 24542 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 02:43:29.102612 24542 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 02:43:29.102618 24542 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 02:43:29.102622 24542 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 02:43:29.102624 24542 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 02:43:29.102629 24542 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 02:43:29.102632 24542 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 02:43:29.102635 24542 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 02:43:29.102638 24542 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 02:43:29.102641 24542 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 02:43:29.102645 24542 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 02:43:29.102649 24542 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 02:43:29.102653 24542 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 02:43:29.102658 24542 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 02:43:29.102663 24542 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 02:43:29.102668 24542 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 02:43:29.102672 24542 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 02:43:29.102676 24542 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 02:43:29.102681 24542 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 02:43:29.102685 24542 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 02:43:29.102689 24542 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 02:43:29.102694 24542 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 02:43:29.102697 24542 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 02:43:29.102702 24542 net.cpp:202] data does not need backward computation.\n",
      "I0430 02:43:29.102706 24542 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 02:43:29.102725 24542 net.cpp:257] Network initialization done.\n",
      "I0430 02:43:29.199889 24542 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:43:29.319336 24542 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 02:43:29.320312 24542 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:43:29.320319 24542 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 02:43:29.320322 24542 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/388902.jpg'}, '/tmp/tmp_yYebW.mat')\n",
      "Processed 1806 windows in 227.477 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.034 s.\n",
      "prediction    [-1.8646, -2.02744, -1.76739, -2.15851, -1.891...\n",
      "ymin                                                        130\n",
      "xmin                                                          0\n",
      "ymax                                                        169\n",
      "xmax                                                         75\n",
      "Name: /home/ambika/INF_project/data/bird/388902.jpg, dtype: object\n",
      "prediction    [-1.73174, -2.05291, -1.62797, -1.88669, -1.56...\n",
      "ymin                                                        120\n",
      "xmin                                                          0\n",
      "ymax                                                        170\n",
      "xmax                                                         75\n",
      "Name: /home/ambika/INF_project/data/bird/388902.jpg, dtype: object\n",
      "goldfish\n",
      "0\t130\t75\t169\n",
      "bird\n",
      "0\t120\t75\t170\n",
      "388902\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 02:47:18.386351 24687 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 02:47:18.386368 24687 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 02:47:18.386373 24687 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 02:47:18.387470 24687 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 02:47:18.387574 24687 layer_factory.hpp:77] Creating layer data\n",
      "I0430 02:47:18.387581 24687 net.cpp:86] Creating Layer data\n",
      "I0430 02:47:18.387586 24687 net.cpp:382] data -> data\n",
      "I0430 02:47:18.387600 24687 net.cpp:124] Setting up data\n",
      "I0430 02:47:18.387606 24687 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 02:47:18.387609 24687 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 02:47:18.387614 24687 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 02:47:18.387620 24687 net.cpp:86] Creating Layer conv1\n",
      "I0430 02:47:18.387624 24687 net.cpp:408] conv1 <- data\n",
      "I0430 02:47:18.387629 24687 net.cpp:382] conv1 -> conv1\n",
      "I0430 02:47:18.387688 24687 net.cpp:124] Setting up conv1\n",
      "I0430 02:47:18.387693 24687 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:47:18.387697 24687 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 02:47:18.387706 24687 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 02:47:18.387711 24687 net.cpp:86] Creating Layer relu1\n",
      "I0430 02:47:18.387714 24687 net.cpp:408] relu1 <- conv1\n",
      "I0430 02:47:18.387718 24687 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 02:47:18.387723 24687 net.cpp:124] Setting up relu1\n",
      "I0430 02:47:18.387727 24687 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:47:18.387730 24687 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 02:47:18.387733 24687 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 02:47:18.387738 24687 net.cpp:86] Creating Layer pool1\n",
      "I0430 02:47:18.387742 24687 net.cpp:408] pool1 <- conv1\n",
      "I0430 02:47:18.387747 24687 net.cpp:382] pool1 -> pool1\n",
      "I0430 02:47:18.387753 24687 net.cpp:124] Setting up pool1\n",
      "I0430 02:47:18.387758 24687 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:47:18.387760 24687 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 02:47:18.387763 24687 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 02:47:18.387769 24687 net.cpp:86] Creating Layer norm1\n",
      "I0430 02:47:18.387771 24687 net.cpp:408] norm1 <- pool1\n",
      "I0430 02:47:18.387776 24687 net.cpp:382] norm1 -> norm1\n",
      "I0430 02:47:18.387783 24687 net.cpp:124] Setting up norm1\n",
      "I0430 02:47:18.387786 24687 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:47:18.387789 24687 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 02:47:18.387792 24687 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 02:47:18.387797 24687 net.cpp:86] Creating Layer conv2\n",
      "I0430 02:47:18.387800 24687 net.cpp:408] conv2 <- norm1\n",
      "I0430 02:47:18.387805 24687 net.cpp:382] conv2 -> conv2\n",
      "I0430 02:47:18.388152 24687 net.cpp:124] Setting up conv2\n",
      "I0430 02:47:18.388159 24687 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:47:18.388161 24687 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 02:47:18.388169 24687 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 02:47:18.388173 24687 net.cpp:86] Creating Layer relu2\n",
      "I0430 02:47:18.388176 24687 net.cpp:408] relu2 <- conv2\n",
      "I0430 02:47:18.388180 24687 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 02:47:18.388185 24687 net.cpp:124] Setting up relu2\n",
      "I0430 02:47:18.388190 24687 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:47:18.388192 24687 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 02:47:18.388195 24687 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 02:47:18.388200 24687 net.cpp:86] Creating Layer pool2\n",
      "I0430 02:47:18.388203 24687 net.cpp:408] pool2 <- conv2\n",
      "I0430 02:47:18.388208 24687 net.cpp:382] pool2 -> pool2\n",
      "I0430 02:47:18.388214 24687 net.cpp:124] Setting up pool2\n",
      "I0430 02:47:18.388219 24687 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:47:18.388221 24687 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 02:47:18.388224 24687 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 02:47:18.388231 24687 net.cpp:86] Creating Layer norm2\n",
      "I0430 02:47:18.388232 24687 net.cpp:408] norm2 <- pool2\n",
      "I0430 02:47:18.388237 24687 net.cpp:382] norm2 -> norm2\n",
      "I0430 02:47:18.388243 24687 net.cpp:124] Setting up norm2\n",
      "I0430 02:47:18.388247 24687 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:47:18.388249 24687 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 02:47:18.388253 24687 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 02:47:18.388259 24687 net.cpp:86] Creating Layer conv3\n",
      "I0430 02:47:18.388262 24687 net.cpp:408] conv3 <- norm2\n",
      "I0430 02:47:18.388267 24687 net.cpp:382] conv3 -> conv3\n",
      "I0430 02:47:18.388948 24687 net.cpp:124] Setting up conv3\n",
      "I0430 02:47:18.388957 24687 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:47:18.388960 24687 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 02:47:18.388967 24687 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 02:47:18.388973 24687 net.cpp:86] Creating Layer relu3\n",
      "I0430 02:47:18.388977 24687 net.cpp:408] relu3 <- conv3\n",
      "I0430 02:47:18.388980 24687 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 02:47:18.388985 24687 net.cpp:124] Setting up relu3\n",
      "I0430 02:47:18.388989 24687 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:47:18.388993 24687 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 02:47:18.388995 24687 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 02:47:18.389003 24687 net.cpp:86] Creating Layer conv4\n",
      "I0430 02:47:18.389005 24687 net.cpp:408] conv4 <- conv3\n",
      "I0430 02:47:18.389011 24687 net.cpp:382] conv4 -> conv4\n",
      "I0430 02:47:18.389726 24687 net.cpp:124] Setting up conv4\n",
      "I0430 02:47:18.389737 24687 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:47:18.389740 24687 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 02:47:18.389746 24687 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 02:47:18.389751 24687 net.cpp:86] Creating Layer relu4\n",
      "I0430 02:47:18.389756 24687 net.cpp:408] relu4 <- conv4\n",
      "I0430 02:47:18.389770 24687 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 02:47:18.389776 24687 net.cpp:124] Setting up relu4\n",
      "I0430 02:47:18.389780 24687 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:47:18.389783 24687 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 02:47:18.389787 24687 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 02:47:18.389792 24687 net.cpp:86] Creating Layer conv5\n",
      "I0430 02:47:18.389796 24687 net.cpp:408] conv5 <- conv4\n",
      "I0430 02:47:18.389801 24687 net.cpp:382] conv5 -> conv5\n",
      "I0430 02:47:18.390420 24687 net.cpp:124] Setting up conv5\n",
      "I0430 02:47:18.390435 24687 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:47:18.390439 24687 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 02:47:18.390451 24687 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 02:47:18.390460 24687 net.cpp:86] Creating Layer relu5\n",
      "I0430 02:47:18.390463 24687 net.cpp:408] relu5 <- conv5\n",
      "I0430 02:47:18.390470 24687 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 02:47:18.390476 24687 net.cpp:124] Setting up relu5\n",
      "I0430 02:47:18.390482 24687 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:47:18.390485 24687 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 02:47:18.390491 24687 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 02:47:18.390498 24687 net.cpp:86] Creating Layer pool5\n",
      "I0430 02:47:18.390502 24687 net.cpp:408] pool5 <- conv5\n",
      "I0430 02:47:18.390507 24687 net.cpp:382] pool5 -> pool5\n",
      "I0430 02:47:18.390516 24687 net.cpp:124] Setting up pool5\n",
      "I0430 02:47:18.390522 24687 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 02:47:18.390524 24687 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 02:47:18.390528 24687 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 02:47:18.390537 24687 net.cpp:86] Creating Layer fc6\n",
      "I0430 02:47:18.390542 24687 net.cpp:408] fc6 <- pool5\n",
      "I0430 02:47:18.390547 24687 net.cpp:382] fc6 -> fc6\n",
      "I0430 02:47:18.413810 24687 net.cpp:124] Setting up fc6\n",
      "I0430 02:47:18.413844 24687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:47:18.413861 24687 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 02:47:18.413874 24687 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 02:47:18.413887 24687 net.cpp:86] Creating Layer relu6\n",
      "I0430 02:47:18.413892 24687 net.cpp:408] relu6 <- fc6\n",
      "I0430 02:47:18.413900 24687 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 02:47:18.413909 24687 net.cpp:124] Setting up relu6\n",
      "I0430 02:47:18.413913 24687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:47:18.413915 24687 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 02:47:18.413920 24687 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 02:47:18.413929 24687 net.cpp:86] Creating Layer drop6\n",
      "I0430 02:47:18.413933 24687 net.cpp:408] drop6 <- fc6\n",
      "I0430 02:47:18.413938 24687 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 02:47:18.413944 24687 net.cpp:124] Setting up drop6\n",
      "I0430 02:47:18.413947 24687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:47:18.413950 24687 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 02:47:18.413954 24687 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 02:47:18.413959 24687 net.cpp:86] Creating Layer fc7\n",
      "I0430 02:47:18.413962 24687 net.cpp:408] fc7 <- fc6\n",
      "I0430 02:47:18.413967 24687 net.cpp:382] fc7 -> fc7\n",
      "I0430 02:47:18.427178 24687 net.cpp:124] Setting up fc7\n",
      "I0430 02:47:18.427218 24687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:47:18.427222 24687 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 02:47:18.427232 24687 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 02:47:18.427242 24687 net.cpp:86] Creating Layer relu7\n",
      "I0430 02:47:18.427245 24687 net.cpp:408] relu7 <- fc7\n",
      "I0430 02:47:18.427254 24687 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 02:47:18.427263 24687 net.cpp:124] Setting up relu7\n",
      "I0430 02:47:18.427268 24687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:47:18.427271 24687 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 02:47:18.427274 24687 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 02:47:18.427281 24687 net.cpp:86] Creating Layer drop7\n",
      "I0430 02:47:18.427285 24687 net.cpp:408] drop7 <- fc7\n",
      "I0430 02:47:18.427290 24687 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 02:47:18.427296 24687 net.cpp:124] Setting up drop7\n",
      "I0430 02:47:18.427301 24687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:47:18.427304 24687 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 02:47:18.427309 24687 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 02:47:18.427315 24687 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 02:47:18.427320 24687 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 02:47:18.427325 24687 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 02:47:18.428176 24687 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 02:47:18.428189 24687 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 02:47:18.428191 24687 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 02:47:18.428200 24687 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 02:47:18.428205 24687 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 02:47:18.428208 24687 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 02:47:18.428212 24687 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 02:47:18.428216 24687 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 02:47:18.428220 24687 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 02:47:18.428225 24687 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 02:47:18.428228 24687 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 02:47:18.428232 24687 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 02:47:18.428236 24687 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 02:47:18.428239 24687 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 02:47:18.428243 24687 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 02:47:18.428247 24687 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 02:47:18.428251 24687 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 02:47:18.428256 24687 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 02:47:18.428261 24687 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 02:47:18.428267 24687 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 02:47:18.428270 24687 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 02:47:18.428275 24687 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 02:47:18.428279 24687 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 02:47:18.428283 24687 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 02:47:18.428287 24687 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 02:47:18.428292 24687 net.cpp:202] data does not need backward computation.\n",
      "I0430 02:47:18.428294 24687 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 02:47:18.428309 24687 net.cpp:257] Network initialization done.\n",
      "I0430 02:47:18.532208 24687 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:47:18.647013 24687 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 02:47:18.647925 24687 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:47:18.647931 24687 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 02:47:18.647933 24687 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/171298.jpg'}, '/tmp/tmpWxUVwH.mat')\n",
      "Processed 3090 windows in 388.926 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.065 s.\n",
      "prediction    [-1.99055, -2.18222, -2.19645, -2.08208, -2.09...\n",
      "ymin                                                        112\n",
      "xmin                                                          0\n",
      "ymax                                                        337\n",
      "xmax                                                        129\n",
      "Name: /home/ambika/INF_project/data/bus/171298.jpg, dtype: object\n",
      "prediction    [-2.2386, -2.01786, -2.19259, -2.12618, -2.904...\n",
      "ymin                                                        151\n",
      "xmin                                                          0\n",
      "ymax                                                        270\n",
      "xmax                                                         40\n",
      "Name: /home/ambika/INF_project/data/bus/171298.jpg, dtype: object\n",
      "bus\n",
      "0\t112\t129\t337\n",
      "coffee maker\n",
      "0\t151\t40\t270\n",
      "171298\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 02:53:49.767688 24934 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 02:53:49.767705 24934 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 02:53:49.767710 24934 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 02:53:49.769462 24934 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 02:53:49.769621 24934 layer_factory.hpp:77] Creating layer data\n",
      "I0430 02:53:49.769637 24934 net.cpp:86] Creating Layer data\n",
      "I0430 02:53:49.769642 24934 net.cpp:382] data -> data\n",
      "I0430 02:53:49.769659 24934 net.cpp:124] Setting up data\n",
      "I0430 02:53:49.769665 24934 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 02:53:49.769668 24934 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 02:53:49.769673 24934 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 02:53:49.769680 24934 net.cpp:86] Creating Layer conv1\n",
      "I0430 02:53:49.769685 24934 net.cpp:408] conv1 <- data\n",
      "I0430 02:53:49.769690 24934 net.cpp:382] conv1 -> conv1\n",
      "I0430 02:53:49.769778 24934 net.cpp:124] Setting up conv1\n",
      "I0430 02:53:49.769784 24934 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:53:49.769788 24934 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 02:53:49.769795 24934 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 02:53:49.769801 24934 net.cpp:86] Creating Layer relu1\n",
      "I0430 02:53:49.769804 24934 net.cpp:408] relu1 <- conv1\n",
      "I0430 02:53:49.769809 24934 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 02:53:49.769814 24934 net.cpp:124] Setting up relu1\n",
      "I0430 02:53:49.769817 24934 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:53:49.769819 24934 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 02:53:49.769822 24934 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 02:53:49.769826 24934 net.cpp:86] Creating Layer pool1\n",
      "I0430 02:53:49.769829 24934 net.cpp:408] pool1 <- conv1\n",
      "I0430 02:53:49.769834 24934 net.cpp:382] pool1 -> pool1\n",
      "I0430 02:53:49.769840 24934 net.cpp:124] Setting up pool1\n",
      "I0430 02:53:49.769845 24934 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:53:49.769846 24934 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 02:53:49.769850 24934 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 02:53:49.769855 24934 net.cpp:86] Creating Layer norm1\n",
      "I0430 02:53:49.769857 24934 net.cpp:408] norm1 <- pool1\n",
      "I0430 02:53:49.769861 24934 net.cpp:382] norm1 -> norm1\n",
      "I0430 02:53:49.769866 24934 net.cpp:124] Setting up norm1\n",
      "I0430 02:53:49.769870 24934 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:53:49.769872 24934 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 02:53:49.769876 24934 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 02:53:49.769881 24934 net.cpp:86] Creating Layer conv2\n",
      "I0430 02:53:49.769882 24934 net.cpp:408] conv2 <- norm1\n",
      "I0430 02:53:49.769886 24934 net.cpp:382] conv2 -> conv2\n",
      "I0430 02:53:49.770332 24934 net.cpp:124] Setting up conv2\n",
      "I0430 02:53:49.770340 24934 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:53:49.770344 24934 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 02:53:49.770354 24934 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 02:53:49.770360 24934 net.cpp:86] Creating Layer relu2\n",
      "I0430 02:53:49.770364 24934 net.cpp:408] relu2 <- conv2\n",
      "I0430 02:53:49.770367 24934 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 02:53:49.770372 24934 net.cpp:124] Setting up relu2\n",
      "I0430 02:53:49.770376 24934 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:53:49.770380 24934 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 02:53:49.770381 24934 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 02:53:49.770385 24934 net.cpp:86] Creating Layer pool2\n",
      "I0430 02:53:49.770388 24934 net.cpp:408] pool2 <- conv2\n",
      "I0430 02:53:49.770391 24934 net.cpp:382] pool2 -> pool2\n",
      "I0430 02:53:49.770397 24934 net.cpp:124] Setting up pool2\n",
      "I0430 02:53:49.770401 24934 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:53:49.770404 24934 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 02:53:49.770406 24934 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 02:53:49.770411 24934 net.cpp:86] Creating Layer norm2\n",
      "I0430 02:53:49.770413 24934 net.cpp:408] norm2 <- pool2\n",
      "I0430 02:53:49.770417 24934 net.cpp:382] norm2 -> norm2\n",
      "I0430 02:53:49.770422 24934 net.cpp:124] Setting up norm2\n",
      "I0430 02:53:49.770426 24934 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:53:49.770429 24934 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 02:53:49.770431 24934 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 02:53:49.770438 24934 net.cpp:86] Creating Layer conv3\n",
      "I0430 02:53:49.770440 24934 net.cpp:408] conv3 <- norm2\n",
      "I0430 02:53:49.770444 24934 net.cpp:382] conv3 -> conv3\n",
      "I0430 02:53:49.771545 24934 net.cpp:124] Setting up conv3\n",
      "I0430 02:53:49.771558 24934 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:53:49.771561 24934 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 02:53:49.771571 24934 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 02:53:49.771580 24934 net.cpp:86] Creating Layer relu3\n",
      "I0430 02:53:49.771585 24934 net.cpp:408] relu3 <- conv3\n",
      "I0430 02:53:49.771590 24934 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 02:53:49.771595 24934 net.cpp:124] Setting up relu3\n",
      "I0430 02:53:49.771600 24934 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:53:49.771601 24934 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 02:53:49.771605 24934 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 02:53:49.771610 24934 net.cpp:86] Creating Layer conv4\n",
      "I0430 02:53:49.771612 24934 net.cpp:408] conv4 <- conv3\n",
      "I0430 02:53:49.771616 24934 net.cpp:382] conv4 -> conv4\n",
      "I0430 02:53:49.772222 24934 net.cpp:124] Setting up conv4\n",
      "I0430 02:53:49.772238 24934 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:53:49.772243 24934 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 02:53:49.772253 24934 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 02:53:49.772261 24934 net.cpp:86] Creating Layer relu4\n",
      "I0430 02:53:49.772265 24934 net.cpp:408] relu4 <- conv4\n",
      "I0430 02:53:49.772270 24934 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 02:53:49.772277 24934 net.cpp:124] Setting up relu4\n",
      "I0430 02:53:49.772280 24934 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:53:49.772284 24934 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 02:53:49.772286 24934 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 02:53:49.772291 24934 net.cpp:86] Creating Layer conv5\n",
      "I0430 02:53:49.772294 24934 net.cpp:408] conv5 <- conv4\n",
      "I0430 02:53:49.772297 24934 net.cpp:382] conv5 -> conv5\n",
      "I0430 02:53:49.772850 24934 net.cpp:124] Setting up conv5\n",
      "I0430 02:53:49.772858 24934 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:53:49.772862 24934 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 02:53:49.772874 24934 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 02:53:49.772881 24934 net.cpp:86] Creating Layer relu5\n",
      "I0430 02:53:49.772883 24934 net.cpp:408] relu5 <- conv5\n",
      "I0430 02:53:49.772887 24934 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 02:53:49.772892 24934 net.cpp:124] Setting up relu5\n",
      "I0430 02:53:49.772897 24934 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:53:49.772899 24934 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 02:53:49.772902 24934 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 02:53:49.772907 24934 net.cpp:86] Creating Layer pool5\n",
      "I0430 02:53:49.772908 24934 net.cpp:408] pool5 <- conv5\n",
      "I0430 02:53:49.772912 24934 net.cpp:382] pool5 -> pool5\n",
      "I0430 02:53:49.772920 24934 net.cpp:124] Setting up pool5\n",
      "I0430 02:53:49.772924 24934 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 02:53:49.772927 24934 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 02:53:49.772929 24934 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 02:53:49.772936 24934 net.cpp:86] Creating Layer fc6\n",
      "I0430 02:53:49.772939 24934 net.cpp:408] fc6 <- pool5\n",
      "I0430 02:53:49.772943 24934 net.cpp:382] fc6 -> fc6\n",
      "I0430 02:53:49.800231 24934 net.cpp:124] Setting up fc6\n",
      "I0430 02:53:49.800284 24934 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:53:49.800289 24934 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 02:53:49.800318 24934 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 02:53:49.800348 24934 net.cpp:86] Creating Layer relu6\n",
      "I0430 02:53:49.800356 24934 net.cpp:408] relu6 <- fc6\n",
      "I0430 02:53:49.800370 24934 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 02:53:49.800389 24934 net.cpp:124] Setting up relu6\n",
      "I0430 02:53:49.800395 24934 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:53:49.800400 24934 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 02:53:49.800403 24934 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 02:53:49.800415 24934 net.cpp:86] Creating Layer drop6\n",
      "I0430 02:53:49.800420 24934 net.cpp:408] drop6 <- fc6\n",
      "I0430 02:53:49.800426 24934 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 02:53:49.800436 24934 net.cpp:124] Setting up drop6\n",
      "I0430 02:53:49.800441 24934 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:53:49.800446 24934 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 02:53:49.800449 24934 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 02:53:49.800458 24934 net.cpp:86] Creating Layer fc7\n",
      "I0430 02:53:49.800462 24934 net.cpp:408] fc7 <- fc6\n",
      "I0430 02:53:49.800469 24934 net.cpp:382] fc7 -> fc7\n",
      "I0430 02:53:49.811779 24934 net.cpp:124] Setting up fc7\n",
      "I0430 02:53:49.811801 24934 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:53:49.811803 24934 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 02:53:49.811811 24934 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 02:53:49.811818 24934 net.cpp:86] Creating Layer relu7\n",
      "I0430 02:53:49.811820 24934 net.cpp:408] relu7 <- fc7\n",
      "I0430 02:53:49.811825 24934 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 02:53:49.811831 24934 net.cpp:124] Setting up relu7\n",
      "I0430 02:53:49.811846 24934 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:53:49.811849 24934 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 02:53:49.811852 24934 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 02:53:49.811857 24934 net.cpp:86] Creating Layer drop7\n",
      "I0430 02:53:49.811861 24934 net.cpp:408] drop7 <- fc7\n",
      "I0430 02:53:49.811866 24934 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 02:53:49.811873 24934 net.cpp:124] Setting up drop7\n",
      "I0430 02:53:49.811877 24934 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:53:49.811880 24934 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 02:53:49.811882 24934 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 02:53:49.811887 24934 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 02:53:49.811888 24934 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 02:53:49.811892 24934 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 02:53:49.812598 24934 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 02:53:49.812608 24934 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 02:53:49.812610 24934 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 02:53:49.812616 24934 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 02:53:49.812619 24934 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 02:53:49.812621 24934 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 02:53:49.812623 24934 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 02:53:49.812625 24934 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 02:53:49.812628 24934 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 02:53:49.812630 24934 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 02:53:49.812633 24934 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 02:53:49.812634 24934 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 02:53:49.812636 24934 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 02:53:49.812639 24934 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 02:53:49.812644 24934 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 02:53:49.812662 24934 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 02:53:49.812666 24934 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 02:53:49.812671 24934 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 02:53:49.812674 24934 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 02:53:49.812678 24934 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 02:53:49.812682 24934 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 02:53:49.812686 24934 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 02:53:49.812690 24934 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 02:53:49.812692 24934 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 02:53:49.812695 24934 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 02:53:49.812697 24934 net.cpp:202] data does not need backward computation.\n",
      "I0430 02:53:49.812701 24934 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 02:53:49.812716 24934 net.cpp:257] Network initialization done.\n",
      "I0430 02:53:50.099510 24934 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:53:50.236963 24934 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 02:53:50.237880 24934 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:53:50.237890 24934 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 02:53:50.237893 24934 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/126260.jpg'}, '/tmp/tmpJYMe93.mat')\n",
      "Processed 2443 windows in 311.222 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.036 s.\n",
      "prediction    [-1.53668, -1.76203, -2.23497, -2.24498, -2.00...\n",
      "ymin                                                        229\n",
      "xmin                                                        174\n",
      "ymax                                                        261\n",
      "xmax                                                        250\n",
      "Name: /home/ambika/INF_project/data/car/126260.jpg, dtype: object\n",
      "prediction    [-2.32986, -1.83773, -2.2718, -2.54474, -1.893...\n",
      "ymin                                                        129\n",
      "xmin                                                          0\n",
      "ymax                                                        268\n",
      "xmax                                                        268\n",
      "Name: /home/ambika/INF_project/data/car/126260.jpg, dtype: object\n",
      "car\n",
      "174\t229\t250\t261\n",
      "watercraft\n",
      "0\t129\t268\t268\n",
      "126260\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 02:59:03.048558 25143 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 02:59:03.048596 25143 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 02:59:03.048601 25143 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 02:59:03.050444 25143 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 02:59:03.050592 25143 layer_factory.hpp:77] Creating layer data\n",
      "I0430 02:59:03.050602 25143 net.cpp:86] Creating Layer data\n",
      "I0430 02:59:03.050609 25143 net.cpp:382] data -> data\n",
      "I0430 02:59:03.050626 25143 net.cpp:124] Setting up data\n",
      "I0430 02:59:03.050632 25143 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 02:59:03.050634 25143 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 02:59:03.050638 25143 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 02:59:03.050645 25143 net.cpp:86] Creating Layer conv1\n",
      "I0430 02:59:03.050647 25143 net.cpp:408] conv1 <- data\n",
      "I0430 02:59:03.050652 25143 net.cpp:382] conv1 -> conv1\n",
      "I0430 02:59:03.050724 25143 net.cpp:124] Setting up conv1\n",
      "I0430 02:59:03.050731 25143 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:59:03.050735 25143 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 02:59:03.050745 25143 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 02:59:03.050752 25143 net.cpp:86] Creating Layer relu1\n",
      "I0430 02:59:03.050756 25143 net.cpp:408] relu1 <- conv1\n",
      "I0430 02:59:03.050761 25143 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 02:59:03.050767 25143 net.cpp:124] Setting up relu1\n",
      "I0430 02:59:03.050770 25143 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 02:59:03.050772 25143 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 02:59:03.050776 25143 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 02:59:03.050779 25143 net.cpp:86] Creating Layer pool1\n",
      "I0430 02:59:03.050781 25143 net.cpp:408] pool1 <- conv1\n",
      "I0430 02:59:03.050784 25143 net.cpp:382] pool1 -> pool1\n",
      "I0430 02:59:03.050791 25143 net.cpp:124] Setting up pool1\n",
      "I0430 02:59:03.050796 25143 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:59:03.050797 25143 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 02:59:03.050799 25143 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 02:59:03.050804 25143 net.cpp:86] Creating Layer norm1\n",
      "I0430 02:59:03.050807 25143 net.cpp:408] norm1 <- pool1\n",
      "I0430 02:59:03.050810 25143 net.cpp:382] norm1 -> norm1\n",
      "I0430 02:59:03.050815 25143 net.cpp:124] Setting up norm1\n",
      "I0430 02:59:03.050819 25143 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 02:59:03.050822 25143 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 02:59:03.050823 25143 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 02:59:03.050828 25143 net.cpp:86] Creating Layer conv2\n",
      "I0430 02:59:03.050830 25143 net.cpp:408] conv2 <- norm1\n",
      "I0430 02:59:03.050833 25143 net.cpp:382] conv2 -> conv2\n",
      "I0430 02:59:03.051198 25143 net.cpp:124] Setting up conv2\n",
      "I0430 02:59:03.051213 25143 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:59:03.051223 25143 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 02:59:03.051229 25143 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 02:59:03.051234 25143 net.cpp:86] Creating Layer relu2\n",
      "I0430 02:59:03.051237 25143 net.cpp:408] relu2 <- conv2\n",
      "I0430 02:59:03.051241 25143 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 02:59:03.051245 25143 net.cpp:124] Setting up relu2\n",
      "I0430 02:59:03.051249 25143 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 02:59:03.051251 25143 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 02:59:03.051254 25143 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 02:59:03.051257 25143 net.cpp:86] Creating Layer pool2\n",
      "I0430 02:59:03.051260 25143 net.cpp:408] pool2 <- conv2\n",
      "I0430 02:59:03.051264 25143 net.cpp:382] pool2 -> pool2\n",
      "I0430 02:59:03.051270 25143 net.cpp:124] Setting up pool2\n",
      "I0430 02:59:03.051272 25143 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:59:03.051275 25143 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 02:59:03.051277 25143 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 02:59:03.051281 25143 net.cpp:86] Creating Layer norm2\n",
      "I0430 02:59:03.051283 25143 net.cpp:408] norm2 <- pool2\n",
      "I0430 02:59:03.051287 25143 net.cpp:382] norm2 -> norm2\n",
      "I0430 02:59:03.051291 25143 net.cpp:124] Setting up norm2\n",
      "I0430 02:59:03.051295 25143 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:59:03.051297 25143 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 02:59:03.051300 25143 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 02:59:03.051304 25143 net.cpp:86] Creating Layer conv3\n",
      "I0430 02:59:03.051306 25143 net.cpp:408] conv3 <- norm2\n",
      "I0430 02:59:03.051311 25143 net.cpp:382] conv3 -> conv3\n",
      "I0430 02:59:03.052021 25143 net.cpp:124] Setting up conv3\n",
      "I0430 02:59:03.052031 25143 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:59:03.052034 25143 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 02:59:03.052045 25143 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 02:59:03.052054 25143 net.cpp:86] Creating Layer relu3\n",
      "I0430 02:59:03.052058 25143 net.cpp:408] relu3 <- conv3\n",
      "I0430 02:59:03.052063 25143 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 02:59:03.052068 25143 net.cpp:124] Setting up relu3\n",
      "I0430 02:59:03.052073 25143 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:59:03.052074 25143 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 02:59:03.052076 25143 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 02:59:03.052081 25143 net.cpp:86] Creating Layer conv4\n",
      "I0430 02:59:03.052083 25143 net.cpp:408] conv4 <- conv3\n",
      "I0430 02:59:03.052088 25143 net.cpp:382] conv4 -> conv4\n",
      "I0430 02:59:03.052830 25143 net.cpp:124] Setting up conv4\n",
      "I0430 02:59:03.052841 25143 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:59:03.052845 25143 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 02:59:03.052851 25143 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 02:59:03.052860 25143 net.cpp:86] Creating Layer relu4\n",
      "I0430 02:59:03.052865 25143 net.cpp:408] relu4 <- conv4\n",
      "I0430 02:59:03.052868 25143 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 02:59:03.052873 25143 net.cpp:124] Setting up relu4\n",
      "I0430 02:59:03.052876 25143 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 02:59:03.052880 25143 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 02:59:03.052881 25143 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 02:59:03.052886 25143 net.cpp:86] Creating Layer conv5\n",
      "I0430 02:59:03.052889 25143 net.cpp:408] conv5 <- conv4\n",
      "I0430 02:59:03.052892 25143 net.cpp:382] conv5 -> conv5\n",
      "I0430 02:59:03.053411 25143 net.cpp:124] Setting up conv5\n",
      "I0430 02:59:03.053417 25143 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:59:03.053421 25143 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 02:59:03.053432 25143 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 02:59:03.053437 25143 net.cpp:86] Creating Layer relu5\n",
      "I0430 02:59:03.053441 25143 net.cpp:408] relu5 <- conv5\n",
      "I0430 02:59:03.053445 25143 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 02:59:03.053449 25143 net.cpp:124] Setting up relu5\n",
      "I0430 02:59:03.053452 25143 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 02:59:03.053455 25143 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 02:59:03.053458 25143 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 02:59:03.053462 25143 net.cpp:86] Creating Layer pool5\n",
      "I0430 02:59:03.053465 25143 net.cpp:408] pool5 <- conv5\n",
      "I0430 02:59:03.053468 25143 net.cpp:382] pool5 -> pool5\n",
      "I0430 02:59:03.053477 25143 net.cpp:124] Setting up pool5\n",
      "I0430 02:59:03.053479 25143 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 02:59:03.053481 25143 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 02:59:03.053484 25143 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 02:59:03.053493 25143 net.cpp:86] Creating Layer fc6\n",
      "I0430 02:59:03.053496 25143 net.cpp:408] fc6 <- pool5\n",
      "I0430 02:59:03.053499 25143 net.cpp:382] fc6 -> fc6\n",
      "I0430 02:59:03.074633 25143 net.cpp:124] Setting up fc6\n",
      "I0430 02:59:03.074652 25143 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:59:03.074654 25143 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 02:59:03.074661 25143 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 02:59:03.074668 25143 net.cpp:86] Creating Layer relu6\n",
      "I0430 02:59:03.074671 25143 net.cpp:408] relu6 <- fc6\n",
      "I0430 02:59:03.074678 25143 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 02:59:03.074687 25143 net.cpp:124] Setting up relu6\n",
      "I0430 02:59:03.074692 25143 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:59:03.074693 25143 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 02:59:03.074697 25143 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 02:59:03.074702 25143 net.cpp:86] Creating Layer drop6\n",
      "I0430 02:59:03.074707 25143 net.cpp:408] drop6 <- fc6\n",
      "I0430 02:59:03.074709 25143 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 02:59:03.074715 25143 net.cpp:124] Setting up drop6\n",
      "I0430 02:59:03.074720 25143 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:59:03.074723 25143 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 02:59:03.074725 25143 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 02:59:03.074729 25143 net.cpp:86] Creating Layer fc7\n",
      "I0430 02:59:03.074733 25143 net.cpp:408] fc7 <- fc6\n",
      "I0430 02:59:03.074738 25143 net.cpp:382] fc7 -> fc7\n",
      "I0430 02:59:03.084888 25143 net.cpp:124] Setting up fc7\n",
      "I0430 02:59:03.084910 25143 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:59:03.084914 25143 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 02:59:03.084924 25143 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 02:59:03.084934 25143 net.cpp:86] Creating Layer relu7\n",
      "I0430 02:59:03.084939 25143 net.cpp:408] relu7 <- fc7\n",
      "I0430 02:59:03.084945 25143 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 02:59:03.084954 25143 net.cpp:124] Setting up relu7\n",
      "I0430 02:59:03.084959 25143 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:59:03.084961 25143 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 02:59:03.084964 25143 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 02:59:03.084969 25143 net.cpp:86] Creating Layer drop7\n",
      "I0430 02:59:03.084970 25143 net.cpp:408] drop7 <- fc7\n",
      "I0430 02:59:03.084974 25143 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 02:59:03.084978 25143 net.cpp:124] Setting up drop7\n",
      "I0430 02:59:03.084980 25143 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 02:59:03.084982 25143 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 02:59:03.084985 25143 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 02:59:03.084988 25143 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 02:59:03.084991 25143 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 02:59:03.084995 25143 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 02:59:03.085654 25143 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 02:59:03.085664 25143 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 02:59:03.085669 25143 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 02:59:03.085677 25143 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 02:59:03.085682 25143 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 02:59:03.085686 25143 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 02:59:03.085690 25143 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 02:59:03.085695 25143 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 02:59:03.085700 25143 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 02:59:03.085702 25143 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 02:59:03.085705 25143 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 02:59:03.085707 25143 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 02:59:03.085711 25143 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 02:59:03.085713 25143 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 02:59:03.085716 25143 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 02:59:03.085718 25143 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 02:59:03.085721 25143 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 02:59:03.085724 25143 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 02:59:03.085727 25143 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 02:59:03.085729 25143 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 02:59:03.085732 25143 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 02:59:03.085736 25143 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 02:59:03.085737 25143 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 02:59:03.085741 25143 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 02:59:03.085743 25143 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 02:59:03.085746 25143 net.cpp:202] data does not need backward computation.\n",
      "I0430 02:59:03.085747 25143 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 02:59:03.085757 25143 net.cpp:257] Network initialization done.\n",
      "I0430 02:59:03.190734 25143 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:59:03.306653 25143 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 02:59:03.307641 25143 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 02:59:03.307649 25143 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 02:59:03.307652 25143 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/223626.jpg'}, '/tmp/tmpiePJBe.mat')\n",
      "Processed 1936 windows in 260.099 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.038 s.\n",
      "prediction    [-2.08671, -1.95696, -1.75984, -2.27725, -2.12...\n",
      "ymin                                                    234.192\n",
      "xmin                                                    108.896\n",
      "ymax                                                     420.84\n",
      "xmax                                                    231.912\n",
      "Name: /home/ambika/INF_project/data/cat/223626.jpg, dtype: object\n",
      "prediction    [-2.30889, -2.32541, -1.83162, -2.04258, -2.29...\n",
      "ymin                                                    227.632\n",
      "xmin                                                      131.2\n",
      "ymax                                                    386.072\n",
      "xmax                                                    231.912\n",
      "Name: /home/ambika/INF_project/data/cat/223626.jpg, dtype: object\n",
      "domestic cat\n",
      "108.896\t234.192\t231.912\t420.84\n",
      "dog\n",
      "131.2\t227.632\t231.912\t386.072\n",
      "223626\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:03:25.072366 25328 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:03:25.072386 25328 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:03:25.072388 25328 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:03:25.073472 25328 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:03:25.073541 25328 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:03:25.073547 25328 net.cpp:86] Creating Layer data\n",
      "I0430 03:03:25.073554 25328 net.cpp:382] data -> data\n",
      "I0430 03:03:25.073570 25328 net.cpp:124] Setting up data\n",
      "I0430 03:03:25.073575 25328 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:03:25.073577 25328 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:03:25.073580 25328 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:03:25.073586 25328 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:03:25.073588 25328 net.cpp:408] conv1 <- data\n",
      "I0430 03:03:25.073592 25328 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:03:25.073650 25328 net.cpp:124] Setting up conv1\n",
      "I0430 03:03:25.073654 25328 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:03:25.073657 25328 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:03:25.073664 25328 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:03:25.073668 25328 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:03:25.073671 25328 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:03:25.073674 25328 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:03:25.073678 25328 net.cpp:124] Setting up relu1\n",
      "I0430 03:03:25.073683 25328 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:03:25.073684 25328 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:03:25.073686 25328 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:03:25.073690 25328 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:03:25.073693 25328 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:03:25.073696 25328 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:03:25.073703 25328 net.cpp:124] Setting up pool1\n",
      "I0430 03:03:25.073705 25328 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:03:25.073709 25328 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:03:25.073710 25328 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:03:25.073714 25328 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:03:25.073717 25328 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:03:25.073720 25328 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:03:25.073725 25328 net.cpp:124] Setting up norm1\n",
      "I0430 03:03:25.073729 25328 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:03:25.073730 25328 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:03:25.073734 25328 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:03:25.073737 25328 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:03:25.073740 25328 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:03:25.073742 25328 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:03:25.074071 25328 net.cpp:124] Setting up conv2\n",
      "I0430 03:03:25.074077 25328 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:03:25.074079 25328 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:03:25.074085 25328 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:03:25.074090 25328 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:03:25.074091 25328 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:03:25.074095 25328 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:03:25.074098 25328 net.cpp:124] Setting up relu2\n",
      "I0430 03:03:25.074101 25328 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:03:25.074105 25328 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:03:25.074106 25328 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:03:25.074110 25328 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:03:25.074113 25328 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:03:25.074116 25328 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:03:25.074121 25328 net.cpp:124] Setting up pool2\n",
      "I0430 03:03:25.074125 25328 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:03:25.074126 25328 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:03:25.074128 25328 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:03:25.074132 25328 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:03:25.074136 25328 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:03:25.074138 25328 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:03:25.074142 25328 net.cpp:124] Setting up norm2\n",
      "I0430 03:03:25.074146 25328 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:03:25.074148 25328 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:03:25.074151 25328 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:03:25.074156 25328 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:03:25.074157 25328 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:03:25.074162 25328 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:03:25.074915 25328 net.cpp:124] Setting up conv3\n",
      "I0430 03:03:25.074930 25328 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:03:25.074934 25328 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:03:25.074961 25328 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:03:25.074970 25328 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:03:25.074973 25328 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:03:25.074978 25328 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:03:25.074985 25328 net.cpp:124] Setting up relu3\n",
      "I0430 03:03:25.074990 25328 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:03:25.074992 25328 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:03:25.074995 25328 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:03:25.075003 25328 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:03:25.075006 25328 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:03:25.075011 25328 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:03:25.075793 25328 net.cpp:124] Setting up conv4\n",
      "I0430 03:03:25.075805 25328 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:03:25.075809 25328 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:03:25.075815 25328 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:03:25.075822 25328 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:03:25.075826 25328 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:03:25.075831 25328 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:03:25.075837 25328 net.cpp:124] Setting up relu4\n",
      "I0430 03:03:25.075841 25328 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:03:25.075845 25328 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:03:25.075847 25328 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:03:25.075853 25328 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:03:25.075856 25328 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:03:25.075861 25328 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:03:25.076344 25328 net.cpp:124] Setting up conv5\n",
      "I0430 03:03:25.076350 25328 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:03:25.076354 25328 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:03:25.076362 25328 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:03:25.076367 25328 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:03:25.076370 25328 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:03:25.076375 25328 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:03:25.076380 25328 net.cpp:124] Setting up relu5\n",
      "I0430 03:03:25.076385 25328 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:03:25.076386 25328 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:03:25.076390 25328 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:03:25.076395 25328 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:03:25.076397 25328 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:03:25.076401 25328 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:03:25.076409 25328 net.cpp:124] Setting up pool5\n",
      "I0430 03:03:25.076414 25328 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:03:25.076416 25328 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:03:25.076419 25328 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:03:25.076426 25328 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:03:25.076429 25328 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:03:25.076433 25328 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:03:25.103180 25328 net.cpp:124] Setting up fc6\n",
      "I0430 03:03:25.103204 25328 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:03:25.103215 25328 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:03:25.103225 25328 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:03:25.103240 25328 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:03:25.103245 25328 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:03:25.103251 25328 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:03:25.103260 25328 net.cpp:124] Setting up relu6\n",
      "I0430 03:03:25.103265 25328 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:03:25.103268 25328 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:03:25.103271 25328 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:03:25.103277 25328 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:03:25.103281 25328 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:03:25.103286 25328 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:03:25.103294 25328 net.cpp:124] Setting up drop6\n",
      "I0430 03:03:25.103297 25328 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:03:25.103299 25328 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:03:25.103302 25328 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:03:25.103307 25328 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:03:25.103309 25328 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:03:25.103314 25328 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:03:25.112994 25328 net.cpp:124] Setting up fc7\n",
      "I0430 03:03:25.113018 25328 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:03:25.113023 25328 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:03:25.113051 25328 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:03:25.113065 25328 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:03:25.113070 25328 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:03:25.113075 25328 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:03:25.113085 25328 net.cpp:124] Setting up relu7\n",
      "I0430 03:03:25.113090 25328 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:03:25.113092 25328 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:03:25.113099 25328 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:03:25.113104 25328 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:03:25.113106 25328 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:03:25.113111 25328 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:03:25.113116 25328 net.cpp:124] Setting up drop7\n",
      "I0430 03:03:25.113118 25328 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:03:25.113121 25328 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:03:25.113123 25328 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:03:25.113127 25328 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:03:25.113129 25328 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:03:25.113133 25328 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:03:25.113768 25328 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:03:25.113776 25328 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:03:25.113780 25328 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:03:25.113785 25328 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:03:25.113786 25328 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:03:25.113788 25328 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:03:25.113790 25328 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:03:25.113793 25328 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:03:25.113795 25328 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:03:25.113797 25328 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:03:25.113801 25328 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:03:25.113803 25328 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:03:25.113806 25328 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:03:25.113808 25328 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:03:25.113811 25328 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:03:25.113813 25328 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:03:25.113816 25328 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:03:25.113819 25328 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:03:25.113822 25328 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:03:25.113824 25328 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:03:25.113827 25328 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:03:25.113831 25328 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:03:25.113832 25328 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:03:25.113836 25328 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:03:25.113837 25328 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:03:25.113840 25328 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:03:25.113842 25328 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:03:25.113853 25328 net.cpp:257] Network initialization done.\n",
      "I0430 03:03:25.207746 25328 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:03:25.323066 25328 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:03:25.323946 25328 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:03:25.323957 25328 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:03:25.323961 25328 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/422886.jpg'}, '/tmp/tmp665_WA.mat')\n",
      "Processed 2183 windows in 280.409 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.10552, -1.98084, -2.16748, -1.73291, -1.42...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                        500\n",
      "xmax                                                        395\n",
      "Name: /home/ambika/INF_project/data/couch/422886.jpg, dtype: object\n",
      "prediction    [-2.13135, -2.10033, -2.38026, -2.48058, -0.98...\n",
      "ymin                                                         22\n",
      "xmin                                                         27\n",
      "ymax                                                        229\n",
      "xmax                                                        273\n",
      "Name: /home/ambika/INF_project/data/couch/422886.jpg, dtype: object\n",
      "person\n",
      "0\t0\t395\t500\n",
      "hat with a wide brim\n",
      "27\t22\t273\t229\n",
      "422886\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:08:07.449880 25535 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:08:07.449898 25535 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:08:07.449903 25535 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:08:07.451001 25535 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:08:07.451078 25535 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:08:07.451086 25535 net.cpp:86] Creating Layer data\n",
      "I0430 03:08:07.451089 25535 net.cpp:382] data -> data\n",
      "I0430 03:08:07.451098 25535 net.cpp:124] Setting up data\n",
      "I0430 03:08:07.451103 25535 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:08:07.451107 25535 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:08:07.451109 25535 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:08:07.451114 25535 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:08:07.451117 25535 net.cpp:408] conv1 <- data\n",
      "I0430 03:08:07.451122 25535 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:08:07.451175 25535 net.cpp:124] Setting up conv1\n",
      "I0430 03:08:07.451180 25535 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:08:07.451182 25535 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:08:07.451189 25535 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:08:07.451195 25535 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:08:07.451196 25535 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:08:07.451200 25535 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:08:07.451236 25535 net.cpp:124] Setting up relu1\n",
      "I0430 03:08:07.451241 25535 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:08:07.451248 25535 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:08:07.451251 25535 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:08:07.451254 25535 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:08:07.451256 25535 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:08:07.451261 25535 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:08:07.451268 25535 net.cpp:124] Setting up pool1\n",
      "I0430 03:08:07.451272 25535 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:08:07.451273 25535 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:08:07.451277 25535 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:08:07.451280 25535 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:08:07.451282 25535 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:08:07.451287 25535 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:08:07.451292 25535 net.cpp:124] Setting up norm1\n",
      "I0430 03:08:07.451294 25535 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:08:07.451297 25535 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:08:07.451299 25535 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:08:07.451303 25535 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:08:07.451305 25535 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:08:07.451308 25535 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:08:07.451647 25535 net.cpp:124] Setting up conv2\n",
      "I0430 03:08:07.451654 25535 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:08:07.451658 25535 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:08:07.451664 25535 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:08:07.451669 25535 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:08:07.451673 25535 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:08:07.451678 25535 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:08:07.451683 25535 net.cpp:124] Setting up relu2\n",
      "I0430 03:08:07.451688 25535 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:08:07.451690 25535 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:08:07.451694 25535 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:08:07.451699 25535 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:08:07.451701 25535 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:08:07.451705 25535 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:08:07.451712 25535 net.cpp:124] Setting up pool2\n",
      "I0430 03:08:07.451716 25535 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:08:07.451720 25535 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:08:07.451723 25535 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:08:07.451731 25535 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:08:07.451735 25535 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:08:07.451740 25535 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:08:07.451746 25535 net.cpp:124] Setting up norm2\n",
      "I0430 03:08:07.451751 25535 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:08:07.451756 25535 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:08:07.451758 25535 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:08:07.451764 25535 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:08:07.451767 25535 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:08:07.451771 25535 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:08:07.452774 25535 net.cpp:124] Setting up conv3\n",
      "I0430 03:08:07.452788 25535 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:08:07.452792 25535 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:08:07.452805 25535 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:08:07.452811 25535 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:08:07.452814 25535 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:08:07.452818 25535 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:08:07.452823 25535 net.cpp:124] Setting up relu3\n",
      "I0430 03:08:07.452828 25535 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:08:07.452831 25535 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:08:07.452836 25535 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:08:07.452846 25535 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:08:07.452849 25535 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:08:07.452855 25535 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:08:07.453613 25535 net.cpp:124] Setting up conv4\n",
      "I0430 03:08:07.453624 25535 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:08:07.453627 25535 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:08:07.453632 25535 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:08:07.453637 25535 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:08:07.453642 25535 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:08:07.453645 25535 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:08:07.453651 25535 net.cpp:124] Setting up relu4\n",
      "I0430 03:08:07.453655 25535 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:08:07.453657 25535 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:08:07.453660 25535 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:08:07.453665 25535 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:08:07.453666 25535 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:08:07.453670 25535 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:08:07.454157 25535 net.cpp:124] Setting up conv5\n",
      "I0430 03:08:07.454165 25535 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:08:07.454167 25535 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:08:07.454174 25535 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:08:07.454179 25535 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:08:07.454180 25535 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:08:07.454186 25535 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:08:07.454190 25535 net.cpp:124] Setting up relu5\n",
      "I0430 03:08:07.454192 25535 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:08:07.454195 25535 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:08:07.454196 25535 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:08:07.454205 25535 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:08:07.454207 25535 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:08:07.454210 25535 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:08:07.454221 25535 net.cpp:124] Setting up pool5\n",
      "I0430 03:08:07.454224 25535 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:08:07.454226 25535 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:08:07.454227 25535 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:08:07.454234 25535 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:08:07.454236 25535 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:08:07.454239 25535 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:08:07.481765 25535 net.cpp:124] Setting up fc6\n",
      "I0430 03:08:07.481791 25535 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:08:07.481796 25535 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:08:07.481806 25535 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:08:07.481817 25535 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:08:07.481819 25535 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:08:07.481823 25535 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:08:07.481830 25535 net.cpp:124] Setting up relu6\n",
      "I0430 03:08:07.481832 25535 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:08:07.481834 25535 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:08:07.481835 25535 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:08:07.481840 25535 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:08:07.481842 25535 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:08:07.481844 25535 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:08:07.481848 25535 net.cpp:124] Setting up drop6\n",
      "I0430 03:08:07.481864 25535 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:08:07.481868 25535 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:08:07.481868 25535 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:08:07.481873 25535 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:08:07.481875 25535 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:08:07.481879 25535 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:08:07.491525 25535 net.cpp:124] Setting up fc7\n",
      "I0430 03:08:07.491545 25535 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:08:07.491549 25535 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:08:07.491556 25535 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:08:07.491565 25535 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:08:07.491567 25535 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:08:07.491571 25535 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:08:07.491576 25535 net.cpp:124] Setting up relu7\n",
      "I0430 03:08:07.491580 25535 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:08:07.491581 25535 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:08:07.491582 25535 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:08:07.491586 25535 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:08:07.491588 25535 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:08:07.491591 25535 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:08:07.491595 25535 net.cpp:124] Setting up drop7\n",
      "I0430 03:08:07.491605 25535 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:08:07.491606 25535 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:08:07.491610 25535 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:08:07.491613 25535 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:08:07.491616 25535 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:08:07.491618 25535 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:08:07.492231 25535 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:08:07.492239 25535 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:08:07.492243 25535 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:08:07.492249 25535 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:08:07.492251 25535 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:08:07.492252 25535 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:08:07.492254 25535 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:08:07.492259 25535 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:08:07.492260 25535 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:08:07.492264 25535 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:08:07.492265 25535 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:08:07.492269 25535 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:08:07.492271 25535 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:08:07.492274 25535 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:08:07.492276 25535 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:08:07.492280 25535 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:08:07.492281 25535 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:08:07.492285 25535 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:08:07.492287 25535 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:08:07.492290 25535 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:08:07.492293 25535 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:08:07.492295 25535 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:08:07.492298 25535 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:08:07.492301 25535 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:08:07.492303 25535 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:08:07.492306 25535 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:08:07.492308 25535 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:08:07.492317 25535 net.cpp:257] Network initialization done.\n",
      "I0430 03:08:07.590037 25535 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:08:07.700784 25535 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:08:07.701730 25535 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:08:07.701740 25535 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:08:07.701743 25535 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/362219.jpg'}, '/tmp/tmpa3qhgl.mat')\n",
      "Processed 2078 windows in 267.197 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-1.43686, -1.49606, -2.18629, -2.11472, -2.22...\n",
      "ymin                                                          0\n",
      "xmin                                                         86\n",
      "ymax                                                        375\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/dog/362219.jpg, dtype: object\n",
      "prediction    [-1.74361, -1.92146, -2.14973, -2.04978, -2.33...\n",
      "ymin                                                          0\n",
      "xmin                                                         71\n",
      "ymax                                                        227\n",
      "xmax                                                        425\n",
      "Name: /home/ambika/INF_project/data/dog/362219.jpg, dtype: object\n",
      "cup or mug\n",
      "86\t0\t500\t375\n",
      "bowl\n",
      "71\t0\t425\t227\n",
      "362219\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:12:36.574218 25729 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:12:36.574239 25729 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:12:36.574241 25729 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:12:36.575372 25729 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:12:36.575449 25729 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:12:36.575456 25729 net.cpp:86] Creating Layer data\n",
      "I0430 03:12:36.575459 25729 net.cpp:382] data -> data\n",
      "I0430 03:12:36.575471 25729 net.cpp:124] Setting up data\n",
      "I0430 03:12:36.575479 25729 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:12:36.575481 25729 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:12:36.575484 25729 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:12:36.575490 25729 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:12:36.575492 25729 net.cpp:408] conv1 <- data\n",
      "I0430 03:12:36.575496 25729 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:12:36.575556 25729 net.cpp:124] Setting up conv1\n",
      "I0430 03:12:36.575561 25729 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:12:36.575562 25729 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:12:36.575569 25729 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:12:36.575573 25729 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:12:36.575577 25729 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:12:36.575579 25729 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:12:36.575584 25729 net.cpp:124] Setting up relu1\n",
      "I0430 03:12:36.575587 25729 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:12:36.575589 25729 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:12:36.575592 25729 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:12:36.575595 25729 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:12:36.575598 25729 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:12:36.575601 25729 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:12:36.575606 25729 net.cpp:124] Setting up pool1\n",
      "I0430 03:12:36.575610 25729 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:12:36.575613 25729 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:12:36.575614 25729 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:12:36.575619 25729 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:12:36.575621 25729 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:12:36.575624 25729 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:12:36.575629 25729 net.cpp:124] Setting up norm1\n",
      "I0430 03:12:36.575633 25729 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:12:36.575635 25729 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:12:36.575637 25729 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:12:36.575641 25729 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:12:36.575644 25729 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:12:36.575646 25729 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:12:36.575990 25729 net.cpp:124] Setting up conv2\n",
      "I0430 03:12:36.575997 25729 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:12:36.576000 25729 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:12:36.576005 25729 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:12:36.576010 25729 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:12:36.576012 25729 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:12:36.576015 25729 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:12:36.576020 25729 net.cpp:124] Setting up relu2\n",
      "I0430 03:12:36.576022 25729 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:12:36.576025 25729 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:12:36.576027 25729 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:12:36.576031 25729 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:12:36.576033 25729 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:12:36.576036 25729 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:12:36.576041 25729 net.cpp:124] Setting up pool2\n",
      "I0430 03:12:36.576045 25729 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:12:36.576046 25729 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:12:36.576050 25729 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:12:36.576052 25729 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:12:36.576056 25729 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:12:36.576058 25729 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:12:36.576063 25729 net.cpp:124] Setting up norm2\n",
      "I0430 03:12:36.576066 25729 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:12:36.576068 25729 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:12:36.576071 25729 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:12:36.576077 25729 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:12:36.576081 25729 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:12:36.576083 25729 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:12:36.576753 25729 net.cpp:124] Setting up conv3\n",
      "I0430 03:12:36.576761 25729 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:12:36.576764 25729 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:12:36.576771 25729 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:12:36.576778 25729 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:12:36.576781 25729 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:12:36.576784 25729 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:12:36.576788 25729 net.cpp:124] Setting up relu3\n",
      "I0430 03:12:36.576792 25729 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:12:36.576794 25729 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:12:36.576797 25729 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:12:36.576800 25729 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:12:36.576802 25729 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:12:36.576807 25729 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:12:36.577569 25729 net.cpp:124] Setting up conv4\n",
      "I0430 03:12:36.577579 25729 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:12:36.577581 25729 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:12:36.577586 25729 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:12:36.577592 25729 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:12:36.577595 25729 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:12:36.577600 25729 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:12:36.577605 25729 net.cpp:124] Setting up relu4\n",
      "I0430 03:12:36.577607 25729 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:12:36.577610 25729 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:12:36.577612 25729 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:12:36.577617 25729 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:12:36.577620 25729 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:12:36.577622 25729 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:12:36.578192 25729 net.cpp:124] Setting up conv5\n",
      "I0430 03:12:36.578204 25729 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:12:36.578207 25729 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:12:36.578217 25729 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:12:36.578220 25729 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:12:36.578224 25729 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:12:36.578235 25729 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:12:36.578241 25729 net.cpp:124] Setting up relu5\n",
      "I0430 03:12:36.578245 25729 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:12:36.578248 25729 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:12:36.578253 25729 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:12:36.578258 25729 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:12:36.578260 25729 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:12:36.578265 25729 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:12:36.578274 25729 net.cpp:124] Setting up pool5\n",
      "I0430 03:12:36.578277 25729 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:12:36.578280 25729 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:12:36.578284 25729 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:12:36.578291 25729 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:12:36.578294 25729 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:12:36.578299 25729 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:12:36.603140 25729 net.cpp:124] Setting up fc6\n",
      "I0430 03:12:36.603162 25729 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:12:36.603165 25729 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:12:36.603175 25729 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:12:36.603184 25729 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:12:36.603188 25729 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:12:36.603195 25729 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:12:36.603204 25729 net.cpp:124] Setting up relu6\n",
      "I0430 03:12:36.603212 25729 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:12:36.603215 25729 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:12:36.603219 25729 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:12:36.603224 25729 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:12:36.603227 25729 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:12:36.603231 25729 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:12:36.603237 25729 net.cpp:124] Setting up drop6\n",
      "I0430 03:12:36.603241 25729 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:12:36.603243 25729 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:12:36.603246 25729 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:12:36.603255 25729 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:12:36.603258 25729 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:12:36.603266 25729 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:12:36.613333 25729 net.cpp:124] Setting up fc7\n",
      "I0430 03:12:36.613363 25729 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:12:36.613369 25729 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:12:36.613402 25729 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:12:36.613420 25729 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:12:36.613423 25729 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:12:36.613430 25729 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:12:36.613440 25729 net.cpp:124] Setting up relu7\n",
      "I0430 03:12:36.613445 25729 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:12:36.613447 25729 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:12:36.613451 25729 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:12:36.613456 25729 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:12:36.613459 25729 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:12:36.613466 25729 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:12:36.613471 25729 net.cpp:124] Setting up drop7\n",
      "I0430 03:12:36.613474 25729 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:12:36.613477 25729 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:12:36.613479 25729 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:12:36.613483 25729 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:12:36.613486 25729 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:12:36.613489 25729 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:12:36.614420 25729 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:12:36.614434 25729 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:12:36.614439 25729 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:12:36.614447 25729 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:12:36.614452 25729 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:12:36.614455 25729 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:12:36.614459 25729 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:12:36.614464 25729 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:12:36.614466 25729 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:12:36.614471 25729 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:12:36.614475 25729 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:12:36.614477 25729 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:12:36.614480 25729 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:12:36.614482 25729 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:12:36.614485 25729 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:12:36.614488 25729 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:12:36.614490 25729 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:12:36.614493 25729 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:12:36.614496 25729 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:12:36.614500 25729 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:12:36.614501 25729 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:12:36.614504 25729 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:12:36.614507 25729 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:12:36.614509 25729 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:12:36.614512 25729 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:12:36.614514 25729 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:12:36.614517 25729 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:12:36.614526 25729 net.cpp:257] Network initialization done.\n",
      "I0430 03:12:36.706475 25729 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:12:36.825809 25729 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:12:36.826802 25729 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:12:36.826812 25729 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:12:36.826814 25729 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/26201.jpg'}, '/tmp/tmpo2Lt8L.mat')\n",
      "Processed 2168 windows in 270.634 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-1.79035, -2.70556, -2.00262, -2.16305, -1.90...\n",
      "ymin                                                        268\n",
      "xmin                                                         78\n",
      "ymax                                                        326\n",
      "xmax                                                        158\n",
      "Name: /home/ambika/INF_project/data/horse/26201.jpg, dtype: object\n",
      "prediction    [-1.79035, -2.70556, -2.00262, -2.16305, -1.90...\n",
      "ymin                                                        268\n",
      "xmin                                                         78\n",
      "ymax                                                        326\n",
      "xmax                                                        158\n",
      "Name: /home/ambika/INF_project/data/horse/26201.jpg, dtype: object\n",
      "bicycle\n",
      "78\t268\t158\t326\n",
      "motorcycle\n",
      "78\t268\t158\t326\n",
      "26201\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:17:09.067502 25911 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:17:09.067518 25911 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:17:09.067522 25911 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:17:09.068722 25911 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:17:09.068847 25911 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:17:09.068855 25911 net.cpp:86] Creating Layer data\n",
      "I0430 03:17:09.068858 25911 net.cpp:382] data -> data\n",
      "I0430 03:17:09.068867 25911 net.cpp:124] Setting up data\n",
      "I0430 03:17:09.068872 25911 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:17:09.068876 25911 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:17:09.068877 25911 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:17:09.068884 25911 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:17:09.068886 25911 net.cpp:408] conv1 <- data\n",
      "I0430 03:17:09.068891 25911 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:17:09.068948 25911 net.cpp:124] Setting up conv1\n",
      "I0430 03:17:09.068953 25911 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:17:09.068955 25911 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:17:09.068964 25911 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:17:09.068967 25911 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:17:09.068970 25911 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:17:09.068974 25911 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:17:09.068977 25911 net.cpp:124] Setting up relu1\n",
      "I0430 03:17:09.068981 25911 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:17:09.068984 25911 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:17:09.068985 25911 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:17:09.068989 25911 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:17:09.068991 25911 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:17:09.068994 25911 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:17:09.069001 25911 net.cpp:124] Setting up pool1\n",
      "I0430 03:17:09.069005 25911 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:17:09.069007 25911 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:17:09.069010 25911 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:17:09.069013 25911 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:17:09.069015 25911 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:17:09.069020 25911 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:17:09.069023 25911 net.cpp:124] Setting up norm1\n",
      "I0430 03:17:09.069027 25911 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:17:09.069030 25911 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:17:09.069031 25911 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:17:09.069036 25911 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:17:09.069038 25911 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:17:09.069041 25911 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:17:09.069396 25911 net.cpp:124] Setting up conv2\n",
      "I0430 03:17:09.069401 25911 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:17:09.069404 25911 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:17:09.069409 25911 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:17:09.069412 25911 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:17:09.069416 25911 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:17:09.069418 25911 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:17:09.069422 25911 net.cpp:124] Setting up relu2\n",
      "I0430 03:17:09.069425 25911 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:17:09.069427 25911 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:17:09.069430 25911 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:17:09.069433 25911 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:17:09.069435 25911 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:17:09.069438 25911 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:17:09.069443 25911 net.cpp:124] Setting up pool2\n",
      "I0430 03:17:09.069447 25911 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:17:09.069449 25911 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:17:09.069452 25911 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:17:09.069456 25911 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:17:09.069458 25911 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:17:09.069463 25911 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:17:09.069466 25911 net.cpp:124] Setting up norm2\n",
      "I0430 03:17:09.069469 25911 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:17:09.069471 25911 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:17:09.069474 25911 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:17:09.069479 25911 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:17:09.069483 25911 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:17:09.069485 25911 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:17:09.070168 25911 net.cpp:124] Setting up conv3\n",
      "I0430 03:17:09.070175 25911 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:17:09.070178 25911 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:17:09.070183 25911 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:17:09.070188 25911 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:17:09.070191 25911 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:17:09.070194 25911 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:17:09.070199 25911 net.cpp:124] Setting up relu3\n",
      "I0430 03:17:09.070202 25911 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:17:09.070204 25911 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:17:09.070206 25911 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:17:09.070211 25911 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:17:09.070214 25911 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:17:09.070217 25911 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:17:09.070943 25911 net.cpp:124] Setting up conv4\n",
      "I0430 03:17:09.070952 25911 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:17:09.070955 25911 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:17:09.070960 25911 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:17:09.070963 25911 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:17:09.070966 25911 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:17:09.070969 25911 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:17:09.070973 25911 net.cpp:124] Setting up relu4\n",
      "I0430 03:17:09.070976 25911 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:17:09.070979 25911 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:17:09.070981 25911 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:17:09.070986 25911 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:17:09.070988 25911 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:17:09.070992 25911 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:17:09.071492 25911 net.cpp:124] Setting up conv5\n",
      "I0430 03:17:09.071499 25911 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:17:09.071501 25911 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:17:09.071509 25911 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:17:09.071513 25911 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:17:09.071516 25911 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:17:09.071521 25911 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:17:09.071524 25911 net.cpp:124] Setting up relu5\n",
      "I0430 03:17:09.071527 25911 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:17:09.071529 25911 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:17:09.071532 25911 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:17:09.071537 25911 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:17:09.071538 25911 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:17:09.071542 25911 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:17:09.071548 25911 net.cpp:124] Setting up pool5\n",
      "I0430 03:17:09.071552 25911 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:17:09.071553 25911 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:17:09.071557 25911 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:17:09.071563 25911 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:17:09.071565 25911 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:17:09.071568 25911 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:17:09.094403 25911 net.cpp:124] Setting up fc6\n",
      "I0430 03:17:09.094437 25911 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:17:09.094442 25911 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:17:09.094455 25911 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:17:09.094471 25911 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:17:09.094476 25911 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:17:09.094485 25911 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:17:09.094496 25911 net.cpp:124] Setting up relu6\n",
      "I0430 03:17:09.094501 25911 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:17:09.094502 25911 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:17:09.094506 25911 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:17:09.094513 25911 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:17:09.094518 25911 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:17:09.094522 25911 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:17:09.094530 25911 net.cpp:124] Setting up drop6\n",
      "I0430 03:17:09.094534 25911 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:17:09.094537 25911 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:17:09.094542 25911 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:17:09.094548 25911 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:17:09.094553 25911 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:17:09.094561 25911 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:17:09.106200 25911 net.cpp:124] Setting up fc7\n",
      "I0430 03:17:09.106228 25911 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:17:09.106231 25911 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:17:09.106241 25911 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:17:09.106250 25911 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:17:09.106256 25911 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:17:09.106266 25911 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:17:09.106276 25911 net.cpp:124] Setting up relu7\n",
      "I0430 03:17:09.106281 25911 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:17:09.106283 25911 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:17:09.106287 25911 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:17:09.106292 25911 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:17:09.106293 25911 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:17:09.106297 25911 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:17:09.106302 25911 net.cpp:124] Setting up drop7\n",
      "I0430 03:17:09.106303 25911 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:17:09.106305 25911 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:17:09.106307 25911 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:17:09.106310 25911 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:17:09.106312 25911 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:17:09.106324 25911 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:17:09.106971 25911 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:17:09.106977 25911 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:17:09.106979 25911 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:17:09.106984 25911 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:17:09.106986 25911 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:17:09.106988 25911 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:17:09.106992 25911 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:17:09.106994 25911 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:17:09.106997 25911 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:17:09.106999 25911 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:17:09.107002 25911 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:17:09.107005 25911 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:17:09.107008 25911 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:17:09.107012 25911 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:17:09.107014 25911 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:17:09.107017 25911 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:17:09.107019 25911 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:17:09.107023 25911 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:17:09.107025 25911 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:17:09.107028 25911 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:17:09.107031 25911 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:17:09.107034 25911 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:17:09.107038 25911 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:17:09.107041 25911 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:17:09.107044 25911 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:17:09.107048 25911 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:17:09.107051 25911 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:17:09.107064 25911 net.cpp:257] Network initialization done.\n",
      "I0430 03:17:09.196547 25911 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:17:09.310874 25911 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:17:09.311851 25911 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:17:09.311861 25911 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:17:09.311862 25911 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/561314.jpg'}, '/tmp/tmpCTVrrC.mat')\n",
      "Processed 1379 windows in 175.210 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.039 s.\n",
      "prediction    [-2.4364, -1.634, -2.30832, -2.4756, -1.99368,...\n",
      "ymin                                                         12\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        353\n",
      "Name: /home/ambika/INF_project/data/person/561314.jpg, dtype: object\n",
      "prediction    [-2.31556, -1.53752, -2.2952, -2.49187, -1.951...\n",
      "ymin                                                         14\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        353\n",
      "Name: /home/ambika/INF_project/data/person/561314.jpg, dtype: object\n",
      "bench\n",
      "0\t12\t353\t375\n",
      "tv or monitor\n",
      "0\t14\t353\t375\n",
      "561314\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:20:06.246587 26073 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:20:06.246615 26073 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:20:06.246618 26073 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:20:06.248081 26073 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:20:06.248195 26073 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:20:06.248203 26073 net.cpp:86] Creating Layer data\n",
      "I0430 03:20:06.248208 26073 net.cpp:382] data -> data\n",
      "I0430 03:20:06.248219 26073 net.cpp:124] Setting up data\n",
      "I0430 03:20:06.248224 26073 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:20:06.248226 26073 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:20:06.248230 26073 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:20:06.248236 26073 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:20:06.248239 26073 net.cpp:408] conv1 <- data\n",
      "I0430 03:20:06.248245 26073 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:20:06.248307 26073 net.cpp:124] Setting up conv1\n",
      "I0430 03:20:06.248312 26073 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:20:06.248314 26073 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:20:06.248322 26073 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:20:06.248327 26073 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:20:06.248330 26073 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:20:06.248335 26073 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:20:06.248339 26073 net.cpp:124] Setting up relu1\n",
      "I0430 03:20:06.248342 26073 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:20:06.248344 26073 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:20:06.248347 26073 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:20:06.248349 26073 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:20:06.248352 26073 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:20:06.248354 26073 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:20:06.248361 26073 net.cpp:124] Setting up pool1\n",
      "I0430 03:20:06.248364 26073 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:20:06.248366 26073 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:20:06.248368 26073 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:20:06.248371 26073 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:20:06.248373 26073 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:20:06.248376 26073 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:20:06.248381 26073 net.cpp:124] Setting up norm1\n",
      "I0430 03:20:06.248384 26073 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:20:06.248386 26073 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:20:06.248389 26073 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:20:06.248395 26073 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:20:06.248399 26073 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:20:06.248401 26073 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:20:06.248802 26073 net.cpp:124] Setting up conv2\n",
      "I0430 03:20:06.248811 26073 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:20:06.248813 26073 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:20:06.248819 26073 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:20:06.248824 26073 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:20:06.248827 26073 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:20:06.248832 26073 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:20:06.248837 26073 net.cpp:124] Setting up relu2\n",
      "I0430 03:20:06.248842 26073 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:20:06.248843 26073 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:20:06.248847 26073 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:20:06.248852 26073 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:20:06.248855 26073 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:20:06.248860 26073 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:20:06.248867 26073 net.cpp:124] Setting up pool2\n",
      "I0430 03:20:06.248870 26073 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:20:06.248872 26073 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:20:06.248877 26073 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:20:06.248881 26073 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:20:06.248883 26073 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:20:06.248888 26073 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:20:06.248894 26073 net.cpp:124] Setting up norm2\n",
      "I0430 03:20:06.248898 26073 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:20:06.248900 26073 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:20:06.248903 26073 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:20:06.248909 26073 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:20:06.248913 26073 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:20:06.248916 26073 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:20:06.250051 26073 net.cpp:124] Setting up conv3\n",
      "I0430 03:20:06.250067 26073 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:20:06.250072 26073 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:20:06.250080 26073 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:20:06.250088 26073 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:20:06.250092 26073 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:20:06.250095 26073 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:20:06.250102 26073 net.cpp:124] Setting up relu3\n",
      "I0430 03:20:06.250104 26073 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:20:06.250108 26073 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:20:06.250110 26073 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:20:06.250116 26073 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:20:06.250118 26073 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:20:06.250123 26073 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:20:06.250658 26073 net.cpp:124] Setting up conv4\n",
      "I0430 03:20:06.250666 26073 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:20:06.250669 26073 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:20:06.250674 26073 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:20:06.250680 26073 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:20:06.250684 26073 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:20:06.250689 26073 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:20:06.250694 26073 net.cpp:124] Setting up relu4\n",
      "I0430 03:20:06.250699 26073 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:20:06.250700 26073 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:20:06.250704 26073 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:20:06.250710 26073 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:20:06.250712 26073 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:20:06.250715 26073 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:20:06.251278 26073 net.cpp:124] Setting up conv5\n",
      "I0430 03:20:06.251286 26073 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:20:06.251288 26073 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:20:06.251297 26073 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:20:06.251302 26073 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:20:06.251303 26073 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:20:06.251307 26073 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:20:06.251312 26073 net.cpp:124] Setting up relu5\n",
      "I0430 03:20:06.251317 26073 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:20:06.251320 26073 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:20:06.251322 26073 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:20:06.251327 26073 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:20:06.251330 26073 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:20:06.251334 26073 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:20:06.251341 26073 net.cpp:124] Setting up pool5\n",
      "I0430 03:20:06.251345 26073 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:20:06.251348 26073 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:20:06.251350 26073 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:20:06.251358 26073 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:20:06.251361 26073 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:20:06.251365 26073 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:20:06.278540 26073 net.cpp:124] Setting up fc6\n",
      "I0430 03:20:06.278563 26073 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:20:06.278564 26073 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:20:06.278573 26073 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:20:06.278584 26073 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:20:06.278587 26073 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:20:06.278592 26073 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:20:06.278599 26073 net.cpp:124] Setting up relu6\n",
      "I0430 03:20:06.278601 26073 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:20:06.278604 26073 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:20:06.278605 26073 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:20:06.278609 26073 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:20:06.278611 26073 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:20:06.278614 26073 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:20:06.278619 26073 net.cpp:124] Setting up drop6\n",
      "I0430 03:20:06.278620 26073 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:20:06.278622 26073 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:20:06.278625 26073 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:20:06.278628 26073 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:20:06.278630 26073 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:20:06.278635 26073 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:20:06.290582 26073 net.cpp:124] Setting up fc7\n",
      "I0430 03:20:06.290619 26073 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:20:06.290626 26073 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:20:06.290637 26073 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:20:06.290649 26073 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:20:06.290654 26073 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:20:06.290662 26073 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:20:06.290669 26073 net.cpp:124] Setting up relu7\n",
      "I0430 03:20:06.290674 26073 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:20:06.290678 26073 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:20:06.290683 26073 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:20:06.290690 26073 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:20:06.290695 26073 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:20:06.290704 26073 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:20:06.290711 26073 net.cpp:124] Setting up drop7\n",
      "I0430 03:20:06.290717 26073 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:20:06.290721 26073 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:20:06.290725 26073 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:20:06.290733 26073 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:20:06.290738 26073 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:20:06.290745 26073 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:20:06.291785 26073 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:20:06.291808 26073 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:20:06.291813 26073 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:20:06.291824 26073 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:20:06.291828 26073 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:20:06.291832 26073 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:20:06.291836 26073 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:20:06.291841 26073 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:20:06.291843 26073 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:20:06.291846 26073 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:20:06.291851 26073 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:20:06.291853 26073 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:20:06.291857 26073 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:20:06.291862 26073 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:20:06.291867 26073 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:20:06.291872 26073 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:20:06.291877 26073 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:20:06.291882 26073 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:20:06.291887 26073 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:20:06.291891 26073 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:20:06.291896 26073 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:20:06.291901 26073 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:20:06.291906 26073 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:20:06.291911 26073 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:20:06.291915 26073 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:20:06.291919 26073 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:20:06.291923 26073 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:20:06.291940 26073 net.cpp:257] Network initialization done.\n",
      "I0430 03:20:06.392298 26073 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:20:06.507125 26073 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:20:06.508460 26073 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:20:06.508482 26073 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:20:06.508488 26073 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/546687.jpg'}, '/tmp/tmpRIVaiO.mat')\n",
      "Processed 2630 windows in 328.225 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.038 s.\n",
      "prediction    [-2.13256, -2.64875, -1.81152, -2.21107, -1.88...\n",
      "ymin                                                        178\n",
      "xmin                                                         83\n",
      "ymax                                                        222\n",
      "xmax                                                        104\n",
      "Name: /home/ambika/INF_project/data/train/546687.jpg, dtype: object\n",
      "prediction    [-2.06281, -1.21563, -1.95129, -2.21161, -1.75...\n",
      "ymin                                                        194\n",
      "xmin                                                        378\n",
      "ymax                                                        254\n",
      "xmax                                                        445\n",
      "Name: /home/ambika/INF_project/data/train/546687.jpg, dtype: object\n",
      "person\n",
      "83\t178\t104\t222\n",
      "car\n",
      "378\t194\t445\t254\n",
      "546687\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:25:36.407683 26266 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:25:36.407714 26266 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:25:36.407717 26266 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:25:36.408826 26266 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:25:36.408936 26266 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:25:36.408943 26266 net.cpp:86] Creating Layer data\n",
      "I0430 03:25:36.408946 26266 net.cpp:382] data -> data\n",
      "I0430 03:25:36.408957 26266 net.cpp:124] Setting up data\n",
      "I0430 03:25:36.408962 26266 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:25:36.408964 26266 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:25:36.408968 26266 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:25:36.408977 26266 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:25:36.408979 26266 net.cpp:408] conv1 <- data\n",
      "I0430 03:25:36.408983 26266 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:25:36.409050 26266 net.cpp:124] Setting up conv1\n",
      "I0430 03:25:36.409054 26266 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:25:36.409056 26266 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:25:36.409063 26266 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:25:36.409068 26266 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:25:36.409070 26266 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:25:36.409075 26266 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:25:36.409078 26266 net.cpp:124] Setting up relu1\n",
      "I0430 03:25:36.409081 26266 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:25:36.409085 26266 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:25:36.409086 26266 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:25:36.409090 26266 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:25:36.409093 26266 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:25:36.409097 26266 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:25:36.409103 26266 net.cpp:124] Setting up pool1\n",
      "I0430 03:25:36.409107 26266 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:25:36.409109 26266 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:25:36.409112 26266 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:25:36.409118 26266 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:25:36.409121 26266 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:25:36.409124 26266 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:25:36.409131 26266 net.cpp:124] Setting up norm1\n",
      "I0430 03:25:36.409133 26266 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:25:36.409137 26266 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:25:36.409138 26266 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:25:36.409142 26266 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:25:36.409145 26266 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:25:36.409148 26266 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:25:36.409502 26266 net.cpp:124] Setting up conv2\n",
      "I0430 03:25:36.409508 26266 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:25:36.409512 26266 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:25:36.409518 26266 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:25:36.409523 26266 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:25:36.409525 26266 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:25:36.409528 26266 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:25:36.409533 26266 net.cpp:124] Setting up relu2\n",
      "I0430 03:25:36.409535 26266 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:25:36.409538 26266 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:25:36.409540 26266 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:25:36.409544 26266 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:25:36.409548 26266 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:25:36.409550 26266 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:25:36.409555 26266 net.cpp:124] Setting up pool2\n",
      "I0430 03:25:36.409559 26266 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:25:36.409561 26266 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:25:36.409564 26266 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:25:36.409567 26266 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:25:36.409570 26266 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:25:36.409574 26266 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:25:36.409579 26266 net.cpp:124] Setting up norm2\n",
      "I0430 03:25:36.409581 26266 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:25:36.409584 26266 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:25:36.409585 26266 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:25:36.409590 26266 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:25:36.409593 26266 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:25:36.409596 26266 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:25:36.410329 26266 net.cpp:124] Setting up conv3\n",
      "I0430 03:25:36.410339 26266 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:25:36.410342 26266 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:25:36.410351 26266 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:25:36.410357 26266 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:25:36.410359 26266 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:25:36.410364 26266 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:25:36.410368 26266 net.cpp:124] Setting up relu3\n",
      "I0430 03:25:36.410372 26266 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:25:36.410374 26266 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:25:36.410377 26266 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:25:36.410382 26266 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:25:36.410383 26266 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:25:36.410387 26266 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:25:36.411118 26266 net.cpp:124] Setting up conv4\n",
      "I0430 03:25:36.411125 26266 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:25:36.411128 26266 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:25:36.411134 26266 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:25:36.411139 26266 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:25:36.411141 26266 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:25:36.411145 26266 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:25:36.411149 26266 net.cpp:124] Setting up relu4\n",
      "I0430 03:25:36.411152 26266 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:25:36.411154 26266 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:25:36.411156 26266 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:25:36.411161 26266 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:25:36.411164 26266 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:25:36.411167 26266 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:25:36.411669 26266 net.cpp:124] Setting up conv5\n",
      "I0430 03:25:36.411676 26266 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:25:36.411679 26266 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:25:36.411687 26266 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:25:36.411691 26266 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:25:36.411695 26266 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:25:36.411698 26266 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:25:36.411702 26266 net.cpp:124] Setting up relu5\n",
      "I0430 03:25:36.411705 26266 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:25:36.411707 26266 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:25:36.411710 26266 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:25:36.411713 26266 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:25:36.411715 26266 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:25:36.411720 26266 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:25:36.411725 26266 net.cpp:124] Setting up pool5\n",
      "I0430 03:25:36.411730 26266 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:25:36.411731 26266 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:25:36.411733 26266 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:25:36.411741 26266 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:25:36.411743 26266 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:25:36.411747 26266 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:25:36.436445 26266 net.cpp:124] Setting up fc6\n",
      "I0430 03:25:36.436470 26266 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:25:36.436471 26266 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:25:36.436480 26266 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:25:36.436486 26266 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:25:36.436489 26266 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:25:36.436493 26266 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:25:36.436499 26266 net.cpp:124] Setting up relu6\n",
      "I0430 03:25:36.436501 26266 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:25:36.436503 26266 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:25:36.436506 26266 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:25:36.436508 26266 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:25:36.436513 26266 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:25:36.436517 26266 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:25:36.436534 26266 net.cpp:124] Setting up drop6\n",
      "I0430 03:25:36.436538 26266 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:25:36.436540 26266 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:25:36.436542 26266 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:25:36.436547 26266 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:25:36.436548 26266 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:25:36.436553 26266 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:25:36.446418 26266 net.cpp:124] Setting up fc7\n",
      "I0430 03:25:36.446439 26266 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:25:36.446442 26266 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:25:36.446450 26266 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:25:36.446458 26266 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:25:36.446461 26266 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:25:36.446465 26266 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:25:36.446471 26266 net.cpp:124] Setting up relu7\n",
      "I0430 03:25:36.446473 26266 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:25:36.446475 26266 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:25:36.446477 26266 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:25:36.446480 26266 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:25:36.446482 26266 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:25:36.446485 26266 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:25:36.446490 26266 net.cpp:124] Setting up drop7\n",
      "I0430 03:25:36.446493 26266 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:25:36.446496 26266 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:25:36.446497 26266 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:25:36.446501 26266 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:25:36.446503 26266 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:25:36.446507 26266 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:25:36.447177 26266 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:25:36.447190 26266 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:25:36.447192 26266 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:25:36.447198 26266 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:25:36.447201 26266 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:25:36.447204 26266 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:25:36.447211 26266 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:25:36.447214 26266 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:25:36.447216 26266 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:25:36.447218 26266 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:25:36.447221 26266 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:25:36.447223 26266 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:25:36.447226 26266 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:25:36.447227 26266 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:25:36.447229 26266 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:25:36.447232 26266 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:25:36.447234 26266 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:25:36.447237 26266 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:25:36.447238 26266 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:25:36.447242 26266 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:25:36.447245 26266 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:25:36.447248 26266 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:25:36.447252 26266 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:25:36.447253 26266 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:25:36.447257 26266 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:25:36.447258 26266 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:25:36.447262 26266 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:25:36.447270 26266 net.cpp:257] Network initialization done.\n",
      "I0430 03:25:36.536674 26266 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:25:36.652096 26266 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:25:36.653022 26266 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:25:36.653030 26266 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:25:36.653033 26266 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/274959.jpg'}, '/tmp/tmpepCxEN.mat')\n",
      "Processed 2197 windows in 277.878 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.041 s.\n",
      "prediction    [-2.24204, -0.781189, -2.25218, -1.99099, -1.7...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/airplane/274959.jpg, dtype: object\n",
      "prediction    [-2.63544, 0.228662, -2.61633, -1.93457, -1.90...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                        199\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/airplane/274959.jpg, dtype: object\n",
      "watercraft\n",
      "0\t0\t500\t375\n",
      "airplane\n",
      "0\t0\t500\t199\n",
      "274959\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:30:16.416044 26518 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:30:16.416065 26518 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:30:16.416069 26518 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:30:16.417165 26518 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:30:16.417258 26518 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:30:16.417268 26518 net.cpp:86] Creating Layer data\n",
      "I0430 03:30:16.417274 26518 net.cpp:382] data -> data\n",
      "I0430 03:30:16.417286 26518 net.cpp:124] Setting up data\n",
      "I0430 03:30:16.417291 26518 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:30:16.417294 26518 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:30:16.417296 26518 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:30:16.417302 26518 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:30:16.417304 26518 net.cpp:408] conv1 <- data\n",
      "I0430 03:30:16.417309 26518 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:30:16.417366 26518 net.cpp:124] Setting up conv1\n",
      "I0430 03:30:16.417371 26518 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:30:16.417373 26518 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:30:16.417381 26518 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:30:16.417385 26518 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:30:16.417387 26518 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:30:16.417390 26518 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:30:16.417395 26518 net.cpp:124] Setting up relu1\n",
      "I0430 03:30:16.417398 26518 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:30:16.417400 26518 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:30:16.417402 26518 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:30:16.417407 26518 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:30:16.417408 26518 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:30:16.417412 26518 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:30:16.417418 26518 net.cpp:124] Setting up pool1\n",
      "I0430 03:30:16.417421 26518 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:30:16.417423 26518 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:30:16.417426 26518 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:30:16.417430 26518 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:30:16.417433 26518 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:30:16.417436 26518 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:30:16.417440 26518 net.cpp:124] Setting up norm1\n",
      "I0430 03:30:16.417444 26518 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:30:16.417446 26518 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:30:16.417448 26518 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:30:16.417453 26518 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:30:16.417454 26518 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:30:16.417459 26518 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:30:16.417794 26518 net.cpp:124] Setting up conv2\n",
      "I0430 03:30:16.417799 26518 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:30:16.417801 26518 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:30:16.417806 26518 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:30:16.417810 26518 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:30:16.417812 26518 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:30:16.417815 26518 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:30:16.417819 26518 net.cpp:124] Setting up relu2\n",
      "I0430 03:30:16.417822 26518 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:30:16.417825 26518 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:30:16.417827 26518 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:30:16.417831 26518 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:30:16.417834 26518 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:30:16.417837 26518 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:30:16.417842 26518 net.cpp:124] Setting up pool2\n",
      "I0430 03:30:16.417845 26518 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:30:16.417847 26518 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:30:16.417850 26518 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:30:16.417855 26518 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:30:16.417856 26518 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:30:16.417860 26518 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:30:16.417863 26518 net.cpp:124] Setting up norm2\n",
      "I0430 03:30:16.417867 26518 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:30:16.417870 26518 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:30:16.417871 26518 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:30:16.417876 26518 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:30:16.417878 26518 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:30:16.417881 26518 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:30:16.418659 26518 net.cpp:124] Setting up conv3\n",
      "I0430 03:30:16.418671 26518 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:30:16.418674 26518 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:30:16.418684 26518 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:30:16.418689 26518 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:30:16.418692 26518 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:30:16.418696 26518 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:30:16.418701 26518 net.cpp:124] Setting up relu3\n",
      "I0430 03:30:16.418705 26518 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:30:16.418707 26518 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:30:16.418709 26518 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:30:16.418715 26518 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:30:16.418717 26518 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:30:16.418721 26518 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:30:16.419456 26518 net.cpp:124] Setting up conv4\n",
      "I0430 03:30:16.419462 26518 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:30:16.419464 26518 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:30:16.419469 26518 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:30:16.419473 26518 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:30:16.419476 26518 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:30:16.419481 26518 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:30:16.419484 26518 net.cpp:124] Setting up relu4\n",
      "I0430 03:30:16.419487 26518 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:30:16.419490 26518 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:30:16.419492 26518 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:30:16.419497 26518 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:30:16.419499 26518 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:30:16.419503 26518 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:30:16.419996 26518 net.cpp:124] Setting up conv5\n",
      "I0430 03:30:16.420001 26518 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:30:16.420004 26518 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:30:16.420011 26518 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:30:16.420016 26518 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:30:16.420017 26518 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:30:16.420022 26518 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:30:16.420025 26518 net.cpp:124] Setting up relu5\n",
      "I0430 03:30:16.420028 26518 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:30:16.420032 26518 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:30:16.420033 26518 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:30:16.420037 26518 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:30:16.420039 26518 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:30:16.420043 26518 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:30:16.420049 26518 net.cpp:124] Setting up pool5\n",
      "I0430 03:30:16.420053 26518 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:30:16.420055 26518 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:30:16.420058 26518 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:30:16.420064 26518 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:30:16.420068 26518 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:30:16.420070 26518 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:30:16.449048 26518 net.cpp:124] Setting up fc6\n",
      "I0430 03:30:16.449074 26518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:30:16.449076 26518 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:30:16.449087 26518 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:30:16.449097 26518 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:30:16.449105 26518 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:30:16.449112 26518 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:30:16.449123 26518 net.cpp:124] Setting up relu6\n",
      "I0430 03:30:16.449129 26518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:30:16.449132 26518 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:30:16.449136 26518 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:30:16.449142 26518 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:30:16.449146 26518 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:30:16.449151 26518 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:30:16.449158 26518 net.cpp:124] Setting up drop6\n",
      "I0430 03:30:16.449163 26518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:30:16.449167 26518 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:30:16.449170 26518 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:30:16.449177 26518 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:30:16.449179 26518 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:30:16.449187 26518 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:30:16.464457 26518 net.cpp:124] Setting up fc7\n",
      "I0430 03:30:16.464517 26518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:30:16.464522 26518 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:30:16.464565 26518 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:30:16.464582 26518 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:30:16.464588 26518 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:30:16.464599 26518 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:30:16.464612 26518 net.cpp:124] Setting up relu7\n",
      "I0430 03:30:16.464618 26518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:30:16.464622 26518 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:30:16.464627 26518 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:30:16.464632 26518 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:30:16.464637 26518 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:30:16.464643 26518 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:30:16.464651 26518 net.cpp:124] Setting up drop7\n",
      "I0430 03:30:16.464655 26518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:30:16.464658 26518 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:30:16.464663 26518 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:30:16.464668 26518 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:30:16.464671 26518 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:30:16.464678 26518 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:30:16.466125 26518 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:30:16.466156 26518 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:30:16.466163 26518 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:30:16.466181 26518 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:30:16.466188 26518 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:30:16.466192 26518 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:30:16.466197 26518 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:30:16.466202 26518 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:30:16.466205 26518 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:30:16.466209 26518 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:30:16.466213 26518 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:30:16.466218 26518 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:30:16.466223 26518 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:30:16.466228 26518 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:30:16.466233 26518 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:30:16.466236 26518 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:30:16.466240 26518 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:30:16.466244 26518 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:30:16.466248 26518 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:30:16.466253 26518 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:30:16.466258 26518 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:30:16.466261 26518 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:30:16.466266 26518 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:30:16.466270 26518 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:30:16.466274 26518 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:30:16.466279 26518 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:30:16.466282 26518 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:30:16.466311 26518 net.cpp:257] Network initialization done.\n",
      "I0430 03:30:16.557536 26518 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:30:16.681493 26518 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:30:16.682468 26518 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:30:16.682476 26518 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:30:16.682477 26518 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/323847.jpg'}, '/tmp/tmpg03SAc.mat')\n",
      "Processed 3088 windows in 364.033 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.047 s.\n",
      "prediction    [-1.98253, -2.7103, -2.41336, -2.82365, -2.236...\n",
      "ymin                                                     41.552\n",
      "xmin                                                       42.4\n",
      "ymax                                                    465.704\n",
      "xmax                                                    190.952\n",
      "Name: /home/ambika/INF_project/data/bird/323847.jpg, dtype: object\n",
      "prediction    [-1.70578, -1.93248, -2.63041, -2.90259, -1.94...\n",
      "ymin                                                    368.032\n",
      "xmin                                                          0\n",
      "ymax                                                    500.472\n",
      "xmax                                                      98.52\n",
      "Name: /home/ambika/INF_project/data/bird/323847.jpg, dtype: object\n",
      "bird\n",
      "42.4\t41.552\t190.952\t465.704\n",
      "dog\n",
      "0.0\t368.032\t98.52\t500.472\n",
      "323847\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:36:22.508421 26783 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:36:22.508440 26783 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:36:22.508441 26783 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:36:22.509559 26783 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:36:22.509639 26783 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:36:22.509646 26783 net.cpp:86] Creating Layer data\n",
      "I0430 03:36:22.509649 26783 net.cpp:382] data -> data\n",
      "I0430 03:36:22.509658 26783 net.cpp:124] Setting up data\n",
      "I0430 03:36:22.509663 26783 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:36:22.509665 26783 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:36:22.509668 26783 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:36:22.509675 26783 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:36:22.509676 26783 net.cpp:408] conv1 <- data\n",
      "I0430 03:36:22.509680 26783 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:36:22.509734 26783 net.cpp:124] Setting up conv1\n",
      "I0430 03:36:22.509738 26783 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:36:22.509742 26783 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:36:22.509748 26783 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:36:22.509752 26783 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:36:22.509755 26783 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:36:22.509758 26783 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:36:22.509763 26783 net.cpp:124] Setting up relu1\n",
      "I0430 03:36:22.509765 26783 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:36:22.509768 26783 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:36:22.509770 26783 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:36:22.509774 26783 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:36:22.509776 26783 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:36:22.509779 26783 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:36:22.509785 26783 net.cpp:124] Setting up pool1\n",
      "I0430 03:36:22.509788 26783 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:36:22.509791 26783 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:36:22.509793 26783 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:36:22.509798 26783 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:36:22.509799 26783 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:36:22.509804 26783 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:36:22.509807 26783 net.cpp:124] Setting up norm1\n",
      "I0430 03:36:22.509811 26783 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:36:22.509814 26783 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:36:22.509815 26783 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:36:22.509819 26783 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:36:22.509821 26783 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:36:22.509825 26783 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:36:22.510161 26783 net.cpp:124] Setting up conv2\n",
      "I0430 03:36:22.510166 26783 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:36:22.510169 26783 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:36:22.510174 26783 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:36:22.510177 26783 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:36:22.510180 26783 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:36:22.510184 26783 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:36:22.510186 26783 net.cpp:124] Setting up relu2\n",
      "I0430 03:36:22.510190 26783 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:36:22.510192 26783 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:36:22.510195 26783 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:36:22.510198 26783 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:36:22.510201 26783 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:36:22.510205 26783 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:36:22.510210 26783 net.cpp:124] Setting up pool2\n",
      "I0430 03:36:22.510212 26783 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:36:22.510215 26783 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:36:22.510216 26783 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:36:22.510221 26783 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:36:22.510223 26783 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:36:22.510226 26783 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:36:22.510231 26783 net.cpp:124] Setting up norm2\n",
      "I0430 03:36:22.510233 26783 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:36:22.510236 26783 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:36:22.510238 26783 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:36:22.510243 26783 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:36:22.510246 26783 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:36:22.510249 26783 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:36:22.510913 26783 net.cpp:124] Setting up conv3\n",
      "I0430 03:36:22.510921 26783 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:36:22.510922 26783 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:36:22.510928 26783 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:36:22.510934 26783 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:36:22.510936 26783 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:36:22.510941 26783 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:36:22.510944 26783 net.cpp:124] Setting up relu3\n",
      "I0430 03:36:22.510947 26783 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:36:22.510949 26783 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:36:22.510952 26783 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:36:22.510957 26783 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:36:22.510958 26783 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:36:22.510962 26783 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:36:22.511739 26783 net.cpp:124] Setting up conv4\n",
      "I0430 03:36:22.511750 26783 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:36:22.511752 26783 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:36:22.511757 26783 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:36:22.511764 26783 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:36:22.511765 26783 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:36:22.511770 26783 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:36:22.511775 26783 net.cpp:124] Setting up relu4\n",
      "I0430 03:36:22.511777 26783 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:36:22.511780 26783 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:36:22.511781 26783 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:36:22.511786 26783 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:36:22.511788 26783 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:36:22.511791 26783 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:36:22.512281 26783 net.cpp:124] Setting up conv5\n",
      "I0430 03:36:22.512287 26783 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:36:22.512290 26783 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:36:22.512297 26783 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:36:22.512301 26783 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:36:22.512303 26783 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:36:22.512307 26783 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:36:22.512311 26783 net.cpp:124] Setting up relu5\n",
      "I0430 03:36:22.512315 26783 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:36:22.512316 26783 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:36:22.512318 26783 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:36:22.512323 26783 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:36:22.512326 26783 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:36:22.512329 26783 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:36:22.512336 26783 net.cpp:124] Setting up pool5\n",
      "I0430 03:36:22.512339 26783 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:36:22.512341 26783 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:36:22.512343 26783 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:36:22.512349 26783 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:36:22.512352 26783 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:36:22.512356 26783 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:36:22.534255 26783 net.cpp:124] Setting up fc6\n",
      "I0430 03:36:22.534277 26783 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:36:22.534281 26783 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:36:22.534292 26783 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:36:22.534303 26783 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:36:22.534307 26783 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:36:22.534312 26783 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:36:22.534320 26783 net.cpp:124] Setting up relu6\n",
      "I0430 03:36:22.534324 26783 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:36:22.534325 26783 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:36:22.534329 26783 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:36:22.534335 26783 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:36:22.534338 26783 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:36:22.534343 26783 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:36:22.534349 26783 net.cpp:124] Setting up drop6\n",
      "I0430 03:36:22.534353 26783 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:36:22.534356 26783 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:36:22.534359 26783 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:36:22.534366 26783 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:36:22.534369 26783 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:36:22.534374 26783 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:36:22.548656 26783 net.cpp:124] Setting up fc7\n",
      "I0430 03:36:22.548689 26783 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:36:22.548693 26783 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:36:22.548702 26783 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:36:22.548709 26783 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:36:22.548712 26783 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:36:22.548717 26783 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:36:22.548723 26783 net.cpp:124] Setting up relu7\n",
      "I0430 03:36:22.548727 26783 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:36:22.548727 26783 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:36:22.548729 26783 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:36:22.548733 26783 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:36:22.548735 26783 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:36:22.548738 26783 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:36:22.548743 26783 net.cpp:124] Setting up drop7\n",
      "I0430 03:36:22.548744 26783 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:36:22.548748 26783 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:36:22.548750 26783 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:36:22.548755 26783 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:36:22.548758 26783 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:36:22.548761 26783 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:36:22.549707 26783 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:36:22.549727 26783 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:36:22.549731 26783 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:36:22.549742 26783 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:36:22.549746 26783 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:36:22.549748 26783 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:36:22.549749 26783 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:36:22.549752 26783 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:36:22.549754 26783 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:36:22.549757 26783 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:36:22.549759 26783 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:36:22.549762 26783 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:36:22.549763 26783 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:36:22.549767 26783 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:36:22.549768 26783 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:36:22.549770 26783 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:36:22.549772 26783 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:36:22.549775 26783 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:36:22.549778 26783 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:36:22.549780 26783 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:36:22.549783 26783 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:36:22.549787 26783 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:36:22.549790 26783 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:36:22.549793 26783 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:36:22.549796 26783 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:36:22.549799 26783 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:36:22.549803 26783 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:36:22.549823 26783 net.cpp:257] Network initialization done.\n",
      "I0430 03:36:22.764036 26783 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:36:22.875916 26783 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:36:22.876751 26783 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:36:22.876760 26783 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:36:22.876762 26783 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/371322.jpg'}, '/tmp/tmp0xqaIT.mat')\n",
      "Processed 1931 windows in 229.128 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.02893, -2.90918, -1.69715, -2.06341, -1.85...\n",
      "ymin                                                        262\n",
      "xmin                                                         53\n",
      "ymax                                                        326\n",
      "xmax                                                         73\n",
      "Name: /home/ambika/INF_project/data/bus/371322.jpg, dtype: object\n",
      "prediction    [-2.59307, -2.46939, -2.16704, -2.69083, -2.06...\n",
      "ymin                                                        173\n",
      "xmin                                                        168\n",
      "ymax                                                        211\n",
      "xmax                                                        205\n",
      "Name: /home/ambika/INF_project/data/bus/371322.jpg, dtype: object\n",
      "person\n",
      "53\t262\t73\t326\n",
      "watercraft\n",
      "168\t173\t205\t211\n",
      "371322\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:40:13.634410 26962 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:40:13.634426 26962 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:40:13.634438 26962 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:40:13.635593 26962 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:40:13.635751 26962 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:40:13.635758 26962 net.cpp:86] Creating Layer data\n",
      "I0430 03:40:13.635762 26962 net.cpp:382] data -> data\n",
      "I0430 03:40:13.635774 26962 net.cpp:124] Setting up data\n",
      "I0430 03:40:13.635781 26962 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:40:13.635783 26962 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:40:13.635787 26962 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:40:13.635792 26962 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:40:13.635794 26962 net.cpp:408] conv1 <- data\n",
      "I0430 03:40:13.635799 26962 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:40:13.635857 26962 net.cpp:124] Setting up conv1\n",
      "I0430 03:40:13.635862 26962 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:40:13.635865 26962 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:40:13.635872 26962 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:40:13.635877 26962 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:40:13.635880 26962 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:40:13.635885 26962 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:40:13.635890 26962 net.cpp:124] Setting up relu1\n",
      "I0430 03:40:13.635893 26962 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:40:13.635896 26962 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:40:13.635900 26962 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:40:13.635903 26962 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:40:13.635906 26962 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:40:13.635910 26962 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:40:13.635918 26962 net.cpp:124] Setting up pool1\n",
      "I0430 03:40:13.635922 26962 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:40:13.635924 26962 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:40:13.635927 26962 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:40:13.635934 26962 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:40:13.635936 26962 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:40:13.635941 26962 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:40:13.635947 26962 net.cpp:124] Setting up norm1\n",
      "I0430 03:40:13.635951 26962 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:40:13.635953 26962 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:40:13.635956 26962 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:40:13.635960 26962 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:40:13.635963 26962 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:40:13.635967 26962 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:40:13.636299 26962 net.cpp:124] Setting up conv2\n",
      "I0430 03:40:13.636304 26962 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:40:13.636307 26962 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:40:13.636313 26962 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:40:13.636317 26962 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:40:13.636320 26962 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:40:13.636323 26962 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:40:13.636327 26962 net.cpp:124] Setting up relu2\n",
      "I0430 03:40:13.636332 26962 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:40:13.636333 26962 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:40:13.636337 26962 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:40:13.636343 26962 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:40:13.636345 26962 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:40:13.636349 26962 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:40:13.636354 26962 net.cpp:124] Setting up pool2\n",
      "I0430 03:40:13.636358 26962 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:40:13.636360 26962 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:40:13.636363 26962 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:40:13.636369 26962 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:40:13.636373 26962 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:40:13.636376 26962 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:40:13.636381 26962 net.cpp:124] Setting up norm2\n",
      "I0430 03:40:13.636384 26962 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:40:13.636387 26962 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:40:13.636390 26962 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:40:13.636395 26962 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:40:13.636397 26962 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:40:13.636401 26962 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:40:13.637076 26962 net.cpp:124] Setting up conv3\n",
      "I0430 03:40:13.637085 26962 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:40:13.637089 26962 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:40:13.637096 26962 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:40:13.637104 26962 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:40:13.637105 26962 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:40:13.637109 26962 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:40:13.637115 26962 net.cpp:124] Setting up relu3\n",
      "I0430 03:40:13.637118 26962 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:40:13.637121 26962 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:40:13.637123 26962 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:40:13.637130 26962 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:40:13.637131 26962 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:40:13.637135 26962 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:40:13.637915 26962 net.cpp:124] Setting up conv4\n",
      "I0430 03:40:13.637928 26962 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:40:13.637931 26962 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:40:13.637938 26962 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:40:13.637943 26962 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:40:13.637945 26962 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:40:13.637949 26962 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:40:13.637954 26962 net.cpp:124] Setting up relu4\n",
      "I0430 03:40:13.637956 26962 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:40:13.637959 26962 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:40:13.637962 26962 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:40:13.637969 26962 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:40:13.637970 26962 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:40:13.637975 26962 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:40:13.638502 26962 net.cpp:124] Setting up conv5\n",
      "I0430 03:40:13.638511 26962 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:40:13.638514 26962 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:40:13.638523 26962 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:40:13.638527 26962 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:40:13.638530 26962 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:40:13.638533 26962 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:40:13.638538 26962 net.cpp:124] Setting up relu5\n",
      "I0430 03:40:13.638541 26962 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:40:13.638543 26962 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:40:13.638546 26962 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:40:13.638550 26962 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:40:13.638553 26962 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:40:13.638557 26962 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:40:13.638563 26962 net.cpp:124] Setting up pool5\n",
      "I0430 03:40:13.638566 26962 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:40:13.638568 26962 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:40:13.638571 26962 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:40:13.638577 26962 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:40:13.638581 26962 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:40:13.638584 26962 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:40:13.669881 26962 net.cpp:124] Setting up fc6\n",
      "I0430 03:40:13.669900 26962 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:40:13.669903 26962 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:40:13.669910 26962 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:40:13.669916 26962 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:40:13.669919 26962 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:40:13.669922 26962 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:40:13.669929 26962 net.cpp:124] Setting up relu6\n",
      "I0430 03:40:13.669934 26962 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:40:13.669934 26962 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:40:13.669939 26962 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:40:13.669942 26962 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:40:13.669944 26962 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:40:13.669946 26962 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:40:13.669950 26962 net.cpp:124] Setting up drop6\n",
      "I0430 03:40:13.669955 26962 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:40:13.669955 26962 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:40:13.669957 26962 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:40:13.669962 26962 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:40:13.669965 26962 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:40:13.669967 26962 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:40:13.679841 26962 net.cpp:124] Setting up fc7\n",
      "I0430 03:40:13.679864 26962 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:40:13.679868 26962 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:40:13.679877 26962 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:40:13.679884 26962 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:40:13.679888 26962 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:40:13.679893 26962 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:40:13.679899 26962 net.cpp:124] Setting up relu7\n",
      "I0430 03:40:13.679903 26962 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:40:13.679903 26962 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:40:13.679905 26962 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:40:13.679909 26962 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:40:13.679913 26962 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:40:13.679915 26962 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:40:13.679919 26962 net.cpp:124] Setting up drop7\n",
      "I0430 03:40:13.679924 26962 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:40:13.679925 26962 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:40:13.679927 26962 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:40:13.679932 26962 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:40:13.679934 26962 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:40:13.679939 26962 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:40:13.680593 26962 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:40:13.680603 26962 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:40:13.680608 26962 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:40:13.680613 26962 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:40:13.680615 26962 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:40:13.680618 26962 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:40:13.680619 26962 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:40:13.680621 26962 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:40:13.680625 26962 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:40:13.680630 26962 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:40:13.680634 26962 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:40:13.680636 26962 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:40:13.680639 26962 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:40:13.680641 26962 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:40:13.680644 26962 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:40:13.680646 26962 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:40:13.680649 26962 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:40:13.680652 26962 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:40:13.680655 26962 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:40:13.680657 26962 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:40:13.680660 26962 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:40:13.680663 26962 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:40:13.680665 26962 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:40:13.680668 26962 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:40:13.680670 26962 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:40:13.680673 26962 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:40:13.680675 26962 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:40:13.680686 26962 net.cpp:257] Network initialization done.\n",
      "I0430 03:40:13.769767 26962 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:40:13.882372 26962 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:40:13.883596 26962 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:40:13.883606 26962 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:40:13.883610 26962 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/351840.jpg'}, '/tmp/tmpIUQqRE.mat')\n",
      "Processed 3032 windows in 370.560 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.048 s.\n",
      "prediction    [-2.11946, -1.92318, -1.86075, -1.67328, -2.26...\n",
      "ymin                                                         96\n",
      "xmin                                                         87\n",
      "ymax                                                     489.25\n",
      "xmax                                                     375.25\n",
      "Name: /home/ambika/INF_project/data/car/351840.jpg, dtype: object\n",
      "prediction    [-1.6578, -2.22028, -1.99924, -2.02272, -2.236...\n",
      "ymin                                                     102.75\n",
      "xmin                                                          0\n",
      "ymax                                                     420.25\n",
      "xmax                                                     337.75\n",
      "Name: /home/ambika/INF_project/data/car/351840.jpg, dtype: object\n",
      "golfcart\n",
      "87.0\t96.0\t375.25\t489.25\n",
      "car\n",
      "0.0\t102.75\t337.75\t420.25\n",
      "351840\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:46:26.269592 27168 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:46:26.269609 27168 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:46:26.269623 27168 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:46:26.270704 27168 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:46:26.270809 27168 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:46:26.270817 27168 net.cpp:86] Creating Layer data\n",
      "I0430 03:46:26.270835 27168 net.cpp:382] data -> data\n",
      "I0430 03:46:26.270846 27168 net.cpp:124] Setting up data\n",
      "I0430 03:46:26.270851 27168 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:46:26.270854 27168 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:46:26.270859 27168 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:46:26.270865 27168 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:46:26.270869 27168 net.cpp:408] conv1 <- data\n",
      "I0430 03:46:26.270874 27168 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:46:26.270931 27168 net.cpp:124] Setting up conv1\n",
      "I0430 03:46:26.270936 27168 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:46:26.270941 27168 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:46:26.270954 27168 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:46:26.270959 27168 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:46:26.270962 27168 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:46:26.270967 27168 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:46:26.270972 27168 net.cpp:124] Setting up relu1\n",
      "I0430 03:46:26.270977 27168 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:46:26.270978 27168 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:46:26.270982 27168 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:46:26.270987 27168 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:46:26.270988 27168 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:46:26.270993 27168 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:46:26.270999 27168 net.cpp:124] Setting up pool1\n",
      "I0430 03:46:26.271004 27168 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:46:26.271006 27168 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:46:26.271009 27168 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:46:26.271014 27168 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:46:26.271018 27168 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:46:26.271021 27168 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:46:26.271028 27168 net.cpp:124] Setting up norm1\n",
      "I0430 03:46:26.271031 27168 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:46:26.271034 27168 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:46:26.271037 27168 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:46:26.271041 27168 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:46:26.271044 27168 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:46:26.271049 27168 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:46:26.271400 27168 net.cpp:124] Setting up conv2\n",
      "I0430 03:46:26.271407 27168 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:46:26.271410 27168 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:46:26.271417 27168 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:46:26.271421 27168 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:46:26.271425 27168 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:46:26.271428 27168 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:46:26.271433 27168 net.cpp:124] Setting up relu2\n",
      "I0430 03:46:26.271437 27168 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:46:26.271440 27168 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:46:26.271443 27168 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:46:26.271448 27168 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:46:26.271451 27168 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:46:26.271456 27168 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:46:26.271461 27168 net.cpp:124] Setting up pool2\n",
      "I0430 03:46:26.271466 27168 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:46:26.271468 27168 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:46:26.271471 27168 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:46:26.271476 27168 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:46:26.271478 27168 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:46:26.271483 27168 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:46:26.271488 27168 net.cpp:124] Setting up norm2\n",
      "I0430 03:46:26.271492 27168 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:46:26.271495 27168 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:46:26.271498 27168 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:46:26.271504 27168 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:46:26.271507 27168 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:46:26.271512 27168 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:46:26.272202 27168 net.cpp:124] Setting up conv3\n",
      "I0430 03:46:26.272210 27168 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:46:26.272214 27168 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:46:26.272222 27168 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:46:26.272227 27168 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:46:26.272229 27168 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:46:26.272233 27168 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:46:26.272238 27168 net.cpp:124] Setting up relu3\n",
      "I0430 03:46:26.272241 27168 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:46:26.272244 27168 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:46:26.272248 27168 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:46:26.272253 27168 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:46:26.272256 27168 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:46:26.272260 27168 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:46:26.272984 27168 net.cpp:124] Setting up conv4\n",
      "I0430 03:46:26.272994 27168 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:46:26.272997 27168 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:46:26.273003 27168 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:46:26.273010 27168 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:46:26.273012 27168 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:46:26.273016 27168 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:46:26.273021 27168 net.cpp:124] Setting up relu4\n",
      "I0430 03:46:26.273025 27168 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:46:26.273028 27168 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:46:26.273031 27168 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:46:26.273036 27168 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:46:26.273039 27168 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:46:26.273043 27168 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:46:26.273540 27168 net.cpp:124] Setting up conv5\n",
      "I0430 03:46:26.273546 27168 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:46:26.273550 27168 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:46:26.273558 27168 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:46:26.273563 27168 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:46:26.273566 27168 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:46:26.273571 27168 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:46:26.273576 27168 net.cpp:124] Setting up relu5\n",
      "I0430 03:46:26.273579 27168 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:46:26.273582 27168 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:46:26.273586 27168 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:46:26.273592 27168 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:46:26.273596 27168 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:46:26.273599 27168 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:46:26.273607 27168 net.cpp:124] Setting up pool5\n",
      "I0430 03:46:26.273612 27168 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:46:26.273614 27168 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:46:26.273617 27168 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:46:26.273624 27168 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:46:26.273627 27168 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:46:26.273633 27168 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:46:26.295541 27168 net.cpp:124] Setting up fc6\n",
      "I0430 03:46:26.295563 27168 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:46:26.295567 27168 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:46:26.295578 27168 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:46:26.295599 27168 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:46:26.295603 27168 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:46:26.295608 27168 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:46:26.295616 27168 net.cpp:124] Setting up relu6\n",
      "I0430 03:46:26.295620 27168 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:46:26.295622 27168 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:46:26.295625 27168 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:46:26.295631 27168 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:46:26.295634 27168 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:46:26.295639 27168 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:46:26.295644 27168 net.cpp:124] Setting up drop6\n",
      "I0430 03:46:26.295648 27168 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:46:26.295651 27168 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:46:26.295655 27168 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:46:26.295660 27168 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:46:26.295662 27168 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:46:26.295667 27168 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:46:26.309655 27168 net.cpp:124] Setting up fc7\n",
      "I0430 03:46:26.309676 27168 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:46:26.309679 27168 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:46:26.309685 27168 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:46:26.309691 27168 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:46:26.309693 27168 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:46:26.309698 27168 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:46:26.309705 27168 net.cpp:124] Setting up relu7\n",
      "I0430 03:46:26.309706 27168 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:46:26.309711 27168 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:46:26.309713 27168 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:46:26.309720 27168 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:46:26.309722 27168 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:46:26.309725 27168 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:46:26.309731 27168 net.cpp:124] Setting up drop7\n",
      "I0430 03:46:26.309733 27168 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:46:26.309736 27168 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:46:26.309737 27168 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:46:26.309741 27168 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:46:26.309743 27168 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:46:26.309746 27168 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:46:26.310372 27168 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:46:26.310381 27168 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:46:26.310382 27168 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:46:26.310387 27168 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:46:26.310389 27168 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:46:26.310391 27168 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:46:26.310394 27168 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:46:26.310395 27168 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:46:26.310397 27168 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:46:26.310400 27168 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:46:26.310401 27168 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:46:26.310403 27168 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:46:26.310405 27168 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:46:26.310407 27168 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:46:26.310410 27168 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:46:26.310413 27168 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:46:26.310415 27168 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:46:26.310431 27168 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:46:26.310434 27168 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:46:26.310436 27168 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:46:26.310438 27168 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:46:26.310441 27168 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:46:26.310446 27168 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:46:26.310448 27168 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:46:26.310452 27168 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:46:26.310456 27168 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:46:26.310458 27168 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:46:26.310470 27168 net.cpp:257] Network initialization done.\n",
      "I0430 03:46:26.411938 27168 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:46:26.516916 27168 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:46:26.517782 27168 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:46:26.517789 27168 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:46:26.517791 27168 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/306395.jpg'}, '/tmp/tmpg6i1V5.mat')\n",
      "Processed 1569 windows in 186.599 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-1.73026, -2.36634, -1.61043, -2.33504, -2.59...\n",
      "ymin                                                         65\n",
      "xmin                                                        141\n",
      "ymax                                                        265\n",
      "xmax                                                        455\n",
      "Name: /home/ambika/INF_project/data/cat/306395.jpg, dtype: object\n",
      "prediction    [-1.44383, -1.98573, -1.68988, -1.99783, -2.15...\n",
      "ymin                                                         62\n",
      "xmin                                                         72\n",
      "ymax                                                        334\n",
      "xmax                                                        459\n",
      "Name: /home/ambika/INF_project/data/cat/306395.jpg, dtype: object\n",
      "dog\n",
      "141\t65\t455\t265\n",
      "bowl\n",
      "72\t62\t459\t334\n",
      "306395\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:49:34.654060 27359 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:49:34.654074 27359 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:49:34.654078 27359 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:49:34.655163 27359 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:49:34.655279 27359 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:49:34.655290 27359 net.cpp:86] Creating Layer data\n",
      "I0430 03:49:34.655294 27359 net.cpp:382] data -> data\n",
      "I0430 03:49:34.655306 27359 net.cpp:124] Setting up data\n",
      "I0430 03:49:34.655313 27359 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:49:34.655314 27359 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:49:34.655318 27359 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:49:34.655325 27359 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:49:34.655328 27359 net.cpp:408] conv1 <- data\n",
      "I0430 03:49:34.655333 27359 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:49:34.655391 27359 net.cpp:124] Setting up conv1\n",
      "I0430 03:49:34.655396 27359 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:49:34.655400 27359 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:49:34.655407 27359 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:49:34.655412 27359 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:49:34.655416 27359 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:49:34.655419 27359 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:49:34.655424 27359 net.cpp:124] Setting up relu1\n",
      "I0430 03:49:34.655428 27359 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:49:34.655431 27359 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:49:34.655433 27359 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:49:34.655438 27359 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:49:34.655441 27359 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:49:34.655444 27359 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:49:34.655452 27359 net.cpp:124] Setting up pool1\n",
      "I0430 03:49:34.655455 27359 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:49:34.655458 27359 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:49:34.655462 27359 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:49:34.655467 27359 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:49:34.655469 27359 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:49:34.655473 27359 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:49:34.655478 27359 net.cpp:124] Setting up norm1\n",
      "I0430 03:49:34.655483 27359 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:49:34.655485 27359 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:49:34.655488 27359 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:49:34.655493 27359 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:49:34.655495 27359 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:49:34.655499 27359 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:49:34.655835 27359 net.cpp:124] Setting up conv2\n",
      "I0430 03:49:34.655840 27359 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:49:34.655843 27359 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:49:34.655848 27359 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:49:34.655853 27359 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:49:34.655854 27359 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:49:34.655859 27359 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:49:34.655864 27359 net.cpp:124] Setting up relu2\n",
      "I0430 03:49:34.655867 27359 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:49:34.655869 27359 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:49:34.655872 27359 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:49:34.655877 27359 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:49:34.655880 27359 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:49:34.655884 27359 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:49:34.655890 27359 net.cpp:124] Setting up pool2\n",
      "I0430 03:49:34.655894 27359 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:49:34.655895 27359 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:49:34.655899 27359 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:49:34.655903 27359 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:49:34.655906 27359 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:49:34.655910 27359 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:49:34.655915 27359 net.cpp:124] Setting up norm2\n",
      "I0430 03:49:34.655918 27359 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:49:34.655921 27359 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:49:34.655925 27359 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:49:34.655930 27359 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:49:34.655933 27359 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:49:34.655937 27359 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:49:34.656612 27359 net.cpp:124] Setting up conv3\n",
      "I0430 03:49:34.656620 27359 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:49:34.656623 27359 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:49:34.656632 27359 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:49:34.656639 27359 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:49:34.656642 27359 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:49:34.656647 27359 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:49:34.656652 27359 net.cpp:124] Setting up relu3\n",
      "I0430 03:49:34.656656 27359 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:49:34.656659 27359 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:49:34.656662 27359 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:49:34.656668 27359 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:49:34.656671 27359 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:49:34.656675 27359 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:49:34.657404 27359 net.cpp:124] Setting up conv4\n",
      "I0430 03:49:34.657413 27359 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:49:34.657416 27359 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:49:34.657423 27359 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:49:34.657429 27359 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:49:34.657433 27359 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:49:34.657438 27359 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:49:34.657443 27359 net.cpp:124] Setting up relu4\n",
      "I0430 03:49:34.657446 27359 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:49:34.657449 27359 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:49:34.657452 27359 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:49:34.657459 27359 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:49:34.657462 27359 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:49:34.657467 27359 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:49:34.657963 27359 net.cpp:124] Setting up conv5\n",
      "I0430 03:49:34.657973 27359 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:49:34.657975 27359 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:49:34.657984 27359 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:49:34.657989 27359 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:49:34.657991 27359 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:49:34.657997 27359 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:49:34.658001 27359 net.cpp:124] Setting up relu5\n",
      "I0430 03:49:34.658005 27359 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:49:34.658008 27359 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:49:34.658011 27359 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:49:34.658016 27359 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:49:34.658020 27359 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:49:34.658025 27359 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:49:34.658032 27359 net.cpp:124] Setting up pool5\n",
      "I0430 03:49:34.658036 27359 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:49:34.658040 27359 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:49:34.658042 27359 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:49:34.658051 27359 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:49:34.658052 27359 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:49:34.658057 27359 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:49:34.679426 27359 net.cpp:124] Setting up fc6\n",
      "I0430 03:49:34.679452 27359 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:49:34.679456 27359 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:49:34.679466 27359 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:49:34.679476 27359 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:49:34.679479 27359 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:49:34.679488 27359 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:49:34.679507 27359 net.cpp:124] Setting up relu6\n",
      "I0430 03:49:34.679512 27359 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:49:34.679515 27359 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:49:34.679518 27359 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:49:34.679525 27359 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:49:34.679528 27359 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:49:34.679535 27359 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:49:34.679543 27359 net.cpp:124] Setting up drop6\n",
      "I0430 03:49:34.679548 27359 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:49:34.679551 27359 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:49:34.679555 27359 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:49:34.679561 27359 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:49:34.679565 27359 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:49:34.679570 27359 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:49:34.694346 27359 net.cpp:124] Setting up fc7\n",
      "I0430 03:49:34.694367 27359 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:49:34.694370 27359 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:49:34.694377 27359 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:49:34.694384 27359 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:49:34.694386 27359 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:49:34.694391 27359 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:49:34.694397 27359 net.cpp:124] Setting up relu7\n",
      "I0430 03:49:34.694402 27359 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:49:34.694418 27359 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:49:34.694422 27359 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:49:34.694427 27359 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:49:34.694429 27359 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:49:34.694433 27359 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:49:34.694438 27359 net.cpp:124] Setting up drop7\n",
      "I0430 03:49:34.694442 27359 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:49:34.694445 27359 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:49:34.694448 27359 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:49:34.694453 27359 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:49:34.694455 27359 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:49:34.694461 27359 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:49:34.695170 27359 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:49:34.695188 27359 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:49:34.695192 27359 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:49:34.695202 27359 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:49:34.695214 27359 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:49:34.695217 27359 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:49:34.695221 27359 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:49:34.695226 27359 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:49:34.695230 27359 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:49:34.695233 27359 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:49:34.695236 27359 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:49:34.695240 27359 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:49:34.695243 27359 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:49:34.695247 27359 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:49:34.695250 27359 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:49:34.695255 27359 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:49:34.695258 27359 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:49:34.695261 27359 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:49:34.695264 27359 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:49:34.695267 27359 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:49:34.695269 27359 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:49:34.695272 27359 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:49:34.695276 27359 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:49:34.695278 27359 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:49:34.695281 27359 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:49:34.695283 27359 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:49:34.695286 27359 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:49:34.695297 27359 net.cpp:257] Network initialization done.\n",
      "I0430 03:49:34.780814 27359 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:49:34.892544 27359 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:49:34.894975 27359 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:49:34.895012 27359 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:49:34.895015 27359 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/361055.jpg'}, '/tmp/tmpSWIyQH.mat')\n",
      "Processed 1684 windows in 200.008 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.12687, -1.99123, -2.05419, -2.32717, -2.26...\n",
      "ymin                                                     95.904\n",
      "xmin                                                    127.206\n",
      "ymax                                                     363.97\n",
      "xmax                                                    233.434\n",
      "Name: /home/ambika/INF_project/data/couch/361055.jpg, dtype: object\n",
      "prediction    [-2.08614, -2.33409, -1.8533, -2.91463, -2.283...\n",
      "ymin                                                    192.474\n",
      "xmin                                                    127.206\n",
      "ymax                                                     363.97\n",
      "xmax                                                    186.814\n",
      "Name: /home/ambika/INF_project/data/couch/361055.jpg, dtype: object\n",
      "person\n",
      "127.206\t95.904\t233.434\t363.97\n",
      "dog\n",
      "127.206\t192.474\t186.814\t363.97\n",
      "361055\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:52:56.464545 27520 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:52:56.464587 27520 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:52:56.464592 27520 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:52:56.466495 27520 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:52:56.466645 27520 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:52:56.466653 27520 net.cpp:86] Creating Layer data\n",
      "I0430 03:52:56.466658 27520 net.cpp:382] data -> data\n",
      "I0430 03:52:56.466675 27520 net.cpp:124] Setting up data\n",
      "I0430 03:52:56.466681 27520 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:52:56.466684 27520 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:52:56.466688 27520 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:52:56.466696 27520 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:52:56.466699 27520 net.cpp:408] conv1 <- data\n",
      "I0430 03:52:56.466703 27520 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:52:56.466775 27520 net.cpp:124] Setting up conv1\n",
      "I0430 03:52:56.466781 27520 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:52:56.466784 27520 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:52:56.466792 27520 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:52:56.466799 27520 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:52:56.466804 27520 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:52:56.466809 27520 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:52:56.466814 27520 net.cpp:124] Setting up relu1\n",
      "I0430 03:52:56.466817 27520 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:52:56.466820 27520 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:52:56.466822 27520 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:52:56.466826 27520 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:52:56.466830 27520 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:52:56.466832 27520 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:52:56.466841 27520 net.cpp:124] Setting up pool1\n",
      "I0430 03:52:56.466845 27520 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:52:56.466847 27520 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:52:56.466850 27520 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:52:56.466856 27520 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:52:56.466858 27520 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:52:56.466862 27520 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:52:56.466873 27520 net.cpp:124] Setting up norm1\n",
      "I0430 03:52:56.466892 27520 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:52:56.466894 27520 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:52:56.466897 27520 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:52:56.466902 27520 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:52:56.466905 27520 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:52:56.466909 27520 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:52:56.467591 27520 net.cpp:124] Setting up conv2\n",
      "I0430 03:52:56.467630 27520 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:52:56.467636 27520 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:52:56.467653 27520 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:52:56.467665 27520 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:52:56.467669 27520 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:52:56.467677 27520 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:52:56.467689 27520 net.cpp:124] Setting up relu2\n",
      "I0430 03:52:56.467694 27520 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:52:56.467696 27520 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:52:56.467700 27520 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:52:56.467706 27520 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:52:56.467708 27520 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:52:56.467713 27520 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:52:56.467726 27520 net.cpp:124] Setting up pool2\n",
      "I0430 03:52:56.467731 27520 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:52:56.467734 27520 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:52:56.467738 27520 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:52:56.467782 27520 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:52:56.467787 27520 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:52:56.467792 27520 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:52:56.467802 27520 net.cpp:124] Setting up norm2\n",
      "I0430 03:52:56.467808 27520 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:52:56.467810 27520 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:52:56.467813 27520 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:52:56.467828 27520 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:52:56.467833 27520 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:52:56.467839 27520 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:52:56.469174 27520 net.cpp:124] Setting up conv3\n",
      "I0430 03:52:56.469205 27520 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:52:56.469208 27520 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:52:56.469223 27520 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:52:56.469236 27520 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:52:56.469241 27520 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:52:56.469249 27520 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:52:56.469261 27520 net.cpp:124] Setting up relu3\n",
      "I0430 03:52:56.469267 27520 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:52:56.469270 27520 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:52:56.469274 27520 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:52:56.469292 27520 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:52:56.469297 27520 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:52:56.469305 27520 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:52:56.470788 27520 net.cpp:124] Setting up conv4\n",
      "I0430 03:52:56.470842 27520 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:52:56.470850 27520 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:52:56.470867 27520 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:52:56.470887 27520 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:52:56.470892 27520 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:52:56.470903 27520 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:52:56.470919 27520 net.cpp:124] Setting up relu4\n",
      "I0430 03:52:56.470926 27520 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:52:56.470928 27520 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:52:56.470932 27520 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:52:56.470945 27520 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:52:56.470950 27520 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:52:56.470957 27520 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:52:56.471765 27520 net.cpp:124] Setting up conv5\n",
      "I0430 03:52:56.471783 27520 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:52:56.471787 27520 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:52:56.471802 27520 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:52:56.471810 27520 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:52:56.471815 27520 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:52:56.471820 27520 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:52:56.471828 27520 net.cpp:124] Setting up relu5\n",
      "I0430 03:52:56.471832 27520 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:52:56.471835 27520 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:52:56.471838 27520 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:52:56.471844 27520 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:52:56.471848 27520 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:52:56.471853 27520 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:52:56.471863 27520 net.cpp:124] Setting up pool5\n",
      "I0430 03:52:56.471866 27520 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:52:56.471869 27520 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:52:56.471873 27520 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:52:56.471882 27520 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:52:56.471885 27520 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:52:56.471890 27520 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:52:56.496070 27520 net.cpp:124] Setting up fc6\n",
      "I0430 03:52:56.496094 27520 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:52:56.496098 27520 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:52:56.496121 27520 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:52:56.496129 27520 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:52:56.496132 27520 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:52:56.496137 27520 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:52:56.496145 27520 net.cpp:124] Setting up relu6\n",
      "I0430 03:52:56.496147 27520 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:52:56.496150 27520 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:52:56.496152 27520 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:52:56.496156 27520 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:52:56.496158 27520 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:52:56.496161 27520 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:52:56.496166 27520 net.cpp:124] Setting up drop6\n",
      "I0430 03:52:56.496170 27520 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:52:56.496171 27520 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:52:56.496175 27520 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:52:56.496179 27520 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:52:56.496181 27520 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:52:56.496186 27520 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:52:56.505893 27520 net.cpp:124] Setting up fc7\n",
      "I0430 03:52:56.505913 27520 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:52:56.505916 27520 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:52:56.505926 27520 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:52:56.505934 27520 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:52:56.505937 27520 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:52:56.505940 27520 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:52:56.505950 27520 net.cpp:124] Setting up relu7\n",
      "I0430 03:52:56.505952 27520 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:52:56.505954 27520 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:52:56.505956 27520 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:52:56.505959 27520 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:52:56.505961 27520 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:52:56.505964 27520 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:52:56.505967 27520 net.cpp:124] Setting up drop7\n",
      "I0430 03:52:56.505970 27520 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:52:56.505983 27520 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:52:56.505985 27520 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:52:56.505990 27520 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:52:56.505992 27520 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:52:56.505995 27520 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:52:56.506889 27520 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:52:56.506897 27520 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:52:56.506901 27520 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:52:56.506906 27520 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:52:56.506908 27520 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:52:56.506911 27520 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:52:56.506912 27520 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:52:56.506914 27520 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:52:56.506916 27520 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:52:56.506919 27520 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:52:56.506922 27520 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:52:56.506924 27520 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:52:56.506927 27520 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:52:56.506930 27520 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:52:56.506932 27520 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:52:56.506935 27520 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:52:56.506938 27520 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:52:56.506942 27520 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:52:56.506944 27520 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:52:56.506947 27520 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:52:56.506949 27520 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:52:56.506953 27520 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:52:56.506954 27520 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:52:56.506958 27520 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:52:56.506959 27520 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:52:56.506963 27520 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:52:56.506964 27520 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:52:56.506975 27520 net.cpp:257] Network initialization done.\n",
      "I0430 03:52:56.596673 27520 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:52:56.708848 27520 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:52:56.709928 27520 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:52:56.709944 27520 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:52:56.709949 27520 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/166995.jpg'}, '/tmp/tmpn8tDtN.mat')\n",
      "Processed 3432 windows in 397.889 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.073 s.\n",
      "prediction    [-1.78443, -2.55202, -1.91307, -3.12513, -1.70...\n",
      "ymin                                                      55.61\n",
      "xmin                                                     104.52\n",
      "ymax                                                     213.39\n",
      "xmax                                                     273.69\n",
      "Name: /home/ambika/INF_project/data/dog/166995.jpg, dtype: object\n",
      "prediction    [-2.28292, -2.2204, -2.58368, -2.51689, -2.165...\n",
      "ymin                                                     295.47\n",
      "xmin                                                     144.72\n",
      "ymax                                                     412.38\n",
      "xmax                                                     237.51\n",
      "Name: /home/ambika/INF_project/data/dog/166995.jpg, dtype: object\n",
      "dog\n",
      "104.52\t55.61\t273.69\t213.39\n",
      "drum\n",
      "144.72\t295.47\t237.51\t412.38\n",
      "166995\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 03:59:36.613306 27758 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 03:59:36.613344 27758 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 03:59:36.613348 27758 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 03:59:36.615092 27758 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 03:59:36.615175 27758 layer_factory.hpp:77] Creating layer data\n",
      "I0430 03:59:36.615183 27758 net.cpp:86] Creating Layer data\n",
      "I0430 03:59:36.615366 27758 net.cpp:382] data -> data\n",
      "I0430 03:59:36.615382 27758 net.cpp:124] Setting up data\n",
      "I0430 03:59:36.615391 27758 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 03:59:36.615392 27758 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 03:59:36.615394 27758 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 03:59:36.615399 27758 net.cpp:86] Creating Layer conv1\n",
      "I0430 03:59:36.615401 27758 net.cpp:408] conv1 <- data\n",
      "I0430 03:59:36.615406 27758 net.cpp:382] conv1 -> conv1\n",
      "I0430 03:59:36.615605 27758 net.cpp:124] Setting up conv1\n",
      "I0430 03:59:36.615612 27758 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:59:36.615613 27758 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 03:59:36.615620 27758 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 03:59:36.615625 27758 net.cpp:86] Creating Layer relu1\n",
      "I0430 03:59:36.615628 27758 net.cpp:408] relu1 <- conv1\n",
      "I0430 03:59:36.615629 27758 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 03:59:36.615633 27758 net.cpp:124] Setting up relu1\n",
      "I0430 03:59:36.615636 27758 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 03:59:36.615638 27758 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 03:59:36.615639 27758 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 03:59:36.615643 27758 net.cpp:86] Creating Layer pool1\n",
      "I0430 03:59:36.615644 27758 net.cpp:408] pool1 <- conv1\n",
      "I0430 03:59:36.615648 27758 net.cpp:382] pool1 -> pool1\n",
      "I0430 03:59:36.615653 27758 net.cpp:124] Setting up pool1\n",
      "I0430 03:59:36.615655 27758 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:59:36.615658 27758 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 03:59:36.615658 27758 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 03:59:36.615663 27758 net.cpp:86] Creating Layer norm1\n",
      "I0430 03:59:36.615665 27758 net.cpp:408] norm1 <- pool1\n",
      "I0430 03:59:36.615670 27758 net.cpp:382] norm1 -> norm1\n",
      "I0430 03:59:36.615679 27758 net.cpp:124] Setting up norm1\n",
      "I0430 03:59:36.615684 27758 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 03:59:36.615687 27758 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 03:59:36.615691 27758 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 03:59:36.615697 27758 net.cpp:86] Creating Layer conv2\n",
      "I0430 03:59:36.615700 27758 net.cpp:408] conv2 <- norm1\n",
      "I0430 03:59:36.615703 27758 net.cpp:382] conv2 -> conv2\n",
      "I0430 03:59:36.616061 27758 net.cpp:124] Setting up conv2\n",
      "I0430 03:59:36.616067 27758 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:59:36.616070 27758 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 03:59:36.616080 27758 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 03:59:36.616084 27758 net.cpp:86] Creating Layer relu2\n",
      "I0430 03:59:36.616087 27758 net.cpp:408] relu2 <- conv2\n",
      "I0430 03:59:36.616091 27758 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 03:59:36.616094 27758 net.cpp:124] Setting up relu2\n",
      "I0430 03:59:36.616098 27758 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 03:59:36.616101 27758 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 03:59:36.616102 27758 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 03:59:36.616106 27758 net.cpp:86] Creating Layer pool2\n",
      "I0430 03:59:36.616108 27758 net.cpp:408] pool2 <- conv2\n",
      "I0430 03:59:36.616112 27758 net.cpp:382] pool2 -> pool2\n",
      "I0430 03:59:36.616117 27758 net.cpp:124] Setting up pool2\n",
      "I0430 03:59:36.616120 27758 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:59:36.616122 27758 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 03:59:36.616125 27758 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 03:59:36.616130 27758 net.cpp:86] Creating Layer norm2\n",
      "I0430 03:59:36.616133 27758 net.cpp:408] norm2 <- pool2\n",
      "I0430 03:59:36.616137 27758 net.cpp:382] norm2 -> norm2\n",
      "I0430 03:59:36.616140 27758 net.cpp:124] Setting up norm2\n",
      "I0430 03:59:36.616144 27758 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:59:36.616147 27758 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 03:59:36.616148 27758 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 03:59:36.616154 27758 net.cpp:86] Creating Layer conv3\n",
      "I0430 03:59:36.616156 27758 net.cpp:408] conv3 <- norm2\n",
      "I0430 03:59:36.616160 27758 net.cpp:382] conv3 -> conv3\n",
      "I0430 03:59:36.616863 27758 net.cpp:124] Setting up conv3\n",
      "I0430 03:59:36.616873 27758 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:59:36.616876 27758 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 03:59:36.616886 27758 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 03:59:36.616894 27758 net.cpp:86] Creating Layer relu3\n",
      "I0430 03:59:36.616896 27758 net.cpp:408] relu3 <- conv3\n",
      "I0430 03:59:36.616900 27758 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 03:59:36.616905 27758 net.cpp:124] Setting up relu3\n",
      "I0430 03:59:36.616909 27758 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:59:36.616911 27758 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 03:59:36.616914 27758 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 03:59:36.616919 27758 net.cpp:86] Creating Layer conv4\n",
      "I0430 03:59:36.616920 27758 net.cpp:408] conv4 <- conv3\n",
      "I0430 03:59:36.616924 27758 net.cpp:382] conv4 -> conv4\n",
      "I0430 03:59:36.617646 27758 net.cpp:124] Setting up conv4\n",
      "I0430 03:59:36.617655 27758 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:59:36.617660 27758 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 03:59:36.617666 27758 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 03:59:36.617673 27758 net.cpp:86] Creating Layer relu4\n",
      "I0430 03:59:36.617676 27758 net.cpp:408] relu4 <- conv4\n",
      "I0430 03:59:36.617681 27758 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 03:59:36.617686 27758 net.cpp:124] Setting up relu4\n",
      "I0430 03:59:36.617688 27758 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 03:59:36.617691 27758 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 03:59:36.617693 27758 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 03:59:36.617697 27758 net.cpp:86] Creating Layer conv5\n",
      "I0430 03:59:36.617700 27758 net.cpp:408] conv5 <- conv4\n",
      "I0430 03:59:36.617704 27758 net.cpp:382] conv5 -> conv5\n",
      "I0430 03:59:36.618217 27758 net.cpp:124] Setting up conv5\n",
      "I0430 03:59:36.618224 27758 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:59:36.618228 27758 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 03:59:36.618242 27758 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 03:59:36.618245 27758 net.cpp:86] Creating Layer relu5\n",
      "I0430 03:59:36.618248 27758 net.cpp:408] relu5 <- conv5\n",
      "I0430 03:59:36.618252 27758 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 03:59:36.618255 27758 net.cpp:124] Setting up relu5\n",
      "I0430 03:59:36.618259 27758 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 03:59:36.618261 27758 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 03:59:36.618263 27758 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 03:59:36.618268 27758 net.cpp:86] Creating Layer pool5\n",
      "I0430 03:59:36.618270 27758 net.cpp:408] pool5 <- conv5\n",
      "I0430 03:59:36.618274 27758 net.cpp:382] pool5 -> pool5\n",
      "I0430 03:59:36.618280 27758 net.cpp:124] Setting up pool5\n",
      "I0430 03:59:36.618283 27758 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 03:59:36.618285 27758 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 03:59:36.618288 27758 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 03:59:36.618294 27758 net.cpp:86] Creating Layer fc6\n",
      "I0430 03:59:36.618297 27758 net.cpp:408] fc6 <- pool5\n",
      "I0430 03:59:36.618300 27758 net.cpp:382] fc6 -> fc6\n",
      "I0430 03:59:36.639137 27758 net.cpp:124] Setting up fc6\n",
      "I0430 03:59:36.639158 27758 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:59:36.639160 27758 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 03:59:36.639166 27758 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 03:59:36.639173 27758 net.cpp:86] Creating Layer relu6\n",
      "I0430 03:59:36.639174 27758 net.cpp:408] relu6 <- fc6\n",
      "I0430 03:59:36.639178 27758 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 03:59:36.639185 27758 net.cpp:124] Setting up relu6\n",
      "I0430 03:59:36.639188 27758 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:59:36.639189 27758 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 03:59:36.639190 27758 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 03:59:36.639196 27758 net.cpp:86] Creating Layer drop6\n",
      "I0430 03:59:36.639200 27758 net.cpp:408] drop6 <- fc6\n",
      "I0430 03:59:36.639204 27758 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 03:59:36.639217 27758 net.cpp:124] Setting up drop6\n",
      "I0430 03:59:36.639221 27758 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:59:36.639225 27758 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 03:59:36.639228 27758 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 03:59:36.639235 27758 net.cpp:86] Creating Layer fc7\n",
      "I0430 03:59:36.639238 27758 net.cpp:408] fc7 <- fc6\n",
      "I0430 03:59:36.639243 27758 net.cpp:382] fc7 -> fc7\n",
      "I0430 03:59:36.649150 27758 net.cpp:124] Setting up fc7\n",
      "I0430 03:59:36.649181 27758 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:59:36.649188 27758 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 03:59:36.649215 27758 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 03:59:36.649226 27758 net.cpp:86] Creating Layer relu7\n",
      "I0430 03:59:36.649231 27758 net.cpp:408] relu7 <- fc7\n",
      "I0430 03:59:36.649238 27758 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 03:59:36.649247 27758 net.cpp:124] Setting up relu7\n",
      "I0430 03:59:36.649251 27758 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:59:36.649255 27758 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 03:59:36.649256 27758 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 03:59:36.649260 27758 net.cpp:86] Creating Layer drop7\n",
      "I0430 03:59:36.649262 27758 net.cpp:408] drop7 <- fc7\n",
      "I0430 03:59:36.649265 27758 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 03:59:36.649268 27758 net.cpp:124] Setting up drop7\n",
      "I0430 03:59:36.649271 27758 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 03:59:36.649272 27758 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 03:59:36.649274 27758 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 03:59:36.649277 27758 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 03:59:36.649279 27758 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 03:59:36.649282 27758 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 03:59:36.649966 27758 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 03:59:36.649976 27758 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 03:59:36.649979 27758 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 03:59:36.649987 27758 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 03:59:36.649991 27758 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 03:59:36.649996 27758 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 03:59:36.649998 27758 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 03:59:36.650001 27758 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 03:59:36.650003 27758 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 03:59:36.650005 27758 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 03:59:36.650008 27758 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 03:59:36.650010 27758 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 03:59:36.650013 27758 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 03:59:36.650015 27758 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 03:59:36.650018 27758 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 03:59:36.650022 27758 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 03:59:36.650023 27758 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 03:59:36.650027 27758 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 03:59:36.650029 27758 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 03:59:36.650032 27758 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 03:59:36.650034 27758 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 03:59:36.650038 27758 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 03:59:36.650040 27758 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 03:59:36.650043 27758 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 03:59:36.650045 27758 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 03:59:36.650048 27758 net.cpp:202] data does not need backward computation.\n",
      "I0430 03:59:36.650050 27758 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 03:59:36.650063 27758 net.cpp:257] Network initialization done.\n",
      "I0430 03:59:36.894762 27758 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:59:36.992856 27758 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 03:59:36.993839 27758 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 03:59:36.993849 27758 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 03:59:36.993852 27758 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/75990.jpg'}, '/tmp/tmpHcdhoW.mat')\n",
      "Processed 2925 windows in 319.545 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.47849, -2.57438, -1.68632, -2.07464, -2.06...\n",
      "ymin                                                        172\n",
      "xmin                                                         54\n",
      "ymax                                                        334\n",
      "xmax                                                        104\n",
      "Name: /home/ambika/INF_project/data/horse/75990.jpg, dtype: object\n",
      "prediction    [-2.23021, -2.14385, -2.8318, -3.12603, -2.084...\n",
      "ymin                                                        120\n",
      "xmin                                                        214\n",
      "ymax                                                        316\n",
      "xmax                                                        396\n",
      "Name: /home/ambika/INF_project/data/horse/75990.jpg, dtype: object\n",
      "person\n",
      "54\t172\t104\t334\n",
      "horse\n",
      "214\t120\t396\t316\n",
      "75990\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:04:58.044837 27954 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:04:58.044857 27954 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:04:58.044869 27954 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:04:58.045954 27954 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:04:58.046030 27954 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:04:58.046037 27954 net.cpp:86] Creating Layer data\n",
      "I0430 04:04:58.046041 27954 net.cpp:382] data -> data\n",
      "I0430 04:04:58.046056 27954 net.cpp:124] Setting up data\n",
      "I0430 04:04:58.046061 27954 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:04:58.046063 27954 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:04:58.046067 27954 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:04:58.046074 27954 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:04:58.046077 27954 net.cpp:408] conv1 <- data\n",
      "I0430 04:04:58.046082 27954 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:04:58.046142 27954 net.cpp:124] Setting up conv1\n",
      "I0430 04:04:58.046147 27954 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:04:58.046150 27954 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:04:58.046159 27954 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:04:58.046164 27954 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:04:58.046166 27954 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:04:58.046169 27954 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:04:58.046174 27954 net.cpp:124] Setting up relu1\n",
      "I0430 04:04:58.046177 27954 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:04:58.046180 27954 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:04:58.046181 27954 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:04:58.046186 27954 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:04:58.046188 27954 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:04:58.046191 27954 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:04:58.046198 27954 net.cpp:124] Setting up pool1\n",
      "I0430 04:04:58.046201 27954 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:04:58.046203 27954 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:04:58.046205 27954 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:04:58.046211 27954 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:04:58.046212 27954 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:04:58.046216 27954 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:04:58.046221 27954 net.cpp:124] Setting up norm1\n",
      "I0430 04:04:58.046223 27954 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:04:58.046226 27954 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:04:58.046228 27954 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:04:58.046232 27954 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:04:58.046234 27954 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:04:58.046238 27954 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:04:58.046574 27954 net.cpp:124] Setting up conv2\n",
      "I0430 04:04:58.046579 27954 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:04:58.046582 27954 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:04:58.046587 27954 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:04:58.046591 27954 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:04:58.046593 27954 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:04:58.046597 27954 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:04:58.046600 27954 net.cpp:124] Setting up relu2\n",
      "I0430 04:04:58.046603 27954 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:04:58.046605 27954 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:04:58.046608 27954 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:04:58.046612 27954 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:04:58.046615 27954 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:04:58.046618 27954 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:04:58.046623 27954 net.cpp:124] Setting up pool2\n",
      "I0430 04:04:58.046627 27954 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:04:58.046629 27954 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:04:58.046632 27954 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:04:58.046636 27954 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:04:58.046638 27954 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:04:58.046641 27954 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:04:58.046646 27954 net.cpp:124] Setting up norm2\n",
      "I0430 04:04:58.046649 27954 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:04:58.046653 27954 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:04:58.046654 27954 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:04:58.046658 27954 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:04:58.046660 27954 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:04:58.046663 27954 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:04:58.047385 27954 net.cpp:124] Setting up conv3\n",
      "I0430 04:04:58.047395 27954 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:04:58.047399 27954 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:04:58.047405 27954 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:04:58.047411 27954 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:04:58.047415 27954 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:04:58.047418 27954 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:04:58.047422 27954 net.cpp:124] Setting up relu3\n",
      "I0430 04:04:58.047426 27954 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:04:58.047428 27954 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:04:58.047430 27954 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:04:58.047435 27954 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:04:58.047437 27954 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:04:58.047441 27954 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:04:58.048158 27954 net.cpp:124] Setting up conv4\n",
      "I0430 04:04:58.048168 27954 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:04:58.048171 27954 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:04:58.048177 27954 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:04:58.048183 27954 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:04:58.048189 27954 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:04:58.048197 27954 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:04:58.048205 27954 net.cpp:124] Setting up relu4\n",
      "I0430 04:04:58.048208 27954 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:04:58.048213 27954 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:04:58.048215 27954 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:04:58.048221 27954 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:04:58.048224 27954 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:04:58.048228 27954 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:04:58.048710 27954 net.cpp:124] Setting up conv5\n",
      "I0430 04:04:58.048718 27954 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:04:58.048720 27954 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:04:58.048727 27954 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:04:58.048732 27954 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:04:58.048734 27954 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:04:58.048738 27954 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:04:58.048741 27954 net.cpp:124] Setting up relu5\n",
      "I0430 04:04:58.048744 27954 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:04:58.048746 27954 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:04:58.048749 27954 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:04:58.048753 27954 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:04:58.048756 27954 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:04:58.048759 27954 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:04:58.048766 27954 net.cpp:124] Setting up pool5\n",
      "I0430 04:04:58.048770 27954 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:04:58.048773 27954 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:04:58.048774 27954 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:04:58.048780 27954 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:04:58.048784 27954 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:04:58.048787 27954 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:04:58.069568 27954 net.cpp:124] Setting up fc6\n",
      "I0430 04:04:58.069584 27954 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:04:58.069587 27954 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:04:58.069594 27954 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:04:58.069602 27954 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:04:58.069604 27954 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:04:58.069609 27954 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:04:58.069615 27954 net.cpp:124] Setting up relu6\n",
      "I0430 04:04:58.069618 27954 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:04:58.069622 27954 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:04:58.069624 27954 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:04:58.069629 27954 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:04:58.069631 27954 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:04:58.069636 27954 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:04:58.069641 27954 net.cpp:124] Setting up drop6\n",
      "I0430 04:04:58.069644 27954 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:04:58.069648 27954 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:04:58.069649 27954 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:04:58.069653 27954 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:04:58.069656 27954 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:04:58.069659 27954 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:04:58.079857 27954 net.cpp:124] Setting up fc7\n",
      "I0430 04:04:58.079881 27954 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:04:58.079885 27954 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:04:58.079893 27954 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:04:58.079903 27954 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:04:58.079907 27954 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:04:58.079912 27954 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:04:58.079919 27954 net.cpp:124] Setting up relu7\n",
      "I0430 04:04:58.079922 27954 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:04:58.079926 27954 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:04:58.079927 27954 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:04:58.079931 27954 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:04:58.079934 27954 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:04:58.079938 27954 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:04:58.079943 27954 net.cpp:124] Setting up drop7\n",
      "I0430 04:04:58.079946 27954 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:04:58.079948 27954 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:04:58.079952 27954 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:04:58.079954 27954 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:04:58.079957 27954 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:04:58.079960 27954 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:04:58.080626 27954 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:04:58.080634 27954 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:04:58.080637 27954 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:04:58.080644 27954 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:04:58.080647 27954 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:04:58.080649 27954 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:04:58.080652 27954 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:04:58.080655 27954 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:04:58.080658 27954 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:04:58.080660 27954 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:04:58.080663 27954 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:04:58.080667 27954 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:04:58.080668 27954 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:04:58.080672 27954 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:04:58.080674 27954 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:04:58.080704 27954 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:04:58.080706 27954 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:04:58.080710 27954 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:04:58.080713 27954 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:04:58.080715 27954 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:04:58.080718 27954 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:04:58.080721 27954 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:04:58.080724 27954 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:04:58.080726 27954 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:04:58.080729 27954 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:04:58.080731 27954 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:04:58.080734 27954 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:04:58.080744 27954 net.cpp:257] Network initialization done.\n",
      "I0430 04:04:58.164477 27954 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:04:58.259532 27954 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:04:58.261270 27954 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:04:58.261291 27954 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:04:58.261292 27954 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/579457.jpg'}, '/tmp/tmpHcgzD8.mat')\n",
      "Processed 1964 windows in 220.720 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-2.79083, -2.46569, -1.937, -2.20538, -2.1070...\n",
      "ymin                                                          0\n",
      "xmin                                                        253\n",
      "ymax                                                        333\n",
      "xmax                                                        364\n",
      "Name: /home/ambika/INF_project/data/person/579457.jpg, dtype: object\n",
      "prediction    [-1.87335, -1.9717, -2.4248, -2.71757, -1.8608...\n",
      "ymin                                                         18\n",
      "xmin                                                        111\n",
      "ymax                                                        333\n",
      "xmax                                                        274\n",
      "Name: /home/ambika/INF_project/data/person/579457.jpg, dtype: object\n",
      "person\n",
      "253\t0\t364\t333\n",
      "horse\n",
      "111\t18\t274\t333\n",
      "579457\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:08:40.459640 28151 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:08:40.459661 28151 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:08:40.459666 28151 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:08:40.460739 28151 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:08:40.460839 28151 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:08:40.460851 28151 net.cpp:86] Creating Layer data\n",
      "I0430 04:08:40.460856 28151 net.cpp:382] data -> data\n",
      "I0430 04:08:40.460870 28151 net.cpp:124] Setting up data\n",
      "I0430 04:08:40.460876 28151 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:08:40.460880 28151 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:08:40.460885 28151 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:08:40.460891 28151 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:08:40.460894 28151 net.cpp:408] conv1 <- data\n",
      "I0430 04:08:40.460901 28151 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:08:40.460971 28151 net.cpp:124] Setting up conv1\n",
      "I0430 04:08:40.460978 28151 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:08:40.460980 28151 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:08:40.460989 28151 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:08:40.460995 28151 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:08:40.460999 28151 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:08:40.461004 28151 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:08:40.461009 28151 net.cpp:124] Setting up relu1\n",
      "I0430 04:08:40.461012 28151 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:08:40.461015 28151 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:08:40.461019 28151 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:08:40.461024 28151 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:08:40.461026 28151 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:08:40.461031 28151 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:08:40.461038 28151 net.cpp:124] Setting up pool1\n",
      "I0430 04:08:40.461043 28151 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:08:40.461046 28151 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:08:40.461050 28151 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:08:40.461055 28151 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:08:40.461058 28151 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:08:40.461063 28151 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:08:40.461069 28151 net.cpp:124] Setting up norm1\n",
      "I0430 04:08:40.461073 28151 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:08:40.461076 28151 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:08:40.461079 28151 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:08:40.461086 28151 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:08:40.461088 28151 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:08:40.461093 28151 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:08:40.461424 28151 net.cpp:124] Setting up conv2\n",
      "I0430 04:08:40.461431 28151 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:08:40.461436 28151 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:08:40.461442 28151 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:08:40.461447 28151 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:08:40.461449 28151 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:08:40.461454 28151 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:08:40.461459 28151 net.cpp:124] Setting up relu2\n",
      "I0430 04:08:40.461463 28151 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:08:40.461467 28151 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:08:40.461470 28151 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:08:40.461477 28151 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:08:40.461479 28151 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:08:40.461484 28151 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:08:40.461490 28151 net.cpp:124] Setting up pool2\n",
      "I0430 04:08:40.461494 28151 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:08:40.461498 28151 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:08:40.461500 28151 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:08:40.461506 28151 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:08:40.461509 28151 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:08:40.461514 28151 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:08:40.461519 28151 net.cpp:124] Setting up norm2\n",
      "I0430 04:08:40.461524 28151 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:08:40.461526 28151 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:08:40.461530 28151 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:08:40.461536 28151 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:08:40.461539 28151 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:08:40.461544 28151 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:08:40.462220 28151 net.cpp:124] Setting up conv3\n",
      "I0430 04:08:40.462230 28151 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:08:40.462234 28151 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:08:40.462241 28151 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:08:40.462247 28151 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:08:40.462250 28151 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:08:40.462255 28151 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:08:40.462260 28151 net.cpp:124] Setting up relu3\n",
      "I0430 04:08:40.462265 28151 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:08:40.462268 28151 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:08:40.462271 28151 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:08:40.462280 28151 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:08:40.462282 28151 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:08:40.462287 28151 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:08:40.463012 28151 net.cpp:124] Setting up conv4\n",
      "I0430 04:08:40.463021 28151 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:08:40.463026 28151 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:08:40.463032 28151 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:08:40.463037 28151 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:08:40.463039 28151 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:08:40.463044 28151 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:08:40.463049 28151 net.cpp:124] Setting up relu4\n",
      "I0430 04:08:40.463054 28151 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:08:40.463057 28151 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:08:40.463060 28151 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:08:40.463068 28151 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:08:40.463070 28151 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:08:40.463075 28151 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:08:40.463583 28151 net.cpp:124] Setting up conv5\n",
      "I0430 04:08:40.463591 28151 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:08:40.463595 28151 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:08:40.463605 28151 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:08:40.463610 28151 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:08:40.463613 28151 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:08:40.463618 28151 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:08:40.463624 28151 net.cpp:124] Setting up relu5\n",
      "I0430 04:08:40.463627 28151 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:08:40.463630 28151 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:08:40.463634 28151 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:08:40.463640 28151 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:08:40.463644 28151 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:08:40.463649 28151 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:08:40.463656 28151 net.cpp:124] Setting up pool5\n",
      "I0430 04:08:40.463661 28151 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:08:40.463665 28151 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:08:40.463667 28151 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:08:40.463675 28151 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:08:40.463677 28151 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:08:40.463683 28151 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:08:40.485620 28151 net.cpp:124] Setting up fc6\n",
      "I0430 04:08:40.485651 28151 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:08:40.485657 28151 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:08:40.485676 28151 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:08:40.485687 28151 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:08:40.485692 28151 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:08:40.485699 28151 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:08:40.485709 28151 net.cpp:124] Setting up relu6\n",
      "I0430 04:08:40.485713 28151 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:08:40.485716 28151 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:08:40.485719 28151 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:08:40.485726 28151 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:08:40.485729 28151 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:08:40.485736 28151 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:08:40.485754 28151 net.cpp:124] Setting up drop6\n",
      "I0430 04:08:40.485757 28151 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:08:40.485760 28151 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:08:40.485764 28151 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:08:40.485770 28151 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:08:40.485774 28151 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:08:40.485779 28151 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:08:40.495543 28151 net.cpp:124] Setting up fc7\n",
      "I0430 04:08:40.495564 28151 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:08:40.495569 28151 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:08:40.495580 28151 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:08:40.495590 28151 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:08:40.495594 28151 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:08:40.495602 28151 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:08:40.495611 28151 net.cpp:124] Setting up relu7\n",
      "I0430 04:08:40.495616 28151 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:08:40.495620 28151 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:08:40.495622 28151 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:08:40.495630 28151 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:08:40.495641 28151 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:08:40.495651 28151 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:08:40.495656 28151 net.cpp:124] Setting up drop7\n",
      "I0430 04:08:40.495661 28151 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:08:40.495663 28151 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:08:40.495667 28151 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:08:40.495673 28151 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:08:40.495676 28151 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:08:40.495682 28151 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:08:40.496599 28151 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:08:40.496613 28151 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:08:40.496618 28151 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:08:40.496625 28151 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:08:40.496630 28151 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:08:40.496634 28151 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:08:40.496637 28151 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:08:40.496641 28151 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:08:40.496644 28151 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:08:40.496649 28151 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:08:40.496652 28151 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:08:40.496655 28151 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:08:40.496659 28151 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:08:40.496662 28151 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:08:40.496666 28151 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:08:40.496670 28151 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:08:40.496673 28151 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:08:40.496676 28151 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:08:40.496680 28151 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:08:40.496683 28151 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:08:40.496687 28151 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:08:40.496690 28151 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:08:40.496695 28151 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:08:40.496697 28151 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:08:40.496701 28151 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:08:40.496704 28151 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:08:40.496707 28151 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:08:40.496719 28151 net.cpp:257] Network initialization done.\n",
      "I0430 04:08:40.577352 28151 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:08:40.671509 28151 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:08:40.672595 28151 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:08:40.672608 28151 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:08:40.672613 28151 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/140292.jpg'}, '/tmp/tmpLPaRTl.mat')\n",
      "Processed 2507 windows in 287.048 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.75152, -2.95893, -2.26777, -2.7534, -2.284...\n",
      "ymin                                                        229\n",
      "xmin                                                        203\n",
      "ymax                                                        312\n",
      "xmax                                                        274\n",
      "Name: /home/ambika/INF_project/data/train/140292.jpg, dtype: object\n",
      "prediction    [-3.00384, -3.06812, -2.05282, -2.80388, -2.23...\n",
      "ymin                                                        216\n",
      "xmin                                                        119\n",
      "ymax                                                        312\n",
      "xmax                                                        274\n",
      "Name: /home/ambika/INF_project/data/train/140292.jpg, dtype: object\n",
      "train\n",
      "203\t229\t274\t312\n",
      "chain saw\n",
      "119\t216\t274\t312\n",
      "140292\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:13:29.290360 28378 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:13:29.290381 28378 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:13:29.290385 28378 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:13:29.291538 28378 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:13:29.291626 28378 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:13:29.291633 28378 net.cpp:86] Creating Layer data\n",
      "I0430 04:13:29.291638 28378 net.cpp:382] data -> data\n",
      "I0430 04:13:29.291651 28378 net.cpp:124] Setting up data\n",
      "I0430 04:13:29.291658 28378 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:13:29.291661 28378 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:13:29.291666 28378 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:13:29.291672 28378 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:13:29.291676 28378 net.cpp:408] conv1 <- data\n",
      "I0430 04:13:29.291681 28378 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:13:29.291741 28378 net.cpp:124] Setting up conv1\n",
      "I0430 04:13:29.291748 28378 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:13:29.291750 28378 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:13:29.291759 28378 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:13:29.291764 28378 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:13:29.291766 28378 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:13:29.291771 28378 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:13:29.291776 28378 net.cpp:124] Setting up relu1\n",
      "I0430 04:13:29.291780 28378 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:13:29.291784 28378 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:13:29.291786 28378 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:13:29.291791 28378 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:13:29.291793 28378 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:13:29.291798 28378 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:13:29.291805 28378 net.cpp:124] Setting up pool1\n",
      "I0430 04:13:29.291810 28378 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:13:29.291812 28378 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:13:29.291815 28378 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:13:29.291821 28378 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:13:29.291824 28378 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:13:29.291828 28378 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:13:29.291834 28378 net.cpp:124] Setting up norm1\n",
      "I0430 04:13:29.291839 28378 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:13:29.291841 28378 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:13:29.291844 28378 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:13:29.291849 28378 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:13:29.291852 28378 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:13:29.291857 28378 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:13:29.292207 28378 net.cpp:124] Setting up conv2\n",
      "I0430 04:13:29.292212 28378 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:13:29.292217 28378 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:13:29.292223 28378 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:13:29.292228 28378 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:13:29.292230 28378 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:13:29.292235 28378 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:13:29.292239 28378 net.cpp:124] Setting up relu2\n",
      "I0430 04:13:29.292244 28378 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:13:29.292246 28378 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:13:29.292249 28378 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:13:29.292254 28378 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:13:29.292256 28378 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:13:29.292261 28378 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:13:29.292268 28378 net.cpp:124] Setting up pool2\n",
      "I0430 04:13:29.292271 28378 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:13:29.292274 28378 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:13:29.292278 28378 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:13:29.292284 28378 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:13:29.292286 28378 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:13:29.292290 28378 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:13:29.292296 28378 net.cpp:124] Setting up norm2\n",
      "I0430 04:13:29.292300 28378 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:13:29.292304 28378 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:13:29.292306 28378 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:13:29.292312 28378 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:13:29.292315 28378 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:13:29.292320 28378 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:13:29.293046 28378 net.cpp:124] Setting up conv3\n",
      "I0430 04:13:29.293071 28378 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:13:29.293077 28378 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:13:29.293089 28378 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:13:29.293099 28378 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:13:29.293102 28378 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:13:29.293109 28378 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:13:29.293118 28378 net.cpp:124] Setting up relu3\n",
      "I0430 04:13:29.293123 28378 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:13:29.293125 28378 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:13:29.293128 28378 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:13:29.293138 28378 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:13:29.293140 28378 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:13:29.293145 28378 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:13:29.294050 28378 net.cpp:124] Setting up conv4\n",
      "I0430 04:13:29.294072 28378 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:13:29.294076 28378 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:13:29.294085 28378 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:13:29.294093 28378 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:13:29.294097 28378 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:13:29.294104 28378 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:13:29.294112 28378 net.cpp:124] Setting up relu4\n",
      "I0430 04:13:29.294118 28378 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:13:29.294121 28378 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:13:29.294126 28378 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:13:29.294134 28378 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:13:29.294137 28378 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:13:29.294140 28378 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:13:29.294632 28378 net.cpp:124] Setting up conv5\n",
      "I0430 04:13:29.294639 28378 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:13:29.294641 28378 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:13:29.294651 28378 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:13:29.294654 28378 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:13:29.294657 28378 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:13:29.294661 28378 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:13:29.294664 28378 net.cpp:124] Setting up relu5\n",
      "I0430 04:13:29.294667 28378 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:13:29.294669 28378 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:13:29.294672 28378 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:13:29.294689 28378 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:13:29.294692 28378 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:13:29.294697 28378 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:13:29.294703 28378 net.cpp:124] Setting up pool5\n",
      "I0430 04:13:29.294706 28378 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:13:29.294708 28378 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:13:29.294710 28378 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:13:29.294718 28378 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:13:29.294719 28378 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:13:29.294723 28378 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:13:29.319380 28378 net.cpp:124] Setting up fc6\n",
      "I0430 04:13:29.319401 28378 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:13:29.319404 28378 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:13:29.319412 28378 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:13:29.319419 28378 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:13:29.319422 28378 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:13:29.319427 28378 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:13:29.319432 28378 net.cpp:124] Setting up relu6\n",
      "I0430 04:13:29.319434 28378 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:13:29.319437 28378 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:13:29.319437 28378 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:13:29.319442 28378 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:13:29.319443 28378 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:13:29.319445 28378 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:13:29.319452 28378 net.cpp:124] Setting up drop6\n",
      "I0430 04:13:29.319459 28378 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:13:29.319461 28378 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:13:29.319464 28378 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:13:29.319468 28378 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:13:29.319470 28378 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:13:29.319474 28378 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:13:29.329274 28378 net.cpp:124] Setting up fc7\n",
      "I0430 04:13:29.329298 28378 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:13:29.329303 28378 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:13:29.329314 28378 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:13:29.329324 28378 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:13:29.329327 28378 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:13:29.329337 28378 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:13:29.329344 28378 net.cpp:124] Setting up relu7\n",
      "I0430 04:13:29.329349 28378 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:13:29.329352 28378 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:13:29.329355 28378 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:13:29.329361 28378 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:13:29.329363 28378 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:13:29.329370 28378 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:13:29.329375 28378 net.cpp:124] Setting up drop7\n",
      "I0430 04:13:29.329380 28378 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:13:29.329381 28378 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:13:29.329385 28378 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:13:29.329391 28378 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:13:29.329393 28378 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:13:29.329397 28378 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:13:29.330052 28378 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:13:29.330063 28378 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:13:29.330066 28378 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:13:29.330075 28378 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:13:29.330077 28378 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:13:29.330081 28378 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:13:29.330085 28378 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:13:29.330088 28378 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:13:29.330091 28378 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:13:29.330096 28378 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:13:29.330098 28378 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:13:29.330102 28378 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:13:29.330106 28378 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:13:29.330109 28378 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:13:29.330112 28378 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:13:29.330116 28378 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:13:29.330119 28378 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:13:29.330122 28378 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:13:29.330127 28378 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:13:29.330129 28378 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:13:29.330132 28378 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:13:29.330137 28378 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:13:29.330139 28378 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:13:29.330142 28378 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:13:29.330147 28378 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:13:29.330149 28378 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:13:29.330152 28378 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:13:29.330164 28378 net.cpp:257] Network initialization done.\n",
      "I0430 04:13:29.417511 28378 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:13:29.520774 28378 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:13:29.522409 28378 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:13:29.522439 28378 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:13:29.522444 28378 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/436280.jpg'}, '/tmp/tmpI6Ba9M.mat')\n",
      "Processed 536 windows in 66.424 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-2.70329, 4.37633, -2.357, -2.00251, -2.24502...\n",
      "ymin                                                         86\n",
      "xmin                                                          0\n",
      "ymax                                                        257\n",
      "xmax                                                        488\n",
      "Name: /home/ambika/INF_project/data/airplane/436280.jpg, dtype: object\n",
      "prediction    [-2.49851, -2.25128, -1.85246, -2.07048, -3.14...\n",
      "ymin                                                         86\n",
      "xmin                                                        372\n",
      "ymax                                                        131\n",
      "xmax                                                        488\n",
      "Name: /home/ambika/INF_project/data/airplane/436280.jpg, dtype: object\n",
      "airplane\n",
      "0\t86\t488\t257\n",
      "volleyball\n",
      "372\t86\t488\t131\n",
      "436280\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:14:37.361825 28504 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:14:37.361847 28504 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:14:37.361850 28504 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:14:37.362979 28504 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:14:37.363096 28504 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:14:37.363106 28504 net.cpp:86] Creating Layer data\n",
      "I0430 04:14:37.363111 28504 net.cpp:382] data -> data\n",
      "I0430 04:14:37.363123 28504 net.cpp:124] Setting up data\n",
      "I0430 04:14:37.363129 28504 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:14:37.363132 28504 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:14:37.363137 28504 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:14:37.363142 28504 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:14:37.363145 28504 net.cpp:408] conv1 <- data\n",
      "I0430 04:14:37.363150 28504 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:14:37.363242 28504 net.cpp:124] Setting up conv1\n",
      "I0430 04:14:37.363250 28504 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:14:37.363253 28504 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:14:37.363261 28504 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:14:37.363265 28504 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:14:37.363267 28504 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:14:37.363270 28504 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:14:37.363275 28504 net.cpp:124] Setting up relu1\n",
      "I0430 04:14:37.363276 28504 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:14:37.363278 28504 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:14:37.363281 28504 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:14:37.363286 28504 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:14:37.363287 28504 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:14:37.363291 28504 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:14:37.363297 28504 net.cpp:124] Setting up pool1\n",
      "I0430 04:14:37.363301 28504 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:14:37.363303 28504 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:14:37.363306 28504 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:14:37.363309 28504 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:14:37.363312 28504 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:14:37.363315 28504 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:14:37.363320 28504 net.cpp:124] Setting up norm1\n",
      "I0430 04:14:37.363323 28504 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:14:37.363327 28504 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:14:37.363328 28504 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:14:37.363332 28504 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:14:37.363334 28504 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:14:37.363338 28504 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:14:37.363690 28504 net.cpp:124] Setting up conv2\n",
      "I0430 04:14:37.363696 28504 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:14:37.363700 28504 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:14:37.363709 28504 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:14:37.363714 28504 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:14:37.363716 28504 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:14:37.363720 28504 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:14:37.363724 28504 net.cpp:124] Setting up relu2\n",
      "I0430 04:14:37.363728 28504 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:14:37.363729 28504 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:14:37.363732 28504 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:14:37.363735 28504 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:14:37.363737 28504 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:14:37.363740 28504 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:14:37.363746 28504 net.cpp:124] Setting up pool2\n",
      "I0430 04:14:37.363749 28504 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:14:37.363751 28504 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:14:37.363754 28504 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:14:37.363759 28504 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:14:37.363762 28504 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:14:37.363765 28504 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:14:37.363770 28504 net.cpp:124] Setting up norm2\n",
      "I0430 04:14:37.363773 28504 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:14:37.363775 28504 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:14:37.363777 28504 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:14:37.363783 28504 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:14:37.363785 28504 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:14:37.363790 28504 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:14:37.364485 28504 net.cpp:124] Setting up conv3\n",
      "I0430 04:14:37.364495 28504 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:14:37.364498 28504 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:14:37.364508 28504 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:14:37.364516 28504 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:14:37.364518 28504 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:14:37.364522 28504 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:14:37.364527 28504 net.cpp:124] Setting up relu3\n",
      "I0430 04:14:37.364531 28504 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:14:37.364532 28504 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:14:37.364536 28504 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:14:37.364542 28504 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:14:37.364544 28504 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:14:37.364547 28504 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:14:37.365290 28504 net.cpp:124] Setting up conv4\n",
      "I0430 04:14:37.365299 28504 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:14:37.365303 28504 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:14:37.365310 28504 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:14:37.365317 28504 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:14:37.365320 28504 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:14:37.365324 28504 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:14:37.365329 28504 net.cpp:124] Setting up relu4\n",
      "I0430 04:14:37.365332 28504 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:14:37.365334 28504 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:14:37.365336 28504 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:14:37.365342 28504 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:14:37.365345 28504 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:14:37.365348 28504 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:14:37.365854 28504 net.cpp:124] Setting up conv5\n",
      "I0430 04:14:37.365860 28504 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:14:37.365864 28504 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:14:37.365875 28504 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:14:37.365880 28504 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:14:37.365883 28504 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:14:37.365886 28504 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:14:37.365891 28504 net.cpp:124] Setting up relu5\n",
      "I0430 04:14:37.365895 28504 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:14:37.365896 28504 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:14:37.365898 28504 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:14:37.365902 28504 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:14:37.365905 28504 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:14:37.365909 28504 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:14:37.365916 28504 net.cpp:124] Setting up pool5\n",
      "I0430 04:14:37.365919 28504 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:14:37.365922 28504 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:14:37.365924 28504 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:14:37.365931 28504 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:14:37.365932 28504 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:14:37.365936 28504 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:14:37.389763 28504 net.cpp:124] Setting up fc6\n",
      "I0430 04:14:37.389783 28504 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:14:37.389786 28504 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:14:37.389793 28504 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:14:37.389799 28504 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:14:37.389802 28504 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:14:37.389806 28504 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:14:37.389811 28504 net.cpp:124] Setting up relu6\n",
      "I0430 04:14:37.389816 28504 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:14:37.389820 28504 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:14:37.389823 28504 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:14:37.389829 28504 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:14:37.389832 28504 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:14:37.389835 28504 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:14:37.389842 28504 net.cpp:124] Setting up drop6\n",
      "I0430 04:14:37.389847 28504 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:14:37.389849 28504 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:14:37.389853 28504 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:14:37.389860 28504 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:14:37.389864 28504 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:14:37.389868 28504 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:14:37.399449 28504 net.cpp:124] Setting up fc7\n",
      "I0430 04:14:37.399469 28504 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:14:37.399474 28504 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:14:37.399485 28504 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:14:37.399497 28504 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:14:37.399502 28504 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:14:37.399508 28504 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:14:37.399519 28504 net.cpp:124] Setting up relu7\n",
      "I0430 04:14:37.399524 28504 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:14:37.399528 28504 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:14:37.399531 28504 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:14:37.399538 28504 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:14:37.399541 28504 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:14:37.399545 28504 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:14:37.399552 28504 net.cpp:124] Setting up drop7\n",
      "I0430 04:14:37.399557 28504 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:14:37.399560 28504 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:14:37.399564 28504 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:14:37.399569 28504 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:14:37.399571 28504 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:14:37.399575 28504 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:14:37.400262 28504 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:14:37.400280 28504 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:14:37.400283 28504 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:14:37.400291 28504 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:14:37.400295 28504 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:14:37.400298 28504 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:14:37.400300 28504 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:14:37.400303 28504 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:14:37.400306 28504 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:14:37.400310 28504 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:14:37.400315 28504 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:14:37.400319 28504 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:14:37.400323 28504 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:14:37.400326 28504 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:14:37.400331 28504 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:14:37.400333 28504 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:14:37.400337 28504 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:14:37.400341 28504 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:14:37.400346 28504 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:14:37.400348 28504 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:14:37.400352 28504 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:14:37.400355 28504 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:14:37.400359 28504 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:14:37.400362 28504 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:14:37.400367 28504 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:14:37.400370 28504 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:14:37.400373 28504 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:14:37.400389 28504 net.cpp:257] Network initialization done.\n",
      "I0430 04:14:37.488375 28504 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:14:37.586716 28504 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:14:37.587599 28504 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:14:37.587608 28504 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:14:37.587611 28504 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/74711.jpg'}, '/tmp/tmpCai571.mat')\n",
      "Processed 1488 windows in 183.881 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-1.80213, -1.7041, -2.13883, -1.95983, -1.232...\n",
      "ymin                                                         98\n",
      "xmin                                                         82\n",
      "ymax                                                        198\n",
      "xmax                                                        207\n",
      "Name: /home/ambika/INF_project/data/bird/74711.jpg, dtype: object\n",
      "prediction    [-1.89601, -2.02968, -1.92862, -1.03522, -1.34...\n",
      "ymin                                                        211\n",
      "xmin                                                        283\n",
      "ymax                                                        255\n",
      "xmax                                                        386\n",
      "Name: /home/ambika/INF_project/data/bird/74711.jpg, dtype: object\n",
      "bird\n",
      "82\t98\t207\t198\n",
      "hippopotamus\n",
      "283\t211\t386\t255\n",
      "74711\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:17:42.948206 28706 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:17:42.948226 28706 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:17:42.948230 28706 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:17:42.949306 28706 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:17:42.949379 28706 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:17:42.949389 28706 net.cpp:86] Creating Layer data\n",
      "I0430 04:17:42.949393 28706 net.cpp:382] data -> data\n",
      "I0430 04:17:42.949405 28706 net.cpp:124] Setting up data\n",
      "I0430 04:17:42.949410 28706 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:17:42.949414 28706 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:17:42.949416 28706 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:17:42.949421 28706 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:17:42.949424 28706 net.cpp:408] conv1 <- data\n",
      "I0430 04:17:42.949429 28706 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:17:42.949484 28706 net.cpp:124] Setting up conv1\n",
      "I0430 04:17:42.949489 28706 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:17:42.949491 28706 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:17:42.949502 28706 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:17:42.949508 28706 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:17:42.949511 28706 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:17:42.949514 28706 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:17:42.949518 28706 net.cpp:124] Setting up relu1\n",
      "I0430 04:17:42.949522 28706 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:17:42.949524 28706 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:17:42.949527 28706 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:17:42.949530 28706 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:17:42.949532 28706 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:17:42.949535 28706 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:17:42.949542 28706 net.cpp:124] Setting up pool1\n",
      "I0430 04:17:42.949545 28706 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:17:42.949548 28706 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:17:42.949550 28706 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:17:42.949555 28706 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:17:42.949558 28706 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:17:42.949560 28706 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:17:42.949565 28706 net.cpp:124] Setting up norm1\n",
      "I0430 04:17:42.949568 28706 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:17:42.949571 28706 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:17:42.949573 28706 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:17:42.949578 28706 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:17:42.949579 28706 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:17:42.949584 28706 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:17:42.949905 28706 net.cpp:124] Setting up conv2\n",
      "I0430 04:17:42.949909 28706 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:17:42.949913 28706 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:17:42.949918 28706 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:17:42.949921 28706 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:17:42.949923 28706 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:17:42.949926 28706 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:17:42.949930 28706 net.cpp:124] Setting up relu2\n",
      "I0430 04:17:42.949934 28706 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:17:42.949936 28706 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:17:42.949939 28706 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:17:42.949942 28706 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:17:42.949945 28706 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:17:42.949949 28706 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:17:42.949954 28706 net.cpp:124] Setting up pool2\n",
      "I0430 04:17:42.949956 28706 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:17:42.949959 28706 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:17:42.949961 28706 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:17:42.949965 28706 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:17:42.949967 28706 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:17:42.949971 28706 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:17:42.949975 28706 net.cpp:124] Setting up norm2\n",
      "I0430 04:17:42.949978 28706 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:17:42.949981 28706 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:17:42.949983 28706 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:17:42.949988 28706 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:17:42.949990 28706 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:17:42.949993 28706 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:17:42.950963 28706 net.cpp:124] Setting up conv3\n",
      "I0430 04:17:42.950974 28706 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:17:42.950978 28706 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:17:42.950992 28706 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:17:42.951000 28706 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:17:42.951004 28706 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:17:42.951009 28706 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:17:42.951014 28706 net.cpp:124] Setting up relu3\n",
      "I0430 04:17:42.951016 28706 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:17:42.951020 28706 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:17:42.951021 28706 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:17:42.951028 28706 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:17:42.951031 28706 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:17:42.951035 28706 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:17:42.951530 28706 net.cpp:124] Setting up conv4\n",
      "I0430 04:17:42.951537 28706 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:17:42.951540 28706 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:17:42.951545 28706 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:17:42.951550 28706 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:17:42.951552 28706 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:17:42.951556 28706 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:17:42.951560 28706 net.cpp:124] Setting up relu4\n",
      "I0430 04:17:42.951563 28706 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:17:42.951565 28706 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:17:42.951567 28706 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:17:42.951573 28706 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:17:42.951575 28706 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:17:42.951580 28706 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:17:42.952057 28706 net.cpp:124] Setting up conv5\n",
      "I0430 04:17:42.952064 28706 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:17:42.952065 28706 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:17:42.952074 28706 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:17:42.952077 28706 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:17:42.952080 28706 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:17:42.952085 28706 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:17:42.952087 28706 net.cpp:124] Setting up relu5\n",
      "I0430 04:17:42.952090 28706 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:17:42.952093 28706 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:17:42.952095 28706 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:17:42.952100 28706 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:17:42.952102 28706 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:17:42.952106 28706 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:17:42.952112 28706 net.cpp:124] Setting up pool5\n",
      "I0430 04:17:42.952116 28706 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:17:42.952118 28706 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:17:42.952121 28706 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:17:42.952127 28706 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:17:42.952129 28706 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:17:42.952134 28706 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:17:42.975438 28706 net.cpp:124] Setting up fc6\n",
      "I0430 04:17:42.975463 28706 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:17:42.975466 28706 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:17:42.975472 28706 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:17:42.975478 28706 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:17:42.975481 28706 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:17:42.975486 28706 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:17:42.975492 28706 net.cpp:124] Setting up relu6\n",
      "I0430 04:17:42.975494 28706 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:17:42.975497 28706 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:17:42.975500 28706 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:17:42.975507 28706 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:17:42.975510 28706 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:17:42.975514 28706 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:17:42.975520 28706 net.cpp:124] Setting up drop6\n",
      "I0430 04:17:42.975524 28706 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:17:42.975528 28706 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:17:42.975530 28706 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:17:42.975540 28706 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:17:42.975543 28706 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:17:42.975548 28706 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:17:42.985208 28706 net.cpp:124] Setting up fc7\n",
      "I0430 04:17:42.985227 28706 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:17:42.985234 28706 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:17:42.985254 28706 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:17:42.985261 28706 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:17:42.985263 28706 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:17:42.985270 28706 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:17:42.985276 28706 net.cpp:124] Setting up relu7\n",
      "I0430 04:17:42.985280 28706 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:17:42.985281 28706 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:17:42.985283 28706 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:17:42.985290 28706 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:17:42.985291 28706 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:17:42.985296 28706 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:17:42.985301 28706 net.cpp:124] Setting up drop7\n",
      "I0430 04:17:42.985303 28706 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:17:42.985306 28706 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:17:42.985307 28706 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:17:42.985311 28706 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:17:42.985314 28706 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:17:42.985317 28706 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:17:42.985985 28706 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:17:42.985996 28706 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:17:42.985997 28706 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:17:42.986002 28706 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:17:42.986006 28706 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:17:42.986007 28706 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:17:42.986009 28706 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:17:42.986011 28706 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:17:42.986013 28706 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:17:42.986016 28706 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:17:42.986017 28706 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:17:42.986019 28706 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:17:42.986021 28706 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:17:42.986023 28706 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:17:42.986026 28706 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:17:42.986027 28706 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:17:42.986029 28706 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:17:42.986032 28706 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:17:42.986034 28706 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:17:42.986037 28706 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:17:42.986038 28706 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:17:42.986040 28706 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:17:42.986042 28706 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:17:42.986044 28706 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:17:42.986047 28706 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:17:42.986048 28706 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:17:42.986050 28706 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:17:42.986060 28706 net.cpp:257] Network initialization done.\n",
      "I0430 04:17:43.072988 28706 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:17:43.171785 28706 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:17:43.172695 28706 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:17:43.172703 28706 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:17:43.172708 28706 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/26201.jpg'}, '/tmp/tmpDIRYg4.mat')\n",
      "Processed 2168 windows in 255.133 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.034 s.\n",
      "prediction    [-1.79035, -2.70556, -2.00262, -2.16305, -1.90...\n",
      "ymin                                                        268\n",
      "xmin                                                         78\n",
      "ymax                                                        326\n",
      "xmax                                                        158\n",
      "Name: /home/ambika/INF_project/data/bus/26201.jpg, dtype: object\n",
      "prediction    [-1.79035, -2.70556, -2.00262, -2.16305, -1.90...\n",
      "ymin                                                        268\n",
      "xmin                                                         78\n",
      "ymax                                                        326\n",
      "xmax                                                        158\n",
      "Name: /home/ambika/INF_project/data/bus/26201.jpg, dtype: object\n",
      "bicycle\n",
      "78\t268\t158\t326\n",
      "motorcycle\n",
      "78\t268\t158\t326\n",
      "26201\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:21:59.835168 28889 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:21:59.835186 28889 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:21:59.835202 28889 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:21:59.836292 28889 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:21:59.836364 28889 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:21:59.836374 28889 net.cpp:86] Creating Layer data\n",
      "I0430 04:21:59.836377 28889 net.cpp:382] data -> data\n",
      "I0430 04:21:59.836390 28889 net.cpp:124] Setting up data\n",
      "I0430 04:21:59.836395 28889 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:21:59.836397 28889 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:21:59.836400 28889 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:21:59.836405 28889 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:21:59.836408 28889 net.cpp:408] conv1 <- data\n",
      "I0430 04:21:59.836412 28889 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:21:59.836469 28889 net.cpp:124] Setting up conv1\n",
      "I0430 04:21:59.836474 28889 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:21:59.836477 28889 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:21:59.836483 28889 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:21:59.836488 28889 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:21:59.836490 28889 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:21:59.836493 28889 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:21:59.836498 28889 net.cpp:124] Setting up relu1\n",
      "I0430 04:21:59.836501 28889 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:21:59.836503 28889 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:21:59.836505 28889 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:21:59.836509 28889 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:21:59.836511 28889 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:21:59.836514 28889 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:21:59.836521 28889 net.cpp:124] Setting up pool1\n",
      "I0430 04:21:59.836524 28889 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:21:59.836526 28889 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:21:59.836529 28889 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:21:59.836534 28889 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:21:59.836535 28889 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:21:59.836539 28889 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:21:59.836544 28889 net.cpp:124] Setting up norm1\n",
      "I0430 04:21:59.836546 28889 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:21:59.836549 28889 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:21:59.836551 28889 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:21:59.836555 28889 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:21:59.836557 28889 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:21:59.836560 28889 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:21:59.836896 28889 net.cpp:124] Setting up conv2\n",
      "I0430 04:21:59.836901 28889 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:21:59.836904 28889 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:21:59.836908 28889 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:21:59.836912 28889 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:21:59.836915 28889 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:21:59.836918 28889 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:21:59.836921 28889 net.cpp:124] Setting up relu2\n",
      "I0430 04:21:59.836925 28889 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:21:59.836927 28889 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:21:59.836930 28889 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:21:59.836932 28889 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:21:59.836935 28889 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:21:59.836938 28889 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:21:59.836942 28889 net.cpp:124] Setting up pool2\n",
      "I0430 04:21:59.836946 28889 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:21:59.836948 28889 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:21:59.836951 28889 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:21:59.836956 28889 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:21:59.836958 28889 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:21:59.836962 28889 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:21:59.836966 28889 net.cpp:124] Setting up norm2\n",
      "I0430 04:21:59.836969 28889 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:21:59.836972 28889 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:21:59.836974 28889 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:21:59.836978 28889 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:21:59.836980 28889 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:21:59.836983 28889 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:21:59.837944 28889 net.cpp:124] Setting up conv3\n",
      "I0430 04:21:59.837952 28889 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:21:59.837954 28889 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:21:59.837961 28889 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:21:59.837967 28889 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:21:59.837970 28889 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:21:59.837973 28889 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:21:59.837977 28889 net.cpp:124] Setting up relu3\n",
      "I0430 04:21:59.837981 28889 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:21:59.837983 28889 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:21:59.837985 28889 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:21:59.837990 28889 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:21:59.837992 28889 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:21:59.837996 28889 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:21:59.838444 28889 net.cpp:124] Setting up conv4\n",
      "I0430 04:21:59.838451 28889 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:21:59.838455 28889 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:21:59.838459 28889 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:21:59.838464 28889 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:21:59.838465 28889 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:21:59.838469 28889 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:21:59.838472 28889 net.cpp:124] Setting up relu4\n",
      "I0430 04:21:59.838476 28889 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:21:59.838479 28889 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:21:59.838481 28889 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:21:59.838488 28889 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:21:59.838490 28889 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:21:59.838493 28889 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:21:59.838974 28889 net.cpp:124] Setting up conv5\n",
      "I0430 04:21:59.838980 28889 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:21:59.838984 28889 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:21:59.838991 28889 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:21:59.838995 28889 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:21:59.838997 28889 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:21:59.839000 28889 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:21:59.839004 28889 net.cpp:124] Setting up relu5\n",
      "I0430 04:21:59.839007 28889 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:21:59.839010 28889 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:21:59.839012 28889 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:21:59.839016 28889 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:21:59.839018 28889 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:21:59.839022 28889 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:21:59.839028 28889 net.cpp:124] Setting up pool5\n",
      "I0430 04:21:59.839031 28889 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:21:59.839035 28889 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:21:59.839036 28889 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:21:59.839043 28889 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:21:59.839046 28889 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:21:59.839049 28889 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:21:59.862601 28889 net.cpp:124] Setting up fc6\n",
      "I0430 04:21:59.862654 28889 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:21:59.862660 28889 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:21:59.862679 28889 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:21:59.862695 28889 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:21:59.862701 28889 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:21:59.862709 28889 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:21:59.862720 28889 net.cpp:124] Setting up relu6\n",
      "I0430 04:21:59.862725 28889 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:21:59.862730 28889 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:21:59.862733 28889 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:21:59.862740 28889 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:21:59.862745 28889 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:21:59.862749 28889 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:21:59.862757 28889 net.cpp:124] Setting up drop6\n",
      "I0430 04:21:59.862766 28889 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:21:59.862771 28889 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:21:59.862776 28889 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:21:59.862788 28889 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:21:59.862793 28889 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:21:59.862799 28889 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:21:59.875654 28889 net.cpp:124] Setting up fc7\n",
      "I0430 04:21:59.875679 28889 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:21:59.875690 28889 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:21:59.875700 28889 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:21:59.875708 28889 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:21:59.875712 28889 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:21:59.875718 28889 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:21:59.875725 28889 net.cpp:124] Setting up relu7\n",
      "I0430 04:21:59.875727 28889 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:21:59.875730 28889 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:21:59.875731 28889 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:21:59.875737 28889 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:21:59.875740 28889 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:21:59.875742 28889 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:21:59.875747 28889 net.cpp:124] Setting up drop7\n",
      "I0430 04:21:59.875751 28889 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:21:59.875752 28889 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:21:59.875756 28889 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:21:59.875759 28889 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:21:59.875761 28889 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:21:59.875764 28889 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:21:59.876665 28889 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:21:59.876673 28889 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:21:59.876677 28889 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:21:59.876683 28889 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:21:59.876685 28889 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:21:59.876688 28889 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:21:59.876689 28889 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:21:59.876693 28889 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:21:59.876695 28889 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:21:59.876698 28889 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:21:59.876700 28889 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:21:59.876703 28889 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:21:59.876705 28889 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:21:59.876708 28889 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:21:59.876710 28889 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:21:59.876713 28889 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:21:59.876716 28889 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:21:59.876719 28889 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:21:59.876723 28889 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:21:59.876724 28889 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:21:59.876727 28889 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:21:59.876729 28889 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:21:59.876732 28889 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:21:59.876735 28889 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:21:59.876737 28889 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:21:59.876739 28889 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:21:59.876742 28889 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:21:59.876752 28889 net.cpp:257] Network initialization done.\n",
      "I0430 04:21:59.966135 28889 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:22:00.070861 28889 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:22:00.071794 28889 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:22:00.071805 28889 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:22:00.071815 28889 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/572427.jpg'}, '/tmp/tmp8rk7KW.mat')\n",
      "Processed 2315 windows in 275.866 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-2.38528, -1.61359, -1.71034, -1.92869, -2.19...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                        209\n",
      "xmax                                                        278\n",
      "Name: /home/ambika/INF_project/data/car/572427.jpg, dtype: object\n",
      "prediction    [-2.41823, -0.849305, -1.94168, -2.23886, -1.9...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                        264\n",
      "xmax                                                        244\n",
      "Name: /home/ambika/INF_project/data/car/572427.jpg, dtype: object\n",
      "punching bag\n",
      "0\t0\t278\t209\n",
      "drum\n",
      "0\t0\t244\t264\n",
      "572427\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:26:37.455873 29075 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:26:37.455888 29075 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:26:37.455893 29075 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:26:37.456990 29075 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:26:37.457072 29075 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:26:37.457082 29075 net.cpp:86] Creating Layer data\n",
      "I0430 04:26:37.457085 29075 net.cpp:382] data -> data\n",
      "I0430 04:26:37.457098 29075 net.cpp:124] Setting up data\n",
      "I0430 04:26:37.457103 29075 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:26:37.457105 29075 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:26:37.457108 29075 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:26:37.457114 29075 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:26:37.457116 29075 net.cpp:408] conv1 <- data\n",
      "I0430 04:26:37.457120 29075 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:26:37.457178 29075 net.cpp:124] Setting up conv1\n",
      "I0430 04:26:37.457183 29075 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:26:37.457185 29075 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:26:37.457192 29075 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:26:37.457197 29075 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:26:37.457200 29075 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:26:37.457202 29075 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:26:37.457206 29075 net.cpp:124] Setting up relu1\n",
      "I0430 04:26:37.457209 29075 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:26:37.457212 29075 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:26:37.457216 29075 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:26:37.457218 29075 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:26:37.457221 29075 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:26:37.457224 29075 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:26:37.457231 29075 net.cpp:124] Setting up pool1\n",
      "I0430 04:26:37.457233 29075 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:26:37.457236 29075 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:26:37.457238 29075 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:26:37.457242 29075 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:26:37.457244 29075 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:26:37.457247 29075 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:26:37.457252 29075 net.cpp:124] Setting up norm1\n",
      "I0430 04:26:37.457255 29075 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:26:37.457258 29075 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:26:37.457260 29075 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:26:37.457264 29075 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:26:37.457267 29075 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:26:37.457269 29075 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:26:37.457607 29075 net.cpp:124] Setting up conv2\n",
      "I0430 04:26:37.457612 29075 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:26:37.457614 29075 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:26:37.457619 29075 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:26:37.457623 29075 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:26:37.457625 29075 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:26:37.457628 29075 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:26:37.457633 29075 net.cpp:124] Setting up relu2\n",
      "I0430 04:26:37.457635 29075 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:26:37.457638 29075 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:26:37.457640 29075 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:26:37.457643 29075 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:26:37.457646 29075 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:26:37.457649 29075 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:26:37.457654 29075 net.cpp:124] Setting up pool2\n",
      "I0430 04:26:37.457657 29075 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:26:37.457659 29075 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:26:37.457661 29075 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:26:37.457666 29075 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:26:37.457669 29075 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:26:37.457672 29075 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:26:37.457676 29075 net.cpp:124] Setting up norm2\n",
      "I0430 04:26:37.457680 29075 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:26:37.457682 29075 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:26:37.457684 29075 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:26:37.457689 29075 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:26:37.457693 29075 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:26:37.457696 29075 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:26:37.458374 29075 net.cpp:124] Setting up conv3\n",
      "I0430 04:26:37.458381 29075 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:26:37.458384 29075 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:26:37.458390 29075 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:26:37.458396 29075 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:26:37.458398 29075 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:26:37.458402 29075 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:26:37.458406 29075 net.cpp:124] Setting up relu3\n",
      "I0430 04:26:37.458410 29075 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:26:37.458411 29075 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:26:37.458415 29075 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:26:37.458421 29075 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:26:37.458425 29075 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:26:37.458427 29075 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:26:37.459137 29075 net.cpp:124] Setting up conv4\n",
      "I0430 04:26:37.459146 29075 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:26:37.459147 29075 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:26:37.459152 29075 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:26:37.459156 29075 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:26:37.459159 29075 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:26:37.459166 29075 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:26:37.459170 29075 net.cpp:124] Setting up relu4\n",
      "I0430 04:26:37.459173 29075 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:26:37.459175 29075 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:26:37.459178 29075 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:26:37.459182 29075 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:26:37.459184 29075 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:26:37.459189 29075 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:26:37.459687 29075 net.cpp:124] Setting up conv5\n",
      "I0430 04:26:37.459698 29075 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:26:37.459700 29075 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:26:37.459708 29075 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:26:37.459712 29075 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:26:37.459715 29075 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:26:37.459718 29075 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:26:37.459722 29075 net.cpp:124] Setting up relu5\n",
      "I0430 04:26:37.459725 29075 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:26:37.459728 29075 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:26:37.459730 29075 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:26:37.459735 29075 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:26:37.459738 29075 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:26:37.459741 29075 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:26:37.459748 29075 net.cpp:124] Setting up pool5\n",
      "I0430 04:26:37.459750 29075 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:26:37.459753 29075 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:26:37.459755 29075 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:26:37.459761 29075 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:26:37.459764 29075 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:26:37.459769 29075 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:26:37.483077 29075 net.cpp:124] Setting up fc6\n",
      "I0430 04:26:37.483099 29075 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:26:37.483104 29075 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:26:37.483113 29075 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:26:37.483120 29075 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:26:37.483124 29075 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:26:37.483129 29075 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:26:37.483134 29075 net.cpp:124] Setting up relu6\n",
      "I0430 04:26:37.483136 29075 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:26:37.483139 29075 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:26:37.483139 29075 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:26:37.483144 29075 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:26:37.483144 29075 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:26:37.483150 29075 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:26:37.483155 29075 net.cpp:124] Setting up drop6\n",
      "I0430 04:26:37.483158 29075 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:26:37.483160 29075 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:26:37.483163 29075 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:26:37.483168 29075 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:26:37.483171 29075 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:26:37.483175 29075 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:26:37.493340 29075 net.cpp:124] Setting up fc7\n",
      "I0430 04:26:37.493357 29075 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:26:37.493360 29075 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:26:37.493366 29075 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:26:37.493371 29075 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:26:37.493373 29075 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:26:37.493378 29075 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:26:37.493383 29075 net.cpp:124] Setting up relu7\n",
      "I0430 04:26:37.493386 29075 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:26:37.493387 29075 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:26:37.493391 29075 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:26:37.493393 29075 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:26:37.493396 29075 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:26:37.493398 29075 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:26:37.493403 29075 net.cpp:124] Setting up drop7\n",
      "I0430 04:26:37.493405 29075 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:26:37.493407 29075 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:26:37.493408 29075 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:26:37.493412 29075 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:26:37.493413 29075 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:26:37.493417 29075 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:26:37.494164 29075 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:26:37.494179 29075 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:26:37.494182 29075 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:26:37.494191 29075 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:26:37.494196 29075 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:26:37.494201 29075 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:26:37.494204 29075 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:26:37.494210 29075 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:26:37.494213 29075 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:26:37.494217 29075 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:26:37.494221 29075 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:26:37.494225 29075 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:26:37.494228 29075 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:26:37.494232 29075 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:26:37.494236 29075 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:26:37.494240 29075 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:26:37.494244 29075 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:26:37.494248 29075 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:26:37.494253 29075 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:26:37.494257 29075 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:26:37.494261 29075 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:26:37.494266 29075 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:26:37.494271 29075 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:26:37.494276 29075 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:26:37.494279 29075 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:26:37.494283 29075 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:26:37.494287 29075 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:26:37.494305 29075 net.cpp:257] Network initialization done.\n",
      "I0430 04:26:37.582562 29075 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:26:37.682299 29075 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:26:37.683718 29075 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:26:37.683733 29075 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:26:37.683739 29075 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/209419.jpg'}, '/tmp/tmp3zPmvc.mat')\n",
      "Processed 3058 windows in 351.957 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.036 s.\n",
      "prediction    [-1.67693, -2.05035, -1.85517, -2.34766, -1.58...\n",
      "ymin                                                         35\n",
      "xmin                                                        200\n",
      "ymax                                                        371\n",
      "xmax                                                        424\n",
      "Name: /home/ambika/INF_project/data/cat/209419.jpg, dtype: object\n",
      "prediction    [-2.56978, -2.31141, -2.1772, -1.28157, -1.868...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                        208\n",
      "xmax                                                        122\n",
      "Name: /home/ambika/INF_project/data/cat/209419.jpg, dtype: object\n",
      "dog\n",
      "200\t35\t424\t371\n",
      "crutch\n",
      "0\t0\t122\t208\n",
      "209419\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:32:31.195070 29295 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:32:31.195085 29295 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:32:31.195086 29295 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:32:31.196194 29295 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:32:31.196270 29295 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:32:31.196280 29295 net.cpp:86] Creating Layer data\n",
      "I0430 04:32:31.196283 29295 net.cpp:382] data -> data\n",
      "I0430 04:32:31.196296 29295 net.cpp:124] Setting up data\n",
      "I0430 04:32:31.196301 29295 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:32:31.196305 29295 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:32:31.196307 29295 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:32:31.196312 29295 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:32:31.196316 29295 net.cpp:408] conv1 <- data\n",
      "I0430 04:32:31.196319 29295 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:32:31.196377 29295 net.cpp:124] Setting up conv1\n",
      "I0430 04:32:31.196382 29295 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:32:31.196384 29295 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:32:31.196391 29295 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:32:31.196396 29295 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:32:31.196398 29295 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:32:31.196403 29295 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:32:31.196406 29295 net.cpp:124] Setting up relu1\n",
      "I0430 04:32:31.196409 29295 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:32:31.196411 29295 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:32:31.196414 29295 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:32:31.196418 29295 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:32:31.196420 29295 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:32:31.196424 29295 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:32:31.196429 29295 net.cpp:124] Setting up pool1\n",
      "I0430 04:32:31.196434 29295 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:32:31.196435 29295 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:32:31.196437 29295 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:32:31.196442 29295 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:32:31.196444 29295 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:32:31.196449 29295 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:32:31.196454 29295 net.cpp:124] Setting up norm1\n",
      "I0430 04:32:31.196456 29295 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:32:31.196458 29295 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:32:31.196461 29295 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:32:31.196465 29295 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:32:31.196467 29295 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:32:31.196470 29295 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:32:31.196817 29295 net.cpp:124] Setting up conv2\n",
      "I0430 04:32:31.196823 29295 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:32:31.196825 29295 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:32:31.196830 29295 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:32:31.196835 29295 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:32:31.196837 29295 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:32:31.196841 29295 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:32:31.196844 29295 net.cpp:124] Setting up relu2\n",
      "I0430 04:32:31.196847 29295 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:32:31.196849 29295 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:32:31.196852 29295 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:32:31.196856 29295 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:32:31.196858 29295 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:32:31.196862 29295 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:32:31.196867 29295 net.cpp:124] Setting up pool2\n",
      "I0430 04:32:31.196871 29295 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:32:31.196872 29295 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:32:31.196876 29295 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:32:31.196880 29295 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:32:31.196882 29295 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:32:31.196887 29295 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:32:31.196890 29295 net.cpp:124] Setting up norm2\n",
      "I0430 04:32:31.196894 29295 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:32:31.196897 29295 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:32:31.196898 29295 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:32:31.196902 29295 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:32:31.196904 29295 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:32:31.196908 29295 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:32:31.197607 29295 net.cpp:124] Setting up conv3\n",
      "I0430 04:32:31.197615 29295 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:32:31.197618 29295 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:32:31.197625 29295 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:32:31.197631 29295 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:32:31.197634 29295 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:32:31.197638 29295 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:32:31.197643 29295 net.cpp:124] Setting up relu3\n",
      "I0430 04:32:31.197646 29295 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:32:31.197649 29295 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:32:31.197650 29295 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:32:31.197655 29295 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:32:31.197657 29295 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:32:31.197661 29295 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:32:31.198393 29295 net.cpp:124] Setting up conv4\n",
      "I0430 04:32:31.198401 29295 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:32:31.198403 29295 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:32:31.198408 29295 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:32:31.198415 29295 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:32:31.198417 29295 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:32:31.198421 29295 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:32:31.198424 29295 net.cpp:124] Setting up relu4\n",
      "I0430 04:32:31.198427 29295 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:32:31.198431 29295 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:32:31.198432 29295 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:32:31.198438 29295 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:32:31.198441 29295 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:32:31.198444 29295 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:32:31.198925 29295 net.cpp:124] Setting up conv5\n",
      "I0430 04:32:31.198931 29295 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:32:31.198935 29295 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:32:31.198940 29295 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:32:31.198946 29295 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:32:31.198949 29295 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:32:31.198953 29295 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:32:31.198957 29295 net.cpp:124] Setting up relu5\n",
      "I0430 04:32:31.198961 29295 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:32:31.198963 29295 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:32:31.198966 29295 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:32:31.198971 29295 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:32:31.198972 29295 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:32:31.198976 29295 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:32:31.198982 29295 net.cpp:124] Setting up pool5\n",
      "I0430 04:32:31.198985 29295 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:32:31.198987 29295 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:32:31.198990 29295 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:32:31.198997 29295 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:32:31.198999 29295 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:32:31.199004 29295 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:32:31.222168 29295 net.cpp:124] Setting up fc6\n",
      "I0430 04:32:31.222193 29295 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:32:31.222193 29295 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:32:31.222201 29295 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:32:31.222208 29295 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:32:31.222210 29295 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:32:31.222214 29295 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:32:31.222221 29295 net.cpp:124] Setting up relu6\n",
      "I0430 04:32:31.222223 29295 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:32:31.222226 29295 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:32:31.222229 29295 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:32:31.222232 29295 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:32:31.222235 29295 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:32:31.222237 29295 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:32:31.222242 29295 net.cpp:124] Setting up drop6\n",
      "I0430 04:32:31.222244 29295 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:32:31.222246 29295 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:32:31.222247 29295 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:32:31.222254 29295 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:32:31.222255 29295 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:32:31.222259 29295 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:32:31.233078 29295 net.cpp:124] Setting up fc7\n",
      "I0430 04:32:31.233099 29295 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:32:31.233103 29295 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:32:31.233113 29295 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:32:31.233120 29295 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:32:31.233124 29295 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:32:31.233129 29295 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:32:31.233135 29295 net.cpp:124] Setting up relu7\n",
      "I0430 04:32:31.233139 29295 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:32:31.233140 29295 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:32:31.233144 29295 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:32:31.233146 29295 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:32:31.233150 29295 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:32:31.233153 29295 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:32:31.233158 29295 net.cpp:124] Setting up drop7\n",
      "I0430 04:32:31.233161 29295 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:32:31.233163 29295 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:32:31.233165 29295 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:32:31.233170 29295 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:32:31.233172 29295 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:32:31.233175 29295 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:32:31.233885 29295 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:32:31.233898 29295 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:32:31.233901 29295 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:32:31.233909 29295 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:32:31.233912 29295 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:32:31.233914 29295 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:32:31.233916 29295 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:32:31.233918 29295 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:32:31.233921 29295 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:32:31.233922 29295 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:32:31.233924 29295 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:32:31.233927 29295 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:32:31.233929 29295 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:32:31.233932 29295 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:32:31.233934 29295 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:32:31.233937 29295 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:32:31.233940 29295 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:32:31.233943 29295 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:32:31.233947 29295 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:32:31.233948 29295 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:32:31.233952 29295 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:32:31.233954 29295 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:32:31.233956 29295 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:32:31.233959 29295 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:32:31.233961 29295 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:32:31.233964 29295 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:32:31.233966 29295 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:32:31.233978 29295 net.cpp:257] Network initialization done.\n",
      "I0430 04:32:31.321944 29295 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:32:31.423610 29295 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:32:31.424537 29295 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:32:31.424545 29295 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:32:31.424549 29295 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/512657.jpg'}, '/tmp/tmpiXJ69e.mat')\n",
      "Processed 1596 windows in 184.357 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.81404, -2.63559, -1.93676, -2.26886, -1.97...\n",
      "ymin                                                        189\n",
      "xmin                                                        312\n",
      "ymax                                                        333\n",
      "xmax                                                        403\n",
      "Name: /home/ambika/INF_project/data/couch/512657.jpg, dtype: object\n",
      "prediction    [-1.50268, -1.89876, -1.83784, -1.79189, -2.14...\n",
      "ymin                                                        126\n",
      "xmin                                                         68\n",
      "ymax                                                        169\n",
      "xmax                                                        109\n",
      "Name: /home/ambika/INF_project/data/couch/512657.jpg, dtype: object\n",
      "person\n",
      "312\t189\t403\t333\n",
      "face powder\n",
      "68\t126\t109\t169\n",
      "512657\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:35:37.263986 29448 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:35:37.264006 29448 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:35:37.264009 29448 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:35:37.265103 29448 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:35:37.265182 29448 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:35:37.265188 29448 net.cpp:86] Creating Layer data\n",
      "I0430 04:35:37.265192 29448 net.cpp:382] data -> data\n",
      "I0430 04:35:37.265204 29448 net.cpp:124] Setting up data\n",
      "I0430 04:35:37.265213 29448 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:35:37.265214 29448 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:35:37.265218 29448 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:35:37.265223 29448 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:35:37.265226 29448 net.cpp:408] conv1 <- data\n",
      "I0430 04:35:37.265230 29448 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:35:37.265285 29448 net.cpp:124] Setting up conv1\n",
      "I0430 04:35:37.265290 29448 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:35:37.265292 29448 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:35:37.265300 29448 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:35:37.265303 29448 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:35:37.265306 29448 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:35:37.265310 29448 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:35:37.265314 29448 net.cpp:124] Setting up relu1\n",
      "I0430 04:35:37.265317 29448 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:35:37.265319 29448 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:35:37.265322 29448 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:35:37.265326 29448 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:35:37.265327 29448 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:35:37.265331 29448 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:35:37.265337 29448 net.cpp:124] Setting up pool1\n",
      "I0430 04:35:37.265341 29448 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:35:37.265342 29448 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:35:37.265346 29448 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:35:37.265349 29448 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:35:37.265352 29448 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:35:37.265355 29448 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:35:37.265359 29448 net.cpp:124] Setting up norm1\n",
      "I0430 04:35:37.265363 29448 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:35:37.265365 29448 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:35:37.265367 29448 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:35:37.265372 29448 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:35:37.265374 29448 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:35:37.265377 29448 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:35:37.265729 29448 net.cpp:124] Setting up conv2\n",
      "I0430 04:35:37.265735 29448 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:35:37.265738 29448 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:35:37.265748 29448 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:35:37.265760 29448 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:35:37.265763 29448 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:35:37.265769 29448 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:35:37.265774 29448 net.cpp:124] Setting up relu2\n",
      "I0430 04:35:37.265779 29448 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:35:37.265781 29448 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:35:37.265784 29448 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:35:37.265789 29448 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:35:37.265792 29448 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:35:37.265797 29448 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:35:37.265805 29448 net.cpp:124] Setting up pool2\n",
      "I0430 04:35:37.265808 29448 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:35:37.265811 29448 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:35:37.265815 29448 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:35:37.265820 29448 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:35:37.265823 29448 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:35:37.265828 29448 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:35:37.265835 29448 net.cpp:124] Setting up norm2\n",
      "I0430 04:35:37.265838 29448 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:35:37.265841 29448 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:35:37.265844 29448 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:35:37.265849 29448 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:35:37.265852 29448 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:35:37.265857 29448 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:35:37.266543 29448 net.cpp:124] Setting up conv3\n",
      "I0430 04:35:37.266571 29448 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:35:37.266574 29448 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:35:37.266584 29448 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:35:37.266590 29448 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:35:37.266593 29448 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:35:37.266597 29448 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:35:37.266602 29448 net.cpp:124] Setting up relu3\n",
      "I0430 04:35:37.266604 29448 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:35:37.266607 29448 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:35:37.266609 29448 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:35:37.266614 29448 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:35:37.266616 29448 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:35:37.266620 29448 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:35:37.267371 29448 net.cpp:124] Setting up conv4\n",
      "I0430 04:35:37.267383 29448 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:35:37.267387 29448 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:35:37.267392 29448 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:35:37.267398 29448 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:35:37.267400 29448 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:35:37.267403 29448 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:35:37.267410 29448 net.cpp:124] Setting up relu4\n",
      "I0430 04:35:37.267412 29448 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:35:37.267413 29448 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:35:37.267416 29448 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:35:37.267421 29448 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:35:37.267423 29448 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:35:37.267426 29448 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:35:37.267930 29448 net.cpp:124] Setting up conv5\n",
      "I0430 04:35:37.267937 29448 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:35:37.267940 29448 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:35:37.267952 29448 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:35:37.267957 29448 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:35:37.267961 29448 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:35:37.267966 29448 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:35:37.267971 29448 net.cpp:124] Setting up relu5\n",
      "I0430 04:35:37.267974 29448 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:35:37.267977 29448 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:35:37.267980 29448 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:35:37.267987 29448 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:35:37.267989 29448 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:35:37.267993 29448 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:35:37.268002 29448 net.cpp:124] Setting up pool5\n",
      "I0430 04:35:37.268005 29448 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:35:37.268008 29448 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:35:37.268012 29448 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:35:37.268019 29448 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:35:37.268021 29448 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:35:37.268026 29448 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:35:37.291365 29448 net.cpp:124] Setting up fc6\n",
      "I0430 04:35:37.291389 29448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:35:37.291394 29448 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:35:37.291405 29448 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:35:37.291414 29448 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:35:37.291417 29448 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:35:37.291424 29448 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:35:37.291430 29448 net.cpp:124] Setting up relu6\n",
      "I0430 04:35:37.291434 29448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:35:37.291435 29448 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:35:37.291438 29448 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:35:37.291442 29448 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:35:37.291445 29448 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:35:37.291448 29448 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:35:37.291452 29448 net.cpp:124] Setting up drop6\n",
      "I0430 04:35:37.291455 29448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:35:37.291457 29448 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:35:37.291460 29448 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:35:37.291465 29448 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:35:37.291467 29448 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:35:37.291471 29448 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:35:37.300977 29448 net.cpp:124] Setting up fc7\n",
      "I0430 04:35:37.300997 29448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:35:37.300998 29448 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:35:37.301005 29448 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:35:37.301012 29448 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:35:37.301013 29448 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:35:37.301021 29448 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:35:37.301026 29448 net.cpp:124] Setting up relu7\n",
      "I0430 04:35:37.301031 29448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:35:37.301034 29448 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:35:37.301038 29448 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:35:37.301043 29448 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:35:37.301045 29448 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:35:37.301049 29448 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:35:37.301056 29448 net.cpp:124] Setting up drop7\n",
      "I0430 04:35:37.301059 29448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:35:37.301062 29448 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:35:37.301065 29448 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:35:37.301071 29448 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:35:37.301074 29448 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:35:37.301079 29448 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:35:37.301998 29448 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:35:37.302011 29448 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:35:37.302014 29448 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:35:37.302022 29448 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:35:37.302026 29448 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:35:37.302029 29448 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:35:37.302032 29448 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:35:37.302036 29448 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:35:37.302038 29448 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:35:37.302042 29448 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:35:37.302045 29448 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:35:37.302048 29448 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:35:37.302052 29448 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:35:37.302055 29448 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:35:37.302058 29448 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:35:37.302062 29448 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:35:37.302065 29448 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:35:37.302068 29448 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:35:37.302073 29448 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:35:37.302075 29448 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:35:37.302078 29448 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:35:37.302081 29448 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:35:37.302085 29448 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:35:37.302088 29448 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:35:37.302091 29448 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:35:37.302095 29448 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:35:37.302098 29448 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:35:37.302109 29448 net.cpp:257] Network initialization done.\n",
      "I0430 04:35:37.388695 29448 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:35:37.486615 29448 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:35:37.487594 29448 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:35:37.487602 29448 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:35:37.487607 29448 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/531995.jpg'}, '/tmp/tmp2bGbgO.mat')\n",
      "Processed 2157 windows in 254.541 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-1.88187, -2.38448, -1.85034, -2.73052, -2.07...\n",
      "ymin                                                        116\n",
      "xmin                                                        170\n",
      "ymax                                                        363\n",
      "xmax                                                        350\n",
      "Name: /home/ambika/INF_project/data/dog/531995.jpg, dtype: object\n",
      "prediction    [-2.30409, -2.3142, -2.56728, -2.03218, -3.266...\n",
      "ymin                                                         33\n",
      "xmin                                                          6\n",
      "ymax                                                        100\n",
      "xmax                                                         65\n",
      "Name: /home/ambika/INF_project/data/dog/531995.jpg, dtype: object\n",
      "dog\n",
      "170\t116\t350\t363\n",
      "salt or pepper shaker\n",
      "6\t33\t65\t100\n",
      "531995\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:39:53.572265 29648 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:39:53.572281 29648 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:39:53.572283 29648 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:39:53.573374 29648 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:39:53.573448 29648 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:39:53.573454 29648 net.cpp:86] Creating Layer data\n",
      "I0430 04:39:53.573458 29648 net.cpp:382] data -> data\n",
      "I0430 04:39:53.573467 29648 net.cpp:124] Setting up data\n",
      "I0430 04:39:53.573473 29648 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:39:53.573475 29648 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:39:53.573478 29648 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:39:53.573484 29648 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:39:53.573487 29648 net.cpp:408] conv1 <- data\n",
      "I0430 04:39:53.573490 29648 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:39:53.573546 29648 net.cpp:124] Setting up conv1\n",
      "I0430 04:39:53.573550 29648 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:39:53.573554 29648 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:39:53.573560 29648 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:39:53.573565 29648 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:39:53.573567 29648 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:39:53.573570 29648 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:39:53.573575 29648 net.cpp:124] Setting up relu1\n",
      "I0430 04:39:53.573578 29648 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:39:53.573580 29648 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:39:53.573583 29648 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:39:53.573586 29648 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:39:53.573590 29648 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:39:53.573592 29648 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:39:53.573598 29648 net.cpp:124] Setting up pool1\n",
      "I0430 04:39:53.573602 29648 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:39:53.573604 29648 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:39:53.573606 29648 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:39:53.573611 29648 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:39:53.573613 29648 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:39:53.573616 29648 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:39:53.573621 29648 net.cpp:124] Setting up norm1\n",
      "I0430 04:39:53.573624 29648 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:39:53.573627 29648 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:39:53.573629 29648 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:39:53.573633 29648 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:39:53.573635 29648 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:39:53.573639 29648 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:39:53.573963 29648 net.cpp:124] Setting up conv2\n",
      "I0430 04:39:53.573969 29648 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:39:53.573971 29648 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:39:53.573976 29648 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:39:53.573981 29648 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:39:53.573982 29648 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:39:53.573987 29648 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:39:53.573989 29648 net.cpp:124] Setting up relu2\n",
      "I0430 04:39:53.573992 29648 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:39:53.573995 29648 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:39:53.573997 29648 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:39:53.574000 29648 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:39:53.574003 29648 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:39:53.574007 29648 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:39:53.574012 29648 net.cpp:124] Setting up pool2\n",
      "I0430 04:39:53.574014 29648 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:39:53.574018 29648 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:39:53.574019 29648 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:39:53.574024 29648 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:39:53.574026 29648 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:39:53.574030 29648 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:39:53.574034 29648 net.cpp:124] Setting up norm2\n",
      "I0430 04:39:53.574038 29648 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:39:53.574040 29648 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:39:53.574043 29648 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:39:53.574046 29648 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:39:53.574048 29648 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:39:53.574053 29648 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:39:53.575029 29648 net.cpp:124] Setting up conv3\n",
      "I0430 04:39:53.575044 29648 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:39:53.575047 29648 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:39:53.575055 29648 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:39:53.575062 29648 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:39:53.575065 29648 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:39:53.575070 29648 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:39:53.575079 29648 net.cpp:124] Setting up relu3\n",
      "I0430 04:39:53.575083 29648 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:39:53.575085 29648 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:39:53.575088 29648 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:39:53.575099 29648 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:39:53.575101 29648 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:39:53.575105 29648 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:39:53.575588 29648 net.cpp:124] Setting up conv4\n",
      "I0430 04:39:53.575595 29648 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:39:53.575598 29648 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:39:53.575603 29648 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:39:53.575608 29648 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:39:53.575610 29648 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:39:53.575614 29648 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:39:53.575618 29648 net.cpp:124] Setting up relu4\n",
      "I0430 04:39:53.575621 29648 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:39:53.575624 29648 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:39:53.575626 29648 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:39:53.575631 29648 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:39:53.575634 29648 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:39:53.575637 29648 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:39:53.576211 29648 net.cpp:124] Setting up conv5\n",
      "I0430 04:39:53.576222 29648 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:39:53.576225 29648 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:39:53.576231 29648 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:39:53.576236 29648 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:39:53.576238 29648 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:39:53.576242 29648 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:39:53.576247 29648 net.cpp:124] Setting up relu5\n",
      "I0430 04:39:53.576251 29648 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:39:53.576252 29648 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:39:53.576256 29648 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:39:53.576259 29648 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:39:53.576261 29648 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:39:53.576266 29648 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:39:53.576272 29648 net.cpp:124] Setting up pool5\n",
      "I0430 04:39:53.576277 29648 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:39:53.576278 29648 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:39:53.576280 29648 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:39:53.576287 29648 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:39:53.576289 29648 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:39:53.576293 29648 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:39:53.599733 29648 net.cpp:124] Setting up fc6\n",
      "I0430 04:39:53.599761 29648 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:39:53.599766 29648 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:39:53.599778 29648 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:39:53.599788 29648 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:39:53.599792 29648 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:39:53.599797 29648 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:39:53.599804 29648 net.cpp:124] Setting up relu6\n",
      "I0430 04:39:53.599808 29648 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:39:53.599810 29648 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:39:53.599813 29648 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:39:53.599817 29648 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:39:53.599820 29648 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:39:53.599824 29648 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:39:53.599829 29648 net.cpp:124] Setting up drop6\n",
      "I0430 04:39:53.599833 29648 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:39:53.599835 29648 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:39:53.599838 29648 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:39:53.599843 29648 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:39:53.599844 29648 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:39:53.599848 29648 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:39:53.610955 29648 net.cpp:124] Setting up fc7\n",
      "I0430 04:39:53.610981 29648 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:39:53.610985 29648 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:39:53.610997 29648 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:39:53.611017 29648 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:39:53.611030 29648 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:39:53.611045 29648 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:39:53.611053 29648 net.cpp:124] Setting up relu7\n",
      "I0430 04:39:53.611058 29648 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:39:53.611063 29648 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:39:53.611066 29648 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:39:53.611073 29648 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:39:53.611075 29648 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:39:53.611080 29648 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:39:53.611086 29648 net.cpp:124] Setting up drop7\n",
      "I0430 04:39:53.611090 29648 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:39:53.611093 29648 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:39:53.611095 29648 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:39:53.611101 29648 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:39:53.611104 29648 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:39:53.611110 29648 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:39:53.611780 29648 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:39:53.611793 29648 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:39:53.611798 29648 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:39:53.611806 29648 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:39:53.611810 29648 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:39:53.611814 29648 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:39:53.611816 29648 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:39:53.611819 29648 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:39:53.611822 29648 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:39:53.611824 29648 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:39:53.611830 29648 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:39:53.611834 29648 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:39:53.611836 29648 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:39:53.611840 29648 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:39:53.611845 29648 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:39:53.611847 29648 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:39:53.611851 29648 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:39:53.611855 29648 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:39:53.611860 29648 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:39:53.611862 29648 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:39:53.611866 29648 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:39:53.611870 29648 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:39:53.611873 29648 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:39:53.611877 29648 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:39:53.611881 29648 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:39:53.611883 29648 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:39:53.611886 29648 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:39:53.611905 29648 net.cpp:257] Network initialization done.\n",
      "I0430 04:39:53.699703 29648 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:39:53.799983 29648 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:39:53.801175 29648 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:39:53.801198 29648 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:39:53.801203 29648 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/23033.jpg'}, '/tmp/tmpSQsMKA.mat')\n",
      "Processed 1483 windows in 177.837 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-1.76814, -2.09502, -2.03934, -0.514412, -1.8...\n",
      "ymin                                                         29\n",
      "xmin                                                        146\n",
      "ymax                                                        384\n",
      "xmax                                                        380\n",
      "Name: /home/ambika/INF_project/data/horse/23033.jpg, dtype: object\n",
      "prediction    [-1.7642, -1.66204, -2.57563, -1.34014, -1.710...\n",
      "ymin                                                         30\n",
      "xmin                                                        193\n",
      "ymax                                                        310\n",
      "xmax                                                        380\n",
      "Name: /home/ambika/INF_project/data/horse/23033.jpg, dtype: object\n",
      "horse\n",
      "146\t29\t380\t384\n",
      "camel\n",
      "193\t30\t380\t310\n",
      "23033\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:42:53.137943 29817 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:42:53.137960 29817 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:42:53.137964 29817 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:42:53.139061 29817 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:42:53.139166 29817 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:42:53.139178 29817 net.cpp:86] Creating Layer data\n",
      "I0430 04:42:53.139181 29817 net.cpp:382] data -> data\n",
      "I0430 04:42:53.139195 29817 net.cpp:124] Setting up data\n",
      "I0430 04:42:53.139201 29817 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:42:53.139204 29817 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:42:53.139255 29817 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:42:53.139262 29817 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:42:53.139266 29817 net.cpp:408] conv1 <- data\n",
      "I0430 04:42:53.139271 29817 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:42:53.139335 29817 net.cpp:124] Setting up conv1\n",
      "I0430 04:42:53.139341 29817 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:42:53.139343 29817 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:42:53.139353 29817 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:42:53.139358 29817 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:42:53.139360 29817 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:42:53.139365 29817 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:42:53.139370 29817 net.cpp:124] Setting up relu1\n",
      "I0430 04:42:53.139374 29817 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:42:53.139377 29817 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:42:53.139380 29817 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:42:53.139385 29817 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:42:53.139389 29817 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:42:53.139392 29817 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:42:53.139400 29817 net.cpp:124] Setting up pool1\n",
      "I0430 04:42:53.139405 29817 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:42:53.139406 29817 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:42:53.139410 29817 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:42:53.139415 29817 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:42:53.139418 29817 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:42:53.139422 29817 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:42:53.139430 29817 net.cpp:124] Setting up norm1\n",
      "I0430 04:42:53.139433 29817 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:42:53.139436 29817 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:42:53.139438 29817 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:42:53.139443 29817 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:42:53.139446 29817 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:42:53.139451 29817 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:42:53.139796 29817 net.cpp:124] Setting up conv2\n",
      "I0430 04:42:53.139802 29817 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:42:53.139806 29817 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:42:53.139812 29817 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:42:53.139820 29817 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:42:53.139823 29817 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:42:53.139828 29817 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:42:53.139835 29817 net.cpp:124] Setting up relu2\n",
      "I0430 04:42:53.139839 29817 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:42:53.139842 29817 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:42:53.139845 29817 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:42:53.139850 29817 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:42:53.139855 29817 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:42:53.139860 29817 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:42:53.139866 29817 net.cpp:124] Setting up pool2\n",
      "I0430 04:42:53.139870 29817 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:42:53.139873 29817 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:42:53.139876 29817 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:42:53.139881 29817 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:42:53.139884 29817 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:42:53.139889 29817 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:42:53.139894 29817 net.cpp:124] Setting up norm2\n",
      "I0430 04:42:53.139899 29817 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:42:53.139901 29817 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:42:53.139904 29817 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:42:53.139911 29817 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:42:53.139914 29817 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:42:53.139919 29817 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:42:53.140884 29817 net.cpp:124] Setting up conv3\n",
      "I0430 04:42:53.140894 29817 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:42:53.140898 29817 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:42:53.140907 29817 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:42:53.140913 29817 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:42:53.140914 29817 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:42:53.140919 29817 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:42:53.140924 29817 net.cpp:124] Setting up relu3\n",
      "I0430 04:42:53.140928 29817 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:42:53.140931 29817 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:42:53.140934 29817 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:42:53.140941 29817 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:42:53.140944 29817 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:42:53.140949 29817 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:42:53.141418 29817 net.cpp:124] Setting up conv4\n",
      "I0430 04:42:53.141427 29817 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:42:53.141430 29817 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:42:53.141436 29817 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:42:53.141441 29817 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:42:53.141443 29817 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:42:53.141448 29817 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:42:53.141453 29817 net.cpp:124] Setting up relu4\n",
      "I0430 04:42:53.141458 29817 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:42:53.141459 29817 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:42:53.141463 29817 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:42:53.141469 29817 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:42:53.141472 29817 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:42:53.141477 29817 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:42:53.141973 29817 net.cpp:124] Setting up conv5\n",
      "I0430 04:42:53.141980 29817 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:42:53.141983 29817 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:42:53.141993 29817 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:42:53.141997 29817 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:42:53.141999 29817 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:42:53.142004 29817 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:42:53.142009 29817 net.cpp:124] Setting up relu5\n",
      "I0430 04:42:53.142012 29817 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:42:53.142015 29817 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:42:53.142019 29817 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:42:53.142024 29817 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:42:53.142027 29817 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:42:53.142031 29817 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:42:53.142040 29817 net.cpp:124] Setting up pool5\n",
      "I0430 04:42:53.142043 29817 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:42:53.142045 29817 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:42:53.142050 29817 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:42:53.142056 29817 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:42:53.142060 29817 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:42:53.142063 29817 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:42:53.163797 29817 net.cpp:124] Setting up fc6\n",
      "I0430 04:42:53.163825 29817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:42:53.163830 29817 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:42:53.163841 29817 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:42:53.163851 29817 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:42:53.163854 29817 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:42:53.163861 29817 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:42:53.163872 29817 net.cpp:124] Setting up relu6\n",
      "I0430 04:42:53.163875 29817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:42:53.163877 29817 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:42:53.163882 29817 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:42:53.163888 29817 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:42:53.163892 29817 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:42:53.163895 29817 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:42:53.163902 29817 net.cpp:124] Setting up drop6\n",
      "I0430 04:42:53.163905 29817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:42:53.163908 29817 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:42:53.163911 29817 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:42:53.163919 29817 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:42:53.163923 29817 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:42:53.163928 29817 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:42:53.174851 29817 net.cpp:124] Setting up fc7\n",
      "I0430 04:42:53.174873 29817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:42:53.174877 29817 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:42:53.174886 29817 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:42:53.174896 29817 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:42:53.174899 29817 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:42:53.174906 29817 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:42:53.174913 29817 net.cpp:124] Setting up relu7\n",
      "I0430 04:42:53.174917 29817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:42:53.174919 29817 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:42:53.174921 29817 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:42:53.174926 29817 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:42:53.174929 29817 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:42:53.174945 29817 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:42:53.174959 29817 net.cpp:124] Setting up drop7\n",
      "I0430 04:42:53.174968 29817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:42:53.174969 29817 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:42:53.174973 29817 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:42:53.174978 29817 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:42:53.174981 29817 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:42:53.174986 29817 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:42:53.175647 29817 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:42:53.175659 29817 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:42:53.175663 29817 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:42:53.175671 29817 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:42:53.175675 29817 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:42:53.175678 29817 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:42:53.175683 29817 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:42:53.175685 29817 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:42:53.175688 29817 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:42:53.175691 29817 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:42:53.175695 29817 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:42:53.175698 29817 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:42:53.175701 29817 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:42:53.175704 29817 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:42:53.175709 29817 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:42:53.175711 29817 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:42:53.175714 29817 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:42:53.175717 29817 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:42:53.175721 29817 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:42:53.175724 29817 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:42:53.175727 29817 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:42:53.175730 29817 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:42:53.175734 29817 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:42:53.175737 29817 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:42:53.175740 29817 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:42:53.175743 29817 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:42:53.175746 29817 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:42:53.175757 29817 net.cpp:257] Network initialization done.\n",
      "I0430 04:42:53.262509 29817 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:42:53.360534 29817 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:42:53.361435 29817 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:42:53.361444 29817 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:42:53.361449 29817 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/106575.jpg'}, '/tmp/tmptsQZN8.mat')\n",
      "Processed 2357 windows in 270.276 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.33683, -2.08178, -1.88289, -2.39496, -1.86...\n",
      "ymin                                                          0\n",
      "xmin                                                        113\n",
      "ymax                                                        333\n",
      "xmax                                                        378\n",
      "Name: /home/ambika/INF_project/data/person/106575.jpg, dtype: object\n",
      "prediction    [-1.66842, -2.44423, -2.10583, -2.17899, -1.95...\n",
      "ymin                                                        108\n",
      "xmin                                                        213\n",
      "ymax                                                        304\n",
      "xmax                                                        394\n",
      "Name: /home/ambika/INF_project/data/person/106575.jpg, dtype: object\n",
      "person\n",
      "113\t0\t378\t333\n",
      "maillot\n",
      "213\t108\t394\t304\n",
      "106575\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:47:25.186651 30010 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:47:25.186667 30010 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:47:25.186671 30010 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:47:25.187768 30010 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:47:25.187872 30010 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:47:25.187880 30010 net.cpp:86] Creating Layer data\n",
      "I0430 04:47:25.187883 30010 net.cpp:382] data -> data\n",
      "I0430 04:47:25.187896 30010 net.cpp:124] Setting up data\n",
      "I0430 04:47:25.187903 30010 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:47:25.187906 30010 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:47:25.187909 30010 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:47:25.187914 30010 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:47:25.187917 30010 net.cpp:408] conv1 <- data\n",
      "I0430 04:47:25.187922 30010 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:47:25.187981 30010 net.cpp:124] Setting up conv1\n",
      "I0430 04:47:25.187986 30010 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:47:25.187989 30010 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:47:25.187996 30010 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:47:25.188000 30010 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:47:25.188004 30010 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:47:25.188006 30010 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:47:25.188011 30010 net.cpp:124] Setting up relu1\n",
      "I0430 04:47:25.188014 30010 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:47:25.188016 30010 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:47:25.188019 30010 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:47:25.188022 30010 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:47:25.188024 30010 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:47:25.188029 30010 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:47:25.188035 30010 net.cpp:124] Setting up pool1\n",
      "I0430 04:47:25.188037 30010 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:47:25.188040 30010 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:47:25.188042 30010 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:47:25.188046 30010 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:47:25.188050 30010 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:47:25.188052 30010 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:47:25.188057 30010 net.cpp:124] Setting up norm1\n",
      "I0430 04:47:25.188060 30010 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:47:25.188062 30010 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:47:25.188066 30010 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:47:25.188069 30010 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:47:25.188071 30010 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:47:25.188074 30010 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:47:25.188503 30010 net.cpp:124] Setting up conv2\n",
      "I0430 04:47:25.188511 30010 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:47:25.188513 30010 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:47:25.188519 30010 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:47:25.188524 30010 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:47:25.188527 30010 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:47:25.188531 30010 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:47:25.188535 30010 net.cpp:124] Setting up relu2\n",
      "I0430 04:47:25.188539 30010 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:47:25.188541 30010 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:47:25.188544 30010 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:47:25.188547 30010 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:47:25.188549 30010 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:47:25.188554 30010 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:47:25.188558 30010 net.cpp:124] Setting up pool2\n",
      "I0430 04:47:25.188562 30010 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:47:25.188565 30010 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:47:25.188566 30010 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:47:25.188572 30010 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:47:25.188575 30010 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:47:25.188577 30010 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:47:25.188582 30010 net.cpp:124] Setting up norm2\n",
      "I0430 04:47:25.188585 30010 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:47:25.188588 30010 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:47:25.188591 30010 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:47:25.188596 30010 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:47:25.188597 30010 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:47:25.188601 30010 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:47:25.189368 30010 net.cpp:124] Setting up conv3\n",
      "I0430 04:47:25.189398 30010 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:47:25.189400 30010 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:47:25.189414 30010 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:47:25.189422 30010 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:47:25.189426 30010 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:47:25.189434 30010 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:47:25.189441 30010 net.cpp:124] Setting up relu3\n",
      "I0430 04:47:25.189445 30010 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:47:25.189448 30010 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:47:25.189451 30010 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:47:25.189458 30010 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:47:25.189462 30010 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:47:25.189467 30010 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:47:25.190241 30010 net.cpp:124] Setting up conv4\n",
      "I0430 04:47:25.190256 30010 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:47:25.190260 30010 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:47:25.190268 30010 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:47:25.190276 30010 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:47:25.190279 30010 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:47:25.190284 30010 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:47:25.190290 30010 net.cpp:124] Setting up relu4\n",
      "I0430 04:47:25.190296 30010 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:47:25.190299 30010 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:47:25.190302 30010 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:47:25.190309 30010 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:47:25.190310 30010 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:47:25.190315 30010 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:47:25.190800 30010 net.cpp:124] Setting up conv5\n",
      "I0430 04:47:25.190809 30010 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:47:25.190811 30010 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:47:25.190821 30010 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:47:25.190825 30010 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:47:25.190829 30010 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:47:25.190834 30010 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:47:25.190837 30010 net.cpp:124] Setting up relu5\n",
      "I0430 04:47:25.190841 30010 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:47:25.190845 30010 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:47:25.190848 30010 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:47:25.190855 30010 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:47:25.190858 30010 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:47:25.190866 30010 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:47:25.190878 30010 net.cpp:124] Setting up pool5\n",
      "I0430 04:47:25.190883 30010 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:47:25.190886 30010 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:47:25.190889 30010 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:47:25.190896 30010 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:47:25.190899 30010 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:47:25.190904 30010 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:47:25.213954 30010 net.cpp:124] Setting up fc6\n",
      "I0430 04:47:25.213979 30010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:47:25.213984 30010 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:47:25.213995 30010 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:47:25.214007 30010 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:47:25.214012 30010 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:47:25.214021 30010 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:47:25.214033 30010 net.cpp:124] Setting up relu6\n",
      "I0430 04:47:25.214037 30010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:47:25.214040 30010 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:47:25.214042 30010 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:47:25.214051 30010 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:47:25.214053 30010 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:47:25.214056 30010 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:47:25.214063 30010 net.cpp:124] Setting up drop6\n",
      "I0430 04:47:25.214093 30010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:47:25.214097 30010 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:47:25.214099 30010 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:47:25.214108 30010 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:47:25.214110 30010 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:47:25.214117 30010 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:47:25.226140 30010 net.cpp:124] Setting up fc7\n",
      "I0430 04:47:25.226172 30010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:47:25.226178 30010 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:47:25.226189 30010 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:47:25.226199 30010 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:47:25.226203 30010 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:47:25.226212 30010 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:47:25.226220 30010 net.cpp:124] Setting up relu7\n",
      "I0430 04:47:25.226224 30010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:47:25.226227 30010 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:47:25.226229 30010 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:47:25.226234 30010 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:47:25.226236 30010 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:47:25.226256 30010 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:47:25.226263 30010 net.cpp:124] Setting up drop7\n",
      "I0430 04:47:25.226267 30010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:47:25.226270 30010 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:47:25.226274 30010 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:47:25.226279 30010 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:47:25.226281 30010 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:47:25.226286 30010 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:47:25.227265 30010 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:47:25.227282 30010 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:47:25.227285 30010 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:47:25.227294 30010 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:47:25.227298 30010 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:47:25.227301 30010 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:47:25.227303 30010 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:47:25.227306 30010 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:47:25.227309 30010 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:47:25.227313 30010 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:47:25.227315 30010 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:47:25.227319 30010 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:47:25.227322 30010 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:47:25.227325 30010 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:47:25.227329 30010 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:47:25.227332 30010 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:47:25.227335 30010 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:47:25.227339 30010 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:47:25.227342 30010 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:47:25.227345 30010 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:47:25.227349 30010 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:47:25.227352 30010 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:47:25.227355 30010 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:47:25.227358 30010 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:47:25.227361 30010 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:47:25.227365 30010 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:47:25.227367 30010 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:47:25.227380 30010 net.cpp:257] Network initialization done.\n",
      "I0430 04:47:25.314769 30010 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:47:25.415105 30010 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:47:25.416102 30010 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:47:25.416115 30010 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:47:25.416121 30010 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/561967.jpg'}, '/tmp/tmp3zWU7C.mat')\n",
      "Processed 2754 windows in 321.956 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-3.06775, -2.27501, -2.34598, -2.70027, -2.34...\n",
      "ymin                                                         48\n",
      "xmin                                                        151\n",
      "ymax                                                        291\n",
      "xmax                                                        411\n",
      "Name: /home/ambika/INF_project/data/train/561967.jpg, dtype: object\n",
      "prediction    [-2.70245, -2.37477, -2.21941, -2.23404, -2.07...\n",
      "ymin                                                        157\n",
      "xmin                                                        297\n",
      "ymax                                                        274\n",
      "xmax                                                        400\n",
      "Name: /home/ambika/INF_project/data/train/561967.jpg, dtype: object\n",
      "train\n",
      "151\t48\t411\t291\n",
      "bus\n",
      "297\t157\t400\t274\n",
      "561967\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:52:48.946477 30228 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:52:48.946496 30228 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:52:48.946499 30228 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:52:48.947629 30228 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:52:48.947703 30228 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:52:48.947710 30228 net.cpp:86] Creating Layer data\n",
      "I0430 04:52:48.947713 30228 net.cpp:382] data -> data\n",
      "I0430 04:52:48.947726 30228 net.cpp:124] Setting up data\n",
      "I0430 04:52:48.947734 30228 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:52:48.947736 30228 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:52:48.947739 30228 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:52:48.947746 30228 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:52:48.947748 30228 net.cpp:408] conv1 <- data\n",
      "I0430 04:52:48.947752 30228 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:52:48.947809 30228 net.cpp:124] Setting up conv1\n",
      "I0430 04:52:48.947813 30228 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:52:48.947816 30228 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:52:48.947824 30228 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:52:48.947827 30228 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:52:48.947830 30228 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:52:48.947834 30228 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:52:48.947839 30228 net.cpp:124] Setting up relu1\n",
      "I0430 04:52:48.947841 30228 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:52:48.947844 30228 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:52:48.947846 30228 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:52:48.947850 30228 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:52:48.947852 30228 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:52:48.947855 30228 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:52:48.947861 30228 net.cpp:124] Setting up pool1\n",
      "I0430 04:52:48.947865 30228 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:52:48.947867 30228 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:52:48.947870 30228 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:52:48.947875 30228 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:52:48.947876 30228 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:52:48.947880 30228 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:52:48.947885 30228 net.cpp:124] Setting up norm1\n",
      "I0430 04:52:48.947887 30228 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:52:48.947890 30228 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:52:48.947892 30228 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:52:48.947896 30228 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:52:48.947898 30228 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:52:48.947901 30228 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:52:48.948235 30228 net.cpp:124] Setting up conv2\n",
      "I0430 04:52:48.948240 30228 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:52:48.948241 30228 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:52:48.948246 30228 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:52:48.948251 30228 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:52:48.948253 30228 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:52:48.948257 30228 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:52:48.948261 30228 net.cpp:124] Setting up relu2\n",
      "I0430 04:52:48.948264 30228 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:52:48.948267 30228 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:52:48.948269 30228 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:52:48.948272 30228 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:52:48.948276 30228 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:52:48.948278 30228 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:52:48.948283 30228 net.cpp:124] Setting up pool2\n",
      "I0430 04:52:48.948287 30228 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:52:48.948288 30228 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:52:48.948292 30228 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:52:48.948295 30228 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:52:48.948298 30228 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:52:48.948302 30228 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:52:48.948305 30228 net.cpp:124] Setting up norm2\n",
      "I0430 04:52:48.948309 30228 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:52:48.948312 30228 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:52:48.948313 30228 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:52:48.948318 30228 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:52:48.948321 30228 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:52:48.948324 30228 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:52:48.949319 30228 net.cpp:124] Setting up conv3\n",
      "I0430 04:52:48.949331 30228 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:52:48.949333 30228 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:52:48.949340 30228 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:52:48.949345 30228 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:52:48.949348 30228 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:52:48.949352 30228 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:52:48.949357 30228 net.cpp:124] Setting up relu3\n",
      "I0430 04:52:48.949359 30228 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:52:48.949362 30228 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:52:48.949364 30228 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:52:48.949370 30228 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:52:48.949373 30228 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:52:48.949376 30228 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:52:48.949844 30228 net.cpp:124] Setting up conv4\n",
      "I0430 04:52:48.949851 30228 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:52:48.949856 30228 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:52:48.949863 30228 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:52:48.949880 30228 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:52:48.949884 30228 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:52:48.949890 30228 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:52:48.949897 30228 net.cpp:124] Setting up relu4\n",
      "I0430 04:52:48.949900 30228 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:52:48.949903 30228 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:52:48.949908 30228 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:52:48.949913 30228 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:52:48.949916 30228 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:52:48.949923 30228 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:52:48.950417 30228 net.cpp:124] Setting up conv5\n",
      "I0430 04:52:48.950425 30228 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:52:48.950428 30228 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:52:48.950438 30228 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:52:48.950443 30228 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:52:48.950445 30228 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:52:48.950450 30228 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:52:48.950455 30228 net.cpp:124] Setting up relu5\n",
      "I0430 04:52:48.950459 30228 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:52:48.950462 30228 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:52:48.950465 30228 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:52:48.950471 30228 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:52:48.950474 30228 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:52:48.950479 30228 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:52:48.950486 30228 net.cpp:124] Setting up pool5\n",
      "I0430 04:52:48.950490 30228 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:52:48.950494 30228 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:52:48.950496 30228 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:52:48.950505 30228 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:52:48.950507 30228 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:52:48.950511 30228 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:52:48.974308 30228 net.cpp:124] Setting up fc6\n",
      "I0430 04:52:48.974329 30228 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:52:48.974334 30228 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:52:48.974344 30228 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:52:48.974354 30228 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:52:48.974356 30228 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:52:48.974364 30228 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:52:48.974370 30228 net.cpp:124] Setting up relu6\n",
      "I0430 04:52:48.974375 30228 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:52:48.974376 30228 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:52:48.974380 30228 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:52:48.974385 30228 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:52:48.974387 30228 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:52:48.974391 30228 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:52:48.974397 30228 net.cpp:124] Setting up drop6\n",
      "I0430 04:52:48.974400 30228 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:52:48.974403 30228 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:52:48.974406 30228 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:52:48.974412 30228 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:52:48.974414 30228 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:52:48.974419 30228 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:52:48.984519 30228 net.cpp:124] Setting up fc7\n",
      "I0430 04:52:48.984544 30228 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:52:48.984550 30228 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:52:48.984560 30228 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:52:48.984568 30228 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:52:48.984572 30228 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:52:48.984580 30228 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:52:48.984588 30228 net.cpp:124] Setting up relu7\n",
      "I0430 04:52:48.984592 30228 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:52:48.984594 30228 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:52:48.984597 30228 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:52:48.984603 30228 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:52:48.984606 30228 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:52:48.984609 30228 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:52:48.984616 30228 net.cpp:124] Setting up drop7\n",
      "I0430 04:52:48.984621 30228 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:52:48.984622 30228 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:52:48.984625 30228 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:52:48.984630 30228 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:52:48.984633 30228 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:52:48.984637 30228 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:52:48.985575 30228 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:52:48.985587 30228 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:52:48.985590 30228 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:52:48.985597 30228 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:52:48.985600 30228 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:52:48.985604 30228 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:52:48.985606 30228 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:52:48.985610 30228 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:52:48.985612 30228 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:52:48.985616 30228 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:52:48.985620 30228 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:52:48.985622 30228 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:52:48.985625 30228 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:52:48.985628 30228 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:52:48.985631 30228 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:52:48.985635 30228 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:52:48.985638 30228 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:52:48.985641 30228 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:52:48.985644 30228 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:52:48.985647 30228 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:52:48.985651 30228 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:52:48.985654 30228 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:52:48.985657 30228 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:52:48.985661 30228 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:52:48.985663 30228 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:52:48.985666 30228 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:52:48.985669 30228 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:52:48.985680 30228 net.cpp:257] Network initialization done.\n",
      "I0430 04:52:49.071509 30228 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:52:49.169859 30228 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:52:49.171064 30228 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:52:49.171077 30228 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:52:49.171084 30228 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/316429.jpg'}, '/tmp/tmpHGEo63.mat')\n",
      "Processed 557 windows in 71.509 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.026 s.\n",
      "prediction    [-1.51864, -1.76655, -1.25042, -0.941232, -2.2...\n",
      "ymin                                                      121.5\n",
      "xmin                                                      160.5\n",
      "ymax                                                        145\n",
      "xmax                                                        181\n",
      "Name: /home/ambika/INF_project/data/airplane/316429.jpg, dtype: object\n",
      "prediction    [-1.66947, -1.74, -1.41031, -1.22813, -2.40199...\n",
      "ymin                                                      92.25\n",
      "xmin                                                        102\n",
      "ymax                                                        124\n",
      "xmax                                                        130\n",
      "Name: /home/ambika/INF_project/data/airplane/316429.jpg, dtype: object\n",
      "person\n",
      "160.5\t121.5\t181.0\t145.0\n",
      "bird\n",
      "102.0\t92.25\t130.0\t124.0\n",
      "316429\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:54:02.098644 30368 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:54:02.098668 30368 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:54:02.098681 30368 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:54:02.099812 30368 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:54:02.099978 30368 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:54:02.099987 30368 net.cpp:86] Creating Layer data\n",
      "I0430 04:54:02.099989 30368 net.cpp:382] data -> data\n",
      "I0430 04:54:02.099998 30368 net.cpp:124] Setting up data\n",
      "I0430 04:54:02.100003 30368 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:54:02.100006 30368 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:54:02.100009 30368 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:54:02.100015 30368 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:54:02.100018 30368 net.cpp:408] conv1 <- data\n",
      "I0430 04:54:02.100021 30368 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:54:02.100077 30368 net.cpp:124] Setting up conv1\n",
      "I0430 04:54:02.100082 30368 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:54:02.100085 30368 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:54:02.100091 30368 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:54:02.100096 30368 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:54:02.100098 30368 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:54:02.100102 30368 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:54:02.100106 30368 net.cpp:124] Setting up relu1\n",
      "I0430 04:54:02.100109 30368 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:54:02.100112 30368 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:54:02.100114 30368 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:54:02.100118 30368 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:54:02.100121 30368 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:54:02.100123 30368 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:54:02.100129 30368 net.cpp:124] Setting up pool1\n",
      "I0430 04:54:02.100133 30368 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:54:02.100136 30368 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:54:02.100137 30368 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:54:02.100142 30368 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:54:02.100144 30368 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:54:02.100147 30368 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:54:02.100152 30368 net.cpp:124] Setting up norm1\n",
      "I0430 04:54:02.100155 30368 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:54:02.100157 30368 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:54:02.100160 30368 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:54:02.100164 30368 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:54:02.100167 30368 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:54:02.100170 30368 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:54:02.100502 30368 net.cpp:124] Setting up conv2\n",
      "I0430 04:54:02.100507 30368 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:54:02.100509 30368 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:54:02.100514 30368 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:54:02.100519 30368 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:54:02.100522 30368 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:54:02.100525 30368 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:54:02.100528 30368 net.cpp:124] Setting up relu2\n",
      "I0430 04:54:02.100531 30368 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:54:02.100534 30368 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:54:02.100536 30368 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:54:02.100539 30368 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:54:02.100543 30368 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:54:02.100545 30368 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:54:02.100549 30368 net.cpp:124] Setting up pool2\n",
      "I0430 04:54:02.100553 30368 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:54:02.100555 30368 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:54:02.100558 30368 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:54:02.100563 30368 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:54:02.100565 30368 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:54:02.100569 30368 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:54:02.100574 30368 net.cpp:124] Setting up norm2\n",
      "I0430 04:54:02.100576 30368 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:54:02.100579 30368 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:54:02.100580 30368 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:54:02.100586 30368 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:54:02.100589 30368 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:54:02.100592 30368 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:54:02.101265 30368 net.cpp:124] Setting up conv3\n",
      "I0430 04:54:02.101289 30368 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:54:02.101290 30368 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:54:02.101297 30368 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:54:02.101301 30368 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:54:02.101305 30368 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:54:02.101307 30368 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:54:02.101311 30368 net.cpp:124] Setting up relu3\n",
      "I0430 04:54:02.101315 30368 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:54:02.101317 30368 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:54:02.101320 30368 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:54:02.101325 30368 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:54:02.101327 30368 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:54:02.101331 30368 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:54:02.102047 30368 net.cpp:124] Setting up conv4\n",
      "I0430 04:54:02.102054 30368 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:54:02.102057 30368 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:54:02.102061 30368 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:54:02.102066 30368 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:54:02.102068 30368 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:54:02.102073 30368 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:54:02.102077 30368 net.cpp:124] Setting up relu4\n",
      "I0430 04:54:02.102080 30368 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:54:02.102082 30368 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:54:02.102085 30368 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:54:02.102089 30368 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:54:02.102092 30368 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:54:02.102097 30368 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:54:02.102588 30368 net.cpp:124] Setting up conv5\n",
      "I0430 04:54:02.102593 30368 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:54:02.102596 30368 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:54:02.102603 30368 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:54:02.102607 30368 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:54:02.102609 30368 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:54:02.102613 30368 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:54:02.102617 30368 net.cpp:124] Setting up relu5\n",
      "I0430 04:54:02.102620 30368 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:54:02.102622 30368 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:54:02.102624 30368 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:54:02.102629 30368 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:54:02.102632 30368 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:54:02.102635 30368 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:54:02.102641 30368 net.cpp:124] Setting up pool5\n",
      "I0430 04:54:02.102646 30368 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:54:02.102650 30368 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:54:02.102653 30368 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:54:02.102660 30368 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:54:02.102663 30368 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:54:02.102668 30368 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:54:02.124469 30368 net.cpp:124] Setting up fc6\n",
      "I0430 04:54:02.124493 30368 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:54:02.124497 30368 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:54:02.124510 30368 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:54:02.124518 30368 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:54:02.124522 30368 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:54:02.124529 30368 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:54:02.124537 30368 net.cpp:124] Setting up relu6\n",
      "I0430 04:54:02.124541 30368 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:54:02.124543 30368 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:54:02.124547 30368 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:54:02.124552 30368 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:54:02.124555 30368 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:54:02.124559 30368 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:54:02.124565 30368 net.cpp:124] Setting up drop6\n",
      "I0430 04:54:02.124568 30368 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:54:02.124572 30368 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:54:02.124574 30368 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:54:02.124583 30368 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:54:02.124586 30368 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:54:02.124591 30368 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:54:02.136252 30368 net.cpp:124] Setting up fc7\n",
      "I0430 04:54:02.136276 30368 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:54:02.136279 30368 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:54:02.136289 30368 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:54:02.136297 30368 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:54:02.136301 30368 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:54:02.136307 30368 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:54:02.136317 30368 net.cpp:124] Setting up relu7\n",
      "I0430 04:54:02.136320 30368 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:54:02.136322 30368 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:54:02.136325 30368 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:54:02.136332 30368 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:54:02.136333 30368 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:54:02.136337 30368 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:54:02.136343 30368 net.cpp:124] Setting up drop7\n",
      "I0430 04:54:02.136348 30368 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:54:02.136349 30368 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:54:02.136353 30368 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:54:02.136358 30368 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:54:02.136359 30368 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:54:02.136363 30368 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:54:02.136977 30368 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:54:02.136984 30368 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:54:02.136987 30368 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:54:02.136993 30368 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:54:02.136996 30368 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:54:02.136999 30368 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:54:02.137002 30368 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:54:02.137004 30368 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:54:02.137007 30368 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:54:02.137011 30368 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:54:02.137013 30368 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:54:02.137017 30368 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:54:02.137020 30368 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:54:02.137023 30368 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:54:02.137027 30368 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:54:02.137029 30368 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:54:02.137033 30368 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:54:02.137037 30368 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:54:02.137040 30368 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:54:02.137043 30368 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:54:02.137046 30368 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:54:02.137050 30368 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:54:02.137053 30368 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:54:02.137056 30368 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:54:02.137059 30368 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:54:02.137063 30368 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:54:02.137064 30368 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:54:02.137075 30368 net.cpp:257] Network initialization done.\n",
      "I0430 04:54:02.234225 30368 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:54:02.337683 30368 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:54:02.338532 30368 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:54:02.338541 30368 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:54:02.338544 30368 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/402000.jpg'}, '/tmp/tmp9Q5ZQg.mat')\n",
      "Processed 1879 windows in 221.076 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.040 s.\n",
      "prediction    [-2.36391, -2.85822, -1.5895, -1.97176, -1.883...\n",
      "ymin                                                        229\n",
      "xmin                                                        198\n",
      "ymax                                                        317\n",
      "xmax                                                        226\n",
      "Name: /home/ambika/INF_project/data/bird/402000.jpg, dtype: object\n",
      "prediction    [-1.89033, -1.96234, -1.49703, -1.55756, -1.85...\n",
      "ymin                                                         35\n",
      "xmin                                                        290\n",
      "ymax                                                         56\n",
      "xmax                                                        386\n",
      "Name: /home/ambika/INF_project/data/bird/402000.jpg, dtype: object\n",
      "person\n",
      "198\t229\t226\t317\n",
      "whale\n",
      "290\t35\t386\t56\n",
      "402000\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 04:57:44.958760 30536 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 04:57:44.958780 30536 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 04:57:44.958783 30536 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 04:57:44.959885 30536 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 04:57:44.959961 30536 layer_factory.hpp:77] Creating layer data\n",
      "I0430 04:57:44.959969 30536 net.cpp:86] Creating Layer data\n",
      "I0430 04:57:44.959972 30536 net.cpp:382] data -> data\n",
      "I0430 04:57:44.959985 30536 net.cpp:124] Setting up data\n",
      "I0430 04:57:44.959993 30536 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 04:57:44.959995 30536 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 04:57:44.959998 30536 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 04:57:44.960003 30536 net.cpp:86] Creating Layer conv1\n",
      "I0430 04:57:44.960006 30536 net.cpp:408] conv1 <- data\n",
      "I0430 04:57:44.960011 30536 net.cpp:382] conv1 -> conv1\n",
      "I0430 04:57:44.960065 30536 net.cpp:124] Setting up conv1\n",
      "I0430 04:57:44.960069 30536 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:57:44.960072 30536 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 04:57:44.960079 30536 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 04:57:44.960083 30536 net.cpp:86] Creating Layer relu1\n",
      "I0430 04:57:44.960086 30536 net.cpp:408] relu1 <- conv1\n",
      "I0430 04:57:44.960089 30536 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 04:57:44.960093 30536 net.cpp:124] Setting up relu1\n",
      "I0430 04:57:44.960096 30536 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 04:57:44.960099 30536 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 04:57:44.960101 30536 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 04:57:44.960105 30536 net.cpp:86] Creating Layer pool1\n",
      "I0430 04:57:44.960108 30536 net.cpp:408] pool1 <- conv1\n",
      "I0430 04:57:44.960110 30536 net.cpp:382] pool1 -> pool1\n",
      "I0430 04:57:44.960116 30536 net.cpp:124] Setting up pool1\n",
      "I0430 04:57:44.960119 30536 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:57:44.960121 30536 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 04:57:44.960124 30536 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 04:57:44.960129 30536 net.cpp:86] Creating Layer norm1\n",
      "I0430 04:57:44.960130 30536 net.cpp:408] norm1 <- pool1\n",
      "I0430 04:57:44.960134 30536 net.cpp:382] norm1 -> norm1\n",
      "I0430 04:57:44.960139 30536 net.cpp:124] Setting up norm1\n",
      "I0430 04:57:44.960141 30536 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 04:57:44.960144 30536 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 04:57:44.960146 30536 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 04:57:44.960150 30536 net.cpp:86] Creating Layer conv2\n",
      "I0430 04:57:44.960152 30536 net.cpp:408] conv2 <- norm1\n",
      "I0430 04:57:44.960155 30536 net.cpp:382] conv2 -> conv2\n",
      "I0430 04:57:44.960489 30536 net.cpp:124] Setting up conv2\n",
      "I0430 04:57:44.960494 30536 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:57:44.960497 30536 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 04:57:44.960502 30536 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 04:57:44.960505 30536 net.cpp:86] Creating Layer relu2\n",
      "I0430 04:57:44.960508 30536 net.cpp:408] relu2 <- conv2\n",
      "I0430 04:57:44.960511 30536 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 04:57:44.960515 30536 net.cpp:124] Setting up relu2\n",
      "I0430 04:57:44.960518 30536 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 04:57:44.960520 30536 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 04:57:44.960522 30536 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 04:57:44.960525 30536 net.cpp:86] Creating Layer pool2\n",
      "I0430 04:57:44.960528 30536 net.cpp:408] pool2 <- conv2\n",
      "I0430 04:57:44.960531 30536 net.cpp:382] pool2 -> pool2\n",
      "I0430 04:57:44.960536 30536 net.cpp:124] Setting up pool2\n",
      "I0430 04:57:44.960539 30536 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:57:44.960541 30536 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 04:57:44.960544 30536 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 04:57:44.960549 30536 net.cpp:86] Creating Layer norm2\n",
      "I0430 04:57:44.960551 30536 net.cpp:408] norm2 <- pool2\n",
      "I0430 04:57:44.960554 30536 net.cpp:382] norm2 -> norm2\n",
      "I0430 04:57:44.960559 30536 net.cpp:124] Setting up norm2\n",
      "I0430 04:57:44.960562 30536 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:57:44.960564 30536 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 04:57:44.960567 30536 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 04:57:44.960571 30536 net.cpp:86] Creating Layer conv3\n",
      "I0430 04:57:44.960573 30536 net.cpp:408] conv3 <- norm2\n",
      "I0430 04:57:44.960577 30536 net.cpp:382] conv3 -> conv3\n",
      "I0430 04:57:44.961252 30536 net.cpp:124] Setting up conv3\n",
      "I0430 04:57:44.961261 30536 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:57:44.961264 30536 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 04:57:44.961272 30536 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 04:57:44.961277 30536 net.cpp:86] Creating Layer relu3\n",
      "I0430 04:57:44.961279 30536 net.cpp:408] relu3 <- conv3\n",
      "I0430 04:57:44.961283 30536 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 04:57:44.961287 30536 net.cpp:124] Setting up relu3\n",
      "I0430 04:57:44.961290 30536 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:57:44.961292 30536 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 04:57:44.961295 30536 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 04:57:44.961299 30536 net.cpp:86] Creating Layer conv4\n",
      "I0430 04:57:44.961302 30536 net.cpp:408] conv4 <- conv3\n",
      "I0430 04:57:44.961307 30536 net.cpp:382] conv4 -> conv4\n",
      "I0430 04:57:44.962062 30536 net.cpp:124] Setting up conv4\n",
      "I0430 04:57:44.962074 30536 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:57:44.962076 30536 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 04:57:44.962082 30536 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 04:57:44.962087 30536 net.cpp:86] Creating Layer relu4\n",
      "I0430 04:57:44.962090 30536 net.cpp:408] relu4 <- conv4\n",
      "I0430 04:57:44.962096 30536 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 04:57:44.962100 30536 net.cpp:124] Setting up relu4\n",
      "I0430 04:57:44.962105 30536 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 04:57:44.962106 30536 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 04:57:44.962108 30536 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 04:57:44.962115 30536 net.cpp:86] Creating Layer conv5\n",
      "I0430 04:57:44.962116 30536 net.cpp:408] conv5 <- conv4\n",
      "I0430 04:57:44.962121 30536 net.cpp:382] conv5 -> conv5\n",
      "I0430 04:57:44.962604 30536 net.cpp:124] Setting up conv5\n",
      "I0430 04:57:44.962610 30536 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:57:44.962613 30536 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 04:57:44.962620 30536 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 04:57:44.962623 30536 net.cpp:86] Creating Layer relu5\n",
      "I0430 04:57:44.962625 30536 net.cpp:408] relu5 <- conv5\n",
      "I0430 04:57:44.962628 30536 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 04:57:44.962632 30536 net.cpp:124] Setting up relu5\n",
      "I0430 04:57:44.962635 30536 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 04:57:44.962637 30536 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 04:57:44.962641 30536 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 04:57:44.962644 30536 net.cpp:86] Creating Layer pool5\n",
      "I0430 04:57:44.962647 30536 net.cpp:408] pool5 <- conv5\n",
      "I0430 04:57:44.962651 30536 net.cpp:382] pool5 -> pool5\n",
      "I0430 04:57:44.962657 30536 net.cpp:124] Setting up pool5\n",
      "I0430 04:57:44.962661 30536 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 04:57:44.962663 30536 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 04:57:44.962666 30536 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 04:57:44.962672 30536 net.cpp:86] Creating Layer fc6\n",
      "I0430 04:57:44.962676 30536 net.cpp:408] fc6 <- pool5\n",
      "I0430 04:57:44.962678 30536 net.cpp:382] fc6 -> fc6\n",
      "I0430 04:57:44.987746 30536 net.cpp:124] Setting up fc6\n",
      "I0430 04:57:44.987771 30536 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:57:44.987776 30536 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 04:57:44.987788 30536 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 04:57:44.987805 30536 net.cpp:86] Creating Layer relu6\n",
      "I0430 04:57:44.987809 30536 net.cpp:408] relu6 <- fc6\n",
      "I0430 04:57:44.987817 30536 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 04:57:44.987825 30536 net.cpp:124] Setting up relu6\n",
      "I0430 04:57:44.987838 30536 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:57:44.987840 30536 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 04:57:44.987843 30536 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 04:57:44.987848 30536 net.cpp:86] Creating Layer drop6\n",
      "I0430 04:57:44.987850 30536 net.cpp:408] drop6 <- fc6\n",
      "I0430 04:57:44.987854 30536 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 04:57:44.987860 30536 net.cpp:124] Setting up drop6\n",
      "I0430 04:57:44.987864 30536 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:57:44.987866 30536 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 04:57:44.987869 30536 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 04:57:44.987874 30536 net.cpp:86] Creating Layer fc7\n",
      "I0430 04:57:44.987875 30536 net.cpp:408] fc7 <- fc6\n",
      "I0430 04:57:44.987880 30536 net.cpp:382] fc7 -> fc7\n",
      "I0430 04:57:44.997849 30536 net.cpp:124] Setting up fc7\n",
      "I0430 04:57:44.997872 30536 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:57:44.997875 30536 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 04:57:44.997889 30536 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 04:57:44.997907 30536 net.cpp:86] Creating Layer relu7\n",
      "I0430 04:57:44.997911 30536 net.cpp:408] relu7 <- fc7\n",
      "I0430 04:57:44.997918 30536 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 04:57:44.997927 30536 net.cpp:124] Setting up relu7\n",
      "I0430 04:57:44.997931 30536 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:57:44.997934 30536 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 04:57:44.997938 30536 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 04:57:44.997944 30536 net.cpp:86] Creating Layer drop7\n",
      "I0430 04:57:44.997947 30536 net.cpp:408] drop7 <- fc7\n",
      "I0430 04:57:44.997953 30536 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 04:57:44.997958 30536 net.cpp:124] Setting up drop7\n",
      "I0430 04:57:44.997962 30536 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 04:57:44.997964 30536 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 04:57:44.997968 30536 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 04:57:44.997973 30536 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 04:57:44.997975 30536 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 04:57:44.997980 30536 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 04:57:44.998903 30536 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 04:57:44.998914 30536 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 04:57:44.998917 30536 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 04:57:44.998924 30536 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 04:57:44.998929 30536 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 04:57:44.998931 30536 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 04:57:44.998934 30536 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 04:57:44.998937 30536 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 04:57:44.998939 30536 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 04:57:44.998942 30536 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 04:57:44.998946 30536 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 04:57:44.998950 30536 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 04:57:44.998953 30536 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 04:57:44.998956 30536 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 04:57:44.998960 30536 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 04:57:44.998963 30536 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 04:57:44.998966 30536 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 04:57:44.998970 30536 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 04:57:44.998973 30536 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 04:57:44.998976 30536 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 04:57:44.998980 30536 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 04:57:44.998983 30536 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 04:57:44.998986 30536 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 04:57:44.998989 30536 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 04:57:44.998992 30536 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 04:57:44.998996 30536 net.cpp:202] data does not need backward computation.\n",
      "I0430 04:57:44.998998 30536 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 04:57:44.999011 30536 net.cpp:257] Network initialization done.\n",
      "I0430 04:57:45.086597 30536 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:57:45.186204 30536 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 04:57:45.187149 30536 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 04:57:45.187157 30536 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 04:57:45.187162 30536 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/184324.jpg'}, '/tmp/tmplE6y1A.mat')\n",
      "Processed 2521 windows in 286.899 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.00809, -2.09617, -1.91067, -1.9403, -1.956...\n",
      "ymin                                                        183\n",
      "xmin                                                        212\n",
      "ymax                                                        210\n",
      "xmax                                                        269\n",
      "Name: /home/ambika/INF_project/data/bus/184324.jpg, dtype: object\n",
      "prediction    [-2.34885, -2.43885, -1.98159, -2.0239, -1.898...\n",
      "ymin                                                        197\n",
      "xmin                                                        430\n",
      "ymax                                                        275\n",
      "xmax                                                        471\n",
      "Name: /home/ambika/INF_project/data/bus/184324.jpg, dtype: object\n",
      "car\n",
      "212\t183\t269\t210\n",
      "person\n",
      "430\t197\t471\t275\n",
      "184324\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:02:33.651859 30739 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:02:33.651873 30739 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:02:33.651875 30739 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:02:33.652971 30739 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:02:33.653048 30739 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:02:33.653053 30739 net.cpp:86] Creating Layer data\n",
      "I0430 05:02:33.653057 30739 net.cpp:382] data -> data\n",
      "I0430 05:02:33.653070 30739 net.cpp:124] Setting up data\n",
      "I0430 05:02:33.653079 30739 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:02:33.653080 30739 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:02:33.653084 30739 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:02:33.653090 30739 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:02:33.653092 30739 net.cpp:408] conv1 <- data\n",
      "I0430 05:02:33.653096 30739 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:02:33.653156 30739 net.cpp:124] Setting up conv1\n",
      "I0430 05:02:33.653161 30739 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:02:33.653163 30739 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:02:33.653170 30739 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:02:33.653174 30739 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:02:33.653177 30739 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:02:33.653180 30739 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:02:33.653185 30739 net.cpp:124] Setting up relu1\n",
      "I0430 05:02:33.653188 30739 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:02:33.653190 30739 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:02:33.653192 30739 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:02:33.653197 30739 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:02:33.653198 30739 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:02:33.653203 30739 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:02:33.653208 30739 net.cpp:124] Setting up pool1\n",
      "I0430 05:02:33.653211 30739 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:02:33.653213 30739 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:02:33.653216 30739 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:02:33.653220 30739 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:02:33.653223 30739 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:02:33.653225 30739 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:02:33.653230 30739 net.cpp:124] Setting up norm1\n",
      "I0430 05:02:33.653234 30739 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:02:33.653236 30739 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:02:33.653239 30739 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:02:33.653242 30739 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:02:33.653244 30739 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:02:33.653249 30739 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:02:33.653589 30739 net.cpp:124] Setting up conv2\n",
      "I0430 05:02:33.653594 30739 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:02:33.653596 30739 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:02:33.653601 30739 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:02:33.653605 30739 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:02:33.653609 30739 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:02:33.653611 30739 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:02:33.653615 30739 net.cpp:124] Setting up relu2\n",
      "I0430 05:02:33.653619 30739 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:02:33.653620 30739 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:02:33.653623 30739 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:02:33.653627 30739 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:02:33.653630 30739 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:02:33.653633 30739 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:02:33.653638 30739 net.cpp:124] Setting up pool2\n",
      "I0430 05:02:33.653641 30739 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:02:33.653643 30739 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:02:33.653646 30739 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:02:33.653650 30739 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:02:33.653653 30739 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:02:33.653656 30739 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:02:33.653661 30739 net.cpp:124] Setting up norm2\n",
      "I0430 05:02:33.653664 30739 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:02:33.653666 30739 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:02:33.653668 30739 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:02:33.653672 30739 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:02:33.653676 30739 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:02:33.653678 30739 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:02:33.654359 30739 net.cpp:124] Setting up conv3\n",
      "I0430 05:02:33.654368 30739 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:02:33.654371 30739 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:02:33.654377 30739 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:02:33.654384 30739 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:02:33.654386 30739 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:02:33.654391 30739 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:02:33.654394 30739 net.cpp:124] Setting up relu3\n",
      "I0430 05:02:33.654398 30739 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:02:33.654400 30739 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:02:33.654402 30739 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:02:33.654407 30739 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:02:33.654409 30739 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:02:33.654412 30739 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:02:33.655135 30739 net.cpp:124] Setting up conv4\n",
      "I0430 05:02:33.655143 30739 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:02:33.655145 30739 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:02:33.655149 30739 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:02:33.655155 30739 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:02:33.655158 30739 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:02:33.655161 30739 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:02:33.655165 30739 net.cpp:124] Setting up relu4\n",
      "I0430 05:02:33.655169 30739 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:02:33.655171 30739 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:02:33.655174 30739 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:02:33.655177 30739 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:02:33.655179 30739 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:02:33.655184 30739 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:02:33.655727 30739 net.cpp:124] Setting up conv5\n",
      "I0430 05:02:33.655736 30739 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:02:33.655740 30739 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:02:33.655748 30739 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:02:33.655753 30739 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:02:33.655756 30739 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:02:33.655761 30739 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:02:33.655764 30739 net.cpp:124] Setting up relu5\n",
      "I0430 05:02:33.655767 30739 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:02:33.655771 30739 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:02:33.655772 30739 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:02:33.655777 30739 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:02:33.655779 30739 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:02:33.655783 30739 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:02:33.655789 30739 net.cpp:124] Setting up pool5\n",
      "I0430 05:02:33.655792 30739 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:02:33.655796 30739 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:02:33.655797 30739 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:02:33.655803 30739 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:02:33.655805 30739 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:02:33.655809 30739 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:02:33.679949 30739 net.cpp:124] Setting up fc6\n",
      "I0430 05:02:33.679970 30739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:02:33.679975 30739 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:02:33.679981 30739 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:02:33.679988 30739 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:02:33.679991 30739 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:02:33.679994 30739 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:02:33.680001 30739 net.cpp:124] Setting up relu6\n",
      "I0430 05:02:33.680006 30739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:02:33.680007 30739 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:02:33.680009 30739 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:02:33.680014 30739 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:02:33.680016 30739 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:02:33.680019 30739 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:02:33.680030 30739 net.cpp:124] Setting up drop6\n",
      "I0430 05:02:33.680033 30739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:02:33.680035 30739 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:02:33.680038 30739 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:02:33.680044 30739 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:02:33.680047 30739 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:02:33.680050 30739 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:02:33.690028 30739 net.cpp:124] Setting up fc7\n",
      "I0430 05:02:33.690053 30739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:02:33.690057 30739 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:02:33.690068 30739 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:02:33.690084 30739 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:02:33.690088 30739 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:02:33.690095 30739 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:02:33.690102 30739 net.cpp:124] Setting up relu7\n",
      "I0430 05:02:33.690105 30739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:02:33.690109 30739 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:02:33.690109 30739 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:02:33.690114 30739 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:02:33.690116 30739 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:02:33.690119 30739 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:02:33.690124 30739 net.cpp:124] Setting up drop7\n",
      "I0430 05:02:33.690127 30739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:02:33.690129 30739 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:02:33.690131 30739 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:02:33.690135 30739 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:02:33.690137 30739 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:02:33.690141 30739 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:02:33.691076 30739 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:02:33.691092 30739 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:02:33.691097 30739 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:02:33.691130 30739 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:02:33.691136 30739 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:02:33.691139 30739 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:02:33.691143 30739 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:02:33.691146 30739 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:02:33.691150 30739 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:02:33.691154 30739 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:02:33.691157 30739 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:02:33.691161 30739 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:02:33.691164 30739 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:02:33.691167 30739 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:02:33.691170 30739 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:02:33.691174 30739 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:02:33.691176 30739 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:02:33.691180 30739 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:02:33.691184 30739 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:02:33.691186 30739 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:02:33.691190 30739 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:02:33.691193 30739 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:02:33.691196 30739 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:02:33.691200 30739 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:02:33.691203 30739 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:02:33.691216 30739 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:02:33.691220 30739 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:02:33.691231 30739 net.cpp:257] Network initialization done.\n",
      "I0430 05:02:33.779397 30739 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:02:33.880648 30739 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:02:33.881573 30739 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:02:33.881582 30739 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:02:33.881585 30739 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/150623.jpg'}, '/tmp/tmpepYidq.mat')\n",
      "Processed 2301 windows in 268.379 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-1.97199, -2.23854, -1.98899, -2.99156, -2.05...\n",
      "ymin                                                         86\n",
      "xmin                                                        210\n",
      "ymax                                                        334\n",
      "xmax                                                        375\n",
      "Name: /home/ambika/INF_project/data/car/150623.jpg, dtype: object\n",
      "prediction    [-2.11324, -2.13045, -2.34809, -2.43907, -2.31...\n",
      "ymin                                                         95\n",
      "xmin                                                        205\n",
      "ymax                                                        150\n",
      "xmax                                                        295\n",
      "Name: /home/ambika/INF_project/data/car/150623.jpg, dtype: object\n",
      "person\n",
      "210\t86\t375\t334\n",
      "car\n",
      "205\t95\t295\t150\n",
      "150623\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:07:03.788455 30923 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:07:03.788470 30923 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:07:03.788472 30923 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:07:03.789561 30923 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:07:03.789639 30923 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:07:03.789649 30923 net.cpp:86] Creating Layer data\n",
      "I0430 05:07:03.789654 30923 net.cpp:382] data -> data\n",
      "I0430 05:07:03.789665 30923 net.cpp:124] Setting up data\n",
      "I0430 05:07:03.789670 30923 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:07:03.789672 30923 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:07:03.789675 30923 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:07:03.789681 30923 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:07:03.789685 30923 net.cpp:408] conv1 <- data\n",
      "I0430 05:07:03.789688 30923 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:07:03.789746 30923 net.cpp:124] Setting up conv1\n",
      "I0430 05:07:03.789750 30923 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:07:03.789753 30923 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:07:03.789760 30923 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:07:03.789765 30923 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:07:03.789768 30923 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:07:03.789772 30923 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:07:03.789775 30923 net.cpp:124] Setting up relu1\n",
      "I0430 05:07:03.789779 30923 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:07:03.789782 30923 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:07:03.789783 30923 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:07:03.789788 30923 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:07:03.789789 30923 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:07:03.789793 30923 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:07:03.789799 30923 net.cpp:124] Setting up pool1\n",
      "I0430 05:07:03.789803 30923 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:07:03.789804 30923 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:07:03.789808 30923 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:07:03.789811 30923 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:07:03.789813 30923 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:07:03.789818 30923 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:07:03.789822 30923 net.cpp:124] Setting up norm1\n",
      "I0430 05:07:03.789825 30923 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:07:03.789827 30923 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:07:03.789830 30923 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:07:03.789834 30923 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:07:03.789836 30923 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:07:03.789839 30923 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:07:03.790163 30923 net.cpp:124] Setting up conv2\n",
      "I0430 05:07:03.790172 30923 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:07:03.790174 30923 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:07:03.790181 30923 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:07:03.790187 30923 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:07:03.790189 30923 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:07:03.790192 30923 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:07:03.790196 30923 net.cpp:124] Setting up relu2\n",
      "I0430 05:07:03.790199 30923 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:07:03.790201 30923 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:07:03.790205 30923 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:07:03.790207 30923 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:07:03.790210 30923 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:07:03.790213 30923 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:07:03.790217 30923 net.cpp:124] Setting up pool2\n",
      "I0430 05:07:03.790221 30923 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:07:03.790223 30923 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:07:03.790226 30923 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:07:03.790231 30923 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:07:03.790233 30923 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:07:03.790236 30923 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:07:03.790241 30923 net.cpp:124] Setting up norm2\n",
      "I0430 05:07:03.790244 30923 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:07:03.790247 30923 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:07:03.790249 30923 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:07:03.790253 30923 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:07:03.790256 30923 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:07:03.790259 30923 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:07:03.791218 30923 net.cpp:124] Setting up conv3\n",
      "I0430 05:07:03.791229 30923 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:07:03.791232 30923 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:07:03.791239 30923 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:07:03.791244 30923 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:07:03.791247 30923 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:07:03.791251 30923 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:07:03.791255 30923 net.cpp:124] Setting up relu3\n",
      "I0430 05:07:03.791259 30923 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:07:03.791260 30923 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:07:03.791263 30923 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:07:03.791268 30923 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:07:03.791270 30923 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:07:03.791273 30923 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:07:03.791785 30923 net.cpp:124] Setting up conv4\n",
      "I0430 05:07:03.791792 30923 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:07:03.791795 30923 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:07:03.791800 30923 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:07:03.791803 30923 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:07:03.791805 30923 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:07:03.791810 30923 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:07:03.791815 30923 net.cpp:124] Setting up relu4\n",
      "I0430 05:07:03.791817 30923 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:07:03.791820 30923 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:07:03.791822 30923 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:07:03.791826 30923 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:07:03.791828 30923 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:07:03.791832 30923 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:07:03.792307 30923 net.cpp:124] Setting up conv5\n",
      "I0430 05:07:03.792313 30923 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:07:03.792316 30923 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:07:03.792322 30923 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:07:03.792327 30923 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:07:03.792330 30923 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:07:03.792333 30923 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:07:03.792336 30923 net.cpp:124] Setting up relu5\n",
      "I0430 05:07:03.792340 30923 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:07:03.792342 30923 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:07:03.792345 30923 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:07:03.792349 30923 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:07:03.792352 30923 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:07:03.792356 30923 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:07:03.792361 30923 net.cpp:124] Setting up pool5\n",
      "I0430 05:07:03.792364 30923 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:07:03.792367 30923 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:07:03.792369 30923 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:07:03.792377 30923 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:07:03.792381 30923 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:07:03.792384 30923 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:07:03.814286 30923 net.cpp:124] Setting up fc6\n",
      "I0430 05:07:03.814319 30923 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:07:03.814323 30923 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:07:03.814350 30923 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:07:03.814359 30923 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:07:03.814363 30923 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:07:03.814368 30923 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:07:03.814376 30923 net.cpp:124] Setting up relu6\n",
      "I0430 05:07:03.814379 30923 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:07:03.814380 30923 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:07:03.814383 30923 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:07:03.814386 30923 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:07:03.814388 30923 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:07:03.814390 30923 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:07:03.814399 30923 net.cpp:124] Setting up drop6\n",
      "I0430 05:07:03.814404 30923 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:07:03.814405 30923 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:07:03.814407 30923 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:07:03.814412 30923 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:07:03.814414 30923 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:07:03.814419 30923 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:07:03.827702 30923 net.cpp:124] Setting up fc7\n",
      "I0430 05:07:03.827729 30923 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:07:03.827733 30923 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:07:03.827741 30923 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:07:03.827750 30923 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:07:03.827754 30923 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:07:03.827764 30923 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:07:03.827774 30923 net.cpp:124] Setting up relu7\n",
      "I0430 05:07:03.827778 30923 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:07:03.827781 30923 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:07:03.827785 30923 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:07:03.827790 30923 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:07:03.827795 30923 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:07:03.827802 30923 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:07:03.827810 30923 net.cpp:124] Setting up drop7\n",
      "I0430 05:07:03.827813 30923 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:07:03.827816 30923 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:07:03.827819 30923 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:07:03.827826 30923 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:07:03.827828 30923 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:07:03.827833 30923 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:07:03.829040 30923 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:07:03.829066 30923 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:07:03.829068 30923 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:07:03.829077 30923 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:07:03.829080 30923 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:07:03.829083 30923 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:07:03.829087 30923 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:07:03.829088 30923 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:07:03.829092 30923 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:07:03.829097 30923 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:07:03.829099 30923 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:07:03.829102 30923 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:07:03.829107 30923 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:07:03.829110 30923 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:07:03.829114 30923 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:07:03.829119 30923 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:07:03.829123 30923 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:07:03.829128 30923 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:07:03.829131 30923 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:07:03.829135 30923 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:07:03.829139 30923 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:07:03.829144 30923 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:07:03.829147 30923 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:07:03.829151 30923 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:07:03.829155 30923 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:07:03.829159 30923 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:07:03.829162 30923 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:07:03.829177 30923 net.cpp:257] Network initialization done.\n",
      "I0430 05:07:03.925503 30923 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:07:04.024823 30923 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:07:04.025683 30923 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:07:04.025691 30923 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:07:04.025692 30923 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/178299.jpg'}, '/tmp/tmpqcAU0h.mat')\n",
      "Processed 2101 windows in 247.163 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.07125, -2.73148, -2.36862, -2.27833, -2.64...\n",
      "ymin                                                         70\n",
      "xmin                                                        255\n",
      "ymax                                                        190\n",
      "xmax                                                        382\n",
      "Name: /home/ambika/INF_project/data/cat/178299.jpg, dtype: object\n",
      "prediction    [-2.49997, -1.87689, -1.82359, -1.50035, -2.28...\n",
      "ymin                                                          0\n",
      "xmin                                                         34\n",
      "ymax                                                        127\n",
      "xmax                                                        102\n",
      "Name: /home/ambika/INF_project/data/cat/178299.jpg, dtype: object\n",
      "domestic cat\n",
      "255\t70\t382\t190\n",
      "cream\n",
      "34\t0\t102\t127\n",
      "178299\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:11:12.723366 31108 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:11:12.723386 31108 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:11:12.723389 31108 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:11:12.724470 31108 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:11:12.724548 31108 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:11:12.724555 31108 net.cpp:86] Creating Layer data\n",
      "I0430 05:11:12.724558 31108 net.cpp:382] data -> data\n",
      "I0430 05:11:12.724570 31108 net.cpp:124] Setting up data\n",
      "I0430 05:11:12.724576 31108 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:11:12.724578 31108 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:11:12.724581 31108 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:11:12.724587 31108 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:11:12.724589 31108 net.cpp:408] conv1 <- data\n",
      "I0430 05:11:12.724594 31108 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:11:12.724659 31108 net.cpp:124] Setting up conv1\n",
      "I0430 05:11:12.724664 31108 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:11:12.724666 31108 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:11:12.724673 31108 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:11:12.724678 31108 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:11:12.724681 31108 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:11:12.724684 31108 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:11:12.724689 31108 net.cpp:124] Setting up relu1\n",
      "I0430 05:11:12.724691 31108 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:11:12.724694 31108 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:11:12.724696 31108 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:11:12.724700 31108 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:11:12.724702 31108 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:11:12.724705 31108 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:11:12.724712 31108 net.cpp:124] Setting up pool1\n",
      "I0430 05:11:12.724715 31108 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:11:12.724717 31108 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:11:12.724720 31108 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:11:12.724725 31108 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:11:12.724726 31108 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:11:12.724730 31108 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:11:12.724735 31108 net.cpp:124] Setting up norm1\n",
      "I0430 05:11:12.724737 31108 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:11:12.724740 31108 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:11:12.724742 31108 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:11:12.724746 31108 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:11:12.724748 31108 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:11:12.724752 31108 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:11:12.725090 31108 net.cpp:124] Setting up conv2\n",
      "I0430 05:11:12.725095 31108 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:11:12.725097 31108 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:11:12.725102 31108 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:11:12.725106 31108 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:11:12.725108 31108 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:11:12.725112 31108 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:11:12.725116 31108 net.cpp:124] Setting up relu2\n",
      "I0430 05:11:12.725118 31108 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:11:12.725121 31108 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:11:12.725123 31108 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:11:12.725126 31108 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:11:12.725128 31108 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:11:12.725131 31108 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:11:12.725136 31108 net.cpp:124] Setting up pool2\n",
      "I0430 05:11:12.725141 31108 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:11:12.725142 31108 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:11:12.725144 31108 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:11:12.725149 31108 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:11:12.725152 31108 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:11:12.725155 31108 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:11:12.725159 31108 net.cpp:124] Setting up norm2\n",
      "I0430 05:11:12.725162 31108 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:11:12.725165 31108 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:11:12.725167 31108 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:11:12.725172 31108 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:11:12.725174 31108 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:11:12.725178 31108 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:11:12.726130 31108 net.cpp:124] Setting up conv3\n",
      "I0430 05:11:12.726138 31108 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:11:12.726142 31108 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:11:12.726155 31108 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:11:12.726178 31108 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:11:12.726182 31108 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:11:12.726187 31108 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:11:12.726194 31108 net.cpp:124] Setting up relu3\n",
      "I0430 05:11:12.726198 31108 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:11:12.726202 31108 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:11:12.726204 31108 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:11:12.726213 31108 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:11:12.726217 31108 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:11:12.726222 31108 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:11:12.726976 31108 net.cpp:124] Setting up conv4\n",
      "I0430 05:11:12.726985 31108 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:11:12.726989 31108 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:11:12.726994 31108 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:11:12.726997 31108 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:11:12.727000 31108 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:11:12.727005 31108 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:11:12.727008 31108 net.cpp:124] Setting up relu4\n",
      "I0430 05:11:12.727011 31108 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:11:12.727013 31108 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:11:12.727016 31108 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:11:12.727021 31108 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:11:12.727023 31108 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:11:12.727027 31108 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:11:12.727530 31108 net.cpp:124] Setting up conv5\n",
      "I0430 05:11:12.727535 31108 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:11:12.727537 31108 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:11:12.727545 31108 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:11:12.727548 31108 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:11:12.727550 31108 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:11:12.727555 31108 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:11:12.727557 31108 net.cpp:124] Setting up relu5\n",
      "I0430 05:11:12.727561 31108 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:11:12.727563 31108 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:11:12.727566 31108 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:11:12.727571 31108 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:11:12.727572 31108 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:11:12.727576 31108 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:11:12.727582 31108 net.cpp:124] Setting up pool5\n",
      "I0430 05:11:12.727586 31108 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:11:12.727587 31108 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:11:12.727591 31108 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:11:12.727596 31108 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:11:12.727599 31108 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:11:12.727603 31108 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:11:12.750313 31108 net.cpp:124] Setting up fc6\n",
      "I0430 05:11:12.750349 31108 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:11:12.750352 31108 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:11:12.750388 31108 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:11:12.750401 31108 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:11:12.750406 31108 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:11:12.750413 31108 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:11:12.750423 31108 net.cpp:124] Setting up relu6\n",
      "I0430 05:11:12.750428 31108 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:11:12.750432 31108 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:11:12.750435 31108 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:11:12.750442 31108 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:11:12.750444 31108 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:11:12.750449 31108 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:11:12.750458 31108 net.cpp:124] Setting up drop6\n",
      "I0430 05:11:12.750463 31108 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:11:12.750466 31108 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:11:12.750470 31108 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:11:12.750475 31108 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:11:12.750478 31108 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:11:12.750483 31108 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:11:12.761014 31108 net.cpp:124] Setting up fc7\n",
      "I0430 05:11:12.761036 31108 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:11:12.761044 31108 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:11:12.761056 31108 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:11:12.761066 31108 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:11:12.761070 31108 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:11:12.761078 31108 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:11:12.761087 31108 net.cpp:124] Setting up relu7\n",
      "I0430 05:11:12.761091 31108 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:11:12.761096 31108 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:11:12.761099 31108 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:11:12.761107 31108 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:11:12.761111 31108 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:11:12.761116 31108 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:11:12.761121 31108 net.cpp:124] Setting up drop7\n",
      "I0430 05:11:12.761124 31108 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:11:12.761126 31108 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:11:12.761129 31108 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:11:12.761133 31108 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:11:12.761137 31108 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:11:12.761139 31108 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:11:12.761879 31108 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:11:12.761898 31108 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:11:12.761900 31108 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:11:12.761910 31108 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:11:12.761915 31108 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:11:12.761919 31108 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:11:12.761922 31108 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:11:12.761925 31108 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:11:12.761930 31108 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:11:12.761934 31108 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:11:12.761937 31108 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:11:12.761940 31108 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:11:12.761942 31108 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:11:12.761945 31108 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:11:12.761948 31108 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:11:12.761951 31108 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:11:12.761955 31108 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:11:12.761956 31108 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:11:12.761960 31108 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:11:12.761962 31108 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:11:12.761965 31108 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:11:12.761968 31108 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:11:12.761971 31108 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:11:12.761975 31108 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:11:12.761976 31108 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:11:12.761979 31108 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:11:12.761981 31108 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:11:12.761992 31108 net.cpp:257] Network initialization done.\n",
      "I0430 05:11:12.848857 31108 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:11:12.949630 31108 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:11:12.951640 31108 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:11:12.951666 31108 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:11:12.951673 31108 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/1404.jpg'}, '/tmp/tmpnYQelP.mat')\n",
      "Processed 2121 windows in 251.813 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.29912, -1.75922, -1.65565, -1.92587, -1.72...\n",
      "ymin                                                      97.24\n",
      "xmin                                                          0\n",
      "ymax                                                    500.664\n",
      "xmax                                                    238.864\n",
      "Name: /home/ambika/INF_project/data/couch/1404.jpg, dtype: object\n",
      "prediction    [-1.75572, -1.89515, -1.61633, -2.09163, -1.78...\n",
      "ymin                                                     24.684\n",
      "xmin                                                          0\n",
      "ymax                                                    418.384\n",
      "xmax                                                    374.252\n",
      "Name: /home/ambika/INF_project/data/couch/1404.jpg, dtype: object\n",
      "person\n",
      "0.0\t97.24\t238.864\t500.664\n",
      "sofa\n",
      "0.0\t24.684\t374.252\t418.384\n",
      "1404\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:15:26.289780 31280 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:15:26.289798 31280 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:15:26.289799 31280 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:15:26.290875 31280 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:15:26.290987 31280 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:15:26.290997 31280 net.cpp:86] Creating Layer data\n",
      "I0430 05:15:26.291002 31280 net.cpp:382] data -> data\n",
      "I0430 05:15:26.291015 31280 net.cpp:124] Setting up data\n",
      "I0430 05:15:26.291021 31280 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:15:26.291024 31280 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:15:26.291028 31280 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:15:26.291035 31280 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:15:26.291038 31280 net.cpp:408] conv1 <- data\n",
      "I0430 05:15:26.291043 31280 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:15:26.291102 31280 net.cpp:124] Setting up conv1\n",
      "I0430 05:15:26.291108 31280 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:15:26.291111 31280 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:15:26.291119 31280 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:15:26.291126 31280 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:15:26.291127 31280 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:15:26.291132 31280 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:15:26.291137 31280 net.cpp:124] Setting up relu1\n",
      "I0430 05:15:26.291141 31280 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:15:26.291144 31280 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:15:26.291147 31280 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:15:26.291152 31280 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:15:26.291155 31280 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:15:26.291159 31280 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:15:26.291167 31280 net.cpp:124] Setting up pool1\n",
      "I0430 05:15:26.291172 31280 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:15:26.291174 31280 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:15:26.291177 31280 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:15:26.291183 31280 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:15:26.291185 31280 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:15:26.291190 31280 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:15:26.291196 31280 net.cpp:124] Setting up norm1\n",
      "I0430 05:15:26.291200 31280 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:15:26.291203 31280 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:15:26.291249 31280 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:15:26.291256 31280 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:15:26.291259 31280 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:15:26.291263 31280 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:15:26.291595 31280 net.cpp:124] Setting up conv2\n",
      "I0430 05:15:26.291601 31280 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:15:26.291604 31280 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:15:26.291611 31280 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:15:26.291617 31280 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:15:26.291620 31280 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:15:26.291625 31280 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:15:26.291630 31280 net.cpp:124] Setting up relu2\n",
      "I0430 05:15:26.291633 31280 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:15:26.291636 31280 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:15:26.291640 31280 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:15:26.291643 31280 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:15:26.291646 31280 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:15:26.291651 31280 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:15:26.291657 31280 net.cpp:124] Setting up pool2\n",
      "I0430 05:15:26.291661 31280 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:15:26.291663 31280 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:15:26.291666 31280 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:15:26.291673 31280 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:15:26.291676 31280 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:15:26.291681 31280 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:15:26.291687 31280 net.cpp:124] Setting up norm2\n",
      "I0430 05:15:26.291690 31280 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:15:26.291693 31280 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:15:26.291697 31280 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:15:26.291702 31280 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:15:26.291704 31280 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:15:26.291708 31280 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:15:26.292397 31280 net.cpp:124] Setting up conv3\n",
      "I0430 05:15:26.292407 31280 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:15:26.292409 31280 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:15:26.292418 31280 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:15:26.292426 31280 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:15:26.292429 31280 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:15:26.292434 31280 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:15:26.292439 31280 net.cpp:124] Setting up relu3\n",
      "I0430 05:15:26.292443 31280 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:15:26.292446 31280 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:15:26.292449 31280 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:15:26.292456 31280 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:15:26.292459 31280 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:15:26.292464 31280 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:15:26.293192 31280 net.cpp:124] Setting up conv4\n",
      "I0430 05:15:26.293213 31280 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:15:26.293217 31280 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:15:26.293223 31280 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:15:26.293228 31280 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:15:26.293231 31280 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:15:26.293236 31280 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:15:26.293241 31280 net.cpp:124] Setting up relu4\n",
      "I0430 05:15:26.293244 31280 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:15:26.293247 31280 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:15:26.293251 31280 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:15:26.293257 31280 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:15:26.293261 31280 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:15:26.293265 31280 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:15:26.293747 31280 net.cpp:124] Setting up conv5\n",
      "I0430 05:15:26.293754 31280 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:15:26.293757 31280 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:15:26.293766 31280 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:15:26.293771 31280 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:15:26.293774 31280 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:15:26.293779 31280 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:15:26.293783 31280 net.cpp:124] Setting up relu5\n",
      "I0430 05:15:26.293787 31280 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:15:26.293790 31280 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:15:26.293793 31280 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:15:26.293799 31280 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:15:26.293802 31280 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:15:26.293807 31280 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:15:26.293814 31280 net.cpp:124] Setting up pool5\n",
      "I0430 05:15:26.293819 31280 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:15:26.293822 31280 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:15:26.293825 31280 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:15:26.293831 31280 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:15:26.293834 31280 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:15:26.293840 31280 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:15:26.316841 31280 net.cpp:124] Setting up fc6\n",
      "I0430 05:15:26.316881 31280 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:15:26.316885 31280 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:15:26.316895 31280 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:15:26.316903 31280 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:15:26.316906 31280 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:15:26.316913 31280 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:15:26.316920 31280 net.cpp:124] Setting up relu6\n",
      "I0430 05:15:26.316925 31280 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:15:26.316927 31280 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:15:26.316931 31280 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:15:26.316936 31280 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:15:26.316939 31280 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:15:26.316946 31280 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:15:26.316951 31280 net.cpp:124] Setting up drop6\n",
      "I0430 05:15:26.316954 31280 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:15:26.316957 31280 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:15:26.316961 31280 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:15:26.316965 31280 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:15:26.316968 31280 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:15:26.316973 31280 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:15:26.327090 31280 net.cpp:124] Setting up fc7\n",
      "I0430 05:15:26.327114 31280 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:15:26.327121 31280 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:15:26.327131 31280 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:15:26.327142 31280 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:15:26.327147 31280 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:15:26.327154 31280 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:15:26.327163 31280 net.cpp:124] Setting up relu7\n",
      "I0430 05:15:26.327168 31280 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:15:26.327172 31280 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:15:26.327174 31280 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:15:26.327180 31280 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:15:26.327183 31280 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:15:26.327190 31280 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:15:26.327198 31280 net.cpp:124] Setting up drop7\n",
      "I0430 05:15:26.327201 31280 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:15:26.327214 31280 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:15:26.327217 31280 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:15:26.327224 31280 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:15:26.327227 31280 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:15:26.327231 31280 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:15:26.328030 31280 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:15:26.328047 31280 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:15:26.328052 31280 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:15:26.328061 31280 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:15:26.328066 31280 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:15:26.328070 31280 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:15:26.328074 31280 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:15:26.328076 31280 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:15:26.328079 31280 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:15:26.328083 31280 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:15:26.328085 31280 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:15:26.328088 31280 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:15:26.328091 31280 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:15:26.328094 31280 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:15:26.328097 31280 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:15:26.328100 31280 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:15:26.328104 31280 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:15:26.328106 31280 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:15:26.328109 31280 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:15:26.328112 31280 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:15:26.328114 31280 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:15:26.328117 31280 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:15:26.328120 31280 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:15:26.328124 31280 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:15:26.328126 31280 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:15:26.328130 31280 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:15:26.328131 31280 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:15:26.328142 31280 net.cpp:257] Network initialization done.\n",
      "I0430 05:15:26.416177 31280 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:15:26.515451 31280 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:15:26.516418 31280 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:15:26.516427 31280 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:15:26.516429 31280 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/370765.jpg'}, '/tmp/tmpgCK_l7.mat')\n",
      "Processed 2704 windows in 314.251 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-1.89, -2.51894, -1.91769, -2.64038, -2.65665...\n",
      "ymin                                                          0\n",
      "xmin                                                         61\n",
      "ymax                                                        211\n",
      "xmax                                                        281\n",
      "Name: /home/ambika/INF_project/data/dog/370765.jpg, dtype: object\n",
      "prediction    [-1.94981, -2.91997, -1.95635, -1.66848, -2.42...\n",
      "ymin                                                        165\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        144\n",
      "Name: /home/ambika/INF_project/data/dog/370765.jpg, dtype: object\n",
      "dog\n",
      "61\t0\t281\t211\n",
      "domestic cat\n",
      "0\t165\t144\t375\n",
      "370765\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:20:42.340524 31482 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:20:42.340546 31482 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:20:42.340548 31482 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:20:42.341632 31482 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:20:42.341708 31482 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:20:42.341716 31482 net.cpp:86] Creating Layer data\n",
      "I0430 05:20:42.341718 31482 net.cpp:382] data -> data\n",
      "I0430 05:20:42.341728 31482 net.cpp:124] Setting up data\n",
      "I0430 05:20:42.341733 31482 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:20:42.341737 31482 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:20:42.341739 31482 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:20:42.341744 31482 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:20:42.341747 31482 net.cpp:408] conv1 <- data\n",
      "I0430 05:20:42.341751 31482 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:20:42.341812 31482 net.cpp:124] Setting up conv1\n",
      "I0430 05:20:42.341817 31482 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:20:42.341820 31482 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:20:42.341826 31482 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:20:42.341831 31482 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:20:42.341835 31482 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:20:42.341837 31482 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:20:42.341841 31482 net.cpp:124] Setting up relu1\n",
      "I0430 05:20:42.341845 31482 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:20:42.341847 31482 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:20:42.341850 31482 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:20:42.341853 31482 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:20:42.341856 31482 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:20:42.341859 31482 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:20:42.341866 31482 net.cpp:124] Setting up pool1\n",
      "I0430 05:20:42.341868 31482 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:20:42.341871 31482 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:20:42.341873 31482 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:20:42.341877 31482 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:20:42.341879 31482 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:20:42.341883 31482 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:20:42.341887 31482 net.cpp:124] Setting up norm1\n",
      "I0430 05:20:42.341892 31482 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:20:42.341893 31482 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:20:42.341895 31482 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:20:42.341899 31482 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:20:42.341902 31482 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:20:42.341905 31482 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:20:42.342243 31482 net.cpp:124] Setting up conv2\n",
      "I0430 05:20:42.342248 31482 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:20:42.342252 31482 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:20:42.342257 31482 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:20:42.342260 31482 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:20:42.342263 31482 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:20:42.342267 31482 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:20:42.342270 31482 net.cpp:124] Setting up relu2\n",
      "I0430 05:20:42.342273 31482 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:20:42.342275 31482 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:20:42.342278 31482 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:20:42.342281 31482 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:20:42.342284 31482 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:20:42.342288 31482 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:20:42.342293 31482 net.cpp:124] Setting up pool2\n",
      "I0430 05:20:42.342298 31482 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:20:42.342300 31482 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:20:42.342303 31482 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:20:42.342308 31482 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:20:42.342311 31482 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:20:42.342314 31482 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:20:42.342320 31482 net.cpp:124] Setting up norm2\n",
      "I0430 05:20:42.342324 31482 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:20:42.342325 31482 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:20:42.342327 31482 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:20:42.342332 31482 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:20:42.342335 31482 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:20:42.342339 31482 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:20:42.343227 31482 net.cpp:124] Setting up conv3\n",
      "I0430 05:20:42.343250 31482 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:20:42.343255 31482 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:20:42.343266 31482 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:20:42.343272 31482 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:20:42.343276 31482 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:20:42.343279 31482 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:20:42.343286 31482 net.cpp:124] Setting up relu3\n",
      "I0430 05:20:42.343288 31482 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:20:42.343291 31482 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:20:42.343293 31482 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:20:42.343300 31482 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:20:42.343302 31482 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:20:42.343307 31482 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:20:42.344048 31482 net.cpp:124] Setting up conv4\n",
      "I0430 05:20:42.344058 31482 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:20:42.344060 31482 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:20:42.344065 31482 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:20:42.344070 31482 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:20:42.344074 31482 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:20:42.344079 31482 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:20:42.344084 31482 net.cpp:124] Setting up relu4\n",
      "I0430 05:20:42.344086 31482 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:20:42.344089 31482 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:20:42.344094 31482 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:20:42.344101 31482 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:20:42.344104 31482 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:20:42.344108 31482 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:20:42.344607 31482 net.cpp:124] Setting up conv5\n",
      "I0430 05:20:42.344614 31482 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:20:42.344616 31482 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:20:42.344625 31482 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:20:42.344630 31482 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:20:42.344633 31482 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:20:42.344637 31482 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:20:42.344641 31482 net.cpp:124] Setting up relu5\n",
      "I0430 05:20:42.344645 31482 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:20:42.344648 31482 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:20:42.344651 31482 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:20:42.344657 31482 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:20:42.344660 31482 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:20:42.344665 31482 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:20:42.344672 31482 net.cpp:124] Setting up pool5\n",
      "I0430 05:20:42.344676 31482 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:20:42.344678 31482 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:20:42.344681 31482 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:20:42.344688 31482 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:20:42.344691 31482 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:20:42.344697 31482 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:20:42.370019 31482 net.cpp:124] Setting up fc6\n",
      "I0430 05:20:42.370051 31482 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:20:42.370054 31482 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:20:42.370064 31482 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:20:42.370074 31482 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:20:42.370077 31482 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:20:42.370085 31482 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:20:42.370095 31482 net.cpp:124] Setting up relu6\n",
      "I0430 05:20:42.370100 31482 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:20:42.370102 31482 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:20:42.370105 31482 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:20:42.370110 31482 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:20:42.370112 31482 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:20:42.370116 31482 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:20:42.370124 31482 net.cpp:124] Setting up drop6\n",
      "I0430 05:20:42.370127 31482 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:20:42.370131 31482 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:20:42.370132 31482 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:20:42.370138 31482 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:20:42.370142 31482 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:20:42.370147 31482 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:20:42.385725 31482 net.cpp:124] Setting up fc7\n",
      "I0430 05:20:42.385751 31482 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:20:42.385754 31482 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:20:42.385764 31482 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:20:42.385774 31482 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:20:42.385778 31482 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:20:42.385787 31482 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:20:42.385794 31482 net.cpp:124] Setting up relu7\n",
      "I0430 05:20:42.385799 31482 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:20:42.385802 31482 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:20:42.385805 31482 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:20:42.385812 31482 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:20:42.385814 31482 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:20:42.385820 31482 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:20:42.385826 31482 net.cpp:124] Setting up drop7\n",
      "I0430 05:20:42.385830 31482 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:20:42.385834 31482 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:20:42.385838 31482 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:20:42.385843 31482 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:20:42.385846 31482 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:20:42.385851 31482 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:20:42.386611 31482 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:20:42.386625 31482 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:20:42.386628 31482 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:20:42.386636 31482 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:20:42.386641 31482 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:20:42.386644 31482 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:20:42.386648 31482 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:20:42.386651 31482 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:20:42.386656 31482 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:20:42.386658 31482 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:20:42.386662 31482 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:20:42.386667 31482 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:20:42.386670 31482 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:20:42.386673 31482 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:20:42.386677 31482 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:20:42.386682 31482 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:20:42.386685 31482 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:20:42.386689 31482 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:20:42.386693 31482 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:20:42.386698 31482 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:20:42.386701 31482 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:20:42.386705 31482 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:20:42.386709 31482 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:20:42.386713 31482 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:20:42.386716 31482 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:20:42.386720 31482 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:20:42.386724 31482 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:20:42.386739 31482 net.cpp:257] Network initialization done.\n",
      "I0430 05:20:42.472674 31482 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:20:42.573107 31482 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:20:42.574116 31482 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:20:42.574127 31482 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:20:42.574132 31482 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/71215.jpg'}, '/tmp/tmpUPzj42.mat')\n",
      "Processed 1993 windows in 229.586 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.23036, -2.46011, -2.27724, -2.98263, -2.09...\n",
      "ymin                                                        158\n",
      "xmin                                                        339\n",
      "ymax                                                        310\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/horse/71215.jpg, dtype: object\n",
      "prediction    [-2.12001, -2.02174, -1.99216, -2.48853, -1.66...\n",
      "ymin                                                        119\n",
      "xmin                                                        258\n",
      "ymax                                                        216\n",
      "xmax                                                        310\n",
      "Name: /home/ambika/INF_project/data/horse/71215.jpg, dtype: object\n",
      "cart\n",
      "339\t158\t500\t310\n",
      "person\n",
      "258\t119\t310\t216\n",
      "71215\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:24:33.718694 31665 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:24:33.718717 31665 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:24:33.718721 31665 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:24:33.719944 31665 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:24:33.720135 31665 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:24:33.720145 31665 net.cpp:86] Creating Layer data\n",
      "I0430 05:24:33.720150 31665 net.cpp:382] data -> data\n",
      "I0430 05:24:33.720165 31665 net.cpp:124] Setting up data\n",
      "I0430 05:24:33.720171 31665 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:24:33.720173 31665 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:24:33.720176 31665 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:24:33.720182 31665 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:24:33.720185 31665 net.cpp:408] conv1 <- data\n",
      "I0430 05:24:33.720190 31665 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:24:33.720252 31665 net.cpp:124] Setting up conv1\n",
      "I0430 05:24:33.720257 31665 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:24:33.720259 31665 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:24:33.720266 31665 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:24:33.720271 31665 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:24:33.720274 31665 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:24:33.720278 31665 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:24:33.720283 31665 net.cpp:124] Setting up relu1\n",
      "I0430 05:24:33.720285 31665 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:24:33.720288 31665 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:24:33.720289 31665 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:24:33.720293 31665 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:24:33.720295 31665 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:24:33.720299 31665 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:24:33.720305 31665 net.cpp:124] Setting up pool1\n",
      "I0430 05:24:33.720310 31665 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:24:33.720314 31665 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:24:33.720317 31665 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:24:33.720324 31665 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:24:33.720329 31665 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:24:33.720333 31665 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:24:33.720341 31665 net.cpp:124] Setting up norm1\n",
      "I0430 05:24:33.720345 31665 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:24:33.720348 31665 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:24:33.720350 31665 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:24:33.720355 31665 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:24:33.720357 31665 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:24:33.720360 31665 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:24:33.720713 31665 net.cpp:124] Setting up conv2\n",
      "I0430 05:24:33.720721 31665 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:24:33.720724 31665 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:24:33.720732 31665 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:24:33.720737 31665 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:24:33.720739 31665 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:24:33.720742 31665 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:24:33.720746 31665 net.cpp:124] Setting up relu2\n",
      "I0430 05:24:33.720751 31665 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:24:33.720752 31665 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:24:33.720754 31665 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:24:33.720758 31665 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:24:33.720760 31665 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:24:33.720763 31665 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:24:33.720768 31665 net.cpp:124] Setting up pool2\n",
      "I0430 05:24:33.720772 31665 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:24:33.720774 31665 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:24:33.720777 31665 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:24:33.720782 31665 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:24:33.720784 31665 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:24:33.720788 31665 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:24:33.720793 31665 net.cpp:124] Setting up norm2\n",
      "I0430 05:24:33.720795 31665 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:24:33.720798 31665 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:24:33.720800 31665 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:24:33.720805 31665 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:24:33.720808 31665 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:24:33.720810 31665 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:24:33.721540 31665 net.cpp:124] Setting up conv3\n",
      "I0430 05:24:33.721556 31665 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:24:33.721559 31665 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:24:33.721566 31665 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:24:33.721572 31665 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:24:33.721575 31665 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:24:33.721580 31665 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:24:33.721585 31665 net.cpp:124] Setting up relu3\n",
      "I0430 05:24:33.721588 31665 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:24:33.721590 31665 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:24:33.721593 31665 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:24:33.721599 31665 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:24:33.721601 31665 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:24:33.721606 31665 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:24:33.722399 31665 net.cpp:124] Setting up conv4\n",
      "I0430 05:24:33.722416 31665 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:24:33.722420 31665 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:24:33.722429 31665 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:24:33.722436 31665 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:24:33.722440 31665 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:24:33.722445 31665 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:24:33.722452 31665 net.cpp:124] Setting up relu4\n",
      "I0430 05:24:33.722457 31665 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:24:33.722461 31665 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:24:33.722465 31665 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:24:33.722473 31665 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:24:33.722477 31665 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:24:33.722483 31665 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:24:33.723116 31665 net.cpp:124] Setting up conv5\n",
      "I0430 05:24:33.723132 31665 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:24:33.723136 31665 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:24:33.723150 31665 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:24:33.723158 31665 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:24:33.723162 31665 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:24:33.723167 31665 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:24:33.723173 31665 net.cpp:124] Setting up relu5\n",
      "I0430 05:24:33.723178 31665 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:24:33.723182 31665 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:24:33.723186 31665 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:24:33.723192 31665 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:24:33.723196 31665 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:24:33.723201 31665 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:24:33.723217 31665 net.cpp:124] Setting up pool5\n",
      "I0430 05:24:33.723224 31665 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:24:33.723227 31665 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:24:33.723230 31665 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:24:33.723240 31665 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:24:33.723243 31665 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:24:33.723249 31665 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:24:33.752801 31665 net.cpp:124] Setting up fc6\n",
      "I0430 05:24:33.752825 31665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:24:33.752830 31665 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:24:33.752840 31665 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:24:33.752846 31665 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:24:33.752849 31665 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:24:33.752853 31665 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:24:33.752859 31665 net.cpp:124] Setting up relu6\n",
      "I0430 05:24:33.752862 31665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:24:33.752863 31665 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:24:33.752866 31665 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:24:33.752869 31665 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:24:33.752871 31665 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:24:33.752873 31665 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:24:33.752877 31665 net.cpp:124] Setting up drop6\n",
      "I0430 05:24:33.752879 31665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:24:33.752882 31665 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:24:33.752897 31665 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:24:33.752902 31665 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:24:33.752905 31665 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:24:33.752908 31665 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:24:33.762404 31665 net.cpp:124] Setting up fc7\n",
      "I0430 05:24:33.762419 31665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:24:33.762423 31665 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:24:33.762430 31665 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:24:33.762436 31665 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:24:33.762439 31665 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:24:33.762444 31665 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:24:33.762449 31665 net.cpp:124] Setting up relu7\n",
      "I0430 05:24:33.762450 31665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:24:33.762452 31665 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:24:33.762454 31665 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:24:33.762457 31665 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:24:33.762459 31665 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:24:33.762461 31665 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:24:33.762465 31665 net.cpp:124] Setting up drop7\n",
      "I0430 05:24:33.762467 31665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:24:33.762468 31665 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:24:33.762471 31665 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:24:33.762478 31665 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:24:33.762480 31665 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:24:33.762483 31665 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:24:33.763129 31665 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:24:33.763137 31665 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:24:33.763140 31665 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:24:33.763147 31665 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:24:33.763149 31665 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:24:33.763151 31665 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:24:33.763154 31665 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:24:33.763155 31665 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:24:33.763157 31665 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:24:33.763159 31665 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:24:33.763162 31665 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:24:33.763165 31665 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:24:33.763169 31665 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:24:33.763170 31665 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:24:33.763173 31665 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:24:33.763176 31665 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:24:33.763178 31665 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:24:33.763181 31665 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:24:33.763185 31665 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:24:33.763186 31665 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:24:33.763190 31665 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:24:33.763191 31665 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:24:33.763195 31665 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:24:33.763197 31665 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:24:33.763200 31665 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:24:33.763202 31665 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:24:33.763209 31665 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:24:33.763221 31665 net.cpp:257] Network initialization done.\n",
      "I0430 05:24:33.849370 31665 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:24:33.949434 31665 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:24:33.950731 31665 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:24:33.950753 31665 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:24:33.950755 31665 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/342273.jpg'}, '/tmp/tmpe7AvNj.mat')\n",
      "Processed 2394 windows in 281.919 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.13861, -2.20922, -2.53127, -2.61343, -2.86...\n",
      "ymin                                                      47.25\n",
      "xmin                                                      166.5\n",
      "ymax                                                     211.75\n",
      "xmax                                                     367.75\n",
      "Name: /home/ambika/INF_project/data/person/342273.jpg, dtype: object\n",
      "prediction    [-2.19454, -2.04033, -1.69616, -1.90032, -1.90...\n",
      "ymin                                                       46.5\n",
      "xmin                                                        171\n",
      "ymax                                                      500.5\n",
      "xmax                                                     375.25\n",
      "Name: /home/ambika/INF_project/data/person/342273.jpg, dtype: object\n",
      "hat with a wide brim\n",
      "166.5\t47.25\t367.75\t211.75\n",
      "person\n",
      "171.0\t46.5\t375.25\t500.5\n",
      "342273\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:29:17.468098 31865 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:29:17.468118 31865 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:29:17.468122 31865 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:29:17.469211 31865 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:29:17.469377 31865 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:29:17.469384 31865 net.cpp:86] Creating Layer data\n",
      "I0430 05:29:17.469388 31865 net.cpp:382] data -> data\n",
      "I0430 05:29:17.469398 31865 net.cpp:124] Setting up data\n",
      "I0430 05:29:17.469401 31865 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:29:17.469404 31865 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:29:17.469406 31865 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:29:17.469413 31865 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:29:17.469415 31865 net.cpp:408] conv1 <- data\n",
      "I0430 05:29:17.469419 31865 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:29:17.469480 31865 net.cpp:124] Setting up conv1\n",
      "I0430 05:29:17.469485 31865 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:29:17.469487 31865 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:29:17.469494 31865 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:29:17.469499 31865 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:29:17.469502 31865 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:29:17.469506 31865 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:29:17.469509 31865 net.cpp:124] Setting up relu1\n",
      "I0430 05:29:17.469513 31865 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:29:17.469516 31865 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:29:17.469517 31865 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:29:17.469521 31865 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:29:17.469524 31865 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:29:17.469527 31865 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:29:17.469533 31865 net.cpp:124] Setting up pool1\n",
      "I0430 05:29:17.469537 31865 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:29:17.469539 31865 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:29:17.469542 31865 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:29:17.469545 31865 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:29:17.469548 31865 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:29:17.469552 31865 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:29:17.469557 31865 net.cpp:124] Setting up norm1\n",
      "I0430 05:29:17.469559 31865 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:29:17.469563 31865 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:29:17.469564 31865 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:29:17.469568 31865 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:29:17.469570 31865 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:29:17.469574 31865 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:29:17.469900 31865 net.cpp:124] Setting up conv2\n",
      "I0430 05:29:17.469907 31865 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:29:17.469908 31865 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:29:17.469913 31865 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:29:17.469918 31865 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:29:17.469919 31865 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:29:17.469923 31865 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:29:17.469926 31865 net.cpp:124] Setting up relu2\n",
      "I0430 05:29:17.469929 31865 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:29:17.469933 31865 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:29:17.469934 31865 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:29:17.469938 31865 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:29:17.469940 31865 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:29:17.469944 31865 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:29:17.469949 31865 net.cpp:124] Setting up pool2\n",
      "I0430 05:29:17.469951 31865 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:29:17.469954 31865 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:29:17.469956 31865 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:29:17.469961 31865 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:29:17.469964 31865 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:29:17.469967 31865 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:29:17.469971 31865 net.cpp:124] Setting up norm2\n",
      "I0430 05:29:17.469975 31865 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:29:17.469977 31865 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:29:17.469980 31865 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:29:17.469985 31865 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:29:17.469986 31865 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:29:17.469990 31865 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:29:17.470664 31865 net.cpp:124] Setting up conv3\n",
      "I0430 05:29:17.470672 31865 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:29:17.470675 31865 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:29:17.470682 31865 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:29:17.470687 31865 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:29:17.470690 31865 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:29:17.470693 31865 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:29:17.470697 31865 net.cpp:124] Setting up relu3\n",
      "I0430 05:29:17.470700 31865 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:29:17.470702 31865 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:29:17.470705 31865 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:29:17.470710 31865 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:29:17.470712 31865 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:29:17.470716 31865 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:29:17.471462 31865 net.cpp:124] Setting up conv4\n",
      "I0430 05:29:17.471470 31865 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:29:17.471473 31865 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:29:17.471478 31865 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:29:17.471483 31865 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:29:17.471485 31865 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:29:17.471489 31865 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:29:17.471493 31865 net.cpp:124] Setting up relu4\n",
      "I0430 05:29:17.471496 31865 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:29:17.471498 31865 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:29:17.471500 31865 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:29:17.471506 31865 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:29:17.471508 31865 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:29:17.471513 31865 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:29:17.471990 31865 net.cpp:124] Setting up conv5\n",
      "I0430 05:29:17.471995 31865 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:29:17.471998 31865 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:29:17.472008 31865 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:29:17.472012 31865 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:29:17.472014 31865 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:29:17.472018 31865 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:29:17.472021 31865 net.cpp:124] Setting up relu5\n",
      "I0430 05:29:17.472024 31865 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:29:17.472026 31865 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:29:17.472029 31865 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:29:17.472033 31865 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:29:17.472035 31865 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:29:17.472039 31865 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:29:17.472046 31865 net.cpp:124] Setting up pool5\n",
      "I0430 05:29:17.472049 31865 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:29:17.472053 31865 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:29:17.472054 31865 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:29:17.472061 31865 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:29:17.472064 31865 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:29:17.472067 31865 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:29:17.493979 31865 net.cpp:124] Setting up fc6\n",
      "I0430 05:29:17.494002 31865 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:29:17.494007 31865 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:29:17.494033 31865 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:29:17.494042 31865 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:29:17.494045 31865 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:29:17.494050 31865 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:29:17.494057 31865 net.cpp:124] Setting up relu6\n",
      "I0430 05:29:17.494060 31865 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:29:17.494062 31865 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:29:17.494065 31865 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:29:17.494076 31865 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:29:17.494077 31865 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:29:17.494082 31865 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:29:17.494092 31865 net.cpp:124] Setting up drop6\n",
      "I0430 05:29:17.494096 31865 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:29:17.494097 31865 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:29:17.494101 31865 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:29:17.494110 31865 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:29:17.494113 31865 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:29:17.494117 31865 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:29:17.507284 31865 net.cpp:124] Setting up fc7\n",
      "I0430 05:29:17.507316 31865 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:29:17.507321 31865 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:29:17.507333 31865 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:29:17.507344 31865 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:29:17.507346 31865 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:29:17.507352 31865 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:29:17.507364 31865 net.cpp:124] Setting up relu7\n",
      "I0430 05:29:17.507367 31865 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:29:17.507369 31865 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:29:17.507371 31865 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:29:17.507375 31865 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:29:17.507377 31865 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:29:17.507380 31865 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:29:17.507383 31865 net.cpp:124] Setting up drop7\n",
      "I0430 05:29:17.507392 31865 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:29:17.507395 31865 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:29:17.507397 31865 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:29:17.507401 31865 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:29:17.507403 31865 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:29:17.507407 31865 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:29:17.508325 31865 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:29:17.508337 31865 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:29:17.508342 31865 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:29:17.508348 31865 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:29:17.508352 31865 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:29:17.508355 31865 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:29:17.508358 31865 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:29:17.508360 31865 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:29:17.508363 31865 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:29:17.508366 31865 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:29:17.508368 31865 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:29:17.508371 31865 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:29:17.508374 31865 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:29:17.508376 31865 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:29:17.508379 31865 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:29:17.508383 31865 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:29:17.508385 31865 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:29:17.508388 31865 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:29:17.508391 31865 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:29:17.508394 31865 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:29:17.508396 31865 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:29:17.508399 31865 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:29:17.508402 31865 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:29:17.508404 31865 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:29:17.508407 31865 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:29:17.508410 31865 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:29:17.508412 31865 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:29:17.508424 31865 net.cpp:257] Network initialization done.\n",
      "I0430 05:29:17.595787 31865 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:29:17.695025 31865 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:29:17.696231 31865 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:29:17.696247 31865 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:29:17.696251 31865 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/166837.jpg'}, '/tmp/tmpwBpP90.mat')\n",
      "Processed 2658 windows in 306.861 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.034 s.\n",
      "prediction    [-3.1109, -2.31989, -2.55295, -3.16988, -2.507...\n",
      "ymin                                                        111\n",
      "xmin                                                        185\n",
      "ymax                                                        288\n",
      "xmax                                                        386\n",
      "Name: /home/ambika/INF_project/data/train/166837.jpg, dtype: object\n",
      "prediction    [-2.89731, -1.627, -2.39598, -2.72157, -2.1335...\n",
      "ymin                                                        107\n",
      "xmin                                                        120\n",
      "ymax                                                        237\n",
      "xmax                                                        379\n",
      "Name: /home/ambika/INF_project/data/train/166837.jpg, dtype: object\n",
      "train\n",
      "185\t111\t386\t288\n",
      "bus\n",
      "120\t107\t379\t237\n",
      "166837\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:34:26.088116 32076 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:34:26.088130 32076 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:34:26.088135 32076 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:34:26.089223 32076 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:34:26.089337 32076 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:34:26.089349 32076 net.cpp:86] Creating Layer data\n",
      "I0430 05:34:26.089352 32076 net.cpp:382] data -> data\n",
      "I0430 05:34:26.089365 32076 net.cpp:124] Setting up data\n",
      "I0430 05:34:26.089376 32076 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:34:26.089378 32076 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:34:26.089383 32076 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:34:26.089392 32076 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:34:26.089395 32076 net.cpp:408] conv1 <- data\n",
      "I0430 05:34:26.089401 32076 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:34:26.089458 32076 net.cpp:124] Setting up conv1\n",
      "I0430 05:34:26.089464 32076 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:34:26.089467 32076 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:34:26.089473 32076 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:34:26.089478 32076 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:34:26.089481 32076 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:34:26.089485 32076 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:34:26.089490 32076 net.cpp:124] Setting up relu1\n",
      "I0430 05:34:26.089494 32076 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:34:26.089496 32076 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:34:26.089499 32076 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:34:26.089504 32076 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:34:26.089507 32076 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:34:26.089511 32076 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:34:26.089519 32076 net.cpp:124] Setting up pool1\n",
      "I0430 05:34:26.089521 32076 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:34:26.089524 32076 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:34:26.089527 32076 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:34:26.089532 32076 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:34:26.089535 32076 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:34:26.089539 32076 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:34:26.089543 32076 net.cpp:124] Setting up norm1\n",
      "I0430 05:34:26.089547 32076 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:34:26.089550 32076 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:34:26.089553 32076 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:34:26.089558 32076 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:34:26.089639 32076 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:34:26.089645 32076 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:34:26.090021 32076 net.cpp:124] Setting up conv2\n",
      "I0430 05:34:26.090029 32076 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:34:26.090031 32076 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:34:26.090037 32076 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:34:26.090041 32076 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:34:26.090044 32076 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:34:26.090049 32076 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:34:26.090054 32076 net.cpp:124] Setting up relu2\n",
      "I0430 05:34:26.090056 32076 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:34:26.090059 32076 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:34:26.090062 32076 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:34:26.090067 32076 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:34:26.090070 32076 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:34:26.090075 32076 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:34:26.090080 32076 net.cpp:124] Setting up pool2\n",
      "I0430 05:34:26.090085 32076 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:34:26.090086 32076 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:34:26.090090 32076 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:34:26.090095 32076 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:34:26.090098 32076 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:34:26.090102 32076 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:34:26.090107 32076 net.cpp:124] Setting up norm2\n",
      "I0430 05:34:26.090111 32076 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:34:26.090114 32076 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:34:26.090117 32076 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:34:26.090124 32076 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:34:26.090126 32076 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:34:26.090131 32076 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:34:26.090809 32076 net.cpp:124] Setting up conv3\n",
      "I0430 05:34:26.090817 32076 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:34:26.090819 32076 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:34:26.090826 32076 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:34:26.090831 32076 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:34:26.090833 32076 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:34:26.090837 32076 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:34:26.090842 32076 net.cpp:124] Setting up relu3\n",
      "I0430 05:34:26.090845 32076 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:34:26.090847 32076 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:34:26.090850 32076 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:34:26.090857 32076 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:34:26.090859 32076 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:34:26.090864 32076 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:34:26.091591 32076 net.cpp:124] Setting up conv4\n",
      "I0430 05:34:26.091599 32076 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:34:26.091603 32076 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:34:26.091608 32076 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:34:26.091611 32076 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:34:26.091614 32076 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:34:26.091619 32076 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:34:26.091624 32076 net.cpp:124] Setting up relu4\n",
      "I0430 05:34:26.091627 32076 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:34:26.091630 32076 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:34:26.091634 32076 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:34:26.091639 32076 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:34:26.091642 32076 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:34:26.091646 32076 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:34:26.092139 32076 net.cpp:124] Setting up conv5\n",
      "I0430 05:34:26.092146 32076 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:34:26.092149 32076 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:34:26.092157 32076 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:34:26.092161 32076 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:34:26.092164 32076 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:34:26.092169 32076 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:34:26.092172 32076 net.cpp:124] Setting up relu5\n",
      "I0430 05:34:26.092176 32076 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:34:26.092180 32076 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:34:26.092182 32076 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:34:26.092187 32076 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:34:26.092190 32076 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:34:26.092195 32076 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:34:26.092201 32076 net.cpp:124] Setting up pool5\n",
      "I0430 05:34:26.092206 32076 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:34:26.092207 32076 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:34:26.092211 32076 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:34:26.092221 32076 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:34:26.092222 32076 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:34:26.092227 32076 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:34:26.115403 32076 net.cpp:124] Setting up fc6\n",
      "I0430 05:34:26.115425 32076 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:34:26.115429 32076 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:34:26.115440 32076 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:34:26.115458 32076 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:34:26.115461 32076 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:34:26.115466 32076 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:34:26.115473 32076 net.cpp:124] Setting up relu6\n",
      "I0430 05:34:26.115475 32076 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:34:26.115476 32076 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:34:26.115478 32076 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:34:26.115483 32076 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:34:26.115486 32076 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:34:26.115489 32076 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:34:26.115494 32076 net.cpp:124] Setting up drop6\n",
      "I0430 05:34:26.115496 32076 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:34:26.115499 32076 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:34:26.115500 32076 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:34:26.115505 32076 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:34:26.115507 32076 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:34:26.115510 32076 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:34:26.127095 32076 net.cpp:124] Setting up fc7\n",
      "I0430 05:34:26.127125 32076 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:34:26.127130 32076 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:34:26.127141 32076 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:34:26.127153 32076 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:34:26.127157 32076 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:34:26.127166 32076 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:34:26.127176 32076 net.cpp:124] Setting up relu7\n",
      "I0430 05:34:26.127179 32076 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:34:26.127182 32076 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:34:26.127187 32076 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:34:26.127197 32076 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:34:26.127199 32076 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:34:26.127203 32076 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:34:26.127226 32076 net.cpp:124] Setting up drop7\n",
      "I0430 05:34:26.127231 32076 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:34:26.127234 32076 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:34:26.127238 32076 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:34:26.127243 32076 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:34:26.127246 32076 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:34:26.127251 32076 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:34:26.128049 32076 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:34:26.128063 32076 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:34:26.128067 32076 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:34:26.128074 32076 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:34:26.128078 32076 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:34:26.128082 32076 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:34:26.128085 32076 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:34:26.128089 32076 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:34:26.128093 32076 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:34:26.128096 32076 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:34:26.128100 32076 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:34:26.128104 32076 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:34:26.128108 32076 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:34:26.128111 32076 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:34:26.128115 32076 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:34:26.128119 32076 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:34:26.128123 32076 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:34:26.128126 32076 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:34:26.128130 32076 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:34:26.128134 32076 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:34:26.128139 32076 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:34:26.128142 32076 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:34:26.128146 32076 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:34:26.128149 32076 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:34:26.128154 32076 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:34:26.128157 32076 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:34:26.128160 32076 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:34:26.128175 32076 net.cpp:257] Network initialization done.\n",
      "I0430 05:34:26.230412 32076 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:34:26.328829 32076 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:34:26.329712 32076 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:34:26.329720 32076 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:34:26.329725 32076 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/127668.jpg'}, '/tmp/tmpO8zPCS.mat')\n",
      "Processed 1603 windows in 189.519 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-1.89168, -0.977877, -2.05606, -1.95212, -1.6...\n",
      "ymin                                                        231\n",
      "xmin                                                         28\n",
      "ymax                                                        278\n",
      "xmax                                                         93\n",
      "Name: /home/ambika/INF_project/data/airplane/127668.jpg, dtype: object\n",
      "prediction    [-2.12286, 0.909981, -1.95405, -1.87665, -1.66...\n",
      "ymin                                                         87\n",
      "xmin                                                        186\n",
      "ymax                                                        298\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/airplane/127668.jpg, dtype: object\n",
      "car\n",
      "28\t231\t93\t278\n",
      "airplane\n",
      "186\t87\t500\t298\n",
      "127668\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:37:37.320631 32246 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:37:37.320652 32246 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:37:37.320655 32246 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:37:37.321763 32246 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:37:37.321873 32246 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:37:37.321884 32246 net.cpp:86] Creating Layer data\n",
      "I0430 05:37:37.321889 32246 net.cpp:382] data -> data\n",
      "I0430 05:37:37.321902 32246 net.cpp:124] Setting up data\n",
      "I0430 05:37:37.321909 32246 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:37:37.321912 32246 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:37:37.321915 32246 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:37:37.321923 32246 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:37:37.321925 32246 net.cpp:408] conv1 <- data\n",
      "I0430 05:37:37.321930 32246 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:37:37.321990 32246 net.cpp:124] Setting up conv1\n",
      "I0430 05:37:37.321996 32246 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:37:37.322000 32246 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:37:37.322007 32246 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:37:37.322013 32246 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:37:37.322016 32246 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:37:37.322021 32246 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:37:37.322026 32246 net.cpp:124] Setting up relu1\n",
      "I0430 05:37:37.322029 32246 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:37:37.322032 32246 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:37:37.322036 32246 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:37:37.322041 32246 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:37:37.322042 32246 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:37:37.322047 32246 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:37:37.322054 32246 net.cpp:124] Setting up pool1\n",
      "I0430 05:37:37.322059 32246 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:37:37.322062 32246 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:37:37.322064 32246 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:37:37.322070 32246 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:37:37.322073 32246 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:37:37.322077 32246 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:37:37.322083 32246 net.cpp:124] Setting up norm1\n",
      "I0430 05:37:37.322088 32246 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:37:37.322090 32246 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:37:37.322093 32246 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:37:37.322098 32246 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:37:37.322101 32246 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:37:37.322105 32246 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:37:37.322448 32246 net.cpp:124] Setting up conv2\n",
      "I0430 05:37:37.322454 32246 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:37:37.322458 32246 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:37:37.322464 32246 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:37:37.322469 32246 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:37:37.322471 32246 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:37:37.322476 32246 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:37:37.322480 32246 net.cpp:124] Setting up relu2\n",
      "I0430 05:37:37.322484 32246 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:37:37.322487 32246 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:37:37.322490 32246 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:37:37.322495 32246 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:37:37.322499 32246 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:37:37.322502 32246 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:37:37.322509 32246 net.cpp:124] Setting up pool2\n",
      "I0430 05:37:37.322512 32246 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:37:37.322515 32246 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:37:37.322518 32246 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:37:37.322525 32246 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:37:37.322527 32246 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:37:37.322532 32246 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:37:37.322538 32246 net.cpp:124] Setting up norm2\n",
      "I0430 05:37:37.322542 32246 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:37:37.322546 32246 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:37:37.322548 32246 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:37:37.322554 32246 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:37:37.322557 32246 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:37:37.322562 32246 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:37:37.323278 32246 net.cpp:124] Setting up conv3\n",
      "I0430 05:37:37.323290 32246 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:37:37.323293 32246 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:37:37.323302 32246 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:37:37.323307 32246 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:37:37.323310 32246 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:37:37.323315 32246 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:37:37.323320 32246 net.cpp:124] Setting up relu3\n",
      "I0430 05:37:37.323324 32246 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:37:37.323328 32246 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:37:37.323331 32246 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:37:37.323338 32246 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:37:37.323340 32246 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:37:37.323345 32246 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:37:37.324067 32246 net.cpp:124] Setting up conv4\n",
      "I0430 05:37:37.324076 32246 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:37:37.324080 32246 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:37:37.324086 32246 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:37:37.324090 32246 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:37:37.324093 32246 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:37:37.324098 32246 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:37:37.324103 32246 net.cpp:124] Setting up relu4\n",
      "I0430 05:37:37.324107 32246 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:37:37.324110 32246 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:37:37.324113 32246 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:37:37.324120 32246 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:37:37.324123 32246 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:37:37.324128 32246 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:37:37.324615 32246 net.cpp:124] Setting up conv5\n",
      "I0430 05:37:37.324622 32246 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:37:37.324625 32246 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:37:37.324635 32246 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:37:37.324638 32246 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:37:37.324641 32246 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:37:37.324646 32246 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:37:37.324651 32246 net.cpp:124] Setting up relu5\n",
      "I0430 05:37:37.324656 32246 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:37:37.324657 32246 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:37:37.324661 32246 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:37:37.324666 32246 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:37:37.324668 32246 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:37:37.324676 32246 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:37:37.324684 32246 net.cpp:124] Setting up pool5\n",
      "I0430 05:37:37.324689 32246 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:37:37.324692 32246 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:37:37.324694 32246 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:37:37.324702 32246 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:37:37.324704 32246 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:37:37.324709 32246 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:37:37.347898 32246 net.cpp:124] Setting up fc6\n",
      "I0430 05:37:37.347916 32246 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:37:37.347919 32246 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:37:37.347929 32246 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:37:37.347937 32246 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:37:37.347941 32246 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:37:37.347947 32246 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:37:37.347955 32246 net.cpp:124] Setting up relu6\n",
      "I0430 05:37:37.347959 32246 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:37:37.347961 32246 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:37:37.347965 32246 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:37:37.347971 32246 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:37:37.347973 32246 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:37:37.347978 32246 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:37:37.347985 32246 net.cpp:124] Setting up drop6\n",
      "I0430 05:37:37.347987 32246 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:37:37.347990 32246 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:37:37.347993 32246 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:37:37.348001 32246 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:37:37.348002 32246 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:37:37.348007 32246 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:37:37.358726 32246 net.cpp:124] Setting up fc7\n",
      "I0430 05:37:37.358757 32246 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:37:37.358760 32246 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:37:37.358770 32246 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:37:37.358779 32246 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:37:37.358783 32246 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:37:37.358788 32246 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:37:37.358798 32246 net.cpp:124] Setting up relu7\n",
      "I0430 05:37:37.358803 32246 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:37:37.358804 32246 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:37:37.358808 32246 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:37:37.358814 32246 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:37:37.358816 32246 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:37:37.358821 32246 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:37:37.358826 32246 net.cpp:124] Setting up drop7\n",
      "I0430 05:37:37.358830 32246 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:37:37.358832 32246 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:37:37.358836 32246 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:37:37.358841 32246 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:37:37.358844 32246 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:37:37.358849 32246 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:37:37.359529 32246 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:37:37.359544 32246 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:37:37.359547 32246 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:37:37.359556 32246 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:37:37.359560 32246 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:37:37.359563 32246 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:37:37.359567 32246 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:37:37.359570 32246 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:37:37.359573 32246 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:37:37.359577 32246 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:37:37.359580 32246 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:37:37.359585 32246 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:37:37.359587 32246 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:37:37.359591 32246 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:37:37.359594 32246 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:37:37.359597 32246 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:37:37.359601 32246 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:37:37.359604 32246 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:37:37.359608 32246 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:37:37.359611 32246 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:37:37.359614 32246 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:37:37.359618 32246 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:37:37.359622 32246 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:37:37.359624 32246 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:37:37.359627 32246 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:37:37.359632 32246 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:37:37.359633 32246 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:37:37.359645 32246 net.cpp:257] Network initialization done.\n",
      "I0430 05:37:37.447347 32246 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:37:37.546929 32246 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:37:37.548085 32246 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:37:37.548100 32246 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:37:37.548105 32246 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/412693.jpg'}, '/tmp/tmp0avPWP.mat')\n",
      "Processed 1501 windows in 177.835 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-2.07433, -2.10231, -2.22745, -2.63352, -1.10...\n",
      "ymin                                                         94\n",
      "xmin                                                         67\n",
      "ymax                                                        274\n",
      "xmax                                                        219\n",
      "Name: /home/ambika/INF_project/data/bird/412693.jpg, dtype: object\n",
      "prediction    [-2.30951, -2.11017, -2.04942, -2.41256, -2.09...\n",
      "ymin                                                        227\n",
      "xmin                                                          0\n",
      "ymax                                                        334\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/bird/412693.jpg, dtype: object\n",
      "bird\n",
      "67\t94\t219\t274\n",
      "balance beam\n",
      "0\t227\t500\t334\n",
      "412693\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:40:36.885478 32407 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:40:36.885494 32407 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:40:36.885498 32407 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:40:36.886597 32407 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:40:36.886672 32407 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:40:36.886682 32407 net.cpp:86] Creating Layer data\n",
      "I0430 05:40:36.886685 32407 net.cpp:382] data -> data\n",
      "I0430 05:40:36.886698 32407 net.cpp:124] Setting up data\n",
      "I0430 05:40:36.886703 32407 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:40:36.886705 32407 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:40:36.886708 32407 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:40:36.886713 32407 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:40:36.886716 32407 net.cpp:408] conv1 <- data\n",
      "I0430 05:40:36.886720 32407 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:40:36.886777 32407 net.cpp:124] Setting up conv1\n",
      "I0430 05:40:36.886782 32407 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:40:36.886785 32407 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:40:36.886791 32407 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:40:36.886796 32407 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:40:36.886798 32407 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:40:36.886802 32407 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:40:36.886806 32407 net.cpp:124] Setting up relu1\n",
      "I0430 05:40:36.886809 32407 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:40:36.886811 32407 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:40:36.886814 32407 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:40:36.886817 32407 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:40:36.886821 32407 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:40:36.886823 32407 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:40:36.886829 32407 net.cpp:124] Setting up pool1\n",
      "I0430 05:40:36.886832 32407 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:40:36.886835 32407 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:40:36.886837 32407 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:40:36.886842 32407 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:40:36.886844 32407 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:40:36.886847 32407 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:40:36.886852 32407 net.cpp:124] Setting up norm1\n",
      "I0430 05:40:36.886855 32407 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:40:36.886857 32407 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:40:36.886860 32407 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:40:36.886864 32407 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:40:36.886867 32407 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:40:36.886869 32407 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:40:36.887218 32407 net.cpp:124] Setting up conv2\n",
      "I0430 05:40:36.887226 32407 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:40:36.887229 32407 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:40:36.887235 32407 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:40:36.887239 32407 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:40:36.887243 32407 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:40:36.887245 32407 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:40:36.887249 32407 net.cpp:124] Setting up relu2\n",
      "I0430 05:40:36.887253 32407 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:40:36.887254 32407 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:40:36.887257 32407 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:40:36.887261 32407 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:40:36.887264 32407 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:40:36.887267 32407 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:40:36.887272 32407 net.cpp:124] Setting up pool2\n",
      "I0430 05:40:36.887275 32407 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:40:36.887277 32407 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:40:36.887280 32407 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:40:36.887284 32407 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:40:36.887286 32407 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:40:36.887290 32407 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:40:36.887295 32407 net.cpp:124] Setting up norm2\n",
      "I0430 05:40:36.887297 32407 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:40:36.887300 32407 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:40:36.887302 32407 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:40:36.887307 32407 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:40:36.887310 32407 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:40:36.887313 32407 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:40:36.888010 32407 net.cpp:124] Setting up conv3\n",
      "I0430 05:40:36.888021 32407 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:40:36.888023 32407 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:40:36.888031 32407 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:40:36.888036 32407 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:40:36.888038 32407 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:40:36.888042 32407 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:40:36.888046 32407 net.cpp:124] Setting up relu3\n",
      "I0430 05:40:36.888049 32407 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:40:36.888052 32407 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:40:36.888054 32407 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:40:36.888061 32407 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:40:36.888063 32407 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:40:36.888067 32407 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:40:36.888844 32407 net.cpp:124] Setting up conv4\n",
      "I0430 05:40:36.888860 32407 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:40:36.888864 32407 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:40:36.888871 32407 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:40:36.888878 32407 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:40:36.888883 32407 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:40:36.888890 32407 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:40:36.888896 32407 net.cpp:124] Setting up relu4\n",
      "I0430 05:40:36.888900 32407 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:40:36.888902 32407 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:40:36.888905 32407 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:40:36.888911 32407 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:40:36.888914 32407 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:40:36.888919 32407 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:40:36.889559 32407 net.cpp:124] Setting up conv5\n",
      "I0430 05:40:36.889570 32407 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:40:36.889575 32407 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:40:36.889586 32407 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:40:36.889595 32407 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:40:36.889600 32407 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:40:36.889606 32407 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:40:36.889613 32407 net.cpp:124] Setting up relu5\n",
      "I0430 05:40:36.889618 32407 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:40:36.889622 32407 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:40:36.889626 32407 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:40:36.889632 32407 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:40:36.889636 32407 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:40:36.889642 32407 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:40:36.889652 32407 net.cpp:124] Setting up pool5\n",
      "I0430 05:40:36.889657 32407 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:40:36.889660 32407 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:40:36.889664 32407 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:40:36.889673 32407 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:40:36.889678 32407 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:40:36.889683 32407 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:40:36.912039 32407 net.cpp:124] Setting up fc6\n",
      "I0430 05:40:36.912060 32407 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:40:36.912065 32407 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:40:36.912073 32407 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:40:36.912081 32407 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:40:36.912083 32407 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:40:36.912087 32407 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:40:36.912093 32407 net.cpp:124] Setting up relu6\n",
      "I0430 05:40:36.912096 32407 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:40:36.912097 32407 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:40:36.912099 32407 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:40:36.912102 32407 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:40:36.912104 32407 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:40:36.912106 32407 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:40:36.912112 32407 net.cpp:124] Setting up drop6\n",
      "I0430 05:40:36.912120 32407 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:40:36.912123 32407 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:40:36.912127 32407 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:40:36.912132 32407 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:40:36.912133 32407 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:40:36.912137 32407 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:40:36.922209 32407 net.cpp:124] Setting up fc7\n",
      "I0430 05:40:36.922226 32407 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:40:36.922231 32407 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:40:36.922238 32407 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:40:36.922245 32407 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:40:36.922248 32407 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:40:36.922253 32407 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:40:36.922260 32407 net.cpp:124] Setting up relu7\n",
      "I0430 05:40:36.922262 32407 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:40:36.922263 32407 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:40:36.922266 32407 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:40:36.922269 32407 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:40:36.922271 32407 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:40:36.922273 32407 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:40:36.922284 32407 net.cpp:124] Setting up drop7\n",
      "I0430 05:40:36.922287 32407 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:40:36.922291 32407 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:40:36.922293 32407 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:40:36.922297 32407 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:40:36.922299 32407 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:40:36.922302 32407 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:40:36.922941 32407 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:40:36.922950 32407 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:40:36.922953 32407 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:40:36.922960 32407 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:40:36.922962 32407 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:40:36.922965 32407 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:40:36.922966 32407 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:40:36.922967 32407 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:40:36.922969 32407 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:40:36.922971 32407 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:40:36.922976 32407 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:40:36.922979 32407 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:40:36.922981 32407 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:40:36.922984 32407 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:40:36.922987 32407 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:40:36.922991 32407 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:40:36.922993 32407 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:40:36.922996 32407 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:40:36.922999 32407 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:40:36.923002 32407 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:40:36.923004 32407 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:40:36.923007 32407 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:40:36.923010 32407 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:40:36.923012 32407 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:40:36.923015 32407 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:40:36.923018 32407 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:40:36.923020 32407 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:40:36.923032 32407 net.cpp:257] Network initialization done.\n",
      "I0430 05:40:37.008512 32407 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:40:37.107517 32407 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:40:37.108541 32407 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:40:37.108551 32407 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:40:37.108556 32407 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/228467.jpg'}, '/tmp/tmpSnDRQx.mat')\n",
      "Processed 2149 windows in 251.229 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.22736, -1.6793, -2.08137, -2.20962, -1.826...\n",
      "ymin                                                         90\n",
      "xmin                                                          0\n",
      "ymax                                                        276\n",
      "xmax                                                        366\n",
      "Name: /home/ambika/INF_project/data/bus/228467.jpg, dtype: object\n",
      "prediction    [-2.66719, -2.56219, -1.60199, -1.74732, -2.16...\n",
      "ymin                                                        133\n",
      "xmin                                                        288\n",
      "ymax                                                        158\n",
      "xmax                                                        397\n",
      "Name: /home/ambika/INF_project/data/bus/228467.jpg, dtype: object\n",
      "bus\n",
      "0\t90\t366\t276\n",
      "digital clock\n",
      "288\t133\t397\t158\n",
      "228467\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:44:49.873229 32595 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:44:49.873247 32595 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:44:49.873250 32595 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:44:49.874341 32595 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:44:49.874419 32595 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:44:49.874433 32595 net.cpp:86] Creating Layer data\n",
      "I0430 05:44:49.874436 32595 net.cpp:382] data -> data\n",
      "I0430 05:44:49.874449 32595 net.cpp:124] Setting up data\n",
      "I0430 05:44:49.874454 32595 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:44:49.874456 32595 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:44:49.874459 32595 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:44:49.874465 32595 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:44:49.874467 32595 net.cpp:408] conv1 <- data\n",
      "I0430 05:44:49.874471 32595 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:44:49.874531 32595 net.cpp:124] Setting up conv1\n",
      "I0430 05:44:49.874536 32595 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:44:49.874539 32595 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:44:49.874546 32595 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:44:49.874550 32595 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:44:49.874553 32595 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:44:49.874557 32595 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:44:49.874562 32595 net.cpp:124] Setting up relu1\n",
      "I0430 05:44:49.874564 32595 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:44:49.874567 32595 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:44:49.874569 32595 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:44:49.874572 32595 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:44:49.874575 32595 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:44:49.874578 32595 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:44:49.874584 32595 net.cpp:124] Setting up pool1\n",
      "I0430 05:44:49.874588 32595 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:44:49.874590 32595 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:44:49.874593 32595 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:44:49.874598 32595 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:44:49.874599 32595 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:44:49.874603 32595 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:44:49.874608 32595 net.cpp:124] Setting up norm1\n",
      "I0430 05:44:49.874610 32595 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:44:49.874614 32595 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:44:49.874615 32595 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:44:49.874619 32595 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:44:49.874621 32595 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:44:49.874625 32595 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:44:49.874960 32595 net.cpp:124] Setting up conv2\n",
      "I0430 05:44:49.874965 32595 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:44:49.874967 32595 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:44:49.874972 32595 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:44:49.874976 32595 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:44:49.874979 32595 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:44:49.874982 32595 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:44:49.874986 32595 net.cpp:124] Setting up relu2\n",
      "I0430 05:44:49.874989 32595 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:44:49.874991 32595 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:44:49.874994 32595 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:44:49.874997 32595 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:44:49.875000 32595 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:44:49.875003 32595 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:44:49.875008 32595 net.cpp:124] Setting up pool2\n",
      "I0430 05:44:49.875011 32595 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:44:49.875013 32595 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:44:49.875015 32595 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:44:49.875020 32595 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:44:49.875023 32595 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:44:49.875026 32595 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:44:49.875031 32595 net.cpp:124] Setting up norm2\n",
      "I0430 05:44:49.875035 32595 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:44:49.875036 32595 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:44:49.875038 32595 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:44:49.875042 32595 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:44:49.875046 32595 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:44:49.875048 32595 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:44:49.875774 32595 net.cpp:124] Setting up conv3\n",
      "I0430 05:44:49.875784 32595 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:44:49.875787 32595 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:44:49.875794 32595 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:44:49.875799 32595 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:44:49.875802 32595 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:44:49.875807 32595 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:44:49.875810 32595 net.cpp:124] Setting up relu3\n",
      "I0430 05:44:49.875813 32595 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:44:49.875816 32595 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:44:49.875818 32595 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:44:49.875823 32595 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:44:49.875826 32595 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:44:49.875830 32595 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:44:49.876555 32595 net.cpp:124] Setting up conv4\n",
      "I0430 05:44:49.876564 32595 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:44:49.876565 32595 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:44:49.876570 32595 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:44:49.876575 32595 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:44:49.876577 32595 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:44:49.876581 32595 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:44:49.876585 32595 net.cpp:124] Setting up relu4\n",
      "I0430 05:44:49.876588 32595 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:44:49.876590 32595 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:44:49.876593 32595 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:44:49.876598 32595 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:44:49.876600 32595 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:44:49.876605 32595 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:44:49.877099 32595 net.cpp:124] Setting up conv5\n",
      "I0430 05:44:49.877104 32595 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:44:49.877106 32595 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:44:49.877116 32595 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:44:49.877120 32595 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:44:49.877123 32595 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:44:49.877126 32595 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:44:49.877130 32595 net.cpp:124] Setting up relu5\n",
      "I0430 05:44:49.877133 32595 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:44:49.877135 32595 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:44:49.877138 32595 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:44:49.877143 32595 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:44:49.877146 32595 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:44:49.877148 32595 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:44:49.877154 32595 net.cpp:124] Setting up pool5\n",
      "I0430 05:44:49.877158 32595 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:44:49.877161 32595 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:44:49.877163 32595 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:44:49.877169 32595 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:44:49.877172 32595 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:44:49.877177 32595 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:44:49.906527 32595 net.cpp:124] Setting up fc6\n",
      "I0430 05:44:49.906565 32595 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:44:49.906569 32595 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:44:49.906585 32595 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:44:49.906599 32595 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:44:49.906605 32595 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:44:49.906612 32595 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:44:49.906622 32595 net.cpp:124] Setting up relu6\n",
      "I0430 05:44:49.906627 32595 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:44:49.906630 32595 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:44:49.906635 32595 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:44:49.906641 32595 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:44:49.906646 32595 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:44:49.906651 32595 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:44:49.906659 32595 net.cpp:124] Setting up drop6\n",
      "I0430 05:44:49.906663 32595 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:44:49.906667 32595 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:44:49.906672 32595 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:44:49.906677 32595 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:44:49.906680 32595 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:44:49.906685 32595 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:44:49.918269 32595 net.cpp:124] Setting up fc7\n",
      "I0430 05:44:49.918304 32595 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:44:49.918309 32595 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:44:49.918323 32595 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:44:49.918337 32595 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:44:49.918341 32595 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:44:49.918354 32595 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:44:49.918365 32595 net.cpp:124] Setting up relu7\n",
      "I0430 05:44:49.918370 32595 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:44:49.918372 32595 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:44:49.918376 32595 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:44:49.918382 32595 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:44:49.918385 32595 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:44:49.918391 32595 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:44:49.918397 32595 net.cpp:124] Setting up drop7\n",
      "I0430 05:44:49.918401 32595 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:44:49.918404 32595 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:44:49.918408 32595 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:44:49.918418 32595 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:44:49.918434 32595 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:44:49.918452 32595 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:44:49.919926 32595 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:44:49.919975 32595 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:44:49.919981 32595 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:44:49.919996 32595 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:44:49.920006 32595 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:44:49.920011 32595 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:44:49.920016 32595 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:44:49.920019 32595 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:44:49.920022 32595 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:44:49.920027 32595 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:44:49.920032 32595 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:44:49.920035 32595 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:44:49.920040 32595 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:44:49.920044 32595 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:44:49.920048 32595 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:44:49.920053 32595 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:44:49.920056 32595 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:44:49.920061 32595 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:44:49.920065 32595 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:44:49.920068 32595 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:44:49.920073 32595 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:44:49.920076 32595 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:44:49.920083 32595 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:44:49.920086 32595 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:44:49.920090 32595 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:44:49.920094 32595 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:44:49.920096 32595 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:44:49.920110 32595 net.cpp:257] Network initialization done.\n",
      "I0430 05:44:50.007552 32595 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:44:50.108172 32595 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:44:50.109170 32595 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:44:50.109179 32595 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:44:50.109184 32595 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/154854.jpg'}, '/tmp/tmpZfelUS.mat')\n",
      "Processed 2066 windows in 243.602 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-1.97898, -1.93445, -1.83538, -1.86221, -2.29...\n",
      "ymin                                                        244\n",
      "xmin                                                        369\n",
      "ymax                                                        375\n",
      "xmax                                                        474\n",
      "Name: /home/ambika/INF_project/data/car/154854.jpg, dtype: object\n",
      "prediction    [-2.13964, -2.20302, -2.12351, -2.27581, -1.90...\n",
      "ymin                                                        249\n",
      "xmin                                                        183\n",
      "ymax                                                        296\n",
      "xmax                                                        293\n",
      "Name: /home/ambika/INF_project/data/car/154854.jpg, dtype: object\n",
      "tape player\n",
      "369\t244\t474\t375\n",
      "car\n",
      "183\t249\t293\t296\n",
      "154854\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:48:55.223647   307 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:48:55.223672   307 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:48:55.223678   307 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:48:55.224830   307 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:48:55.225005   307 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:48:55.225014   307 net.cpp:86] Creating Layer data\n",
      "I0430 05:48:55.225019   307 net.cpp:382] data -> data\n",
      "I0430 05:48:55.225033   307 net.cpp:124] Setting up data\n",
      "I0430 05:48:55.225040   307 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:48:55.225044   307 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:48:55.225049   307 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:48:55.225055   307 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:48:55.225057   307 net.cpp:408] conv1 <- data\n",
      "I0430 05:48:55.225061   307 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:48:55.225121   307 net.cpp:124] Setting up conv1\n",
      "I0430 05:48:55.225126   307 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:48:55.225127   307 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:48:55.225134   307 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:48:55.225139   307 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:48:55.225142   307 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:48:55.225145   307 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:48:55.225149   307 net.cpp:124] Setting up relu1\n",
      "I0430 05:48:55.225152   307 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:48:55.225154   307 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:48:55.225157   307 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:48:55.225160   307 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:48:55.225163   307 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:48:55.225167   307 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:48:55.225172   307 net.cpp:124] Setting up pool1\n",
      "I0430 05:48:55.225177   307 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:48:55.225178   307 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:48:55.225180   307 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:48:55.225185   307 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:48:55.225188   307 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:48:55.225190   307 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:48:55.225196   307 net.cpp:124] Setting up norm1\n",
      "I0430 05:48:55.225201   307 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:48:55.225205   307 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:48:55.225208   307 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:48:55.225215   307 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:48:55.225219   307 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:48:55.225224   307 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:48:55.225575   307 net.cpp:124] Setting up conv2\n",
      "I0430 05:48:55.225584   307 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:48:55.225587   307 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:48:55.225596   307 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:48:55.225600   307 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:48:55.225603   307 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:48:55.225606   307 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:48:55.225610   307 net.cpp:124] Setting up relu2\n",
      "I0430 05:48:55.225615   307 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:48:55.225616   307 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:48:55.225618   307 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:48:55.225623   307 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:48:55.225625   307 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:48:55.225630   307 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:48:55.225634   307 net.cpp:124] Setting up pool2\n",
      "I0430 05:48:55.225638   307 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:48:55.225641   307 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:48:55.225642   307 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:48:55.225648   307 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:48:55.225651   307 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:48:55.225653   307 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:48:55.225658   307 net.cpp:124] Setting up norm2\n",
      "I0430 05:48:55.225661   307 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:48:55.225663   307 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:48:55.225666   307 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:48:55.225672   307 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:48:55.225673   307 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:48:55.225677   307 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:48:55.226661   307 net.cpp:124] Setting up conv3\n",
      "I0430 05:48:55.226672   307 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:48:55.226675   307 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:48:55.226686   307 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:48:55.226694   307 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:48:55.226697   307 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:48:55.226701   307 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:48:55.226707   307 net.cpp:124] Setting up relu3\n",
      "I0430 05:48:55.226711   307 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:48:55.226712   307 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:48:55.226716   307 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:48:55.226722   307 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:48:55.226724   307 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:48:55.226727   307 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:48:55.227183   307 net.cpp:124] Setting up conv4\n",
      "I0430 05:48:55.227191   307 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:48:55.227195   307 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:48:55.227201   307 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:48:55.227252   307 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:48:55.227255   307 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:48:55.227258   307 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:48:55.227263   307 net.cpp:124] Setting up relu4\n",
      "I0430 05:48:55.227267   307 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:48:55.227269   307 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:48:55.227272   307 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:48:55.227277   307 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:48:55.227279   307 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:48:55.227283   307 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:48:55.227795   307 net.cpp:124] Setting up conv5\n",
      "I0430 05:48:55.227802   307 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:48:55.227805   307 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:48:55.227818   307 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:48:55.227823   307 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:48:55.227824   307 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:48:55.227828   307 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:48:55.227833   307 net.cpp:124] Setting up relu5\n",
      "I0430 05:48:55.227835   307 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:48:55.227838   307 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:48:55.227840   307 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:48:55.227845   307 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:48:55.227847   307 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:48:55.227851   307 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:48:55.227859   307 net.cpp:124] Setting up pool5\n",
      "I0430 05:48:55.227861   307 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:48:55.227864   307 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:48:55.227866   307 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:48:55.227872   307 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:48:55.227874   307 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:48:55.227879   307 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:48:55.250754   307 net.cpp:124] Setting up fc6\n",
      "I0430 05:48:55.250777   307 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:48:55.250778   307 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:48:55.250785   307 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:48:55.250792   307 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:48:55.250793   307 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:48:55.250797   307 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:48:55.250803   307 net.cpp:124] Setting up relu6\n",
      "I0430 05:48:55.250807   307 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:48:55.250808   307 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:48:55.250813   307 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:48:55.250818   307 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:48:55.250820   307 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:48:55.250826   307 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:48:55.250831   307 net.cpp:124] Setting up drop6\n",
      "I0430 05:48:55.250834   307 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:48:55.250838   307 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:48:55.250839   307 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:48:55.250844   307 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:48:55.250846   307 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:48:55.250850   307 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:48:55.262789   307 net.cpp:124] Setting up fc7\n",
      "I0430 05:48:55.262814   307 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:48:55.262817   307 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:48:55.262826   307 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:48:55.262835   307 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:48:55.262838   307 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:48:55.262847   307 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:48:55.262867   307 net.cpp:124] Setting up relu7\n",
      "I0430 05:48:55.262872   307 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:48:55.262876   307 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:48:55.262878   307 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:48:55.262884   307 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:48:55.262888   307 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:48:55.262893   307 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:48:55.262900   307 net.cpp:124] Setting up drop7\n",
      "I0430 05:48:55.262904   307 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:48:55.262907   307 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:48:55.262912   307 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:48:55.262917   307 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:48:55.262919   307 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:48:55.262924   307 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:48:55.264204   307 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:48:55.264227   307 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:48:55.264231   307 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:48:55.264242   307 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:48:55.264247   307 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:48:55.264251   307 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:48:55.264255   307 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:48:55.264258   307 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:48:55.264261   307 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:48:55.264264   307 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:48:55.264269   307 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:48:55.264273   307 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:48:55.264277   307 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:48:55.264281   307 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:48:55.264286   307 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:48:55.264289   307 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:48:55.264293   307 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:48:55.264298   307 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:48:55.264302   307 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:48:55.264305   307 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:48:55.264312   307 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:48:55.264317   307 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:48:55.264322   307 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:48:55.264327   307 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:48:55.264333   307 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:48:55.264336   307 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:48:55.264339   307 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:48:55.264355   307 net.cpp:257] Network initialization done.\n",
      "I0430 05:48:55.355660   307 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:48:55.456843   307 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:48:55.457830   307 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:48:55.457840   307 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:48:55.457844   307 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/318722.jpg'}, '/tmp/tmp_DFfrV.mat')\n",
      "Processed 1745 windows in 207.286 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-1.76257, -2.01037, -2.00035, -2.11171, -1.90...\n",
      "ymin                                                         94\n",
      "xmin                                                        173\n",
      "ymax                                                        294\n",
      "xmax                                                        326\n",
      "Name: /home/ambika/INF_project/data/cat/318722.jpg, dtype: object\n",
      "prediction    [-1.74111, -2.14066, -2.03503, -2.44769, -2.09...\n",
      "ymin                                                        155\n",
      "xmin                                                        132\n",
      "ymax                                                        298\n",
      "xmax                                                        338\n",
      "Name: /home/ambika/INF_project/data/cat/318722.jpg, dtype: object\n",
      "domestic cat\n",
      "173\t94\t326\t294\n",
      "dog\n",
      "132\t155\t338\t298\n",
      "318722\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:52:24.248090   512 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:52:24.248106   512 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:52:24.248109   512 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:52:24.249294   512 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:52:24.249501   512 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:52:24.249542   512 net.cpp:86] Creating Layer data\n",
      "I0430 05:52:24.249548   512 net.cpp:382] data -> data\n",
      "I0430 05:52:24.249572   512 net.cpp:124] Setting up data\n",
      "I0430 05:52:24.249581   512 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:52:24.249584   512 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:52:24.249590   512 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:52:24.249599   512 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:52:24.249603   512 net.cpp:408] conv1 <- data\n",
      "I0430 05:52:24.249610   512 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:52:24.249681   512 net.cpp:124] Setting up conv1\n",
      "I0430 05:52:24.249689   512 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:52:24.249692   512 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:52:24.249702   512 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:52:24.249709   512 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:52:24.249712   512 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:52:24.249718   512 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:52:24.249724   512 net.cpp:124] Setting up relu1\n",
      "I0430 05:52:24.249728   512 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:52:24.249732   512 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:52:24.249735   512 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:52:24.249742   512 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:52:24.249744   512 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:52:24.249749   512 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:52:24.249758   512 net.cpp:124] Setting up pool1\n",
      "I0430 05:52:24.249763   512 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:52:24.249766   512 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:52:24.249770   512 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:52:24.249778   512 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:52:24.249780   512 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:52:24.249786   512 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:52:24.249795   512 net.cpp:124] Setting up norm1\n",
      "I0430 05:52:24.249800   512 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:52:24.249804   512 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:52:24.249809   512 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:52:24.249816   512 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:52:24.249821   512 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:52:24.249828   512 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:52:24.250378   512 net.cpp:124] Setting up conv2\n",
      "I0430 05:52:24.250414   512 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:52:24.250418   512 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:52:24.250435   512 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:52:24.250452   512 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:52:24.250455   512 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:52:24.250463   512 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:52:24.250473   512 net.cpp:124] Setting up relu2\n",
      "I0430 05:52:24.250478   512 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:52:24.250481   512 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:52:24.250485   512 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:52:24.250493   512 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:52:24.250495   512 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:52:24.250501   512 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:52:24.250512   512 net.cpp:124] Setting up pool2\n",
      "I0430 05:52:24.250517   512 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:52:24.250521   512 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:52:24.250524   512 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:52:24.250532   512 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:52:24.250535   512 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:52:24.250540   512 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:52:24.250547   512 net.cpp:124] Setting up norm2\n",
      "I0430 05:52:24.250551   512 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:52:24.250555   512 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:52:24.250558   512 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:52:24.250569   512 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:52:24.250572   512 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:52:24.250577   512 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:52:24.251590   512 net.cpp:124] Setting up conv3\n",
      "I0430 05:52:24.251605   512 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:52:24.251610   512 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:52:24.251621   512 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:52:24.251627   512 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:52:24.251631   512 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:52:24.251637   512 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:52:24.251643   512 net.cpp:124] Setting up relu3\n",
      "I0430 05:52:24.251648   512 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:52:24.251651   512 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:52:24.251654   512 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:52:24.251662   512 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:52:24.251664   512 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:52:24.251669   512 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:52:24.252393   512 net.cpp:124] Setting up conv4\n",
      "I0430 05:52:24.252403   512 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:52:24.252405   512 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:52:24.252413   512 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:52:24.252418   512 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:52:24.252420   512 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:52:24.252426   512 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:52:24.252430   512 net.cpp:124] Setting up relu4\n",
      "I0430 05:52:24.252435   512 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:52:24.252437   512 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:52:24.252441   512 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:52:24.252446   512 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:52:24.252449   512 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:52:24.252455   512 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:52:24.252938   512 net.cpp:124] Setting up conv5\n",
      "I0430 05:52:24.252945   512 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:52:24.252948   512 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:52:24.252959   512 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:52:24.252962   512 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:52:24.252965   512 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:52:24.252970   512 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:52:24.252975   512 net.cpp:124] Setting up relu5\n",
      "I0430 05:52:24.252979   512 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:52:24.252981   512 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:52:24.252985   512 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:52:24.252991   512 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:52:24.252993   512 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:52:24.253000   512 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:52:24.253016   512 net.cpp:124] Setting up pool5\n",
      "I0430 05:52:24.253021   512 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:52:24.253023   512 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:52:24.253026   512 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:52:24.253034   512 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:52:24.253037   512 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:52:24.253042   512 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:52:24.274313   512 net.cpp:124] Setting up fc6\n",
      "I0430 05:52:24.274338   512 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:52:24.274343   512 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:52:24.274353   512 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:52:24.274360   512 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:52:24.274364   512 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:52:24.274370   512 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:52:24.274379   512 net.cpp:124] Setting up relu6\n",
      "I0430 05:52:24.274382   512 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:52:24.274384   512 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:52:24.274386   512 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:52:24.274391   512 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:52:24.274394   512 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:52:24.274397   512 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:52:24.274404   512 net.cpp:124] Setting up drop6\n",
      "I0430 05:52:24.274407   512 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:52:24.274410   512 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:52:24.274413   512 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:52:24.274420   512 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:52:24.274423   512 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:52:24.274428   512 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:52:24.284591   512 net.cpp:124] Setting up fc7\n",
      "I0430 05:52:24.284617   512 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:52:24.284621   512 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:52:24.284654   512 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:52:24.284665   512 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:52:24.284670   512 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:52:24.284679   512 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:52:24.284689   512 net.cpp:124] Setting up relu7\n",
      "I0430 05:52:24.284693   512 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:52:24.284695   512 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:52:24.284698   512 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:52:24.284703   512 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:52:24.284705   512 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:52:24.284708   512 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:52:24.284713   512 net.cpp:124] Setting up drop7\n",
      "I0430 05:52:24.284718   512 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:52:24.284719   512 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:52:24.284723   512 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:52:24.284726   512 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:52:24.284729   512 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:52:24.284732   512 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:52:24.285792   512 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:52:24.285809   512 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:52:24.285811   512 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:52:24.285821   512 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:52:24.285826   512 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:52:24.285830   512 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:52:24.285833   512 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:52:24.285836   512 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:52:24.285840   512 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:52:24.285845   512 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:52:24.285847   512 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:52:24.285850   512 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:52:24.285852   512 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:52:24.285854   512 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:52:24.285857   512 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:52:24.285861   512 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:52:24.285862   512 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:52:24.285866   512 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:52:24.285868   512 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:52:24.285871   512 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:52:24.285874   512 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:52:24.285877   512 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:52:24.285879   512 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:52:24.285882   512 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:52:24.285886   512 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:52:24.285887   512 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:52:24.285890   512 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:52:24.285902   512 net.cpp:257] Network initialization done.\n",
      "I0430 05:52:24.375344   512 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:52:24.479894   512 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:52:24.481075   512 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:52:24.481087   512 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:52:24.481091   512 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/170267.jpg'}, '/tmp/tmp0KmYy4.mat')\n",
      "Processed 2283 windows in 264.722 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.13277, -1.99686, -1.75046, -1.7197, -1.929...\n",
      "ymin                                                         93\n",
      "xmin                                                        266\n",
      "ymax                                                        340\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/couch/170267.jpg, dtype: object\n",
      "prediction    [-1.64011, -1.95161, -2.07417, -2.01454, -2.68...\n",
      "ymin                                                         35\n",
      "xmin                                                        325\n",
      "ymax                                                        114\n",
      "xmax                                                        394\n",
      "Name: /home/ambika/INF_project/data/couch/170267.jpg, dtype: object\n",
      "person\n",
      "266\t93\t500\t340\n",
      "tv or monitor\n",
      "325\t35\t394\t114\n",
      "170267\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 05:56:50.755560   740 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 05:56:50.755584   740 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 05:56:50.755586   740 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 05:56:50.756659   740 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 05:56:50.756808   740 layer_factory.hpp:77] Creating layer data\n",
      "I0430 05:56:50.756820   740 net.cpp:86] Creating Layer data\n",
      "I0430 05:56:50.756829   740 net.cpp:382] data -> data\n",
      "I0430 05:56:50.756844   740 net.cpp:124] Setting up data\n",
      "I0430 05:56:50.756851   740 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 05:56:50.756855   740 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 05:56:50.756857   740 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 05:56:50.756865   740 net.cpp:86] Creating Layer conv1\n",
      "I0430 05:56:50.756867   740 net.cpp:408] conv1 <- data\n",
      "I0430 05:56:50.756875   740 net.cpp:382] conv1 -> conv1\n",
      "I0430 05:56:50.756958   740 net.cpp:124] Setting up conv1\n",
      "I0430 05:56:50.756965   740 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:56:50.756969   740 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 05:56:50.756979   740 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 05:56:50.756986   740 net.cpp:86] Creating Layer relu1\n",
      "I0430 05:56:50.756991   740 net.cpp:408] relu1 <- conv1\n",
      "I0430 05:56:50.756996   740 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 05:56:50.757004   740 net.cpp:124] Setting up relu1\n",
      "I0430 05:56:50.757009   740 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 05:56:50.757012   740 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 05:56:50.757015   740 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 05:56:50.757021   740 net.cpp:86] Creating Layer pool1\n",
      "I0430 05:56:50.757025   740 net.cpp:408] pool1 <- conv1\n",
      "I0430 05:56:50.757030   740 net.cpp:382] pool1 -> pool1\n",
      "I0430 05:56:50.757038   740 net.cpp:124] Setting up pool1\n",
      "I0430 05:56:50.757043   740 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:56:50.757046   740 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 05:56:50.757050   740 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 05:56:50.757056   740 net.cpp:86] Creating Layer norm1\n",
      "I0430 05:56:50.757061   740 net.cpp:408] norm1 <- pool1\n",
      "I0430 05:56:50.757066   740 net.cpp:382] norm1 -> norm1\n",
      "I0430 05:56:50.757072   740 net.cpp:124] Setting up norm1\n",
      "I0430 05:56:50.757077   740 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 05:56:50.757081   740 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 05:56:50.757084   740 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 05:56:50.757089   740 net.cpp:86] Creating Layer conv2\n",
      "I0430 05:56:50.757093   740 net.cpp:408] conv2 <- norm1\n",
      "I0430 05:56:50.757097   740 net.cpp:382] conv2 -> conv2\n",
      "I0430 05:56:50.757527   740 net.cpp:124] Setting up conv2\n",
      "I0430 05:56:50.757539   740 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:56:50.757544   740 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 05:56:50.757552   740 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 05:56:50.757560   740 net.cpp:86] Creating Layer relu2\n",
      "I0430 05:56:50.757563   740 net.cpp:408] relu2 <- conv2\n",
      "I0430 05:56:50.757568   740 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 05:56:50.757575   740 net.cpp:124] Setting up relu2\n",
      "I0430 05:56:50.757580   740 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 05:56:50.757585   740 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 05:56:50.757587   740 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 05:56:50.757593   740 net.cpp:86] Creating Layer pool2\n",
      "I0430 05:56:50.757599   740 net.cpp:408] pool2 <- conv2\n",
      "I0430 05:56:50.757604   740 net.cpp:382] pool2 -> pool2\n",
      "I0430 05:56:50.757613   740 net.cpp:124] Setting up pool2\n",
      "I0430 05:56:50.757619   740 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:56:50.757622   740 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 05:56:50.757625   740 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 05:56:50.757632   740 net.cpp:86] Creating Layer norm2\n",
      "I0430 05:56:50.757635   740 net.cpp:408] norm2 <- pool2\n",
      "I0430 05:56:50.757642   740 net.cpp:382] norm2 -> norm2\n",
      "I0430 05:56:50.757649   740 net.cpp:124] Setting up norm2\n",
      "I0430 05:56:50.757655   740 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:56:50.757658   740 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 05:56:50.757661   740 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 05:56:50.757668   740 net.cpp:86] Creating Layer conv3\n",
      "I0430 05:56:50.757671   740 net.cpp:408] conv3 <- norm2\n",
      "I0430 05:56:50.757674   740 net.cpp:382] conv3 -> conv3\n",
      "I0430 05:56:50.758508   740 net.cpp:124] Setting up conv3\n",
      "I0430 05:56:50.758528   740 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:56:50.758533   740 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 05:56:50.758543   740 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 05:56:50.758549   740 net.cpp:86] Creating Layer relu3\n",
      "I0430 05:56:50.758551   740 net.cpp:408] relu3 <- conv3\n",
      "I0430 05:56:50.758556   740 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 05:56:50.758563   740 net.cpp:124] Setting up relu3\n",
      "I0430 05:56:50.758566   740 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:56:50.758569   740 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 05:56:50.758570   740 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 05:56:50.758577   740 net.cpp:86] Creating Layer conv4\n",
      "I0430 05:56:50.758579   740 net.cpp:408] conv4 <- conv3\n",
      "I0430 05:56:50.758584   740 net.cpp:382] conv4 -> conv4\n",
      "I0430 05:56:50.759377   740 net.cpp:124] Setting up conv4\n",
      "I0430 05:56:50.759392   740 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:56:50.759395   740 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 05:56:50.759400   740 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 05:56:50.759407   740 net.cpp:86] Creating Layer relu4\n",
      "I0430 05:56:50.759410   740 net.cpp:408] relu4 <- conv4\n",
      "I0430 05:56:50.759414   740 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 05:56:50.759419   740 net.cpp:124] Setting up relu4\n",
      "I0430 05:56:50.759423   740 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 05:56:50.759425   740 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 05:56:50.759428   740 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 05:56:50.759433   740 net.cpp:86] Creating Layer conv5\n",
      "I0430 05:56:50.759435   740 net.cpp:408] conv5 <- conv4\n",
      "I0430 05:56:50.759439   740 net.cpp:382] conv5 -> conv5\n",
      "I0430 05:56:50.759961   740 net.cpp:124] Setting up conv5\n",
      "I0430 05:56:50.759971   740 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:56:50.759974   740 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 05:56:50.759984   740 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 05:56:50.759987   740 net.cpp:86] Creating Layer relu5\n",
      "I0430 05:56:50.759990   740 net.cpp:408] relu5 <- conv5\n",
      "I0430 05:56:50.759994   740 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 05:56:50.759999   740 net.cpp:124] Setting up relu5\n",
      "I0430 05:56:50.760002   740 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 05:56:50.760004   740 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 05:56:50.760006   740 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 05:56:50.760011   740 net.cpp:86] Creating Layer pool5\n",
      "I0430 05:56:50.760015   740 net.cpp:408] pool5 <- conv5\n",
      "I0430 05:56:50.760017   740 net.cpp:382] pool5 -> pool5\n",
      "I0430 05:56:50.760025   740 net.cpp:124] Setting up pool5\n",
      "I0430 05:56:50.760027   740 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 05:56:50.760030   740 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 05:56:50.760031   740 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 05:56:50.760038   740 net.cpp:86] Creating Layer fc6\n",
      "I0430 05:56:50.760040   740 net.cpp:408] fc6 <- pool5\n",
      "I0430 05:56:50.760045   740 net.cpp:382] fc6 -> fc6\n",
      "I0430 05:56:50.784840   740 net.cpp:124] Setting up fc6\n",
      "I0430 05:56:50.784862   740 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:56:50.784868   740 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 05:56:50.784876   740 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 05:56:50.784886   740 net.cpp:86] Creating Layer relu6\n",
      "I0430 05:56:50.784889   740 net.cpp:408] relu6 <- fc6\n",
      "I0430 05:56:50.784893   740 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 05:56:50.784900   740 net.cpp:124] Setting up relu6\n",
      "I0430 05:56:50.784903   740 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:56:50.784904   740 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 05:56:50.784906   740 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 05:56:50.784910   740 net.cpp:86] Creating Layer drop6\n",
      "I0430 05:56:50.784911   740 net.cpp:408] drop6 <- fc6\n",
      "I0430 05:56:50.784914   740 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 05:56:50.784919   740 net.cpp:124] Setting up drop6\n",
      "I0430 05:56:50.784922   740 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:56:50.784935   740 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 05:56:50.784940   740 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 05:56:50.784952   740 net.cpp:86] Creating Layer fc7\n",
      "I0430 05:56:50.784955   740 net.cpp:408] fc7 <- fc6\n",
      "I0430 05:56:50.784958   740 net.cpp:382] fc7 -> fc7\n",
      "I0430 05:56:50.797061   740 net.cpp:124] Setting up fc7\n",
      "I0430 05:56:50.797097   740 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:56:50.797103   740 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 05:56:50.797116   740 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 05:56:50.797129   740 net.cpp:86] Creating Layer relu7\n",
      "I0430 05:56:50.797133   740 net.cpp:408] relu7 <- fc7\n",
      "I0430 05:56:50.797142   740 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 05:56:50.797154   740 net.cpp:124] Setting up relu7\n",
      "I0430 05:56:50.797158   740 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:56:50.797161   740 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 05:56:50.797163   740 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 05:56:50.797170   740 net.cpp:86] Creating Layer drop7\n",
      "I0430 05:56:50.797194   740 net.cpp:408] drop7 <- fc7\n",
      "I0430 05:56:50.797200   740 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 05:56:50.797209   740 net.cpp:124] Setting up drop7\n",
      "I0430 05:56:50.797214   740 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 05:56:50.797219   740 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 05:56:50.797221   740 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 05:56:50.797229   740 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 05:56:50.797233   740 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 05:56:50.797238   740 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 05:56:50.798249   740 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 05:56:50.798264   740 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 05:56:50.798269   740 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 05:56:50.798277   740 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 05:56:50.798280   740 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 05:56:50.798283   740 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 05:56:50.798285   740 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 05:56:50.798288   740 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 05:56:50.798291   740 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 05:56:50.798295   740 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 05:56:50.798300   740 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 05:56:50.798302   740 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 05:56:50.798306   740 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 05:56:50.798310   740 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 05:56:50.798313   740 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 05:56:50.798317   740 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 05:56:50.798321   740 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 05:56:50.798324   740 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 05:56:50.798327   740 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 05:56:50.798329   740 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 05:56:50.798332   740 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 05:56:50.798336   740 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 05:56:50.798339   740 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 05:56:50.798343   740 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 05:56:50.798346   740 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 05:56:50.798349   740 net.cpp:202] data does not need backward computation.\n",
      "I0430 05:56:50.798352   740 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 05:56:50.798370   740 net.cpp:257] Network initialization done.\n",
      "I0430 05:56:50.886654   740 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:56:50.985096   740 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 05:56:50.986028   740 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 05:56:50.986037   740 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 05:56:50.986040   740 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/131714.jpg'}, '/tmp/tmpFjDbvY.mat')\n",
      "Processed 3283 windows in 398.575 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.091 s.\n",
      "prediction    [-1.88141, -2.80686, -2.3159, -2.55919, -2.230...\n",
      "ymin                                                        162\n",
      "xmin                                                         84\n",
      "ymax                                                        317\n",
      "xmax                                                        281\n",
      "Name: /home/ambika/INF_project/data/dog/131714.jpg, dtype: object\n",
      "prediction    [-1.80726, -2.94661, -2.10643, -3.32351, -1.82...\n",
      "ymin                                                        141\n",
      "xmin                                                          0\n",
      "ymax                                                        242\n",
      "xmax                                                        136\n",
      "Name: /home/ambika/INF_project/data/dog/131714.jpg, dtype: object\n",
      "camel\n",
      "84\t162\t281\t317\n",
      "dog\n",
      "0\t141\t136\t242\n",
      "131714\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:03:31.635862  1519 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:03:31.635887  1519 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:03:31.635891  1519 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:03:31.637748  1519 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:03:31.638105  1519 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:03:31.638113  1519 net.cpp:86] Creating Layer data\n",
      "I0430 06:03:31.638118  1519 net.cpp:382] data -> data\n",
      "I0430 06:03:31.638131  1519 net.cpp:124] Setting up data\n",
      "I0430 06:03:31.638150  1519 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:03:31.638154  1519 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:03:31.638156  1519 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:03:31.638162  1519 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:03:31.638165  1519 net.cpp:408] conv1 <- data\n",
      "I0430 06:03:31.638170  1519 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:03:31.638231  1519 net.cpp:124] Setting up conv1\n",
      "I0430 06:03:31.638236  1519 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:03:31.638238  1519 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:03:31.638245  1519 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:03:31.638250  1519 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:03:31.638253  1519 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:03:31.638257  1519 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:03:31.638262  1519 net.cpp:124] Setting up relu1\n",
      "I0430 06:03:31.638264  1519 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:03:31.638267  1519 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:03:31.638269  1519 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:03:31.638273  1519 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:03:31.638275  1519 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:03:31.638278  1519 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:03:31.638285  1519 net.cpp:124] Setting up pool1\n",
      "I0430 06:03:31.638288  1519 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:03:31.638290  1519 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:03:31.638293  1519 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:03:31.638298  1519 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:03:31.638300  1519 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:03:31.638303  1519 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:03:31.638309  1519 net.cpp:124] Setting up norm1\n",
      "I0430 06:03:31.638312  1519 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:03:31.638315  1519 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:03:31.638317  1519 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:03:31.638321  1519 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:03:31.638324  1519 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:03:31.638327  1519 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:03:31.638674  1519 net.cpp:124] Setting up conv2\n",
      "I0430 06:03:31.638680  1519 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:03:31.638684  1519 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:03:31.638691  1519 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:03:31.638696  1519 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:03:31.638700  1519 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:03:31.638705  1519 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:03:31.638710  1519 net.cpp:124] Setting up relu2\n",
      "I0430 06:03:31.638715  1519 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:03:31.638717  1519 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:03:31.638720  1519 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:03:31.638725  1519 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:03:31.638728  1519 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:03:31.638733  1519 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:03:31.638739  1519 net.cpp:124] Setting up pool2\n",
      "I0430 06:03:31.638744  1519 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:03:31.638746  1519 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:03:31.638749  1519 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:03:31.638756  1519 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:03:31.638759  1519 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:03:31.638764  1519 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:03:31.638770  1519 net.cpp:124] Setting up norm2\n",
      "I0430 06:03:31.638774  1519 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:03:31.638777  1519 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:03:31.638780  1519 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:03:31.638785  1519 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:03:31.638788  1519 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:03:31.638793  1519 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:03:31.639489  1519 net.cpp:124] Setting up conv3\n",
      "I0430 06:03:31.639504  1519 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:03:31.639508  1519 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:03:31.639518  1519 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:03:31.639524  1519 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:03:31.639528  1519 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:03:31.639533  1519 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:03:31.639539  1519 net.cpp:124] Setting up relu3\n",
      "I0430 06:03:31.639544  1519 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:03:31.639547  1519 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:03:31.639551  1519 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:03:31.639559  1519 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:03:31.639562  1519 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:03:31.639567  1519 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:03:31.640301  1519 net.cpp:124] Setting up conv4\n",
      "I0430 06:03:31.640311  1519 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:03:31.640312  1519 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:03:31.640317  1519 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:03:31.640321  1519 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:03:31.640323  1519 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:03:31.640326  1519 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:03:31.640329  1519 net.cpp:124] Setting up relu4\n",
      "I0430 06:03:31.640332  1519 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:03:31.640334  1519 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:03:31.640336  1519 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:03:31.640341  1519 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:03:31.640344  1519 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:03:31.640349  1519 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:03:31.640842  1519 net.cpp:124] Setting up conv5\n",
      "I0430 06:03:31.640849  1519 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:03:31.640852  1519 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:03:31.640862  1519 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:03:31.640867  1519 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:03:31.640871  1519 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:03:31.640875  1519 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:03:31.640880  1519 net.cpp:124] Setting up relu5\n",
      "I0430 06:03:31.640884  1519 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:03:31.640887  1519 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:03:31.640890  1519 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:03:31.640897  1519 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:03:31.640899  1519 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:03:31.640904  1519 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:03:31.640911  1519 net.cpp:124] Setting up pool5\n",
      "I0430 06:03:31.640916  1519 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:03:31.640918  1519 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:03:31.640923  1519 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:03:31.640930  1519 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:03:31.640933  1519 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:03:31.640939  1519 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:03:31.662585  1519 net.cpp:124] Setting up fc6\n",
      "I0430 06:03:31.662621  1519 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:03:31.662626  1519 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:03:31.662642  1519 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:03:31.662657  1519 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:03:31.662660  1519 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:03:31.662669  1519 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:03:31.662680  1519 net.cpp:124] Setting up relu6\n",
      "I0430 06:03:31.662685  1519 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:03:31.662688  1519 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:03:31.662690  1519 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:03:31.662698  1519 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:03:31.662701  1519 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:03:31.662706  1519 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:03:31.662714  1519 net.cpp:124] Setting up drop6\n",
      "I0430 06:03:31.662734  1519 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:03:31.662736  1519 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:03:31.662740  1519 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:03:31.662750  1519 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:03:31.662752  1519 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:03:31.662757  1519 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:03:31.674700  1519 net.cpp:124] Setting up fc7\n",
      "I0430 06:03:31.674723  1519 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:03:31.674729  1519 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:03:31.674759  1519 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:03:31.674769  1519 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:03:31.674774  1519 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:03:31.674783  1519 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:03:31.674790  1519 net.cpp:124] Setting up relu7\n",
      "I0430 06:03:31.674793  1519 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:03:31.674796  1519 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:03:31.674798  1519 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:03:31.674803  1519 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:03:31.674805  1519 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:03:31.674809  1519 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:03:31.674814  1519 net.cpp:124] Setting up drop7\n",
      "I0430 06:03:31.674818  1519 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:03:31.674819  1519 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:03:31.674823  1519 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:03:31.674826  1519 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:03:31.674829  1519 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:03:31.674831  1519 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:03:31.675822  1519 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:03:31.675856  1519 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:03:31.675860  1519 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:03:31.675873  1519 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:03:31.675878  1519 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:03:31.675881  1519 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:03:31.675884  1519 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:03:31.675889  1519 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:03:31.675892  1519 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:03:31.675896  1519 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:03:31.675900  1519 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:03:31.675904  1519 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:03:31.675909  1519 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:03:31.675912  1519 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:03:31.675916  1519 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:03:31.675920  1519 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:03:31.675925  1519 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:03:31.675930  1519 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:03:31.675933  1519 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:03:31.675938  1519 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:03:31.675943  1519 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:03:31.675948  1519 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:03:31.675952  1519 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:03:31.675957  1519 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:03:31.675962  1519 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:03:31.675966  1519 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:03:31.675971  1519 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:03:31.675989  1519 net.cpp:257] Network initialization done.\n",
      "I0430 06:03:31.927376  1519 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:03:32.025825  1519 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:03:32.026801  1519 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:03:32.026811  1519 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:03:32.026821  1519 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/521879.jpg'}, '/tmp/tmpW9qEgP.mat')\n",
      "Processed 3815 windows in 437.597 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.094 s.\n",
      "prediction    [-2.74519, -2.48766, -2.25573, -2.29134, -2.12...\n",
      "ymin                                                     117.18\n",
      "xmin                                                      213.9\n",
      "ymax                                                     433.45\n",
      "xmax                                                     360.91\n",
      "Name: /home/ambika/INF_project/data/horse/521879.jpg, dtype: object\n",
      "prediction    [-2.2769, -2.59997, -3.01859, -2.47345, -2.392...\n",
      "ymin                                                     117.18\n",
      "xmin                                                          0\n",
      "ymax                                                     282.79\n",
      "xmax                                                     187.93\n",
      "Name: /home/ambika/INF_project/data/horse/521879.jpg, dtype: object\n",
      "person\n",
      "213.9\t117.18\t360.91\t433.45\n",
      "horse\n",
      "0.0\t117.18\t187.93\t282.79\n",
      "521879\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:10:51.707926  2006 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:10:51.707939  2006 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:10:51.707942  2006 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:10:51.709689  2006 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:10:51.710016  2006 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:10:51.710028  2006 net.cpp:86] Creating Layer data\n",
      "I0430 06:10:51.710032  2006 net.cpp:382] data -> data\n",
      "I0430 06:10:51.710048  2006 net.cpp:124] Setting up data\n",
      "I0430 06:10:51.710264  2006 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:10:51.710268  2006 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:10:51.710270  2006 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:10:51.710276  2006 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:10:51.710278  2006 net.cpp:408] conv1 <- data\n",
      "I0430 06:10:51.710283  2006 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:10:51.710346  2006 net.cpp:124] Setting up conv1\n",
      "I0430 06:10:51.710351  2006 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:10:51.710353  2006 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:10:51.710361  2006 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:10:51.710366  2006 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:10:51.710367  2006 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:10:51.710371  2006 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:10:51.710376  2006 net.cpp:124] Setting up relu1\n",
      "I0430 06:10:51.710378  2006 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:10:51.710381  2006 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:10:51.710383  2006 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:10:51.710387  2006 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:10:51.710389  2006 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:10:51.710392  2006 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:10:51.710399  2006 net.cpp:124] Setting up pool1\n",
      "I0430 06:10:51.710402  2006 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:10:51.710404  2006 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:10:51.710407  2006 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:10:51.710412  2006 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:10:51.710413  2006 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:10:51.710417  2006 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:10:51.710422  2006 net.cpp:124] Setting up norm1\n",
      "I0430 06:10:51.710425  2006 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:10:51.710427  2006 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:10:51.710429  2006 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:10:51.710434  2006 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:10:51.710436  2006 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:10:51.710439  2006 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:10:51.710799  2006 net.cpp:124] Setting up conv2\n",
      "I0430 06:10:51.710808  2006 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:10:51.710813  2006 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:10:51.710820  2006 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:10:51.710826  2006 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:10:51.710829  2006 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:10:51.710834  2006 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:10:51.710840  2006 net.cpp:124] Setting up relu2\n",
      "I0430 06:10:51.710845  2006 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:10:51.710850  2006 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:10:51.710852  2006 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:10:51.710860  2006 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:10:51.710865  2006 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:10:51.710870  2006 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:10:51.710877  2006 net.cpp:124] Setting up pool2\n",
      "I0430 06:10:51.710882  2006 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:10:51.710886  2006 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:10:51.710888  2006 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:10:51.710896  2006 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:10:51.710899  2006 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:10:51.710904  2006 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:10:51.710911  2006 net.cpp:124] Setting up norm2\n",
      "I0430 06:10:51.710916  2006 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:10:51.710921  2006 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:10:51.710924  2006 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:10:51.710932  2006 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:10:51.710935  2006 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:10:51.710940  2006 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:10:51.712041  2006 net.cpp:124] Setting up conv3\n",
      "I0430 06:10:51.712066  2006 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:10:51.712071  2006 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:10:51.712087  2006 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:10:51.712100  2006 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:10:51.712105  2006 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:10:51.712110  2006 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:10:51.712119  2006 net.cpp:124] Setting up relu3\n",
      "I0430 06:10:51.712124  2006 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:10:51.712128  2006 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:10:51.712132  2006 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:10:51.712141  2006 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:10:51.712144  2006 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:10:51.712151  2006 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:10:51.713171  2006 net.cpp:124] Setting up conv4\n",
      "I0430 06:10:51.713187  2006 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:10:51.713191  2006 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:10:51.713201  2006 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:10:51.713210  2006 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:10:51.713215  2006 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:10:51.713222  2006 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:10:51.713229  2006 net.cpp:124] Setting up relu4\n",
      "I0430 06:10:51.713234  2006 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:10:51.713238  2006 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:10:51.713243  2006 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:10:51.713249  2006 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:10:51.713255  2006 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:10:51.713261  2006 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:10:51.713924  2006 net.cpp:124] Setting up conv5\n",
      "I0430 06:10:51.713934  2006 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:10:51.713938  2006 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:10:51.713951  2006 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:10:51.713958  2006 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:10:51.713963  2006 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:10:51.713968  2006 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:10:51.713973  2006 net.cpp:124] Setting up relu5\n",
      "I0430 06:10:51.713979  2006 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:10:51.713982  2006 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:10:51.713986  2006 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:10:51.713994  2006 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:10:51.713999  2006 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:10:51.714004  2006 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:10:51.714013  2006 net.cpp:124] Setting up pool5\n",
      "I0430 06:10:51.714018  2006 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:10:51.714022  2006 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:10:51.714026  2006 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:10:51.714035  2006 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:10:51.714040  2006 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:10:51.714045  2006 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:10:51.737543  2006 net.cpp:124] Setting up fc6\n",
      "I0430 06:10:51.737563  2006 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:10:51.737566  2006 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:10:51.737574  2006 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:10:51.737581  2006 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:10:51.737584  2006 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:10:51.737588  2006 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:10:51.737593  2006 net.cpp:124] Setting up relu6\n",
      "I0430 06:10:51.737596  2006 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:10:51.737597  2006 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:10:51.737601  2006 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:10:51.737609  2006 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:10:51.737612  2006 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:10:51.737614  2006 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:10:51.737619  2006 net.cpp:124] Setting up drop6\n",
      "I0430 06:10:51.737622  2006 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:10:51.737623  2006 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:10:51.737627  2006 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:10:51.737633  2006 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:10:51.737637  2006 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:10:51.737640  2006 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:10:51.747512  2006 net.cpp:124] Setting up fc7\n",
      "I0430 06:10:51.747534  2006 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:10:51.747539  2006 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:10:51.747546  2006 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:10:51.747552  2006 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:10:51.747555  2006 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:10:51.747561  2006 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:10:51.747566  2006 net.cpp:124] Setting up relu7\n",
      "I0430 06:10:51.747568  2006 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:10:51.747570  2006 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:10:51.747572  2006 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:10:51.747576  2006 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:10:51.747577  2006 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:10:51.747581  2006 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:10:51.747586  2006 net.cpp:124] Setting up drop7\n",
      "I0430 06:10:51.747599  2006 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:10:51.747602  2006 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:10:51.747604  2006 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:10:51.747608  2006 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:10:51.747611  2006 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:10:51.747614  2006 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:10:51.748558  2006 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:10:51.748574  2006 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:10:51.748577  2006 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:10:51.748584  2006 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:10:51.748586  2006 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:10:51.748589  2006 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:10:51.748589  2006 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:10:51.748591  2006 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:10:51.748594  2006 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:10:51.748595  2006 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:10:51.748598  2006 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:10:51.748600  2006 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:10:51.748602  2006 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:10:51.748605  2006 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:10:51.748607  2006 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:10:51.748610  2006 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:10:51.748613  2006 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:10:51.748616  2006 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:10:51.748620  2006 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:10:51.748621  2006 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:10:51.748625  2006 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:10:51.748627  2006 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:10:51.748631  2006 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:10:51.748632  2006 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:10:51.748634  2006 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:10:51.748637  2006 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:10:51.748639  2006 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:10:51.748649  2006 net.cpp:257] Network initialization done.\n",
      "I0430 06:10:52.006031  2006 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:10:52.104092  2006 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:10:52.105059  2006 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:10:52.105069  2006 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:10:52.105077  2006 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/1700.jpg'}, '/tmp/tmpM4Qtzd.mat')\n",
      "Processed 1320 windows in 159.509 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.69348, -3.42004, -2.03918, -1.71657, -1.99...\n",
      "ymin                                                         36\n",
      "xmin                                                        166\n",
      "ymax                                                        318\n",
      "xmax                                                        313\n",
      "Name: /home/ambika/INF_project/data/person/1700.jpg, dtype: object\n",
      "prediction    [-2.64471, -3.0932, -2.77359, -2.99339, -2.133...\n",
      "ymin                                                        268\n",
      "xmin                                                        151\n",
      "ymax                                                        347\n",
      "xmax                                                        283\n",
      "Name: /home/ambika/INF_project/data/person/1700.jpg, dtype: object\n",
      "person\n",
      "166\t36\t313\t318\n",
      "ski\n",
      "151\t268\t283\t347\n",
      "1700\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:13:33.099967  2148 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:13:33.099995  2148 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:13:33.099999  2148 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:13:33.101675  2148 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:13:33.101861  2148 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:13:33.101876  2148 net.cpp:86] Creating Layer data\n",
      "I0430 06:13:33.101881  2148 net.cpp:382] data -> data\n",
      "I0430 06:13:33.101900  2148 net.cpp:124] Setting up data\n",
      "I0430 06:13:33.101908  2148 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:13:33.101912  2148 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:13:33.101917  2148 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:13:33.101924  2148 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:13:33.101928  2148 net.cpp:408] conv1 <- data\n",
      "I0430 06:13:33.101934  2148 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:13:33.102016  2148 net.cpp:124] Setting up conv1\n",
      "I0430 06:13:33.102025  2148 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:13:33.102028  2148 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:13:33.102038  2148 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:13:33.102046  2148 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:13:33.102051  2148 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:13:33.102057  2148 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:13:33.102066  2148 net.cpp:124] Setting up relu1\n",
      "I0430 06:13:33.102072  2148 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:13:33.102074  2148 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:13:33.102078  2148 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:13:33.102084  2148 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:13:33.102087  2148 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:13:33.102093  2148 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:13:33.102104  2148 net.cpp:124] Setting up pool1\n",
      "I0430 06:13:33.102113  2148 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:13:33.102116  2148 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:13:33.102121  2148 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:13:33.102129  2148 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:13:33.102133  2148 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:13:33.102138  2148 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:13:33.102147  2148 net.cpp:124] Setting up norm1\n",
      "I0430 06:13:33.102152  2148 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:13:33.102156  2148 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:13:33.102160  2148 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:13:33.102167  2148 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:13:33.102171  2148 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:13:33.102177  2148 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:13:33.102640  2148 net.cpp:124] Setting up conv2\n",
      "I0430 06:13:33.102654  2148 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:13:33.102658  2148 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:13:33.102669  2148 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:13:33.102677  2148 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:13:33.102682  2148 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:13:33.102687  2148 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:13:33.102695  2148 net.cpp:124] Setting up relu2\n",
      "I0430 06:13:33.102700  2148 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:13:33.102705  2148 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:13:33.102708  2148 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:13:33.102713  2148 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:13:33.102717  2148 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:13:33.102722  2148 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:13:33.102731  2148 net.cpp:124] Setting up pool2\n",
      "I0430 06:13:33.102736  2148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:13:33.102741  2148 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:13:33.102743  2148 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:13:33.102752  2148 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:13:33.102756  2148 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:13:33.102761  2148 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:13:33.102769  2148 net.cpp:124] Setting up norm2\n",
      "I0430 06:13:33.102774  2148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:13:33.102778  2148 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:13:33.102782  2148 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:13:33.102793  2148 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:13:33.102797  2148 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:13:33.102803  2148 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:13:33.103739  2148 net.cpp:124] Setting up conv3\n",
      "I0430 06:13:33.103763  2148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:13:33.103768  2148 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:13:33.103781  2148 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:13:33.103790  2148 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:13:33.103796  2148 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:13:33.103801  2148 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:13:33.103809  2148 net.cpp:124] Setting up relu3\n",
      "I0430 06:13:33.103828  2148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:13:33.103832  2148 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:13:33.103837  2148 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:13:33.103847  2148 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:13:33.103850  2148 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:13:33.103857  2148 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:13:33.104873  2148 net.cpp:124] Setting up conv4\n",
      "I0430 06:13:33.104894  2148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:13:33.104897  2148 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:13:33.104905  2148 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:13:33.104912  2148 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:13:33.104913  2148 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:13:33.104918  2148 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:13:33.104923  2148 net.cpp:124] Setting up relu4\n",
      "I0430 06:13:33.104926  2148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:13:33.104928  2148 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:13:33.104931  2148 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:13:33.104941  2148 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:13:33.104948  2148 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:13:33.104953  2148 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:13:33.105475  2148 net.cpp:124] Setting up conv5\n",
      "I0430 06:13:33.105487  2148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:13:33.105491  2148 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:13:33.105505  2148 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:13:33.105515  2148 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:13:33.105520  2148 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:13:33.105530  2148 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:13:33.105536  2148 net.cpp:124] Setting up relu5\n",
      "I0430 06:13:33.105540  2148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:13:33.105542  2148 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:13:33.105545  2148 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:13:33.105550  2148 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:13:33.105551  2148 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:13:33.105558  2148 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:13:33.105568  2148 net.cpp:124] Setting up pool5\n",
      "I0430 06:13:33.105572  2148 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:13:33.105574  2148 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:13:33.105577  2148 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:13:33.105589  2148 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:13:33.105592  2148 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:13:33.105597  2148 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:13:33.133487  2148 net.cpp:124] Setting up fc6\n",
      "I0430 06:13:33.133509  2148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:13:33.133513  2148 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:13:33.133522  2148 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:13:33.133530  2148 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:13:33.133533  2148 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:13:33.133536  2148 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:13:33.133543  2148 net.cpp:124] Setting up relu6\n",
      "I0430 06:13:33.133544  2148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:13:33.133546  2148 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:13:33.133548  2148 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:13:33.133551  2148 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:13:33.133553  2148 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:13:33.133555  2148 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:13:33.133560  2148 net.cpp:124] Setting up drop6\n",
      "I0430 06:13:33.133564  2148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:13:33.133571  2148 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:13:33.133574  2148 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:13:33.133580  2148 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:13:33.133584  2148 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:13:33.133586  2148 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:13:33.144583  2148 net.cpp:124] Setting up fc7\n",
      "I0430 06:13:33.144603  2148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:13:33.144605  2148 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:13:33.144613  2148 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:13:33.144621  2148 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:13:33.144624  2148 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:13:33.144629  2148 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:13:33.144634  2148 net.cpp:124] Setting up relu7\n",
      "I0430 06:13:33.144635  2148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:13:33.144637  2148 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:13:33.144639  2148 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:13:33.144644  2148 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:13:33.144646  2148 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:13:33.144649  2148 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:13:33.144652  2148 net.cpp:124] Setting up drop7\n",
      "I0430 06:13:33.144654  2148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:13:33.144656  2148 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:13:33.144659  2148 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:13:33.144661  2148 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:13:33.144675  2148 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:13:33.144680  2148 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:13:33.145568  2148 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:13:33.145577  2148 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:13:33.145581  2148 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:13:33.145589  2148 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:13:33.145601  2148 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:13:33.145606  2148 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:13:33.145609  2148 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:13:33.145613  2148 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:13:33.145617  2148 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:13:33.145619  2148 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:13:33.145623  2148 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:13:33.145627  2148 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:13:33.145630  2148 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:13:33.145634  2148 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:13:33.145637  2148 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:13:33.145640  2148 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:13:33.145644  2148 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:13:33.145648  2148 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:13:33.145651  2148 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:13:33.145654  2148 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:13:33.145658  2148 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:13:33.145661  2148 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:13:33.145664  2148 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:13:33.145668  2148 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:13:33.145670  2148 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:13:33.145674  2148 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:13:33.145678  2148 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:13:33.145689  2148 net.cpp:257] Network initialization done.\n",
      "I0430 06:13:33.236910  2148 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:13:33.339848  2148 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:13:33.340809  2148 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:13:33.340818  2148 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:13:33.340823  2148 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/539143.jpg'}, '/tmp/tmp8HAVKZ.mat')\n",
      "Processed 2302 windows in 268.174 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-3.16262, -2.38841, -2.52064, -2.91132, -2.48...\n",
      "ymin                                                        119\n",
      "xmin                                                        141\n",
      "ymax                                                        259\n",
      "xmax                                                        336\n",
      "Name: /home/ambika/INF_project/data/train/539143.jpg, dtype: object\n",
      "prediction    [-2.12507, -2.51357, -1.98723, -2.38564, -2.24...\n",
      "ymin                                                        123\n",
      "xmin                                                        227\n",
      "ymax                                                        236\n",
      "xmax                                                        466\n",
      "Name: /home/ambika/INF_project/data/train/539143.jpg, dtype: object\n",
      "train\n",
      "141\t119\t336\t259\n",
      "bus\n",
      "227\t123\t466\t236\n",
      "539143\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:18:03.072394  2406 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:18:03.072432  2406 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:18:03.072435  2406 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:18:03.074017  2406 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:18:03.074229  2406 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:18:03.074242  2406 net.cpp:86] Creating Layer data\n",
      "I0430 06:18:03.074247  2406 net.cpp:382] data -> data\n",
      "I0430 06:18:03.074265  2406 net.cpp:124] Setting up data\n",
      "I0430 06:18:03.074271  2406 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:18:03.074275  2406 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:18:03.074280  2406 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:18:03.074287  2406 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:18:03.074291  2406 net.cpp:408] conv1 <- data\n",
      "I0430 06:18:03.074297  2406 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:18:03.074376  2406 net.cpp:124] Setting up conv1\n",
      "I0430 06:18:03.074383  2406 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:18:03.074385  2406 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:18:03.074396  2406 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:18:03.074403  2406 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:18:03.074406  2406 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:18:03.074411  2406 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:18:03.074417  2406 net.cpp:124] Setting up relu1\n",
      "I0430 06:18:03.074422  2406 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:18:03.074425  2406 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:18:03.074429  2406 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:18:03.074434  2406 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:18:03.074439  2406 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:18:03.074443  2406 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:18:03.074452  2406 net.cpp:124] Setting up pool1\n",
      "I0430 06:18:03.074457  2406 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:18:03.074460  2406 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:18:03.074463  2406 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:18:03.074470  2406 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:18:03.074473  2406 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:18:03.074478  2406 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:18:03.074486  2406 net.cpp:124] Setting up norm1\n",
      "I0430 06:18:03.074491  2406 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:18:03.074494  2406 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:18:03.074497  2406 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:18:03.074503  2406 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:18:03.074506  2406 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:18:03.074512  2406 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:18:03.074949  2406 net.cpp:124] Setting up conv2\n",
      "I0430 06:18:03.074956  2406 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:18:03.074960  2406 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:18:03.074967  2406 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:18:03.074973  2406 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:18:03.074977  2406 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:18:03.074982  2406 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:18:03.074987  2406 net.cpp:124] Setting up relu2\n",
      "I0430 06:18:03.074992  2406 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:18:03.074995  2406 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:18:03.075000  2406 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:18:03.075006  2406 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:18:03.075009  2406 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:18:03.075014  2406 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:18:03.075021  2406 net.cpp:124] Setting up pool2\n",
      "I0430 06:18:03.075026  2406 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:18:03.075029  2406 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:18:03.075033  2406 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:18:03.075039  2406 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:18:03.075042  2406 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:18:03.075048  2406 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:18:03.075062  2406 net.cpp:124] Setting up norm2\n",
      "I0430 06:18:03.075067  2406 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:18:03.075070  2406 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:18:03.075073  2406 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:18:03.075081  2406 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:18:03.075085  2406 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:18:03.075090  2406 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:18:03.076337  2406 net.cpp:124] Setting up conv3\n",
      "I0430 06:18:03.076359  2406 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:18:03.076364  2406 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:18:03.076376  2406 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:18:03.076385  2406 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:18:03.076388  2406 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:18:03.076393  2406 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:18:03.076401  2406 net.cpp:124] Setting up relu3\n",
      "I0430 06:18:03.076406  2406 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:18:03.076409  2406 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:18:03.076412  2406 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:18:03.076421  2406 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:18:03.076426  2406 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:18:03.076431  2406 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:18:03.077038  2406 net.cpp:124] Setting up conv4\n",
      "I0430 06:18:03.077052  2406 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:18:03.077055  2406 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:18:03.077064  2406 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:18:03.077072  2406 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:18:03.077077  2406 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:18:03.077083  2406 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:18:03.077090  2406 net.cpp:124] Setting up relu4\n",
      "I0430 06:18:03.077095  2406 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:18:03.077098  2406 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:18:03.077101  2406 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:18:03.077108  2406 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:18:03.077111  2406 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:18:03.077118  2406 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:18:03.077836  2406 net.cpp:124] Setting up conv5\n",
      "I0430 06:18:03.077848  2406 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:18:03.077852  2406 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:18:03.077864  2406 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:18:03.077870  2406 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:18:03.077874  2406 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:18:03.077880  2406 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:18:03.077886  2406 net.cpp:124] Setting up relu5\n",
      "I0430 06:18:03.077891  2406 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:18:03.077894  2406 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:18:03.077898  2406 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:18:03.077905  2406 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:18:03.077908  2406 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:18:03.077914  2406 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:18:03.077924  2406 net.cpp:124] Setting up pool5\n",
      "I0430 06:18:03.077930  2406 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:18:03.077934  2406 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:18:03.077937  2406 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:18:03.077944  2406 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:18:03.077947  2406 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:18:03.077953  2406 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:18:03.106561  2406 net.cpp:124] Setting up fc6\n",
      "I0430 06:18:03.106591  2406 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:18:03.106596  2406 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:18:03.106607  2406 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:18:03.106631  2406 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:18:03.106642  2406 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:18:03.106650  2406 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:18:03.106658  2406 net.cpp:124] Setting up relu6\n",
      "I0430 06:18:03.106662  2406 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:18:03.106664  2406 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:18:03.106667  2406 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:18:03.106673  2406 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:18:03.106681  2406 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:18:03.106686  2406 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:18:03.106693  2406 net.cpp:124] Setting up drop6\n",
      "I0430 06:18:03.106698  2406 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:18:03.106700  2406 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:18:03.106703  2406 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:18:03.106709  2406 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:18:03.106712  2406 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:18:03.106716  2406 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:18:03.120136  2406 net.cpp:124] Setting up fc7\n",
      "I0430 06:18:03.120185  2406 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:18:03.120193  2406 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:18:03.120213  2406 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:18:03.120229  2406 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:18:03.120235  2406 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:18:03.120249  2406 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:18:03.120261  2406 net.cpp:124] Setting up relu7\n",
      "I0430 06:18:03.120267  2406 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:18:03.120270  2406 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:18:03.120275  2406 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:18:03.120282  2406 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:18:03.120286  2406 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:18:03.120293  2406 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:18:03.120301  2406 net.cpp:124] Setting up drop7\n",
      "I0430 06:18:03.120306  2406 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:18:03.120309  2406 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:18:03.120312  2406 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:18:03.120321  2406 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:18:03.120323  2406 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:18:03.120328  2406 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:18:03.121109  2406 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:18:03.121129  2406 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:18:03.121134  2406 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:18:03.121143  2406 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:18:03.121147  2406 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:18:03.121150  2406 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:18:03.121152  2406 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:18:03.121156  2406 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:18:03.121158  2406 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:18:03.121161  2406 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:18:03.121166  2406 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:18:03.121171  2406 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:18:03.121176  2406 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:18:03.121179  2406 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:18:03.121183  2406 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:18:03.121187  2406 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:18:03.121191  2406 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:18:03.121196  2406 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:18:03.121199  2406 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:18:03.121203  2406 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:18:03.121207  2406 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:18:03.121212  2406 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:18:03.121217  2406 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:18:03.121220  2406 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:18:03.121224  2406 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:18:03.121228  2406 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:18:03.121232  2406 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:18:03.121246  2406 net.cpp:257] Network initialization done.\n",
      "I0430 06:18:03.225658  2406 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:18:03.328141  2406 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:18:03.329121  2406 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:18:03.329131  2406 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:18:03.329135  2406 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/100974.jpg'}, '/tmp/tmpdQpeFD.mat')\n",
      "Processed 1372 windows in 159.194 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-2.95878, 2.14376, -2.53015, -2.21836, -2.500...\n",
      "ymin                                                        100\n",
      "xmin                                                          0\n",
      "ymax                                                        249\n",
      "xmax                                                        234\n",
      "Name: /home/ambika/INF_project/data/airplane/100974.jpg, dtype: object\n",
      "prediction    [-2.52387, -2.39475, -2.00913, -2.20538, -2.70...\n",
      "ymin                                                        120\n",
      "xmin                                                        400\n",
      "ymax                                                        153\n",
      "xmax                                                        439\n",
      "Name: /home/ambika/INF_project/data/airplane/100974.jpg, dtype: object\n",
      "airplane\n",
      "0\t100\t234\t249\n",
      "tennis ball\n",
      "400\t120\t439\t153\n",
      "100974\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:20:44.028179  2584 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:20:44.028206  2584 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:20:44.028210  2584 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:20:44.029479  2584 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:20:44.029623  2584 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:20:44.029634  2584 net.cpp:86] Creating Layer data\n",
      "I0430 06:20:44.029639  2584 net.cpp:382] data -> data\n",
      "I0430 06:20:44.029654  2584 net.cpp:124] Setting up data\n",
      "I0430 06:20:44.029659  2584 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:20:44.029662  2584 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:20:44.029666  2584 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:20:44.029673  2584 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:20:44.029677  2584 net.cpp:408] conv1 <- data\n",
      "I0430 06:20:44.029682  2584 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:20:44.029744  2584 net.cpp:124] Setting up conv1\n",
      "I0430 06:20:44.029750  2584 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:20:44.029753  2584 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:20:44.029762  2584 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:20:44.029767  2584 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:20:44.029769  2584 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:20:44.029774  2584 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:20:44.029779  2584 net.cpp:124] Setting up relu1\n",
      "I0430 06:20:44.029783  2584 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:20:44.029786  2584 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:20:44.029789  2584 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:20:44.029794  2584 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:20:44.029798  2584 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:20:44.029801  2584 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:20:44.029809  2584 net.cpp:124] Setting up pool1\n",
      "I0430 06:20:44.029814  2584 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:20:44.029816  2584 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:20:44.029819  2584 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:20:44.029824  2584 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:20:44.029827  2584 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:20:44.029832  2584 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:20:44.029839  2584 net.cpp:124] Setting up norm1\n",
      "I0430 06:20:44.029842  2584 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:20:44.029844  2584 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:20:44.029847  2584 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:20:44.029853  2584 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:20:44.029855  2584 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:20:44.029860  2584 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:20:44.030237  2584 net.cpp:124] Setting up conv2\n",
      "I0430 06:20:44.030246  2584 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:20:44.030248  2584 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:20:44.030256  2584 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:20:44.030261  2584 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:20:44.030263  2584 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:20:44.030268  2584 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:20:44.030273  2584 net.cpp:124] Setting up relu2\n",
      "I0430 06:20:44.030277  2584 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:20:44.030280  2584 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:20:44.030283  2584 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:20:44.030288  2584 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:20:44.030290  2584 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:20:44.030295  2584 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:20:44.030302  2584 net.cpp:124] Setting up pool2\n",
      "I0430 06:20:44.030305  2584 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:20:44.030308  2584 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:20:44.030311  2584 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:20:44.030318  2584 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:20:44.030320  2584 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:20:44.030325  2584 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:20:44.030331  2584 net.cpp:124] Setting up norm2\n",
      "I0430 06:20:44.030335  2584 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:20:44.030338  2584 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:20:44.030341  2584 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:20:44.030346  2584 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:20:44.030349  2584 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:20:44.030354  2584 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:20:44.031047  2584 net.cpp:124] Setting up conv3\n",
      "I0430 06:20:44.031059  2584 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:20:44.031061  2584 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:20:44.031070  2584 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:20:44.031076  2584 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:20:44.031080  2584 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:20:44.031085  2584 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:20:44.031091  2584 net.cpp:124] Setting up relu3\n",
      "I0430 06:20:44.031095  2584 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:20:44.031097  2584 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:20:44.031101  2584 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:20:44.031107  2584 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:20:44.031110  2584 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:20:44.031114  2584 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:20:44.031894  2584 net.cpp:124] Setting up conv4\n",
      "I0430 06:20:44.031908  2584 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:20:44.031911  2584 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:20:44.031919  2584 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:20:44.031925  2584 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:20:44.031929  2584 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:20:44.031934  2584 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:20:44.031939  2584 net.cpp:124] Setting up relu4\n",
      "I0430 06:20:44.031944  2584 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:20:44.031945  2584 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:20:44.031949  2584 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:20:44.031955  2584 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:20:44.031958  2584 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:20:44.031963  2584 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:20:44.032493  2584 net.cpp:124] Setting up conv5\n",
      "I0430 06:20:44.032503  2584 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:20:44.032507  2584 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:20:44.032518  2584 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:20:44.032524  2584 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:20:44.032527  2584 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:20:44.032532  2584 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:20:44.032538  2584 net.cpp:124] Setting up relu5\n",
      "I0430 06:20:44.032542  2584 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:20:44.032546  2584 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:20:44.032548  2584 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:20:44.032554  2584 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:20:44.032557  2584 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:20:44.032562  2584 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:20:44.032570  2584 net.cpp:124] Setting up pool5\n",
      "I0430 06:20:44.032574  2584 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:20:44.032577  2584 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:20:44.032580  2584 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:20:44.032588  2584 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:20:44.032590  2584 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:20:44.032595  2584 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:20:44.057097  2584 net.cpp:124] Setting up fc6\n",
      "I0430 06:20:44.057121  2584 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:20:44.057126  2584 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:20:44.057142  2584 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:20:44.057152  2584 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:20:44.057154  2584 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:20:44.057158  2584 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:20:44.057164  2584 net.cpp:124] Setting up relu6\n",
      "I0430 06:20:44.057168  2584 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:20:44.057168  2584 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:20:44.057171  2584 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:20:44.057174  2584 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:20:44.057176  2584 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:20:44.057178  2584 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:20:44.057183  2584 net.cpp:124] Setting up drop6\n",
      "I0430 06:20:44.057195  2584 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:20:44.057198  2584 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:20:44.057200  2584 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:20:44.057206  2584 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:20:44.057210  2584 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:20:44.057215  2584 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:20:44.067150  2584 net.cpp:124] Setting up fc7\n",
      "I0430 06:20:44.067173  2584 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:20:44.067178  2584 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:20:44.067203  2584 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:20:44.067217  2584 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:20:44.067221  2584 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:20:44.067229  2584 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:20:44.067236  2584 net.cpp:124] Setting up relu7\n",
      "I0430 06:20:44.067240  2584 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:20:44.067243  2584 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:20:44.067246  2584 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:20:44.067251  2584 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:20:44.067255  2584 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:20:44.067260  2584 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:20:44.067265  2584 net.cpp:124] Setting up drop7\n",
      "I0430 06:20:44.067270  2584 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:20:44.067271  2584 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:20:44.067276  2584 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:20:44.067281  2584 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:20:44.067283  2584 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:20:44.067287  2584 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:20:44.067962  2584 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:20:44.067981  2584 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:20:44.067986  2584 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:20:44.067996  2584 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:20:44.067999  2584 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:20:44.068002  2584 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:20:44.068006  2584 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:20:44.068009  2584 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:20:44.068012  2584 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:20:44.068017  2584 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:20:44.068019  2584 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:20:44.068022  2584 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:20:44.068025  2584 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:20:44.068029  2584 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:20:44.068032  2584 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:20:44.068035  2584 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:20:44.068038  2584 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:20:44.068042  2584 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:20:44.068045  2584 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:20:44.068049  2584 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:20:44.068053  2584 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:20:44.068055  2584 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:20:44.068059  2584 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:20:44.068063  2584 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:20:44.068065  2584 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:20:44.068069  2584 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:20:44.068073  2584 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:20:44.068086  2584 net.cpp:257] Network initialization done.\n",
      "I0430 06:20:44.164122  2584 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:20:44.265746  2584 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:20:44.266783  2584 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:20:44.266794  2584 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:20:44.266798  2584 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/245513.jpg'}, '/tmp/tmp9sYGfH.mat')\n",
      "Processed 1976 windows in 230.787 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-2.05864, -2.16562, -2.30548, -2.22604, -1.73...\n",
      "ymin                                                        197\n",
      "xmin                                                        181\n",
      "ymax                                                        275\n",
      "xmax                                                        278\n",
      "Name: /home/ambika/INF_project/data/bird/245513.jpg, dtype: object\n",
      "prediction    [-2.05864, -2.16562, -2.30548, -2.22604, -1.73...\n",
      "ymin                                                        197\n",
      "xmin                                                        181\n",
      "ymax                                                        275\n",
      "xmax                                                        278\n",
      "Name: /home/ambika/INF_project/data/bird/245513.jpg, dtype: object\n",
      "camel\n",
      "181\t197\t278\t275\n",
      "horse\n",
      "181\t197\t278\t275\n",
      "245513\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:24:36.570015  2795 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:24:36.570041  2795 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:24:36.570045  2795 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:24:36.571174  2795 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:24:36.571341  2795 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:24:36.571347  2795 net.cpp:86] Creating Layer data\n",
      "I0430 06:24:36.571352  2795 net.cpp:382] data -> data\n",
      "I0430 06:24:36.571362  2795 net.cpp:124] Setting up data\n",
      "I0430 06:24:36.571365  2795 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:24:36.571368  2795 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:24:36.571372  2795 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:24:36.571379  2795 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:24:36.571383  2795 net.cpp:408] conv1 <- data\n",
      "I0430 06:24:36.571389  2795 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:24:36.571452  2795 net.cpp:124] Setting up conv1\n",
      "I0430 06:24:36.571458  2795 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:24:36.571460  2795 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:24:36.571468  2795 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:24:36.571472  2795 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:24:36.571475  2795 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:24:36.571478  2795 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:24:36.571483  2795 net.cpp:124] Setting up relu1\n",
      "I0430 06:24:36.571486  2795 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:24:36.571488  2795 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:24:36.571491  2795 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:24:36.571496  2795 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:24:36.571498  2795 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:24:36.571501  2795 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:24:36.571507  2795 net.cpp:124] Setting up pool1\n",
      "I0430 06:24:36.571511  2795 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:24:36.571513  2795 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:24:36.571516  2795 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:24:36.571519  2795 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:24:36.571521  2795 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:24:36.571526  2795 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:24:36.571530  2795 net.cpp:124] Setting up norm1\n",
      "I0430 06:24:36.571533  2795 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:24:36.571535  2795 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:24:36.571537  2795 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:24:36.571542  2795 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:24:36.571544  2795 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:24:36.571547  2795 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:24:36.571902  2795 net.cpp:124] Setting up conv2\n",
      "I0430 06:24:36.571909  2795 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:24:36.571912  2795 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:24:36.571918  2795 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:24:36.571925  2795 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:24:36.571930  2795 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:24:36.571936  2795 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:24:36.571943  2795 net.cpp:124] Setting up relu2\n",
      "I0430 06:24:36.571949  2795 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:24:36.571951  2795 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:24:36.571954  2795 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:24:36.571959  2795 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:24:36.571961  2795 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:24:36.571965  2795 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:24:36.571970  2795 net.cpp:124] Setting up pool2\n",
      "I0430 06:24:36.571974  2795 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:24:36.571976  2795 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:24:36.571979  2795 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:24:36.571985  2795 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:24:36.571986  2795 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:24:36.571990  2795 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:24:36.571995  2795 net.cpp:124] Setting up norm2\n",
      "I0430 06:24:36.572000  2795 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:24:36.572001  2795 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:24:36.572003  2795 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:24:36.572010  2795 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:24:36.572013  2795 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:24:36.572016  2795 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:24:36.572705  2795 net.cpp:124] Setting up conv3\n",
      "I0430 06:24:36.572715  2795 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:24:36.572718  2795 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:24:36.572729  2795 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:24:36.572738  2795 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:24:36.572742  2795 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:24:36.572747  2795 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:24:36.572753  2795 net.cpp:124] Setting up relu3\n",
      "I0430 06:24:36.572757  2795 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:24:36.572759  2795 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:24:36.572763  2795 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:24:36.572770  2795 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:24:36.572772  2795 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:24:36.572777  2795 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:24:36.573542  2795 net.cpp:124] Setting up conv4\n",
      "I0430 06:24:36.573554  2795 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:24:36.573557  2795 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:24:36.573565  2795 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:24:36.573570  2795 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:24:36.573575  2795 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:24:36.573581  2795 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:24:36.573586  2795 net.cpp:124] Setting up relu4\n",
      "I0430 06:24:36.573591  2795 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:24:36.573593  2795 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:24:36.573597  2795 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:24:36.573602  2795 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:24:36.573606  2795 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:24:36.573611  2795 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:24:36.574110  2795 net.cpp:124] Setting up conv5\n",
      "I0430 06:24:36.574116  2795 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:24:36.574120  2795 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:24:36.574131  2795 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:24:36.574136  2795 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:24:36.574138  2795 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:24:36.574143  2795 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:24:36.574148  2795 net.cpp:124] Setting up relu5\n",
      "I0430 06:24:36.574152  2795 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:24:36.574154  2795 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:24:36.574157  2795 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:24:36.574163  2795 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:24:36.574167  2795 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:24:36.574170  2795 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:24:36.574178  2795 net.cpp:124] Setting up pool5\n",
      "I0430 06:24:36.574182  2795 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:24:36.574185  2795 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:24:36.574187  2795 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:24:36.574195  2795 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:24:36.574198  2795 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:24:36.574203  2795 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:24:36.596269  2795 net.cpp:124] Setting up fc6\n",
      "I0430 06:24:36.596292  2795 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:24:36.596294  2795 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:24:36.596305  2795 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:24:36.596313  2795 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:24:36.596318  2795 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:24:36.596323  2795 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:24:36.596345  2795 net.cpp:124] Setting up relu6\n",
      "I0430 06:24:36.596349  2795 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:24:36.596352  2795 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:24:36.596355  2795 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:24:36.596360  2795 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:24:36.596364  2795 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:24:36.596367  2795 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:24:36.596372  2795 net.cpp:124] Setting up drop6\n",
      "I0430 06:24:36.596376  2795 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:24:36.596379  2795 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:24:36.596382  2795 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:24:36.596388  2795 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:24:36.596390  2795 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:24:36.596395  2795 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:24:36.605967  2795 net.cpp:124] Setting up fc7\n",
      "I0430 06:24:36.605995  2795 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:24:36.605999  2795 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:24:36.606009  2795 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:24:36.606017  2795 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:24:36.606021  2795 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:24:36.606027  2795 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:24:36.606035  2795 net.cpp:124] Setting up relu7\n",
      "I0430 06:24:36.606040  2795 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:24:36.606041  2795 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:24:36.606045  2795 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:24:36.606050  2795 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:24:36.606052  2795 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:24:36.606056  2795 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:24:36.606063  2795 net.cpp:124] Setting up drop7\n",
      "I0430 06:24:36.606066  2795 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:24:36.606070  2795 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:24:36.606072  2795 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:24:36.606077  2795 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:24:36.606079  2795 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:24:36.606084  2795 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:24:36.606694  2795 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:24:36.606703  2795 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:24:36.606705  2795 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:24:36.606712  2795 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:24:36.606716  2795 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:24:36.606719  2795 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:24:36.606722  2795 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:24:36.606725  2795 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:24:36.606729  2795 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:24:36.606731  2795 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:24:36.606734  2795 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:24:36.606737  2795 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:24:36.606740  2795 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:24:36.606744  2795 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:24:36.606746  2795 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:24:36.606750  2795 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:24:36.606753  2795 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:24:36.606756  2795 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:24:36.606760  2795 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:24:36.606762  2795 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:24:36.606765  2795 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:24:36.606768  2795 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:24:36.606772  2795 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:24:36.606775  2795 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:24:36.606777  2795 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:24:36.606781  2795 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:24:36.606783  2795 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:24:36.606794  2795 net.cpp:257] Network initialization done.\n",
      "I0430 06:24:36.704737  2795 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:24:36.802831  2795 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:24:36.803688  2795 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:24:36.803695  2795 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:24:36.803699  2795 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/78627.jpg'}, '/tmp/tmpmdiHDy.mat')\n",
      "Processed 2486 windows in 286.676 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.036 s.\n",
      "prediction    [-1.47718, -1.67183, -1.99046, -1.95902, -1.60...\n",
      "ymin                                                          0\n",
      "xmin                                                        206\n",
      "ymax                                                        375\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/bus/78627.jpg, dtype: object\n",
      "prediction    [-2.59498, -3.10507, -1.62791, -2.00516, -2.09...\n",
      "ymin                                                        151\n",
      "xmin                                                         76\n",
      "ymax                                                        347\n",
      "xmax                                                        156\n",
      "Name: /home/ambika/INF_project/data/bus/78627.jpg, dtype: object\n",
      "bus\n",
      "206\t0\t500\t375\n",
      "person\n",
      "76\t151\t156\t347\n",
      "78627\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:29:25.051738  2989 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:29:25.051760  2989 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:29:25.051764  2989 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:29:25.052907  2989 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:29:25.053102  2989 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:29:25.053112  2989 net.cpp:86] Creating Layer data\n",
      "I0430 06:29:25.053117  2989 net.cpp:382] data -> data\n",
      "I0430 06:29:25.053133  2989 net.cpp:124] Setting up data\n",
      "I0430 06:29:25.053138  2989 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:29:25.053141  2989 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:29:25.053145  2989 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:29:25.053153  2989 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:29:25.053155  2989 net.cpp:408] conv1 <- data\n",
      "I0430 06:29:25.053161  2989 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:29:25.053220  2989 net.cpp:124] Setting up conv1\n",
      "I0430 06:29:25.053226  2989 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:29:25.053230  2989 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:29:25.053237  2989 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:29:25.053242  2989 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:29:25.053246  2989 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:29:25.053251  2989 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:29:25.053256  2989 net.cpp:124] Setting up relu1\n",
      "I0430 06:29:25.053259  2989 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:29:25.053262  2989 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:29:25.053266  2989 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:29:25.053270  2989 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:29:25.053273  2989 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:29:25.053278  2989 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:29:25.053287  2989 net.cpp:124] Setting up pool1\n",
      "I0430 06:29:25.053292  2989 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:29:25.053294  2989 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:29:25.053297  2989 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:29:25.053303  2989 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:29:25.053306  2989 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:29:25.053313  2989 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:29:25.053318  2989 net.cpp:124] Setting up norm1\n",
      "I0430 06:29:25.053323  2989 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:29:25.053325  2989 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:29:25.053328  2989 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:29:25.053333  2989 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:29:25.053336  2989 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:29:25.053341  2989 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:29:25.053688  2989 net.cpp:124] Setting up conv2\n",
      "I0430 06:29:25.053695  2989 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:29:25.053699  2989 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:29:25.053707  2989 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:29:25.053714  2989 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:29:25.053716  2989 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:29:25.053720  2989 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:29:25.053725  2989 net.cpp:124] Setting up relu2\n",
      "I0430 06:29:25.053730  2989 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:29:25.053732  2989 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:29:25.053735  2989 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:29:25.053740  2989 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:29:25.053742  2989 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:29:25.053747  2989 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:29:25.053753  2989 net.cpp:124] Setting up pool2\n",
      "I0430 06:29:25.053757  2989 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:29:25.053761  2989 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:29:25.053763  2989 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:29:25.053771  2989 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:29:25.053772  2989 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:29:25.053777  2989 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:29:25.053782  2989 net.cpp:124] Setting up norm2\n",
      "I0430 06:29:25.053787  2989 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:29:25.053789  2989 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:29:25.053792  2989 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:29:25.053799  2989 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:29:25.053802  2989 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:29:25.053807  2989 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:29:25.054484  2989 net.cpp:124] Setting up conv3\n",
      "I0430 06:29:25.054496  2989 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:29:25.054499  2989 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:29:25.054509  2989 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:29:25.054517  2989 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:29:25.054519  2989 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:29:25.054524  2989 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:29:25.054530  2989 net.cpp:124] Setting up relu3\n",
      "I0430 06:29:25.054534  2989 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:29:25.054538  2989 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:29:25.054540  2989 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:29:25.054548  2989 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:29:25.054550  2989 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:29:25.054558  2989 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:29:25.055289  2989 net.cpp:124] Setting up conv4\n",
      "I0430 06:29:25.055299  2989 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:29:25.055302  2989 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:29:25.055310  2989 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:29:25.055315  2989 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:29:25.055318  2989 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:29:25.055323  2989 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:29:25.055330  2989 net.cpp:124] Setting up relu4\n",
      "I0430 06:29:25.055333  2989 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:29:25.055335  2989 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:29:25.055339  2989 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:29:25.055346  2989 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:29:25.055348  2989 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:29:25.055353  2989 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:29:25.055862  2989 net.cpp:124] Setting up conv5\n",
      "I0430 06:29:25.055871  2989 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:29:25.055874  2989 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:29:25.055884  2989 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:29:25.055891  2989 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:29:25.055893  2989 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:29:25.055897  2989 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:29:25.055902  2989 net.cpp:124] Setting up relu5\n",
      "I0430 06:29:25.055907  2989 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:29:25.055909  2989 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:29:25.055912  2989 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:29:25.055918  2989 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:29:25.055922  2989 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:29:25.055927  2989 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:29:25.055933  2989 net.cpp:124] Setting up pool5\n",
      "I0430 06:29:25.055938  2989 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:29:25.055940  2989 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:29:25.055943  2989 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:29:25.055951  2989 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:29:25.055954  2989 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:29:25.055960  2989 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:29:25.081295  2989 net.cpp:124] Setting up fc6\n",
      "I0430 06:29:25.081321  2989 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:29:25.081326  2989 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:29:25.081338  2989 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:29:25.081347  2989 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:29:25.081351  2989 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:29:25.081357  2989 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:29:25.081364  2989 net.cpp:124] Setting up relu6\n",
      "I0430 06:29:25.081368  2989 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:29:25.081370  2989 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:29:25.081373  2989 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:29:25.081393  2989 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:29:25.081396  2989 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:29:25.081403  2989 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:29:25.081408  2989 net.cpp:124] Setting up drop6\n",
      "I0430 06:29:25.081413  2989 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:29:25.081415  2989 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:29:25.081418  2989 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:29:25.081424  2989 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:29:25.081426  2989 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:29:25.081431  2989 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:29:25.091351  2989 net.cpp:124] Setting up fc7\n",
      "I0430 06:29:25.091374  2989 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:29:25.091379  2989 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:29:25.091389  2989 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:29:25.091398  2989 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:29:25.091401  2989 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:29:25.091408  2989 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:29:25.091415  2989 net.cpp:124] Setting up relu7\n",
      "I0430 06:29:25.091419  2989 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:29:25.091421  2989 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:29:25.091426  2989 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:29:25.091442  2989 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:29:25.091446  2989 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:29:25.091451  2989 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:29:25.091457  2989 net.cpp:124] Setting up drop7\n",
      "I0430 06:29:25.091461  2989 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:29:25.091464  2989 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:29:25.091467  2989 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:29:25.091473  2989 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:29:25.091475  2989 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:29:25.091480  2989 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:29:25.092386  2989 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:29:25.092399  2989 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:29:25.092403  2989 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:29:25.092425  2989 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:29:25.092432  2989 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:29:25.092434  2989 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:29:25.092437  2989 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:29:25.092442  2989 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:29:25.092445  2989 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:29:25.092448  2989 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:29:25.092453  2989 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:29:25.092455  2989 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:29:25.092459  2989 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:29:25.092463  2989 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:29:25.092465  2989 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:29:25.092469  2989 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:29:25.092473  2989 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:29:25.092476  2989 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:29:25.092479  2989 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:29:25.092483  2989 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:29:25.092485  2989 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:29:25.092489  2989 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:29:25.092492  2989 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:29:25.092495  2989 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:29:25.092499  2989 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:29:25.092502  2989 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:29:25.092505  2989 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:29:25.092516  2989 net.cpp:257] Network initialization done.\n",
      "I0430 06:29:25.188918  2989 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:29:25.297343  2989 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:29:25.298569  2989 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:29:25.298586  2989 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:29:25.298591  2989 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/105923.jpg'}, '/tmp/tmpr54Yqq.mat')\n",
      "Processed 2167 windows in 250.141 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-1.56238, -2.43717, -1.92703, -1.71699, -1.84...\n",
      "ymin                                                        158\n",
      "xmin                                                         27\n",
      "ymax                                                        196\n",
      "xmax                                                         87\n",
      "Name: /home/ambika/INF_project/data/car/105923.jpg, dtype: object\n",
      "prediction    [-2.10204, -2.59958, -2.02647, -2.41447, -2.08...\n",
      "ymin                                                         63\n",
      "xmin                                                        263\n",
      "ymax                                                        225\n",
      "xmax                                                        427\n",
      "Name: /home/ambika/INF_project/data/car/105923.jpg, dtype: object\n",
      "car\n",
      "27\t158\t87\t196\n",
      "elephant\n",
      "263\t63\t427\t225\n",
      "105923\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:33:36.953002  3193 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:33:36.953021  3193 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:33:36.953022  3193 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:33:36.954107  3193 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:33:36.954197  3193 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:33:36.954205  3193 net.cpp:86] Creating Layer data\n",
      "I0430 06:33:36.954208  3193 net.cpp:382] data -> data\n",
      "I0430 06:33:36.954221  3193 net.cpp:124] Setting up data\n",
      "I0430 06:33:36.954226  3193 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:33:36.954227  3193 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:33:36.954231  3193 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:33:36.954236  3193 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:33:36.954239  3193 net.cpp:408] conv1 <- data\n",
      "I0430 06:33:36.954243  3193 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:33:36.954301  3193 net.cpp:124] Setting up conv1\n",
      "I0430 06:33:36.954305  3193 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:33:36.954308  3193 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:33:36.954314  3193 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:33:36.954319  3193 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:33:36.954321  3193 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:33:36.954325  3193 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:33:36.954330  3193 net.cpp:124] Setting up relu1\n",
      "I0430 06:33:36.954334  3193 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:33:36.954334  3193 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:33:36.954336  3193 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:33:36.954339  3193 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:33:36.954341  3193 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:33:36.954344  3193 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:33:36.954349  3193 net.cpp:124] Setting up pool1\n",
      "I0430 06:33:36.954352  3193 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:33:36.954355  3193 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:33:36.954355  3193 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:33:36.954360  3193 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:33:36.954362  3193 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:33:36.954365  3193 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:33:36.954370  3193 net.cpp:124] Setting up norm1\n",
      "I0430 06:33:36.954373  3193 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:33:36.954376  3193 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:33:36.954378  3193 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:33:36.954382  3193 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:33:36.954385  3193 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:33:36.954388  3193 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:33:36.954758  3193 net.cpp:124] Setting up conv2\n",
      "I0430 06:33:36.954768  3193 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:33:36.954771  3193 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:33:36.954777  3193 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:33:36.954780  3193 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:33:36.954782  3193 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:33:36.954787  3193 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:33:36.954790  3193 net.cpp:124] Setting up relu2\n",
      "I0430 06:33:36.954794  3193 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:33:36.954797  3193 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:33:36.954799  3193 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:33:36.954802  3193 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:33:36.954805  3193 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:33:36.954808  3193 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:33:36.954814  3193 net.cpp:124] Setting up pool2\n",
      "I0430 06:33:36.954818  3193 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:33:36.954819  3193 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:33:36.954823  3193 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:33:36.954828  3193 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:33:36.954829  3193 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:33:36.954833  3193 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:33:36.954838  3193 net.cpp:124] Setting up norm2\n",
      "I0430 06:33:36.954841  3193 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:33:36.954843  3193 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:33:36.954845  3193 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:33:36.954850  3193 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:33:36.954854  3193 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:33:36.954856  3193 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:33:36.955847  3193 net.cpp:124] Setting up conv3\n",
      "I0430 06:33:36.955858  3193 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:33:36.955862  3193 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:33:36.955869  3193 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:33:36.955874  3193 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:33:36.955878  3193 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:33:36.955880  3193 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:33:36.955885  3193 net.cpp:124] Setting up relu3\n",
      "I0430 06:33:36.955888  3193 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:33:36.955890  3193 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:33:36.955893  3193 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:33:36.955899  3193 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:33:36.955901  3193 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:33:36.955905  3193 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:33:36.956395  3193 net.cpp:124] Setting up conv4\n",
      "I0430 06:33:36.956401  3193 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:33:36.956404  3193 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:33:36.956408  3193 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:33:36.956413  3193 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:33:36.956414  3193 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:33:36.956418  3193 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:33:36.956423  3193 net.cpp:124] Setting up relu4\n",
      "I0430 06:33:36.956425  3193 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:33:36.956429  3193 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:33:36.956430  3193 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:33:36.956435  3193 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:33:36.956437  3193 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:33:36.956441  3193 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:33:36.956925  3193 net.cpp:124] Setting up conv5\n",
      "I0430 06:33:36.956931  3193 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:33:36.956933  3193 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:33:36.956941  3193 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:33:36.956945  3193 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:33:36.956948  3193 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:33:36.956951  3193 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:33:36.956955  3193 net.cpp:124] Setting up relu5\n",
      "I0430 06:33:36.956959  3193 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:33:36.956960  3193 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:33:36.956964  3193 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:33:36.956969  3193 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:33:36.956970  3193 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:33:36.956974  3193 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:33:36.956980  3193 net.cpp:124] Setting up pool5\n",
      "I0430 06:33:36.956984  3193 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:33:36.956987  3193 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:33:36.956990  3193 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:33:36.956995  3193 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:33:36.956997  3193 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:33:36.957001  3193 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:33:36.979159  3193 net.cpp:124] Setting up fc6\n",
      "I0430 06:33:36.979184  3193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:33:36.979188  3193 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:33:36.979197  3193 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:33:36.979203  3193 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:33:36.979213  3193 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:33:36.979220  3193 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:33:36.979229  3193 net.cpp:124] Setting up relu6\n",
      "I0430 06:33:36.979233  3193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:33:36.979233  3193 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:33:36.979235  3193 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:33:36.979239  3193 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:33:36.979241  3193 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:33:36.979245  3193 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:33:36.979249  3193 net.cpp:124] Setting up drop6\n",
      "I0430 06:33:36.979251  3193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:33:36.979254  3193 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:33:36.979255  3193 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:33:36.979259  3193 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:33:36.979260  3193 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:33:36.979264  3193 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:33:36.988837  3193 net.cpp:124] Setting up fc7\n",
      "I0430 06:33:36.988860  3193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:33:36.988863  3193 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:33:36.988873  3193 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:33:36.988880  3193 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:33:36.988883  3193 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:33:36.988888  3193 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:33:36.988893  3193 net.cpp:124] Setting up relu7\n",
      "I0430 06:33:36.988895  3193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:33:36.988898  3193 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:33:36.988899  3193 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:33:36.988903  3193 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:33:36.988904  3193 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:33:36.988909  3193 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:33:36.988912  3193 net.cpp:124] Setting up drop7\n",
      "I0430 06:33:36.988915  3193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:33:36.988929  3193 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:33:36.988932  3193 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:33:36.988936  3193 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:33:36.988940  3193 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:33:36.988943  3193 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:33:36.989647  3193 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:33:36.989660  3193 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:33:36.989662  3193 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:33:36.989668  3193 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:33:36.989670  3193 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:33:36.989673  3193 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:33:36.989675  3193 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:33:36.989676  3193 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:33:36.989678  3193 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:33:36.989681  3193 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:33:36.989684  3193 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:33:36.989686  3193 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:33:36.989689  3193 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:33:36.989692  3193 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:33:36.989696  3193 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:33:36.989697  3193 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:33:36.989701  3193 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:33:36.989703  3193 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:33:36.989706  3193 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:33:36.989708  3193 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:33:36.989711  3193 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:33:36.989714  3193 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:33:36.989717  3193 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:33:36.989720  3193 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:33:36.989722  3193 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:33:36.989725  3193 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:33:36.989727  3193 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:33:36.989738  3193 net.cpp:257] Network initialization done.\n",
      "I0430 06:33:37.079401  3193 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:33:37.194051  3193 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:33:37.195112  3193 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:33:37.195128  3193 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:33:37.195134  3193 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/353970.jpg'}, '/tmp/tmpY_cU3M.mat')\n",
      "Processed 1699 windows in 200.566 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-1.8828, -2.48306, -2.0018, -1.42958, -2.2915...\n",
      "ymin                                                         93\n",
      "xmin                                                        250\n",
      "ymax                                                        307\n",
      "xmax                                                        380\n",
      "Name: /home/ambika/INF_project/data/cat/353970.jpg, dtype: object\n",
      "prediction    [-1.87069, -2.49536, -2.15073, -1.70709, -2.10...\n",
      "ymin                                                         56\n",
      "xmin                                                        224\n",
      "ymax                                                        307\n",
      "xmax                                                        380\n",
      "Name: /home/ambika/INF_project/data/cat/353970.jpg, dtype: object\n",
      "domestic cat\n",
      "250\t93\t380\t307\n",
      "bathing cap\n",
      "224\t56\t380\t307\n",
      "353970\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:36:59.285893  3387 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:36:59.285914  3387 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:36:59.285917  3387 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:36:59.287055  3387 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:36:59.287163  3387 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:36:59.287173  3387 net.cpp:86] Creating Layer data\n",
      "I0430 06:36:59.287176  3387 net.cpp:382] data -> data\n",
      "I0430 06:36:59.287189  3387 net.cpp:124] Setting up data\n",
      "I0430 06:36:59.287199  3387 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:36:59.287200  3387 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:36:59.287214  3387 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:36:59.287220  3387 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:36:59.287223  3387 net.cpp:408] conv1 <- data\n",
      "I0430 06:36:59.287228  3387 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:36:59.287287  3387 net.cpp:124] Setting up conv1\n",
      "I0430 06:36:59.287293  3387 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:36:59.287297  3387 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:36:59.287308  3387 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:36:59.287314  3387 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:36:59.287317  3387 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:36:59.287322  3387 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:36:59.287328  3387 net.cpp:124] Setting up relu1\n",
      "I0430 06:36:59.287333  3387 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:36:59.287335  3387 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:36:59.287339  3387 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:36:59.287345  3387 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:36:59.287348  3387 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:36:59.287353  3387 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:36:59.287359  3387 net.cpp:124] Setting up pool1\n",
      "I0430 06:36:59.287364  3387 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:36:59.287366  3387 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:36:59.287369  3387 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:36:59.287375  3387 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:36:59.287377  3387 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:36:59.287382  3387 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:36:59.287389  3387 net.cpp:124] Setting up norm1\n",
      "I0430 06:36:59.287392  3387 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:36:59.287395  3387 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:36:59.287397  3387 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:36:59.287402  3387 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:36:59.287405  3387 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:36:59.287410  3387 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:36:59.287760  3387 net.cpp:124] Setting up conv2\n",
      "I0430 06:36:59.287768  3387 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:36:59.287771  3387 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:36:59.287780  3387 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:36:59.287784  3387 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:36:59.287787  3387 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:36:59.287792  3387 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:36:59.287796  3387 net.cpp:124] Setting up relu2\n",
      "I0430 06:36:59.287801  3387 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:36:59.287803  3387 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:36:59.287806  3387 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:36:59.287811  3387 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:36:59.287813  3387 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:36:59.287817  3387 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:36:59.287823  3387 net.cpp:124] Setting up pool2\n",
      "I0430 06:36:59.287827  3387 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:36:59.287830  3387 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:36:59.287833  3387 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:36:59.287839  3387 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:36:59.287842  3387 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:36:59.287847  3387 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:36:59.287853  3387 net.cpp:124] Setting up norm2\n",
      "I0430 06:36:59.287856  3387 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:36:59.287859  3387 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:36:59.287863  3387 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:36:59.287868  3387 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:36:59.287871  3387 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:36:59.287876  3387 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:36:59.288841  3387 net.cpp:124] Setting up conv3\n",
      "I0430 06:36:59.288854  3387 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:36:59.288857  3387 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:36:59.288867  3387 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:36:59.288875  3387 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:36:59.288879  3387 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:36:59.288883  3387 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:36:59.288889  3387 net.cpp:124] Setting up relu3\n",
      "I0430 06:36:59.288893  3387 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:36:59.288895  3387 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:36:59.288899  3387 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:36:59.288905  3387 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:36:59.288908  3387 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:36:59.288913  3387 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:36:59.289427  3387 net.cpp:124] Setting up conv4\n",
      "I0430 06:36:59.289435  3387 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:36:59.289438  3387 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:36:59.289445  3387 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:36:59.289451  3387 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:36:59.289454  3387 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:36:59.289459  3387 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:36:59.289465  3387 net.cpp:124] Setting up relu4\n",
      "I0430 06:36:59.289469  3387 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:36:59.289471  3387 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:36:59.289474  3387 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:36:59.289480  3387 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:36:59.289484  3387 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:36:59.289489  3387 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:36:59.289995  3387 net.cpp:124] Setting up conv5\n",
      "I0430 06:36:59.290004  3387 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:36:59.290007  3387 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:36:59.290017  3387 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:36:59.290024  3387 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:36:59.290026  3387 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:36:59.290030  3387 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:36:59.290035  3387 net.cpp:124] Setting up relu5\n",
      "I0430 06:36:59.290040  3387 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:36:59.290042  3387 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:36:59.290045  3387 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:36:59.290051  3387 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:36:59.290053  3387 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:36:59.290058  3387 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:36:59.290066  3387 net.cpp:124] Setting up pool5\n",
      "I0430 06:36:59.290069  3387 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:36:59.290072  3387 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:36:59.290076  3387 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:36:59.290082  3387 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:36:59.290086  3387 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:36:59.290089  3387 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:36:59.311980  3387 net.cpp:124] Setting up fc6\n",
      "I0430 06:36:59.312006  3387 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:36:59.312011  3387 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:36:59.312021  3387 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:36:59.312029  3387 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:36:59.312033  3387 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:36:59.312039  3387 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:36:59.312057  3387 net.cpp:124] Setting up relu6\n",
      "I0430 06:36:59.312060  3387 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:36:59.312062  3387 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:36:59.312067  3387 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:36:59.312072  3387 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:36:59.312075  3387 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:36:59.312079  3387 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:36:59.312085  3387 net.cpp:124] Setting up drop6\n",
      "I0430 06:36:59.312088  3387 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:36:59.312091  3387 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:36:59.312094  3387 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:36:59.312100  3387 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:36:59.312103  3387 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:36:59.312108  3387 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:36:59.324957  3387 net.cpp:124] Setting up fc7\n",
      "I0430 06:36:59.324985  3387 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:36:59.324991  3387 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:36:59.325002  3387 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:36:59.325028  3387 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:36:59.325032  3387 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:36:59.325039  3387 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:36:59.325048  3387 net.cpp:124] Setting up relu7\n",
      "I0430 06:36:59.325052  3387 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:36:59.325054  3387 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:36:59.325057  3387 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:36:59.325078  3387 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:36:59.325080  3387 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:36:59.325085  3387 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:36:59.325093  3387 net.cpp:124] Setting up drop7\n",
      "I0430 06:36:59.325096  3387 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:36:59.325098  3387 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:36:59.325103  3387 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:36:59.325108  3387 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:36:59.325110  3387 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:36:59.325114  3387 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:36:59.325759  3387 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:36:59.325772  3387 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:36:59.325775  3387 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:36:59.325783  3387 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:36:59.325786  3387 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:36:59.325790  3387 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:36:59.325793  3387 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:36:59.325796  3387 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:36:59.325799  3387 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:36:59.325803  3387 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:36:59.325805  3387 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:36:59.325809  3387 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:36:59.325812  3387 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:36:59.325815  3387 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:36:59.325819  3387 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:36:59.325821  3387 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:36:59.325824  3387 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:36:59.325827  3387 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:36:59.325831  3387 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:36:59.325834  3387 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:36:59.325836  3387 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:36:59.325840  3387 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:36:59.325844  3387 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:36:59.325846  3387 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:36:59.325850  3387 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:36:59.325852  3387 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:36:59.325855  3387 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:36:59.325867  3387 net.cpp:257] Network initialization done.\n",
      "I0430 06:36:59.411191  3387 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:36:59.524755  3387 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:36:59.526137  3387 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:36:59.526187  3387 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:36:59.526196  3387 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/49151.jpg'}, '/tmp/tmpX67xDS.mat')\n",
      "Processed 1918 windows in 221.373 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-2.10344, -1.98642, -1.65309, -1.56559, -1.86...\n",
      "ymin                                                         74\n",
      "xmin                                                        134\n",
      "ymax                                                        176\n",
      "xmax                                                        201\n",
      "Name: /home/ambika/INF_project/data/couch/49151.jpg, dtype: object\n",
      "prediction    [-1.78678, -2.07822, -1.76844, -1.56513, -2.28...\n",
      "ymin                                                        175\n",
      "xmin                                                        263\n",
      "ymax                                                        333\n",
      "xmax                                                        499\n",
      "Name: /home/ambika/INF_project/data/couch/49151.jpg, dtype: object\n",
      "person\n",
      "134\t74\t201\t176\n",
      "sofa\n",
      "263\t175\t499\t333\n",
      "49151\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:40:42.411783  3550 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:40:42.411839  3550 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:40:42.411859  3550 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:40:42.413305  3550 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:40:42.413532  3550 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:40:42.413547  3550 net.cpp:86] Creating Layer data\n",
      "I0430 06:40:42.413552  3550 net.cpp:382] data -> data\n",
      "I0430 06:40:42.413570  3550 net.cpp:124] Setting up data\n",
      "I0430 06:40:42.413578  3550 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:40:42.413583  3550 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:40:42.413586  3550 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:40:42.413607  3550 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:40:42.413611  3550 net.cpp:408] conv1 <- data\n",
      "I0430 06:40:42.413619  3550 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:40:42.413715  3550 net.cpp:124] Setting up conv1\n",
      "I0430 06:40:42.413723  3550 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:40:42.413727  3550 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:40:42.413738  3550 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:40:42.413744  3550 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:40:42.413748  3550 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:40:42.413753  3550 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:40:42.413760  3550 net.cpp:124] Setting up relu1\n",
      "I0430 06:40:42.413765  3550 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:40:42.413769  3550 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:40:42.413772  3550 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:40:42.413779  3550 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:40:42.413781  3550 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:40:42.413786  3550 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:40:42.413797  3550 net.cpp:124] Setting up pool1\n",
      "I0430 06:40:42.413803  3550 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:40:42.413807  3550 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:40:42.413811  3550 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:40:42.413817  3550 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:40:42.413820  3550 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:40:42.413825  3550 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:40:42.413831  3550 net.cpp:124] Setting up norm1\n",
      "I0430 06:40:42.413836  3550 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:40:42.413838  3550 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:40:42.413842  3550 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:40:42.413849  3550 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:40:42.413852  3550 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:40:42.413857  3550 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:40:42.414310  3550 net.cpp:124] Setting up conv2\n",
      "I0430 06:40:42.414320  3550 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:40:42.414324  3550 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:40:42.414333  3550 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:40:42.414340  3550 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:40:42.414343  3550 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:40:42.414348  3550 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:40:42.414355  3550 net.cpp:124] Setting up relu2\n",
      "I0430 06:40:42.414360  3550 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:40:42.414362  3550 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:40:42.414366  3550 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:40:42.414371  3550 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:40:42.414374  3550 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:40:42.414378  3550 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:40:42.414386  3550 net.cpp:124] Setting up pool2\n",
      "I0430 06:40:42.414391  3550 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:40:42.414396  3550 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:40:42.414398  3550 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:40:42.414407  3550 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:40:42.414409  3550 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:40:42.414413  3550 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:40:42.414420  3550 net.cpp:124] Setting up norm2\n",
      "I0430 06:40:42.414424  3550 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:40:42.414427  3550 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:40:42.414430  3550 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:40:42.414440  3550 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:40:42.414444  3550 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:40:42.414449  3550 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:40:42.415153  3550 net.cpp:124] Setting up conv3\n",
      "I0430 06:40:42.415161  3550 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:40:42.415166  3550 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:40:42.415174  3550 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:40:42.415180  3550 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:40:42.415184  3550 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:40:42.415189  3550 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:40:42.415194  3550 net.cpp:124] Setting up relu3\n",
      "I0430 06:40:42.415197  3550 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:40:42.415199  3550 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:40:42.415201  3550 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:40:42.415215  3550 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:40:42.415220  3550 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:40:42.415225  3550 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:40:42.416100  3550 net.cpp:124] Setting up conv4\n",
      "I0430 06:40:42.416141  3550 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:40:42.416152  3550 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:40:42.416169  3550 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:40:42.416189  3550 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:40:42.416196  3550 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:40:42.416209  3550 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:40:42.416221  3550 net.cpp:124] Setting up relu4\n",
      "I0430 06:40:42.416229  3550 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:40:42.416234  3550 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:40:42.416237  3550 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:40:42.416249  3550 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:40:42.416278  3550 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:40:42.416292  3550 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:40:42.416965  3550 net.cpp:124] Setting up conv5\n",
      "I0430 06:40:42.416992  3550 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:40:42.416995  3550 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:40:42.417016  3550 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:40:42.417026  3550 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:40:42.417029  3550 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:40:42.417035  3550 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:40:42.417045  3550 net.cpp:124] Setting up relu5\n",
      "I0430 06:40:42.417048  3550 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:40:42.417050  3550 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:40:42.417052  3550 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:40:42.417057  3550 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:40:42.417059  3550 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:40:42.417062  3550 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:40:42.417073  3550 net.cpp:124] Setting up pool5\n",
      "I0430 06:40:42.417078  3550 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:40:42.417079  3550 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:40:42.417083  3550 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:40:42.417089  3550 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:40:42.417093  3550 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:40:42.417096  3550 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:40:42.439299  3550 net.cpp:124] Setting up fc6\n",
      "I0430 06:40:42.439322  3550 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:40:42.439327  3550 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:40:42.439334  3550 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:40:42.439342  3550 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:40:42.439344  3550 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:40:42.439349  3550 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:40:42.439357  3550 net.cpp:124] Setting up relu6\n",
      "I0430 06:40:42.439358  3550 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:40:42.439360  3550 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:40:42.439363  3550 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:40:42.439368  3550 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:40:42.439368  3550 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:40:42.439371  3550 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:40:42.439381  3550 net.cpp:124] Setting up drop6\n",
      "I0430 06:40:42.439384  3550 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:40:42.439386  3550 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:40:42.439388  3550 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:40:42.439393  3550 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:40:42.439395  3550 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:40:42.439399  3550 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:40:42.449039  3550 net.cpp:124] Setting up fc7\n",
      "I0430 06:40:42.449062  3550 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:40:42.449066  3550 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:40:42.449077  3550 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:40:42.449084  3550 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:40:42.449086  3550 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:40:42.449091  3550 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:40:42.449098  3550 net.cpp:124] Setting up relu7\n",
      "I0430 06:40:42.449100  3550 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:40:42.449102  3550 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:40:42.449103  3550 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:40:42.449107  3550 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:40:42.449108  3550 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:40:42.449111  3550 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:40:42.449115  3550 net.cpp:124] Setting up drop7\n",
      "I0430 06:40:42.449117  3550 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:40:42.449118  3550 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:40:42.449120  3550 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:40:42.449137  3550 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:40:42.449141  3550 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:40:42.449143  3550 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:40:42.450036  3550 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:40:42.450044  3550 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:40:42.450047  3550 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:40:42.450054  3550 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:40:42.450057  3550 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:40:42.450058  3550 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:40:42.450060  3550 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:40:42.450062  3550 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:40:42.450064  3550 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:40:42.450067  3550 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:40:42.450069  3550 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:40:42.450072  3550 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:40:42.450074  3550 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:40:42.450076  3550 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:40:42.450079  3550 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:40:42.450083  3550 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:40:42.450084  3550 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:40:42.450088  3550 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:40:42.450090  3550 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:40:42.450093  3550 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:40:42.450095  3550 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:40:42.450098  3550 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:40:42.450100  3550 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:40:42.450103  3550 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:40:42.450105  3550 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:40:42.450109  3550 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:40:42.450110  3550 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:40:42.450121  3550 net.cpp:257] Network initialization done.\n",
      "I0430 06:40:42.536900  3550 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:40:42.646533  3550 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:40:42.647511  3550 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:40:42.647519  3550 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:40:42.647523  3550 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/228764.jpg'}, '/tmp/tmpkdZi8W.mat')\n",
      "Processed 2735 windows in 315.269 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-1.95306, -1.93256, -1.73809, -1.80992, -1.96...\n",
      "ymin                                                     219.75\n",
      "xmin                                                     132.75\n",
      "ymax                                                      500.5\n",
      "xmax                                                     339.25\n",
      "Name: /home/ambika/INF_project/data/dog/228764.jpg, dtype: object\n",
      "prediction    [-1.95306, -1.93256, -1.73809, -1.80992, -1.96...\n",
      "ymin                                                     219.75\n",
      "xmin                                                     132.75\n",
      "ymax                                                      500.5\n",
      "xmax                                                     339.25\n",
      "Name: /home/ambika/INF_project/data/dog/228764.jpg, dtype: object\n",
      "dog\n",
      "132.75\t219.75\t339.25\t500.5\n",
      "domestic cat\n",
      "132.75\t219.75\t339.25\t500.5\n",
      "228764\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:45:59.501245  3770 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:45:59.501276  3770 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:45:59.501282  3770 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:45:59.502370  3770 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:45:59.502542  3770 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:45:59.502552  3770 net.cpp:86] Creating Layer data\n",
      "I0430 06:45:59.502555  3770 net.cpp:382] data -> data\n",
      "I0430 06:45:59.502566  3770 net.cpp:124] Setting up data\n",
      "I0430 06:45:59.502573  3770 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:45:59.502575  3770 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:45:59.502579  3770 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:45:59.502586  3770 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:45:59.502589  3770 net.cpp:408] conv1 <- data\n",
      "I0430 06:45:59.502595  3770 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:45:59.502670  3770 net.cpp:124] Setting up conv1\n",
      "I0430 06:45:59.502676  3770 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:45:59.502678  3770 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:45:59.502686  3770 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:45:59.502692  3770 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:45:59.502694  3770 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:45:59.502698  3770 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:45:59.502703  3770 net.cpp:124] Setting up relu1\n",
      "I0430 06:45:59.502707  3770 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:45:59.502709  3770 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:45:59.502712  3770 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:45:59.502717  3770 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:45:59.502719  3770 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:45:59.502723  3770 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:45:59.502733  3770 net.cpp:124] Setting up pool1\n",
      "I0430 06:45:59.502739  3770 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:45:59.502741  3770 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:45:59.502744  3770 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:45:59.502750  3770 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:45:59.502753  3770 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:45:59.502758  3770 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:45:59.502765  3770 net.cpp:124] Setting up norm1\n",
      "I0430 06:45:59.502770  3770 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:45:59.502774  3770 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:45:59.502776  3770 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:45:59.502782  3770 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:45:59.502785  3770 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:45:59.502790  3770 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:45:59.503149  3770 net.cpp:124] Setting up conv2\n",
      "I0430 06:45:59.503155  3770 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:45:59.503159  3770 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:45:59.503167  3770 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:45:59.503172  3770 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:45:59.503175  3770 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:45:59.503180  3770 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:45:59.503185  3770 net.cpp:124] Setting up relu2\n",
      "I0430 06:45:59.503188  3770 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:45:59.503191  3770 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:45:59.503195  3770 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:45:59.503199  3770 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:45:59.503202  3770 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:45:59.503247  3770 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:45:59.503253  3770 net.cpp:124] Setting up pool2\n",
      "I0430 06:45:59.503258  3770 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:45:59.503260  3770 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:45:59.503264  3770 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:45:59.503269  3770 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:45:59.503273  3770 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:45:59.503278  3770 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:45:59.503283  3770 net.cpp:124] Setting up norm2\n",
      "I0430 06:45:59.503288  3770 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:45:59.503290  3770 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:45:59.503293  3770 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:45:59.503300  3770 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:45:59.503304  3770 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:45:59.503309  3770 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:45:59.504017  3770 net.cpp:124] Setting up conv3\n",
      "I0430 06:45:59.504026  3770 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:45:59.504030  3770 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:45:59.504040  3770 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:45:59.504046  3770 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:45:59.504050  3770 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:45:59.504055  3770 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:45:59.504060  3770 net.cpp:124] Setting up relu3\n",
      "I0430 06:45:59.504063  3770 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:45:59.504066  3770 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:45:59.504070  3770 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:45:59.504076  3770 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:45:59.504078  3770 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:45:59.504082  3770 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:45:59.504812  3770 net.cpp:124] Setting up conv4\n",
      "I0430 06:45:59.504822  3770 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:45:59.504827  3770 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:45:59.504833  3770 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:45:59.504839  3770 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:45:59.504842  3770 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:45:59.504848  3770 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:45:59.504853  3770 net.cpp:124] Setting up relu4\n",
      "I0430 06:45:59.504858  3770 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:45:59.504860  3770 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:45:59.504863  3770 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:45:59.504869  3770 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:45:59.504871  3770 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:45:59.504876  3770 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:45:59.505385  3770 net.cpp:124] Setting up conv5\n",
      "I0430 06:45:59.505393  3770 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:45:59.505398  3770 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:45:59.505405  3770 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:45:59.505411  3770 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:45:59.505414  3770 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:45:59.505419  3770 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:45:59.505424  3770 net.cpp:124] Setting up relu5\n",
      "I0430 06:45:59.505429  3770 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:45:59.505430  3770 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:45:59.505434  3770 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:45:59.505439  3770 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:45:59.505442  3770 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:45:59.505447  3770 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:45:59.505455  3770 net.cpp:124] Setting up pool5\n",
      "I0430 06:45:59.505460  3770 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:45:59.505462  3770 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:45:59.505465  3770 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:45:59.505473  3770 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:45:59.505476  3770 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:45:59.505481  3770 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:45:59.529284  3770 net.cpp:124] Setting up fc6\n",
      "I0430 06:45:59.529310  3770 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:45:59.529316  3770 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:45:59.529326  3770 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:45:59.529336  3770 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:45:59.529341  3770 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:45:59.529347  3770 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:45:59.529356  3770 net.cpp:124] Setting up relu6\n",
      "I0430 06:45:59.529361  3770 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:45:59.529363  3770 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:45:59.529367  3770 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:45:59.529373  3770 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:45:59.529386  3770 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:45:59.529391  3770 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:45:59.529397  3770 net.cpp:124] Setting up drop6\n",
      "I0430 06:45:59.529400  3770 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:45:59.529403  3770 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:45:59.529407  3770 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:45:59.529412  3770 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:45:59.529414  3770 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:45:59.529420  3770 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:45:59.539417  3770 net.cpp:124] Setting up fc7\n",
      "I0430 06:45:59.539441  3770 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:45:59.539446  3770 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:45:59.539456  3770 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:45:59.539466  3770 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:45:59.539470  3770 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:45:59.539476  3770 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:45:59.539484  3770 net.cpp:124] Setting up relu7\n",
      "I0430 06:45:59.539489  3770 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:45:59.539491  3770 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:45:59.539494  3770 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:45:59.539507  3770 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:45:59.539510  3770 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:45:59.539516  3770 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:45:59.539522  3770 net.cpp:124] Setting up drop7\n",
      "I0430 06:45:59.539525  3770 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:45:59.539528  3770 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:45:59.539531  3770 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:45:59.539537  3770 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:45:59.539539  3770 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:45:59.539544  3770 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:45:59.540184  3770 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:45:59.540195  3770 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:45:59.540199  3770 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:45:59.540207  3770 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:45:59.540212  3770 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:45:59.540216  3770 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:45:59.540220  3770 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:45:59.540222  3770 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:45:59.540225  3770 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:45:59.540230  3770 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:45:59.540232  3770 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:45:59.540235  3770 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:45:59.540238  3770 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:45:59.540242  3770 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:45:59.540246  3770 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:45:59.540248  3770 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:45:59.540251  3770 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:45:59.540256  3770 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:45:59.540258  3770 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:45:59.540261  3770 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:45:59.540264  3770 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:45:59.540267  3770 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:45:59.540271  3770 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:45:59.540274  3770 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:45:59.540277  3770 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:45:59.540280  3770 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:45:59.540282  3770 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:45:59.540294  3770 net.cpp:257] Network initialization done.\n",
      "I0430 06:45:59.628792  3770 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:45:59.734211  3770 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:45:59.735492  3770 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:45:59.735512  3770 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:45:59.735517  3770 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/415856.jpg'}, '/tmp/tmpYBjmUZ.mat')\n",
      "Processed 2899 windows in 337.685 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.036 s.\n",
      "prediction    [-2.22228, -2.84005, -2.2148, -2.00705, -1.807...\n",
      "ymin                                                        161\n",
      "xmin                                                        297\n",
      "ymax                                                        322\n",
      "xmax                                                        373\n",
      "Name: /home/ambika/INF_project/data/horse/415856.jpg, dtype: object\n",
      "prediction    [-1.89181, -2.38716, -3.11559, -0.470002, -2.2...\n",
      "ymin                                                        184\n",
      "xmin                                                         34\n",
      "ymax                                                        329\n",
      "xmax                                                        217\n",
      "Name: /home/ambika/INF_project/data/horse/415856.jpg, dtype: object\n",
      "person\n",
      "297\t161\t373\t322\n",
      "horse\n",
      "34\t184\t217\t329\n",
      "415856\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:51:39.076706  4002 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:51:39.076730  4002 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:51:39.076732  4002 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:51:39.077880  4002 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:51:39.078027  4002 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:51:39.078034  4002 net.cpp:86] Creating Layer data\n",
      "I0430 06:51:39.078038  4002 net.cpp:382] data -> data\n",
      "I0430 06:51:39.078053  4002 net.cpp:124] Setting up data\n",
      "I0430 06:51:39.078063  4002 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:51:39.078068  4002 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:51:39.078073  4002 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:51:39.078081  4002 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:51:39.078085  4002 net.cpp:408] conv1 <- data\n",
      "I0430 06:51:39.078091  4002 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:51:39.078161  4002 net.cpp:124] Setting up conv1\n",
      "I0430 06:51:39.078167  4002 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:51:39.078171  4002 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:51:39.078177  4002 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:51:39.078183  4002 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:51:39.078186  4002 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:51:39.078189  4002 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:51:39.078194  4002 net.cpp:124] Setting up relu1\n",
      "I0430 06:51:39.078197  4002 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:51:39.078200  4002 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:51:39.078202  4002 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:51:39.078207  4002 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:51:39.078209  4002 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:51:39.078212  4002 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:51:39.078219  4002 net.cpp:124] Setting up pool1\n",
      "I0430 06:51:39.078223  4002 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:51:39.078225  4002 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:51:39.078227  4002 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:51:39.078233  4002 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:51:39.078234  4002 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:51:39.078238  4002 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:51:39.078243  4002 net.cpp:124] Setting up norm1\n",
      "I0430 06:51:39.078245  4002 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:51:39.078248  4002 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:51:39.078253  4002 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:51:39.078258  4002 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:51:39.078263  4002 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:51:39.078269  4002 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:51:39.078673  4002 net.cpp:124] Setting up conv2\n",
      "I0430 06:51:39.078686  4002 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:51:39.078691  4002 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:51:39.078701  4002 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:51:39.078707  4002 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:51:39.078711  4002 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:51:39.078714  4002 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:51:39.078719  4002 net.cpp:124] Setting up relu2\n",
      "I0430 06:51:39.078723  4002 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:51:39.078725  4002 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:51:39.078728  4002 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:51:39.078733  4002 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:51:39.078737  4002 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:51:39.078739  4002 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:51:39.078745  4002 net.cpp:124] Setting up pool2\n",
      "I0430 06:51:39.078749  4002 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:51:39.078752  4002 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:51:39.078754  4002 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:51:39.078766  4002 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:51:39.078768  4002 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:51:39.078773  4002 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:51:39.078778  4002 net.cpp:124] Setting up norm2\n",
      "I0430 06:51:39.078780  4002 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:51:39.078783  4002 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:51:39.078785  4002 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:51:39.078791  4002 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:51:39.078794  4002 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:51:39.078797  4002 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:51:39.080019  4002 net.cpp:124] Setting up conv3\n",
      "I0430 06:51:39.080044  4002 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:51:39.080045  4002 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:51:39.080059  4002 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:51:39.080068  4002 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:51:39.080070  4002 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:51:39.080076  4002 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:51:39.080083  4002 net.cpp:124] Setting up relu3\n",
      "I0430 06:51:39.080086  4002 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:51:39.080088  4002 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:51:39.080090  4002 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:51:39.080097  4002 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:51:39.080099  4002 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:51:39.080102  4002 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:51:39.080763  4002 net.cpp:124] Setting up conv4\n",
      "I0430 06:51:39.080780  4002 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:51:39.080783  4002 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:51:39.080790  4002 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:51:39.080796  4002 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:51:39.080798  4002 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:51:39.080801  4002 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:51:39.080806  4002 net.cpp:124] Setting up relu4\n",
      "I0430 06:51:39.080811  4002 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:51:39.080812  4002 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:51:39.080813  4002 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:51:39.080818  4002 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:51:39.080821  4002 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:51:39.080826  4002 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:51:39.081328  4002 net.cpp:124] Setting up conv5\n",
      "I0430 06:51:39.081336  4002 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:51:39.081338  4002 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:51:39.081346  4002 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:51:39.081349  4002 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:51:39.081351  4002 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:51:39.081356  4002 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:51:39.081359  4002 net.cpp:124] Setting up relu5\n",
      "I0430 06:51:39.081362  4002 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:51:39.081364  4002 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:51:39.081367  4002 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:51:39.081372  4002 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:51:39.081373  4002 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:51:39.081377  4002 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:51:39.081384  4002 net.cpp:124] Setting up pool5\n",
      "I0430 06:51:39.081388  4002 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:51:39.081390  4002 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:51:39.081393  4002 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:51:39.081399  4002 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:51:39.081403  4002 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:51:39.081405  4002 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:51:39.105209  4002 net.cpp:124] Setting up fc6\n",
      "I0430 06:51:39.105237  4002 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:51:39.105240  4002 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:51:39.105249  4002 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:51:39.105257  4002 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:51:39.105259  4002 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:51:39.105264  4002 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:51:39.105270  4002 net.cpp:124] Setting up relu6\n",
      "I0430 06:51:39.105273  4002 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:51:39.105274  4002 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:51:39.105275  4002 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:51:39.105279  4002 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:51:39.105281  4002 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:51:39.105285  4002 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:51:39.105289  4002 net.cpp:124] Setting up drop6\n",
      "I0430 06:51:39.105293  4002 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:51:39.105304  4002 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:51:39.105307  4002 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:51:39.105310  4002 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:51:39.105312  4002 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:51:39.105316  4002 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:51:39.116298  4002 net.cpp:124] Setting up fc7\n",
      "I0430 06:51:39.116338  4002 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:51:39.116346  4002 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:51:39.116358  4002 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:51:39.116370  4002 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:51:39.116374  4002 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:51:39.116380  4002 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:51:39.116389  4002 net.cpp:124] Setting up relu7\n",
      "I0430 06:51:39.116392  4002 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:51:39.116394  4002 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:51:39.116399  4002 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:51:39.116405  4002 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:51:39.116407  4002 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:51:39.116413  4002 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:51:39.116421  4002 net.cpp:124] Setting up drop7\n",
      "I0430 06:51:39.116425  4002 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:51:39.116428  4002 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:51:39.116432  4002 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:51:39.116438  4002 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:51:39.116441  4002 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:51:39.116448  4002 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:51:39.117489  4002 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:51:39.117511  4002 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:51:39.117514  4002 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:51:39.117525  4002 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:51:39.117529  4002 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:51:39.117533  4002 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:51:39.117537  4002 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:51:39.117539  4002 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:51:39.117543  4002 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:51:39.117547  4002 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:51:39.117552  4002 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:51:39.117557  4002 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:51:39.117560  4002 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:51:39.117564  4002 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:51:39.117569  4002 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:51:39.117573  4002 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:51:39.117578  4002 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:51:39.117583  4002 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:51:39.117588  4002 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:51:39.117591  4002 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:51:39.117595  4002 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:51:39.117600  4002 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:51:39.117604  4002 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:51:39.117609  4002 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:51:39.117614  4002 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:51:39.117617  4002 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:51:39.117621  4002 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:51:39.117637  4002 net.cpp:257] Network initialization done.\n",
      "I0430 06:51:39.204170  4002 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:51:39.319528  4002 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:51:39.320528  4002 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:51:39.320538  4002 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:51:39.320538  4002 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/562345.jpg'}, '/tmp/tmpJdAko7.mat')\n",
      "Processed 2312 windows in 270.236 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.87809, -3.17938, -1.81997, -1.82228, -1.87...\n",
      "ymin                                                          0\n",
      "xmin                                                    172.494\n",
      "ymax                                                    473.194\n",
      "xmax                                                    333.334\n",
      "Name: /home/ambika/INF_project/data/person/562345.jpg, dtype: object\n",
      "prediction    [-1.27821, -1.43218, -2.03323, -1.99145, -1.80...\n",
      "ymin                                                    145.188\n",
      "xmin                                                    215.784\n",
      "ymax                                                    178.156\n",
      "xmax                                                     244.09\n",
      "Name: /home/ambika/INF_project/data/person/562345.jpg, dtype: object\n",
      "person\n",
      "172.494\t0.0\t333.334\t473.194\n",
      "basketball\n",
      "215.784\t145.188\t244.09\t178.156\n",
      "562345\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 06:56:11.161243  4217 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 06:56:11.161259  4217 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 06:56:11.161262  4217 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 06:56:11.162387  4217 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 06:56:11.162526  4217 layer_factory.hpp:77] Creating layer data\n",
      "I0430 06:56:11.162533  4217 net.cpp:86] Creating Layer data\n",
      "I0430 06:56:11.162536  4217 net.cpp:382] data -> data\n",
      "I0430 06:56:11.162549  4217 net.cpp:124] Setting up data\n",
      "I0430 06:56:11.162554  4217 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 06:56:11.162557  4217 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 06:56:11.162559  4217 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 06:56:11.162565  4217 net.cpp:86] Creating Layer conv1\n",
      "I0430 06:56:11.162569  4217 net.cpp:408] conv1 <- data\n",
      "I0430 06:56:11.162573  4217 net.cpp:382] conv1 -> conv1\n",
      "I0430 06:56:11.162650  4217 net.cpp:124] Setting up conv1\n",
      "I0430 06:56:11.162657  4217 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:56:11.162659  4217 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 06:56:11.162667  4217 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 06:56:11.162672  4217 net.cpp:86] Creating Layer relu1\n",
      "I0430 06:56:11.162674  4217 net.cpp:408] relu1 <- conv1\n",
      "I0430 06:56:11.162678  4217 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 06:56:11.162683  4217 net.cpp:124] Setting up relu1\n",
      "I0430 06:56:11.162685  4217 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 06:56:11.162688  4217 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 06:56:11.162690  4217 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 06:56:11.162693  4217 net.cpp:86] Creating Layer pool1\n",
      "I0430 06:56:11.162696  4217 net.cpp:408] pool1 <- conv1\n",
      "I0430 06:56:11.162699  4217 net.cpp:382] pool1 -> pool1\n",
      "I0430 06:56:11.162705  4217 net.cpp:124] Setting up pool1\n",
      "I0430 06:56:11.162708  4217 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:56:11.162711  4217 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 06:56:11.162714  4217 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 06:56:11.162719  4217 net.cpp:86] Creating Layer norm1\n",
      "I0430 06:56:11.162720  4217 net.cpp:408] norm1 <- pool1\n",
      "I0430 06:56:11.162724  4217 net.cpp:382] norm1 -> norm1\n",
      "I0430 06:56:11.162729  4217 net.cpp:124] Setting up norm1\n",
      "I0430 06:56:11.162732  4217 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 06:56:11.162734  4217 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 06:56:11.162736  4217 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 06:56:11.162740  4217 net.cpp:86] Creating Layer conv2\n",
      "I0430 06:56:11.162744  4217 net.cpp:408] conv2 <- norm1\n",
      "I0430 06:56:11.162747  4217 net.cpp:382] conv2 -> conv2\n",
      "I0430 06:56:11.163100  4217 net.cpp:124] Setting up conv2\n",
      "I0430 06:56:11.163106  4217 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:56:11.163108  4217 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 06:56:11.163115  4217 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 06:56:11.163118  4217 net.cpp:86] Creating Layer relu2\n",
      "I0430 06:56:11.163121  4217 net.cpp:408] relu2 <- conv2\n",
      "I0430 06:56:11.163126  4217 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 06:56:11.163132  4217 net.cpp:124] Setting up relu2\n",
      "I0430 06:56:11.163138  4217 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 06:56:11.163141  4217 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 06:56:11.163146  4217 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 06:56:11.163151  4217 net.cpp:86] Creating Layer pool2\n",
      "I0430 06:56:11.163153  4217 net.cpp:408] pool2 <- conv2\n",
      "I0430 06:56:11.163157  4217 net.cpp:382] pool2 -> pool2\n",
      "I0430 06:56:11.163162  4217 net.cpp:124] Setting up pool2\n",
      "I0430 06:56:11.163166  4217 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:56:11.163168  4217 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 06:56:11.163170  4217 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 06:56:11.163177  4217 net.cpp:86] Creating Layer norm2\n",
      "I0430 06:56:11.163178  4217 net.cpp:408] norm2 <- pool2\n",
      "I0430 06:56:11.163182  4217 net.cpp:382] norm2 -> norm2\n",
      "I0430 06:56:11.163187  4217 net.cpp:124] Setting up norm2\n",
      "I0430 06:56:11.163189  4217 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:56:11.163192  4217 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 06:56:11.163194  4217 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 06:56:11.163199  4217 net.cpp:86] Creating Layer conv3\n",
      "I0430 06:56:11.163202  4217 net.cpp:408] conv3 <- norm2\n",
      "I0430 06:56:11.163211  4217 net.cpp:382] conv3 -> conv3\n",
      "I0430 06:56:11.163913  4217 net.cpp:124] Setting up conv3\n",
      "I0430 06:56:11.163923  4217 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:56:11.163928  4217 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 06:56:11.163938  4217 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 06:56:11.163945  4217 net.cpp:86] Creating Layer relu3\n",
      "I0430 06:56:11.163949  4217 net.cpp:408] relu3 <- conv3\n",
      "I0430 06:56:11.163954  4217 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 06:56:11.163959  4217 net.cpp:124] Setting up relu3\n",
      "I0430 06:56:11.163962  4217 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:56:11.163964  4217 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 06:56:11.163967  4217 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 06:56:11.163974  4217 net.cpp:86] Creating Layer conv4\n",
      "I0430 06:56:11.163976  4217 net.cpp:408] conv4 <- conv3\n",
      "I0430 06:56:11.163980  4217 net.cpp:382] conv4 -> conv4\n",
      "I0430 06:56:11.164721  4217 net.cpp:124] Setting up conv4\n",
      "I0430 06:56:11.164729  4217 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:56:11.164732  4217 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 06:56:11.164739  4217 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 06:56:11.164746  4217 net.cpp:86] Creating Layer relu4\n",
      "I0430 06:56:11.164750  4217 net.cpp:408] relu4 <- conv4\n",
      "I0430 06:56:11.164755  4217 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 06:56:11.164760  4217 net.cpp:124] Setting up relu4\n",
      "I0430 06:56:11.164763  4217 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 06:56:11.164765  4217 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 06:56:11.164768  4217 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 06:56:11.164772  4217 net.cpp:86] Creating Layer conv5\n",
      "I0430 06:56:11.164775  4217 net.cpp:408] conv5 <- conv4\n",
      "I0430 06:56:11.164779  4217 net.cpp:382] conv5 -> conv5\n",
      "I0430 06:56:11.165290  4217 net.cpp:124] Setting up conv5\n",
      "I0430 06:56:11.165297  4217 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:56:11.165300  4217 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 06:56:11.165313  4217 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 06:56:11.165318  4217 net.cpp:86] Creating Layer relu5\n",
      "I0430 06:56:11.165320  4217 net.cpp:408] relu5 <- conv5\n",
      "I0430 06:56:11.165323  4217 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 06:56:11.165328  4217 net.cpp:124] Setting up relu5\n",
      "I0430 06:56:11.165331  4217 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 06:56:11.165333  4217 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 06:56:11.165335  4217 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 06:56:11.165340  4217 net.cpp:86] Creating Layer pool5\n",
      "I0430 06:56:11.165343  4217 net.cpp:408] pool5 <- conv5\n",
      "I0430 06:56:11.165346  4217 net.cpp:382] pool5 -> pool5\n",
      "I0430 06:56:11.165354  4217 net.cpp:124] Setting up pool5\n",
      "I0430 06:56:11.165357  4217 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 06:56:11.165359  4217 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 06:56:11.165361  4217 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 06:56:11.165367  4217 net.cpp:86] Creating Layer fc6\n",
      "I0430 06:56:11.165370  4217 net.cpp:408] fc6 <- pool5\n",
      "I0430 06:56:11.165374  4217 net.cpp:382] fc6 -> fc6\n",
      "I0430 06:56:11.190140  4217 net.cpp:124] Setting up fc6\n",
      "I0430 06:56:11.190165  4217 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:56:11.190183  4217 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 06:56:11.190196  4217 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 06:56:11.190206  4217 net.cpp:86] Creating Layer relu6\n",
      "I0430 06:56:11.190210  4217 net.cpp:408] relu6 <- fc6\n",
      "I0430 06:56:11.190217  4217 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 06:56:11.190225  4217 net.cpp:124] Setting up relu6\n",
      "I0430 06:56:11.190230  4217 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:56:11.190233  4217 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 06:56:11.190237  4217 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 06:56:11.190244  4217 net.cpp:86] Creating Layer drop6\n",
      "I0430 06:56:11.190248  4217 net.cpp:408] drop6 <- fc6\n",
      "I0430 06:56:11.190253  4217 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 06:56:11.190260  4217 net.cpp:124] Setting up drop6\n",
      "I0430 06:56:11.190264  4217 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:56:11.190268  4217 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 06:56:11.190271  4217 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 06:56:11.190277  4217 net.cpp:86] Creating Layer fc7\n",
      "I0430 06:56:11.190280  4217 net.cpp:408] fc7 <- fc6\n",
      "I0430 06:56:11.190285  4217 net.cpp:382] fc7 -> fc7\n",
      "I0430 06:56:11.200517  4217 net.cpp:124] Setting up fc7\n",
      "I0430 06:56:11.200538  4217 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:56:11.200546  4217 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 06:56:11.200572  4217 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 06:56:11.200582  4217 net.cpp:86] Creating Layer relu7\n",
      "I0430 06:56:11.200587  4217 net.cpp:408] relu7 <- fc7\n",
      "I0430 06:56:11.200592  4217 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 06:56:11.200599  4217 net.cpp:124] Setting up relu7\n",
      "I0430 06:56:11.200603  4217 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:56:11.200604  4217 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 06:56:11.200608  4217 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 06:56:11.200611  4217 net.cpp:86] Creating Layer drop7\n",
      "I0430 06:56:11.200613  4217 net.cpp:408] drop7 <- fc7\n",
      "I0430 06:56:11.200618  4217 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 06:56:11.200623  4217 net.cpp:124] Setting up drop7\n",
      "I0430 06:56:11.200625  4217 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 06:56:11.200628  4217 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 06:56:11.200629  4217 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 06:56:11.200634  4217 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 06:56:11.200636  4217 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 06:56:11.200639  4217 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 06:56:11.201545  4217 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 06:56:11.201555  4217 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 06:56:11.201558  4217 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 06:56:11.201567  4217 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 06:56:11.201571  4217 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 06:56:11.201575  4217 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 06:56:11.201577  4217 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 06:56:11.201581  4217 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 06:56:11.201584  4217 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 06:56:11.201588  4217 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 06:56:11.201596  4217 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 06:56:11.201601  4217 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 06:56:11.201606  4217 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 06:56:11.201611  4217 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 06:56:11.201614  4217 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 06:56:11.201618  4217 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 06:56:11.201622  4217 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 06:56:11.201625  4217 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 06:56:11.201629  4217 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 06:56:11.201633  4217 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 06:56:11.201637  4217 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 06:56:11.201640  4217 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 06:56:11.201643  4217 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 06:56:11.201647  4217 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 06:56:11.201650  4217 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 06:56:11.201653  4217 net.cpp:202] data does not need backward computation.\n",
      "I0430 06:56:11.201656  4217 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 06:56:11.201671  4217 net.cpp:257] Network initialization done.\n",
      "I0430 06:56:11.293074  4217 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:56:11.398342  4217 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 06:56:11.399324  4217 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 06:56:11.399333  4217 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 06:56:11.399335  4217 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/185789.jpg'}, '/tmp/tmp62N0XX.mat')\n",
      "Processed 2672 windows in 307.867 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.037 s.\n",
      "prediction    [-3.01914, -1.98395, -2.33167, -2.6078, -2.618...\n",
      "ymin                                                        180\n",
      "xmin                                                          0\n",
      "ymax                                                        334\n",
      "xmax                                                        252\n",
      "Name: /home/ambika/INF_project/data/train/185789.jpg, dtype: object\n",
      "prediction    [-2.08411, -1.9562, -1.9526, -2.31901, -2.0053...\n",
      "ymin                                                        145\n",
      "xmin                                                         32\n",
      "ymax                                                        301\n",
      "xmax                                                        374\n",
      "Name: /home/ambika/INF_project/data/train/185789.jpg, dtype: object\n",
      "train\n",
      "0\t180\t252\t334\n",
      "bus\n",
      "32\t145\t374\t301\n",
      "185789\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:01:20.857568  4419 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:01:20.857604  4419 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:01:20.857607  4419 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:01:20.858855  4419 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:01:20.859045  4419 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:01:20.859062  4419 net.cpp:86] Creating Layer data\n",
      "I0430 07:01:20.859068  4419 net.cpp:382] data -> data\n",
      "I0430 07:01:20.859081  4419 net.cpp:124] Setting up data\n",
      "I0430 07:01:20.859088  4419 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:01:20.859092  4419 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:01:20.859097  4419 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:01:20.859105  4419 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:01:20.859110  4419 net.cpp:408] conv1 <- data\n",
      "I0430 07:01:20.859115  4419 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:01:20.859174  4419 net.cpp:124] Setting up conv1\n",
      "I0430 07:01:20.859179  4419 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:01:20.859181  4419 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:01:20.859189  4419 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:01:20.859194  4419 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:01:20.859195  4419 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:01:20.859200  4419 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:01:20.859203  4419 net.cpp:124] Setting up relu1\n",
      "I0430 07:01:20.859220  4419 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:01:20.859221  4419 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:01:20.859225  4419 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:01:20.859228  4419 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:01:20.859230  4419 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:01:20.859235  4419 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:01:20.859241  4419 net.cpp:124] Setting up pool1\n",
      "I0430 07:01:20.859243  4419 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:01:20.859246  4419 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:01:20.859248  4419 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:01:20.859253  4419 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:01:20.859256  4419 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:01:20.859259  4419 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:01:20.859267  4419 net.cpp:124] Setting up norm1\n",
      "I0430 07:01:20.859272  4419 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:01:20.859277  4419 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:01:20.859279  4419 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:01:20.859287  4419 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:01:20.859290  4419 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:01:20.859297  4419 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:01:20.859654  4419 net.cpp:124] Setting up conv2\n",
      "I0430 07:01:20.859661  4419 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:01:20.859665  4419 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:01:20.859673  4419 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:01:20.859680  4419 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:01:20.859683  4419 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:01:20.859686  4419 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:01:20.859690  4419 net.cpp:124] Setting up relu2\n",
      "I0430 07:01:20.859694  4419 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:01:20.859696  4419 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:01:20.859699  4419 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:01:20.859702  4419 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:01:20.859704  4419 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:01:20.859707  4419 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:01:20.859714  4419 net.cpp:124] Setting up pool2\n",
      "I0430 07:01:20.859716  4419 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:01:20.859719  4419 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:01:20.859721  4419 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:01:20.859725  4419 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:01:20.859730  4419 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:01:20.859732  4419 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:01:20.859737  4419 net.cpp:124] Setting up norm2\n",
      "I0430 07:01:20.859741  4419 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:01:20.859743  4419 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:01:20.859745  4419 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:01:20.859750  4419 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:01:20.859752  4419 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:01:20.859755  4419 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:01:20.860456  4419 net.cpp:124] Setting up conv3\n",
      "I0430 07:01:20.860466  4419 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:01:20.860469  4419 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:01:20.860479  4419 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:01:20.860487  4419 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:01:20.860491  4419 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:01:20.860496  4419 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:01:20.860499  4419 net.cpp:124] Setting up relu3\n",
      "I0430 07:01:20.860503  4419 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:01:20.860505  4419 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:01:20.860508  4419 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:01:20.860512  4419 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:01:20.860515  4419 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:01:20.860518  4419 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:01:20.861269  4419 net.cpp:124] Setting up conv4\n",
      "I0430 07:01:20.861279  4419 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:01:20.861284  4419 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:01:20.861290  4419 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:01:20.861299  4419 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:01:20.861301  4419 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:01:20.861305  4419 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:01:20.861310  4419 net.cpp:124] Setting up relu4\n",
      "I0430 07:01:20.861313  4419 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:01:20.861315  4419 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:01:20.861317  4419 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:01:20.861322  4419 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:01:20.861325  4419 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:01:20.861328  4419 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:01:20.861835  4419 net.cpp:124] Setting up conv5\n",
      "I0430 07:01:20.861842  4419 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:01:20.861845  4419 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:01:20.861855  4419 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:01:20.861861  4419 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:01:20.861865  4419 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:01:20.861868  4419 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:01:20.861872  4419 net.cpp:124] Setting up relu5\n",
      "I0430 07:01:20.861876  4419 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:01:20.861878  4419 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:01:20.861881  4419 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:01:20.861884  4419 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:01:20.861886  4419 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:01:20.861891  4419 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:01:20.861897  4419 net.cpp:124] Setting up pool5\n",
      "I0430 07:01:20.861901  4419 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:01:20.861903  4419 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:01:20.861905  4419 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:01:20.861912  4419 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:01:20.861915  4419 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:01:20.861918  4419 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:01:20.883184  4419 net.cpp:124] Setting up fc6\n",
      "I0430 07:01:20.883218  4419 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:01:20.883222  4419 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:01:20.883249  4419 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:01:20.883260  4419 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:01:20.883265  4419 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:01:20.883270  4419 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:01:20.883280  4419 net.cpp:124] Setting up relu6\n",
      "I0430 07:01:20.883283  4419 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:01:20.883285  4419 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:01:20.883287  4419 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:01:20.883291  4419 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:01:20.883293  4419 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:01:20.883296  4419 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:01:20.883301  4419 net.cpp:124] Setting up drop6\n",
      "I0430 07:01:20.883302  4419 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:01:20.883304  4419 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:01:20.883306  4419 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:01:20.883309  4419 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:01:20.883311  4419 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:01:20.883314  4419 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:01:20.893448  4419 net.cpp:124] Setting up fc7\n",
      "I0430 07:01:20.893471  4419 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:01:20.893474  4419 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:01:20.893484  4419 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:01:20.893503  4419 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:01:20.893508  4419 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:01:20.893514  4419 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:01:20.893522  4419 net.cpp:124] Setting up relu7\n",
      "I0430 07:01:20.893527  4419 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:01:20.893530  4419 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:01:20.893533  4419 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:01:20.893537  4419 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:01:20.893540  4419 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:01:20.893544  4419 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:01:20.893549  4419 net.cpp:124] Setting up drop7\n",
      "I0430 07:01:20.893553  4419 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:01:20.893554  4419 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:01:20.893558  4419 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:01:20.893561  4419 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:01:20.893563  4419 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:01:20.893568  4419 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:01:20.894203  4419 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:01:20.894213  4419 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:01:20.894217  4419 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:01:20.894225  4419 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:01:20.894230  4419 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:01:20.894234  4419 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:01:20.894238  4419 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:01:20.894243  4419 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:01:20.894246  4419 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:01:20.894249  4419 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:01:20.894251  4419 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:01:20.894254  4419 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:01:20.894258  4419 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:01:20.894260  4419 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:01:20.894263  4419 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:01:20.894265  4419 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:01:20.894268  4419 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:01:20.894271  4419 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:01:20.894274  4419 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:01:20.894276  4419 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:01:20.894279  4419 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:01:20.894282  4419 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:01:20.894285  4419 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:01:20.894287  4419 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:01:20.894290  4419 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:01:20.894294  4419 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:01:20.894295  4419 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:01:20.894306  4419 net.cpp:257] Network initialization done.\n",
      "I0430 07:01:20.982300  4419 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:01:21.082469  4419 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:01:21.083366  4419 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:01:21.083374  4419 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:01:21.083379  4419 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/366031.jpg'}, '/tmp/tmp9kn8Ch.mat')\n",
      "Processed 1645 windows in 195.233 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-2.3136, -2.48021, -1.63268, -2.59384, -2.069...\n",
      "ymin                                                        174\n",
      "xmin                                                        210\n",
      "ymax                                                        312\n",
      "xmax                                                        251\n",
      "Name: /home/ambika/INF_project/data/airplane/366031.jpg, dtype: object\n",
      "prediction    [-1.80877, -2.64868, -2.21477, -2.29924, -1.80...\n",
      "ymin                                                         11\n",
      "xmin                                                        217\n",
      "ymax                                                        149\n",
      "xmax                                                        393\n",
      "Name: /home/ambika/INF_project/data/airplane/366031.jpg, dtype: object\n",
      "person\n",
      "210\t174\t251\t312\n",
      "bow\n",
      "217\t11\t393\t149\n",
      "366031\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:04:37.860525  4594 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:04:37.860553  4594 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:04:37.860556  4594 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:04:37.861709  4594 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:04:37.861884  4594 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:04:37.861894  4594 net.cpp:86] Creating Layer data\n",
      "I0430 07:04:37.861898  4594 net.cpp:382] data -> data\n",
      "I0430 07:04:37.861912  4594 net.cpp:124] Setting up data\n",
      "I0430 07:04:37.861918  4594 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:04:37.861922  4594 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:04:37.861925  4594 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:04:37.861932  4594 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:04:37.861937  4594 net.cpp:408] conv1 <- data\n",
      "I0430 07:04:37.861941  4594 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:04:37.862002  4594 net.cpp:124] Setting up conv1\n",
      "I0430 07:04:37.862010  4594 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:04:37.862012  4594 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:04:37.862021  4594 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:04:37.862026  4594 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:04:37.862030  4594 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:04:37.862035  4594 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:04:37.862040  4594 net.cpp:124] Setting up relu1\n",
      "I0430 07:04:37.862043  4594 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:04:37.862046  4594 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:04:37.862049  4594 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:04:37.862054  4594 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:04:37.862057  4594 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:04:37.862061  4594 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:04:37.862069  4594 net.cpp:124] Setting up pool1\n",
      "I0430 07:04:37.862073  4594 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:04:37.862076  4594 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:04:37.862079  4594 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:04:37.862084  4594 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:04:37.862087  4594 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:04:37.862092  4594 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:04:37.862098  4594 net.cpp:124] Setting up norm1\n",
      "I0430 07:04:37.862103  4594 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:04:37.862107  4594 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:04:37.862109  4594 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:04:37.862114  4594 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:04:37.862118  4594 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:04:37.862123  4594 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:04:37.862489  4594 net.cpp:124] Setting up conv2\n",
      "I0430 07:04:37.862496  4594 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:04:37.862500  4594 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:04:37.862509  4594 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:04:37.862514  4594 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:04:37.862516  4594 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:04:37.862521  4594 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:04:37.862526  4594 net.cpp:124] Setting up relu2\n",
      "I0430 07:04:37.862530  4594 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:04:37.862534  4594 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:04:37.862536  4594 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:04:37.862540  4594 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:04:37.862543  4594 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:04:37.862548  4594 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:04:37.862555  4594 net.cpp:124] Setting up pool2\n",
      "I0430 07:04:37.862560  4594 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:04:37.862561  4594 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:04:37.862565  4594 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:04:37.862571  4594 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:04:37.862574  4594 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:04:37.862578  4594 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:04:37.862584  4594 net.cpp:124] Setting up norm2\n",
      "I0430 07:04:37.862588  4594 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:04:37.862591  4594 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:04:37.862594  4594 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:04:37.862599  4594 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:04:37.862602  4594 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:04:37.862607  4594 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:04:37.863317  4594 net.cpp:124] Setting up conv3\n",
      "I0430 07:04:37.863328  4594 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:04:37.863332  4594 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:04:37.863343  4594 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:04:37.863349  4594 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:04:37.863353  4594 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:04:37.863358  4594 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:04:37.863364  4594 net.cpp:124] Setting up relu3\n",
      "I0430 07:04:37.863368  4594 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:04:37.863371  4594 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:04:37.863374  4594 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:04:37.863380  4594 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:04:37.863382  4594 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:04:37.863387  4594 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:04:37.864136  4594 net.cpp:124] Setting up conv4\n",
      "I0430 07:04:37.864146  4594 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:04:37.864151  4594 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:04:37.864156  4594 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:04:37.864162  4594 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:04:37.864166  4594 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:04:37.864171  4594 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:04:37.864176  4594 net.cpp:124] Setting up relu4\n",
      "I0430 07:04:37.864181  4594 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:04:37.864183  4594 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:04:37.864187  4594 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:04:37.864194  4594 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:04:37.864197  4594 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:04:37.864202  4594 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:04:37.864701  4594 net.cpp:124] Setting up conv5\n",
      "I0430 07:04:37.864708  4594 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:04:37.864711  4594 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:04:37.864723  4594 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:04:37.864729  4594 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:04:37.864732  4594 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:04:37.864737  4594 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:04:37.864742  4594 net.cpp:124] Setting up relu5\n",
      "I0430 07:04:37.864747  4594 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:04:37.864749  4594 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:04:37.864753  4594 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:04:37.864758  4594 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:04:37.864761  4594 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:04:37.864766  4594 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:04:37.864774  4594 net.cpp:124] Setting up pool5\n",
      "I0430 07:04:37.864778  4594 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:04:37.864781  4594 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:04:37.864784  4594 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:04:37.864794  4594 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:04:37.864796  4594 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:04:37.864801  4594 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:04:37.888736  4594 net.cpp:124] Setting up fc6\n",
      "I0430 07:04:37.888764  4594 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:04:37.888769  4594 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:04:37.888797  4594 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:04:37.888808  4594 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:04:37.888813  4594 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:04:37.888818  4594 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:04:37.888826  4594 net.cpp:124] Setting up relu6\n",
      "I0430 07:04:37.888829  4594 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:04:37.888831  4594 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:04:37.888835  4594 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:04:37.888841  4594 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:04:37.888844  4594 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:04:37.888849  4594 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:04:37.888854  4594 net.cpp:124] Setting up drop6\n",
      "I0430 07:04:37.888859  4594 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:04:37.888861  4594 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:04:37.888864  4594 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:04:37.888871  4594 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:04:37.888875  4594 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:04:37.888880  4594 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:04:37.899174  4594 net.cpp:124] Setting up fc7\n",
      "I0430 07:04:37.899195  4594 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:04:37.899199  4594 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:04:37.899215  4594 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:04:37.899226  4594 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:04:37.899230  4594 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:04:37.899236  4594 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:04:37.899245  4594 net.cpp:124] Setting up relu7\n",
      "I0430 07:04:37.899247  4594 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:04:37.899250  4594 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:04:37.899252  4594 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:04:37.899258  4594 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:04:37.899262  4594 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:04:37.899266  4594 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:04:37.899272  4594 net.cpp:124] Setting up drop7\n",
      "I0430 07:04:37.899277  4594 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:04:37.899279  4594 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:04:37.899283  4594 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:04:37.899288  4594 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:04:37.899291  4594 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:04:37.899296  4594 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:04:37.900215  4594 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:04:37.900228  4594 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:04:37.900231  4594 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:04:37.900238  4594 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:04:37.900243  4594 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:04:37.900248  4594 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:04:37.900261  4594 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:04:37.900264  4594 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:04:37.900266  4594 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:04:37.900269  4594 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:04:37.900271  4594 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:04:37.900274  4594 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:04:37.900276  4594 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:04:37.900279  4594 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:04:37.900281  4594 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:04:37.900285  4594 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:04:37.900287  4594 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:04:37.900290  4594 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:04:37.900292  4594 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:04:37.900295  4594 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:04:37.900298  4594 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:04:37.900300  4594 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:04:37.900303  4594 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:04:37.900306  4594 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:04:37.900308  4594 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:04:37.900311  4594 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:04:37.900313  4594 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:04:37.900323  4594 net.cpp:257] Network initialization done.\n",
      "I0430 07:04:37.989436  4594 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:04:38.089162  4594 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:04:38.090358  4594 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:04:38.090373  4594 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:04:38.090378  4594 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/41867.jpg'}, '/tmp/tmpUWNNFY.mat')\n",
      "Processed 1457 windows in 170.682 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-1.82211, -3.28185, -2.22184, -1.87554, -2.83...\n",
      "ymin                                                         53\n",
      "xmin                                                         61\n",
      "ymax                                                        290\n",
      "xmax                                                        439\n",
      "Name: /home/ambika/INF_project/data/bird/41867.jpg, dtype: object\n",
      "prediction    [-2.61907, -2.73739, -1.99266, -0.451979, -2.7...\n",
      "ymin                                                        229\n",
      "xmin                                                        383\n",
      "ymax                                                        290\n",
      "xmax                                                        413\n",
      "Name: /home/ambika/INF_project/data/bird/41867.jpg, dtype: object\n",
      "bird\n",
      "61\t53\t439\t290\n",
      "antelope\n",
      "383\t229\t413\t290\n",
      "41867\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:07:30.353584  4739 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:07:30.353607  4739 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:07:30.353610  4739 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:07:30.355514  4739 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:07:30.355645  4739 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:07:30.355667  4739 net.cpp:86] Creating Layer data\n",
      "I0430 07:07:30.355672  4739 net.cpp:382] data -> data\n",
      "I0430 07:07:30.355689  4739 net.cpp:124] Setting up data\n",
      "I0430 07:07:30.355697  4739 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:07:30.355700  4739 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:07:30.355705  4739 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:07:30.355711  4739 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:07:30.355715  4739 net.cpp:408] conv1 <- data\n",
      "I0430 07:07:30.355720  4739 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:07:30.355790  4739 net.cpp:124] Setting up conv1\n",
      "I0430 07:07:30.355799  4739 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:07:30.355803  4739 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:07:30.355813  4739 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:07:30.355818  4739 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:07:30.355820  4739 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:07:30.355825  4739 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:07:30.355830  4739 net.cpp:124] Setting up relu1\n",
      "I0430 07:07:30.355834  4739 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:07:30.355837  4739 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:07:30.355840  4739 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:07:30.355845  4739 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:07:30.355849  4739 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:07:30.355852  4739 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:07:30.355860  4739 net.cpp:124] Setting up pool1\n",
      "I0430 07:07:30.355865  4739 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:07:30.355866  4739 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:07:30.355870  4739 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:07:30.355875  4739 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:07:30.355877  4739 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:07:30.355882  4739 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:07:30.355888  4739 net.cpp:124] Setting up norm1\n",
      "I0430 07:07:30.355892  4739 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:07:30.355895  4739 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:07:30.355898  4739 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:07:30.355903  4739 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:07:30.355906  4739 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:07:30.355911  4739 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:07:30.356287  4739 net.cpp:124] Setting up conv2\n",
      "I0430 07:07:30.356300  4739 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:07:30.356304  4739 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:07:30.356313  4739 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:07:30.356322  4739 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:07:30.356326  4739 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:07:30.356331  4739 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:07:30.356338  4739 net.cpp:124] Setting up relu2\n",
      "I0430 07:07:30.356341  4739 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:07:30.356344  4739 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:07:30.356348  4739 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:07:30.356353  4739 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:07:30.356356  4739 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:07:30.356361  4739 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:07:30.356369  4739 net.cpp:124] Setting up pool2\n",
      "I0430 07:07:30.356374  4739 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:07:30.356377  4739 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:07:30.356380  4739 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:07:30.356389  4739 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:07:30.356391  4739 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:07:30.356396  4739 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:07:30.356403  4739 net.cpp:124] Setting up norm2\n",
      "I0430 07:07:30.356410  4739 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:07:30.356411  4739 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:07:30.356415  4739 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:07:30.356425  4739 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:07:30.356428  4739 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:07:30.356433  4739 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:07:30.357663  4739 net.cpp:124] Setting up conv3\n",
      "I0430 07:07:30.357689  4739 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:07:30.357692  4739 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:07:30.357705  4739 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:07:30.357714  4739 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:07:30.357717  4739 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:07:30.357724  4739 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:07:30.357733  4739 net.cpp:124] Setting up relu3\n",
      "I0430 07:07:30.357736  4739 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:07:30.357739  4739 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:07:30.357743  4739 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:07:30.357751  4739 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:07:30.357754  4739 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:07:30.357758  4739 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:07:30.358359  4739 net.cpp:124] Setting up conv4\n",
      "I0430 07:07:30.358377  4739 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:07:30.358381  4739 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:07:30.358389  4739 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:07:30.358398  4739 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:07:30.358402  4739 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:07:30.358407  4739 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:07:30.358414  4739 net.cpp:124] Setting up relu4\n",
      "I0430 07:07:30.358418  4739 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:07:30.358422  4739 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:07:30.358424  4739 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:07:30.358433  4739 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:07:30.358435  4739 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:07:30.358439  4739 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:07:30.359235  4739 net.cpp:124] Setting up conv5\n",
      "I0430 07:07:30.359258  4739 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:07:30.359263  4739 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:07:30.359277  4739 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:07:30.359287  4739 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:07:30.359292  4739 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:07:30.359297  4739 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:07:30.359305  4739 net.cpp:124] Setting up relu5\n",
      "I0430 07:07:30.359309  4739 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:07:30.359313  4739 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:07:30.359314  4739 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:07:30.359319  4739 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:07:30.359323  4739 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:07:30.359328  4739 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:07:30.359338  4739 net.cpp:124] Setting up pool5\n",
      "I0430 07:07:30.359342  4739 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:07:30.359344  4739 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:07:30.359347  4739 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:07:30.359355  4739 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:07:30.359359  4739 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:07:30.359364  4739 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:07:30.382966  4739 net.cpp:124] Setting up fc6\n",
      "I0430 07:07:30.382992  4739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:07:30.382997  4739 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:07:30.383008  4739 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:07:30.383016  4739 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:07:30.383019  4739 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:07:30.383025  4739 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:07:30.383033  4739 net.cpp:124] Setting up relu6\n",
      "I0430 07:07:30.383036  4739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:07:30.383039  4739 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:07:30.383041  4739 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:07:30.383046  4739 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:07:30.383064  4739 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:07:30.383067  4739 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:07:30.383074  4739 net.cpp:124] Setting up drop6\n",
      "I0430 07:07:30.383077  4739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:07:30.383080  4739 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:07:30.383083  4739 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:07:30.383090  4739 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:07:30.383092  4739 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:07:30.383097  4739 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:07:30.393534  4739 net.cpp:124] Setting up fc7\n",
      "I0430 07:07:30.393560  4739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:07:30.393565  4739 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:07:30.393575  4739 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:07:30.393589  4739 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:07:30.393592  4739 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:07:30.393599  4739 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:07:30.393606  4739 net.cpp:124] Setting up relu7\n",
      "I0430 07:07:30.393610  4739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:07:30.393612  4739 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:07:30.393615  4739 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:07:30.393621  4739 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:07:30.393625  4739 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:07:30.393630  4739 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:07:30.393636  4739 net.cpp:124] Setting up drop7\n",
      "I0430 07:07:30.393640  4739 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:07:30.393642  4739 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:07:30.393646  4739 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:07:30.393651  4739 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:07:30.393654  4739 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:07:30.393658  4739 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:07:30.394330  4739 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:07:30.394423  4739 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:07:30.394428  4739 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:07:30.394438  4739 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:07:30.394441  4739 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:07:30.394444  4739 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:07:30.394448  4739 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:07:30.394450  4739 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:07:30.394454  4739 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:07:30.394457  4739 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:07:30.394460  4739 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:07:30.394464  4739 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:07:30.394467  4739 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:07:30.394470  4739 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:07:30.394474  4739 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:07:30.394477  4739 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:07:30.394480  4739 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:07:30.394484  4739 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:07:30.394487  4739 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:07:30.394490  4739 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:07:30.394493  4739 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:07:30.394497  4739 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:07:30.394500  4739 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:07:30.394503  4739 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:07:30.394506  4739 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:07:30.394510  4739 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:07:30.394512  4739 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:07:30.394525  4739 net.cpp:257] Network initialization done.\n",
      "I0430 07:07:30.486037  4739 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:07:30.587277  4739 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:07:30.588258  4739 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:07:30.588268  4739 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:07:30.588273  4739 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/78982.jpg'}, '/tmp/tmps49n4H.mat')\n",
      "Processed 2304 windows in 264.462 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.61573, -2.83424, -2.29281, -2.51885, -2.06...\n",
      "ymin                                                         84\n",
      "xmin                                                        112\n",
      "ymax                                                        205\n",
      "xmax                                                        305\n",
      "Name: /home/ambika/INF_project/data/bus/78982.jpg, dtype: object\n",
      "prediction    [-2.17591, -1.60352, -2.11514, -2.21513, -1.98...\n",
      "ymin                                                         82\n",
      "xmin                                                          0\n",
      "ymax                                                        204\n",
      "xmax                                                        105\n",
      "Name: /home/ambika/INF_project/data/bus/78982.jpg, dtype: object\n",
      "bus\n",
      "112\t84\t305\t205\n",
      "train\n",
      "0\t82\t105\t204\n",
      "78982\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:11:56.671131  4943 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:11:56.671151  4943 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:11:56.671154  4943 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:11:56.672252  4943 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:11:56.672330  4943 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:11:56.672336  4943 net.cpp:86] Creating Layer data\n",
      "I0430 07:11:56.672339  4943 net.cpp:382] data -> data\n",
      "I0430 07:11:56.672348  4943 net.cpp:124] Setting up data\n",
      "I0430 07:11:56.672353  4943 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:11:56.672353  4943 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:11:56.672356  4943 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:11:56.672361  4943 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:11:56.672363  4943 net.cpp:408] conv1 <- data\n",
      "I0430 07:11:56.672366  4943 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:11:56.672422  4943 net.cpp:124] Setting up conv1\n",
      "I0430 07:11:56.672426  4943 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:11:56.672428  4943 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:11:56.672435  4943 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:11:56.672438  4943 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:11:56.672441  4943 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:11:56.672443  4943 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:11:56.672446  4943 net.cpp:124] Setting up relu1\n",
      "I0430 07:11:56.672449  4943 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:11:56.672451  4943 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:11:56.672452  4943 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:11:56.672456  4943 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:11:56.672457  4943 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:11:56.672461  4943 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:11:56.672466  4943 net.cpp:124] Setting up pool1\n",
      "I0430 07:11:56.672467  4943 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:11:56.672469  4943 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:11:56.672472  4943 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:11:56.672474  4943 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:11:56.672477  4943 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:11:56.672478  4943 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:11:56.672482  4943 net.cpp:124] Setting up norm1\n",
      "I0430 07:11:56.672485  4943 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:11:56.672487  4943 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:11:56.672488  4943 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:11:56.672492  4943 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:11:56.672493  4943 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:11:56.672497  4943 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:11:56.672847  4943 net.cpp:124] Setting up conv2\n",
      "I0430 07:11:56.672852  4943 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:11:56.672853  4943 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:11:56.672858  4943 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:11:56.672863  4943 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:11:56.672864  4943 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:11:56.672868  4943 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:11:56.672870  4943 net.cpp:124] Setting up relu2\n",
      "I0430 07:11:56.672873  4943 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:11:56.672874  4943 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:11:56.672875  4943 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:11:56.672878  4943 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:11:56.672880  4943 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:11:56.672883  4943 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:11:56.672888  4943 net.cpp:124] Setting up pool2\n",
      "I0430 07:11:56.672890  4943 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:11:56.672891  4943 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:11:56.672894  4943 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:11:56.672899  4943 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:11:56.672900  4943 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:11:56.672902  4943 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:11:56.672906  4943 net.cpp:124] Setting up norm2\n",
      "I0430 07:11:56.672909  4943 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:11:56.672910  4943 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:11:56.672912  4943 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:11:56.672916  4943 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:11:56.672921  4943 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:11:56.672924  4943 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:11:56.673764  4943 net.cpp:124] Setting up conv3\n",
      "I0430 07:11:56.673789  4943 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:11:56.673794  4943 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:11:56.673805  4943 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:11:56.673820  4943 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:11:56.673823  4943 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:11:56.673832  4943 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:11:56.673856  4943 net.cpp:124] Setting up relu3\n",
      "I0430 07:11:56.673861  4943 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:11:56.673864  4943 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:11:56.673867  4943 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:11:56.673876  4943 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:11:56.673877  4943 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:11:56.673882  4943 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:11:56.674613  4943 net.cpp:124] Setting up conv4\n",
      "I0430 07:11:56.674623  4943 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:11:56.674625  4943 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:11:56.674630  4943 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:11:56.674634  4943 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:11:56.674638  4943 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:11:56.674641  4943 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:11:56.674648  4943 net.cpp:124] Setting up relu4\n",
      "I0430 07:11:56.674650  4943 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:11:56.674654  4943 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:11:56.674657  4943 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:11:56.674661  4943 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:11:56.674664  4943 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:11:56.674669  4943 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:11:56.675163  4943 net.cpp:124] Setting up conv5\n",
      "I0430 07:11:56.675168  4943 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:11:56.675170  4943 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:11:56.675179  4943 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:11:56.675181  4943 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:11:56.675184  4943 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:11:56.675189  4943 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:11:56.675192  4943 net.cpp:124] Setting up relu5\n",
      "I0430 07:11:56.675195  4943 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:11:56.675197  4943 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:11:56.675200  4943 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:11:56.675213  4943 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:11:56.675221  4943 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:11:56.675225  4943 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:11:56.675232  4943 net.cpp:124] Setting up pool5\n",
      "I0430 07:11:56.675236  4943 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:11:56.675238  4943 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:11:56.675240  4943 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:11:56.675247  4943 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:11:56.675249  4943 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:11:56.675253  4943 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:11:56.699153  4943 net.cpp:124] Setting up fc6\n",
      "I0430 07:11:56.699204  4943 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:11:56.699218  4943 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:11:56.699229  4943 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:11:56.699240  4943 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:11:56.699245  4943 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:11:56.699251  4943 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:11:56.699260  4943 net.cpp:124] Setting up relu6\n",
      "I0430 07:11:56.699265  4943 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:11:56.699267  4943 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:11:56.699271  4943 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:11:56.699278  4943 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:11:56.699281  4943 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:11:56.699286  4943 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:11:56.699295  4943 net.cpp:124] Setting up drop6\n",
      "I0430 07:11:56.699300  4943 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:11:56.699302  4943 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:11:56.699306  4943 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:11:56.699314  4943 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:11:56.699317  4943 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:11:56.699323  4943 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:11:56.710283  4943 net.cpp:124] Setting up fc7\n",
      "I0430 07:11:56.710305  4943 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:11:56.710310  4943 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:11:56.710319  4943 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:11:56.710326  4943 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:11:56.710328  4943 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:11:56.710333  4943 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:11:56.710340  4943 net.cpp:124] Setting up relu7\n",
      "I0430 07:11:56.710341  4943 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:11:56.710343  4943 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:11:56.710345  4943 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:11:56.710350  4943 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:11:56.710351  4943 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:11:56.710353  4943 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:11:56.710357  4943 net.cpp:124] Setting up drop7\n",
      "I0430 07:11:56.710361  4943 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:11:56.710361  4943 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:11:56.710363  4943 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:11:56.710367  4943 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:11:56.710381  4943 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:11:56.710386  4943 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:11:56.711038  4943 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:11:56.711055  4943 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:11:56.711058  4943 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:11:56.711067  4943 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:11:56.711071  4943 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:11:56.711074  4943 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:11:56.711076  4943 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:11:56.711078  4943 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:11:56.711082  4943 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:11:56.711086  4943 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:11:56.711088  4943 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:11:56.711092  4943 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:11:56.711096  4943 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:11:56.711098  4943 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:11:56.711102  4943 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:11:56.711107  4943 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:11:56.711110  4943 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:11:56.711117  4943 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:11:56.711120  4943 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:11:56.711127  4943 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:11:56.711133  4943 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:11:56.711138  4943 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:11:56.711143  4943 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:11:56.711148  4943 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:11:56.711151  4943 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:11:56.711154  4943 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:11:56.711158  4943 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:11:56.711169  4943 net.cpp:257] Network initialization done.\n",
      "I0430 07:11:56.798414  4943 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:11:56.898829  4943 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:11:56.900046  4943 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:11:56.900063  4943 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:11:56.900065  4943 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/403054.jpg'}, '/tmp/tmpYSnW7P.mat')\n",
      "Processed 4080 windows in 472.754 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.095 s.\n",
      "prediction    [-2.69926, -2.79674, -1.6561, -2.05505, -1.728...\n",
      "ymin                                                        152\n",
      "xmin                                                       62.4\n",
      "ymax                                                      361.8\n",
      "xmax                                                      149.8\n",
      "Name: /home/ambika/INF_project/data/car/403054.jpg, dtype: object\n",
      "prediction    [-1.70833, -2.33826, -1.81871, -1.7078, -1.616...\n",
      "ymin                                                      177.6\n",
      "xmin                                                      179.2\n",
      "ymax                                                        201\n",
      "xmax                                                        205\n",
      "Name: /home/ambika/INF_project/data/car/403054.jpg, dtype: object\n",
      "person\n",
      "62.4\t152.0\t149.8\t361.8\n",
      "car\n",
      "179.2\t177.6\t205.0\t201.0\n",
      "403054\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:19:51.846657  5215 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:19:51.846679  5215 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:19:51.846683  5215 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:19:51.848654  5215 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:19:51.848862  5215 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:19:51.848875  5215 net.cpp:86] Creating Layer data\n",
      "I0430 07:19:51.848881  5215 net.cpp:382] data -> data\n",
      "I0430 07:19:51.848896  5215 net.cpp:124] Setting up data\n",
      "I0430 07:19:51.848917  5215 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:19:51.848920  5215 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:19:51.848924  5215 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:19:51.848930  5215 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:19:51.848933  5215 net.cpp:408] conv1 <- data\n",
      "I0430 07:19:51.848939  5215 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:19:51.849164  5215 net.cpp:124] Setting up conv1\n",
      "I0430 07:19:51.849171  5215 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:19:51.849174  5215 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:19:51.849182  5215 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:19:51.849187  5215 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:19:51.849190  5215 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:19:51.849195  5215 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:19:51.849200  5215 net.cpp:124] Setting up relu1\n",
      "I0430 07:19:51.849205  5215 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:19:51.849206  5215 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:19:51.849210  5215 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:19:51.849215  5215 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:19:51.849216  5215 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:19:51.849221  5215 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:19:51.849230  5215 net.cpp:124] Setting up pool1\n",
      "I0430 07:19:51.849233  5215 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:19:51.849236  5215 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:19:51.849238  5215 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:19:51.849244  5215 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:19:51.849246  5215 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:19:51.849251  5215 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:19:51.849257  5215 net.cpp:124] Setting up norm1\n",
      "I0430 07:19:51.849261  5215 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:19:51.849263  5215 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:19:51.849267  5215 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:19:51.849272  5215 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:19:51.849274  5215 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:19:51.849278  5215 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:19:51.849618  5215 net.cpp:124] Setting up conv2\n",
      "I0430 07:19:51.849624  5215 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:19:51.849627  5215 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:19:51.849633  5215 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:19:51.849639  5215 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:19:51.849642  5215 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:19:51.849647  5215 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:19:51.849651  5215 net.cpp:124] Setting up relu2\n",
      "I0430 07:19:51.849655  5215 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:19:51.849658  5215 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:19:51.849661  5215 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:19:51.849665  5215 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:19:51.849668  5215 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:19:51.849673  5215 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:19:51.849678  5215 net.cpp:124] Setting up pool2\n",
      "I0430 07:19:51.849683  5215 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:19:51.849684  5215 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:19:51.849687  5215 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:19:51.849694  5215 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:19:51.849696  5215 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:19:51.849700  5215 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:19:51.849706  5215 net.cpp:124] Setting up norm2\n",
      "I0430 07:19:51.849710  5215 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:19:51.849714  5215 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:19:51.849716  5215 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:19:51.849722  5215 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:19:51.849725  5215 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:19:51.849730  5215 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:19:51.850402  5215 net.cpp:124] Setting up conv3\n",
      "I0430 07:19:51.850414  5215 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:19:51.850416  5215 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:19:51.850425  5215 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:19:51.850431  5215 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:19:51.850433  5215 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:19:51.850438  5215 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:19:51.850443  5215 net.cpp:124] Setting up relu3\n",
      "I0430 07:19:51.850447  5215 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:19:51.850450  5215 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:19:51.850453  5215 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:19:51.850459  5215 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:19:51.850462  5215 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:19:51.850466  5215 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:19:51.851196  5215 net.cpp:124] Setting up conv4\n",
      "I0430 07:19:51.851230  5215 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:19:51.851235  5215 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:19:51.851243  5215 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:19:51.851249  5215 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:19:51.851253  5215 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:19:51.851256  5215 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:19:51.851263  5215 net.cpp:124] Setting up relu4\n",
      "I0430 07:19:51.851266  5215 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:19:51.851269  5215 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:19:51.851272  5215 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:19:51.851279  5215 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:19:51.851281  5215 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:19:51.851286  5215 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:19:51.851799  5215 net.cpp:124] Setting up conv5\n",
      "I0430 07:19:51.851809  5215 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:19:51.851812  5215 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:19:51.851820  5215 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:19:51.851826  5215 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:19:51.851830  5215 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:19:51.851835  5215 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:19:51.851841  5215 net.cpp:124] Setting up relu5\n",
      "I0430 07:19:51.851845  5215 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:19:51.851848  5215 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:19:51.851850  5215 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:19:51.851855  5215 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:19:51.851857  5215 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:19:51.851869  5215 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:19:51.851877  5215 net.cpp:124] Setting up pool5\n",
      "I0430 07:19:51.851881  5215 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:19:51.851883  5215 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:19:51.851886  5215 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:19:51.851894  5215 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:19:51.851897  5215 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:19:51.851902  5215 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:19:51.872970  5215 net.cpp:124] Setting up fc6\n",
      "I0430 07:19:51.872992  5215 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:19:51.872994  5215 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:19:51.873003  5215 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:19:51.873009  5215 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:19:51.873011  5215 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:19:51.873015  5215 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:19:51.873021  5215 net.cpp:124] Setting up relu6\n",
      "I0430 07:19:51.873024  5215 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:19:51.873028  5215 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:19:51.873029  5215 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:19:51.873037  5215 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:19:51.873054  5215 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:19:51.873055  5215 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:19:51.873060  5215 net.cpp:124] Setting up drop6\n",
      "I0430 07:19:51.873064  5215 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:19:51.873069  5215 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:19:51.873071  5215 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:19:51.873075  5215 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:19:51.873078  5215 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:19:51.873081  5215 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:19:51.883520  5215 net.cpp:124] Setting up fc7\n",
      "I0430 07:19:51.883545  5215 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:19:51.883550  5215 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:19:51.883561  5215 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:19:51.883570  5215 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:19:51.883574  5215 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:19:51.883580  5215 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:19:51.883587  5215 net.cpp:124] Setting up relu7\n",
      "I0430 07:19:51.883590  5215 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:19:51.883594  5215 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:19:51.883595  5215 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:19:51.883601  5215 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:19:51.883605  5215 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:19:51.883608  5215 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:19:51.883615  5215 net.cpp:124] Setting up drop7\n",
      "I0430 07:19:51.883617  5215 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:19:51.883620  5215 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:19:51.883622  5215 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:19:51.883628  5215 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:19:51.883630  5215 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:19:51.883635  5215 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:19:51.884810  5215 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:19:51.884824  5215 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:19:51.884826  5215 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:19:51.884834  5215 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:19:51.884837  5215 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:19:51.884840  5215 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:19:51.884843  5215 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:19:51.884846  5215 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:19:51.884850  5215 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:19:51.884852  5215 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:19:51.884856  5215 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:19:51.884860  5215 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:19:51.884862  5215 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:19:51.884866  5215 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:19:51.884871  5215 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:19:51.884874  5215 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:19:51.884879  5215 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:19:51.884886  5215 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:19:51.884891  5215 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:19:51.884894  5215 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:19:51.884898  5215 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:19:51.884902  5215 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:19:51.884907  5215 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:19:51.884912  5215 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:19:51.884915  5215 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:19:51.884919  5215 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:19:51.884922  5215 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:19:51.884937  5215 net.cpp:257] Network initialization done.\n",
      "I0430 07:19:52.137651  5215 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:19:52.232547  5215 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:19:52.233566  5215 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:19:52.233575  5215 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:19:52.233584  5215 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/205103.jpg'}, '/tmp/tmpk2vSt3.mat')\n",
      "Processed 3969 windows in 454.773 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.057 s.\n",
      "prediction    [-1.85149, -1.97276, -1.81852, -1.97849, -2.07...\n",
      "ymin                                                         63\n",
      "xmin                                                          0\n",
      "ymax                                                      500.5\n",
      "xmax                                                     351.25\n",
      "Name: /home/ambika/INF_project/data/cat/205103.jpg, dtype: object\n",
      "prediction    [-2.22111, -2.7315, -2.16628, -2.11965, -2.218...\n",
      "ymin                                                     348.75\n",
      "xmin                                                          0\n",
      "ymax                                                      497.5\n",
      "xmax                                                      146.5\n",
      "Name: /home/ambika/INF_project/data/cat/205103.jpg, dtype: object\n",
      "domestic cat\n",
      "0.0\t63.0\t351.25\t500.5\n",
      "monkey\n",
      "0.0\t348.75\t146.5\t497.5\n",
      "205103\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:27:28.962173  5449 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:27:28.962194  5449 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:27:28.962198  5449 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:27:28.964994  5449 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:27:28.965150  5449 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:27:28.965158  5449 net.cpp:86] Creating Layer data\n",
      "I0430 07:27:28.965167  5449 net.cpp:382] data -> data\n",
      "I0430 07:27:28.965184  5449 net.cpp:124] Setting up data\n",
      "I0430 07:27:28.965193  5449 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:27:28.965195  5449 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:27:28.965199  5449 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:27:28.965207  5449 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:27:28.965211  5449 net.cpp:408] conv1 <- data\n",
      "I0430 07:27:28.965216  5449 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:27:28.965279  5449 net.cpp:124] Setting up conv1\n",
      "I0430 07:27:28.965286  5449 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:27:28.965288  5449 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:27:28.965296  5449 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:27:28.965301  5449 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:27:28.965304  5449 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:27:28.965309  5449 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:27:28.965314  5449 net.cpp:124] Setting up relu1\n",
      "I0430 07:27:28.965318  5449 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:27:28.965322  5449 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:27:28.965324  5449 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:27:28.965328  5449 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:27:28.965332  5449 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:27:28.965335  5449 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:27:28.965342  5449 net.cpp:124] Setting up pool1\n",
      "I0430 07:27:28.965348  5449 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:27:28.965349  5449 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:27:28.965353  5449 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:27:28.965358  5449 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:27:28.965360  5449 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:27:28.965364  5449 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:27:28.965370  5449 net.cpp:124] Setting up norm1\n",
      "I0430 07:27:28.965374  5449 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:27:28.965378  5449 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:27:28.965380  5449 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:27:28.965385  5449 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:27:28.965387  5449 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:27:28.965392  5449 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:27:28.965734  5449 net.cpp:124] Setting up conv2\n",
      "I0430 07:27:28.965741  5449 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:27:28.965744  5449 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:27:28.965750  5449 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:27:28.965755  5449 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:27:28.965759  5449 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:27:28.965762  5449 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:27:28.965767  5449 net.cpp:124] Setting up relu2\n",
      "I0430 07:27:28.965771  5449 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:27:28.965773  5449 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:27:28.965776  5449 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:27:28.965781  5449 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:27:28.965783  5449 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:27:28.965788  5449 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:27:28.965795  5449 net.cpp:124] Setting up pool2\n",
      "I0430 07:27:28.965798  5449 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:27:28.965801  5449 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:27:28.965803  5449 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:27:28.965809  5449 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:27:28.965812  5449 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:27:28.965817  5449 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:27:28.965822  5449 net.cpp:124] Setting up norm2\n",
      "I0430 07:27:28.965826  5449 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:27:28.965829  5449 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:27:28.965832  5449 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:27:28.965837  5449 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:27:28.965839  5449 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:27:28.965844  5449 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:27:28.966830  5449 net.cpp:124] Setting up conv3\n",
      "I0430 07:27:28.966842  5449 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:27:28.966845  5449 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:27:28.966856  5449 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:27:28.966862  5449 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:27:28.966866  5449 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:27:28.966871  5449 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:27:28.966877  5449 net.cpp:124] Setting up relu3\n",
      "I0430 07:27:28.966881  5449 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:27:28.966884  5449 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:27:28.966887  5449 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:27:28.966892  5449 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:27:28.966895  5449 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:27:28.966899  5449 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:27:28.967414  5449 net.cpp:124] Setting up conv4\n",
      "I0430 07:27:28.967424  5449 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:27:28.967427  5449 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:27:28.967433  5449 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:27:28.967439  5449 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:27:28.967442  5449 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:27:28.967447  5449 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:27:28.967453  5449 net.cpp:124] Setting up relu4\n",
      "I0430 07:27:28.967456  5449 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:27:28.967458  5449 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:27:28.967461  5449 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:27:28.967466  5449 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:27:28.967469  5449 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:27:28.967474  5449 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:27:28.967967  5449 net.cpp:124] Setting up conv5\n",
      "I0430 07:27:28.967974  5449 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:27:28.967978  5449 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:27:28.967988  5449 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:27:28.967993  5449 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:27:28.967995  5449 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:27:28.968000  5449 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:27:28.968005  5449 net.cpp:124] Setting up relu5\n",
      "I0430 07:27:28.968009  5449 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:27:28.968013  5449 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:27:28.968015  5449 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:27:28.968020  5449 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:27:28.968024  5449 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:27:28.968027  5449 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:27:28.968035  5449 net.cpp:124] Setting up pool5\n",
      "I0430 07:27:28.968039  5449 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:27:28.968042  5449 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:27:28.968045  5449 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:27:28.968052  5449 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:27:28.968055  5449 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:27:28.968060  5449 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:27:28.990325  5449 net.cpp:124] Setting up fc6\n",
      "I0430 07:27:28.990386  5449 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:27:28.990654  5449 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:27:28.990686  5449 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:27:28.990701  5449 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:27:28.990705  5449 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:27:28.990744  5449 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:27:28.990754  5449 net.cpp:124] Setting up relu6\n",
      "I0430 07:27:28.990759  5449 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:27:28.990761  5449 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:27:28.990763  5449 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:27:28.990768  5449 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:27:28.990770  5449 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:27:28.990772  5449 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:27:28.990780  5449 net.cpp:124] Setting up drop6\n",
      "I0430 07:27:28.990783  5449 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:27:28.990785  5449 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:27:28.990787  5449 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:27:28.990793  5449 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:27:28.990795  5449 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:27:28.990798  5449 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:27:29.005705  5449 net.cpp:124] Setting up fc7\n",
      "I0430 07:27:29.005730  5449 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:27:29.005734  5449 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:27:29.005746  5449 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:27:29.005764  5449 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:27:29.005769  5449 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:27:29.005776  5449 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:27:29.005785  5449 net.cpp:124] Setting up relu7\n",
      "I0430 07:27:29.005789  5449 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:27:29.005791  5449 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:27:29.005794  5449 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:27:29.005798  5449 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:27:29.005800  5449 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:27:29.005803  5449 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:27:29.005808  5449 net.cpp:124] Setting up drop7\n",
      "I0430 07:27:29.005811  5449 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:27:29.005813  5449 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:27:29.005816  5449 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:27:29.005820  5449 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:27:29.005822  5449 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:27:29.005825  5449 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:27:29.006736  5449 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:27:29.006745  5449 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:27:29.006749  5449 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:27:29.006757  5449 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:27:29.006762  5449 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:27:29.006765  5449 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:27:29.006769  5449 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:27:29.006773  5449 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:27:29.006777  5449 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:27:29.006779  5449 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:27:29.006783  5449 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:27:29.006786  5449 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:27:29.006790  5449 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:27:29.006793  5449 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:27:29.006796  5449 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:27:29.006800  5449 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:27:29.006803  5449 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:27:29.006806  5449 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:27:29.006810  5449 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:27:29.006814  5449 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:27:29.006816  5449 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:27:29.006820  5449 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:27:29.006824  5449 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:27:29.006826  5449 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:27:29.006829  5449 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:27:29.006834  5449 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:27:29.006835  5449 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:27:29.006847  5449 net.cpp:257] Network initialization done.\n",
      "I0430 07:27:29.256127  5449 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:27:29.354730  5449 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:27:29.355835  5449 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:27:29.355849  5449 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:27:29.355851  5449 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/566012.jpg'}, '/tmp/tmpSo6I0s.mat')\n",
      "Processed 1812 windows in 208.954 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.19768, -2.89429, -2.04858, -2.15719, -2.04...\n",
      "ymin                                                        181\n",
      "xmin                                                        177\n",
      "ymax                                                        333\n",
      "xmax                                                        329\n",
      "Name: /home/ambika/INF_project/data/couch/566012.jpg, dtype: object\n",
      "prediction    [-2.19768, -2.89429, -2.04858, -2.15719, -2.04...\n",
      "ymin                                                        181\n",
      "xmin                                                        177\n",
      "ymax                                                        333\n",
      "xmax                                                        329\n",
      "Name: /home/ambika/INF_project/data/couch/566012.jpg, dtype: object\n",
      "chair\n",
      "177\t181\t329\t333\n",
      "table\n",
      "177\t181\t329\t333\n",
      "566012\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:30:59.843688  5712 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:30:59.843711  5712 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:30:59.843714  5712 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:30:59.844864  5712 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:30:59.844964  5712 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:30:59.844972  5712 net.cpp:86] Creating Layer data\n",
      "I0430 07:30:59.844980  5712 net.cpp:382] data -> data\n",
      "I0430 07:30:59.844998  5712 net.cpp:124] Setting up data\n",
      "I0430 07:30:59.845006  5712 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:30:59.845010  5712 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:30:59.845016  5712 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:30:59.845033  5712 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:30:59.845037  5712 net.cpp:408] conv1 <- data\n",
      "I0430 07:30:59.845043  5712 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:30:59.845119  5712 net.cpp:124] Setting up conv1\n",
      "I0430 07:30:59.845127  5712 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:30:59.845131  5712 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:30:59.845140  5712 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:30:59.845147  5712 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:30:59.845151  5712 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:30:59.845155  5712 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:30:59.845161  5712 net.cpp:124] Setting up relu1\n",
      "I0430 07:30:59.845166  5712 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:30:59.845170  5712 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:30:59.845173  5712 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:30:59.845178  5712 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:30:59.845182  5712 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:30:59.845186  5712 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:30:59.845196  5712 net.cpp:124] Setting up pool1\n",
      "I0430 07:30:59.845201  5712 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:30:59.845203  5712 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:30:59.845207  5712 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:30:59.845213  5712 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:30:59.845217  5712 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:30:59.845223  5712 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:30:59.845232  5712 net.cpp:124] Setting up norm1\n",
      "I0430 07:30:59.845237  5712 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:30:59.845239  5712 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:30:59.845242  5712 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:30:59.845248  5712 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:30:59.845252  5712 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:30:59.845257  5712 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:30:59.845721  5712 net.cpp:124] Setting up conv2\n",
      "I0430 07:30:59.845737  5712 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:30:59.845741  5712 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:30:59.845754  5712 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:30:59.845762  5712 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:30:59.845767  5712 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:30:59.845772  5712 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:30:59.845779  5712 net.cpp:124] Setting up relu2\n",
      "I0430 07:30:59.845784  5712 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:30:59.845787  5712 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:30:59.845790  5712 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:30:59.845795  5712 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:30:59.845798  5712 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:30:59.845803  5712 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:30:59.845813  5712 net.cpp:124] Setting up pool2\n",
      "I0430 07:30:59.845818  5712 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:30:59.845820  5712 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:30:59.845824  5712 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:30:59.845832  5712 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:30:59.845835  5712 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:30:59.845840  5712 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:30:59.845847  5712 net.cpp:124] Setting up norm2\n",
      "I0430 07:30:59.845852  5712 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:30:59.845854  5712 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:30:59.845859  5712 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:30:59.845865  5712 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:30:59.845868  5712 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:30:59.845873  5712 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:30:59.847334  5712 net.cpp:124] Setting up conv3\n",
      "I0430 07:30:59.847358  5712 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:30:59.847363  5712 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:30:59.847375  5712 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:30:59.847385  5712 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:30:59.847389  5712 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:30:59.847395  5712 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:30:59.847403  5712 net.cpp:124] Setting up relu3\n",
      "I0430 07:30:59.847407  5712 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:30:59.847409  5712 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:30:59.847414  5712 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:30:59.847420  5712 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:30:59.847424  5712 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:30:59.847427  5712 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:30:59.847916  5712 net.cpp:124] Setting up conv4\n",
      "I0430 07:30:59.847928  5712 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:30:59.847931  5712 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:30:59.847937  5712 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:30:59.847944  5712 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:30:59.847947  5712 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:30:59.847952  5712 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:30:59.847959  5712 net.cpp:124] Setting up relu4\n",
      "I0430 07:30:59.847964  5712 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:30:59.847965  5712 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:30:59.847968  5712 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:30:59.847975  5712 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:30:59.847977  5712 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:30:59.847983  5712 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:30:59.848475  5712 net.cpp:124] Setting up conv5\n",
      "I0430 07:30:59.848484  5712 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:30:59.848489  5712 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:30:59.848498  5712 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:30:59.848505  5712 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:30:59.848507  5712 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:30:59.848511  5712 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:30:59.848516  5712 net.cpp:124] Setting up relu5\n",
      "I0430 07:30:59.848521  5712 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:30:59.848523  5712 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:30:59.848526  5712 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:30:59.848538  5712 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:30:59.848541  5712 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:30:59.848546  5712 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:30:59.848554  5712 net.cpp:124] Setting up pool5\n",
      "I0430 07:30:59.848559  5712 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:30:59.848562  5712 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:30:59.848565  5712 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:30:59.848572  5712 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:30:59.848575  5712 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:30:59.848580  5712 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:30:59.869981  5712 net.cpp:124] Setting up fc6\n",
      "I0430 07:30:59.870007  5712 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:30:59.870013  5712 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:30:59.870024  5712 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:30:59.870033  5712 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:30:59.870038  5712 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:30:59.870043  5712 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:30:59.870051  5712 net.cpp:124] Setting up relu6\n",
      "I0430 07:30:59.870055  5712 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:30:59.870057  5712 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:30:59.870060  5712 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:30:59.870064  5712 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:30:59.870080  5712 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:30:59.870085  5712 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:30:59.870092  5712 net.cpp:124] Setting up drop6\n",
      "I0430 07:30:59.870096  5712 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:30:59.870098  5712 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:30:59.870102  5712 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:30:59.870110  5712 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:30:59.870112  5712 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:30:59.870117  5712 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:30:59.879622  5712 net.cpp:124] Setting up fc7\n",
      "I0430 07:30:59.879645  5712 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:30:59.879650  5712 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:30:59.879659  5712 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:30:59.879668  5712 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:30:59.879673  5712 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:30:59.879678  5712 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:30:59.879685  5712 net.cpp:124] Setting up relu7\n",
      "I0430 07:30:59.879689  5712 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:30:59.879691  5712 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:30:59.879694  5712 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:30:59.879712  5712 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:30:59.879716  5712 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:30:59.879720  5712 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:30:59.879726  5712 net.cpp:124] Setting up drop7\n",
      "I0430 07:30:59.879731  5712 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:30:59.879734  5712 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:30:59.879737  5712 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:30:59.879742  5712 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:30:59.879745  5712 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:30:59.879750  5712 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:30:59.880426  5712 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:30:59.880441  5712 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:30:59.880445  5712 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:30:59.880455  5712 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:30:59.880460  5712 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:30:59.880463  5712 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:30:59.880466  5712 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:30:59.880470  5712 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:30:59.880473  5712 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:30:59.880477  5712 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:30:59.880481  5712 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:30:59.880483  5712 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:30:59.880487  5712 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:30:59.880491  5712 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:30:59.880493  5712 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:30:59.880497  5712 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:30:59.880501  5712 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:30:59.880504  5712 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:30:59.880507  5712 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:30:59.880511  5712 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:30:59.880514  5712 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:30:59.880517  5712 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:30:59.880520  5712 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:30:59.880524  5712 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:30:59.880527  5712 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:30:59.880530  5712 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:30:59.880533  5712 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:30:59.880545  5712 net.cpp:257] Network initialization done.\n",
      "I0430 07:30:59.968396  5712 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:31:00.063326  5712 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:31:00.064187  5712 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:31:00.064196  5712 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:31:00.064201  5712 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/575219.jpg'}, '/tmp/tmpF1ZYwH.mat')\n",
      "Processed 2581 windows in 297.199 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.16139, -2.51463, -1.81499, -2.25185, -2.37...\n",
      "ymin                                                         53\n",
      "xmin                                                        105\n",
      "ymax                                                        282\n",
      "xmax                                                        471\n",
      "Name: /home/ambika/INF_project/data/dog/575219.jpg, dtype: object\n",
      "prediction    [-2.16237, -2.4967, -1.81271, -2.23222, -2.827...\n",
      "ymin                                                        297\n",
      "xmin                                                        125\n",
      "ymax                                                        376\n",
      "xmax                                                        233\n",
      "Name: /home/ambika/INF_project/data/dog/575219.jpg, dtype: object\n",
      "dog\n",
      "105\t53\t471\t282\n",
      "remote control\n",
      "125\t297\t233\t376\n",
      "575219\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:35:58.820264  6252 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:35:58.820286  6252 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:35:58.820291  6252 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:35:58.821382  6252 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:35:58.821554  6252 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:35:58.821570  6252 net.cpp:86] Creating Layer data\n",
      "I0430 07:35:58.821575  6252 net.cpp:382] data -> data\n",
      "I0430 07:35:58.821589  6252 net.cpp:124] Setting up data\n",
      "I0430 07:35:58.821595  6252 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:35:58.821599  6252 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:35:58.821602  6252 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:35:58.821609  6252 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:35:58.821612  6252 net.cpp:408] conv1 <- data\n",
      "I0430 07:35:58.821619  6252 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:35:58.821676  6252 net.cpp:124] Setting up conv1\n",
      "I0430 07:35:58.821681  6252 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:35:58.821684  6252 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:35:58.821692  6252 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:35:58.821698  6252 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:35:58.821702  6252 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:35:58.821707  6252 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:35:58.821712  6252 net.cpp:124] Setting up relu1\n",
      "I0430 07:35:58.821715  6252 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:35:58.821718  6252 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:35:58.821722  6252 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:35:58.821727  6252 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:35:58.821729  6252 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:35:58.821734  6252 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:35:58.821741  6252 net.cpp:124] Setting up pool1\n",
      "I0430 07:35:58.821745  6252 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:35:58.821748  6252 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:35:58.821751  6252 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:35:58.821758  6252 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:35:58.821760  6252 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:35:58.821764  6252 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:35:58.821770  6252 net.cpp:124] Setting up norm1\n",
      "I0430 07:35:58.821775  6252 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:35:58.821777  6252 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:35:58.821780  6252 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:35:58.821786  6252 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:35:58.821789  6252 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:35:58.821794  6252 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:35:58.822124  6252 net.cpp:124] Setting up conv2\n",
      "I0430 07:35:58.822129  6252 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:35:58.822132  6252 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:35:58.822139  6252 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:35:58.822144  6252 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:35:58.822147  6252 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:35:58.822152  6252 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:35:58.822156  6252 net.cpp:124] Setting up relu2\n",
      "I0430 07:35:58.822160  6252 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:35:58.822163  6252 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:35:58.822166  6252 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:35:58.822171  6252 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:35:58.822175  6252 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:35:58.822180  6252 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:35:58.822185  6252 net.cpp:124] Setting up pool2\n",
      "I0430 07:35:58.822190  6252 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:35:58.822192  6252 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:35:58.822196  6252 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:35:58.822201  6252 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:35:58.822204  6252 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:35:58.822209  6252 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:35:58.822216  6252 net.cpp:124] Setting up norm2\n",
      "I0430 07:35:58.822219  6252 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:35:58.822222  6252 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:35:58.822226  6252 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:35:58.822232  6252 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:35:58.822235  6252 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:35:58.822239  6252 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:35:58.823210  6252 net.cpp:124] Setting up conv3\n",
      "I0430 07:35:58.823222  6252 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:35:58.823226  6252 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:35:58.823236  6252 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:35:58.823243  6252 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:35:58.823246  6252 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:35:58.823251  6252 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:35:58.823257  6252 net.cpp:124] Setting up relu3\n",
      "I0430 07:35:58.823262  6252 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:35:58.823264  6252 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:35:58.823267  6252 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:35:58.823276  6252 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:35:58.823278  6252 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:35:58.823283  6252 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:35:58.824049  6252 net.cpp:124] Setting up conv4\n",
      "I0430 07:35:58.824060  6252 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:35:58.824064  6252 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:35:58.824069  6252 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:35:58.824076  6252 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:35:58.824080  6252 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:35:58.824086  6252 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:35:58.824092  6252 net.cpp:124] Setting up relu4\n",
      "I0430 07:35:58.824096  6252 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:35:58.824100  6252 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:35:58.824102  6252 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:35:58.824108  6252 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:35:58.824111  6252 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:35:58.824116  6252 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:35:58.824641  6252 net.cpp:124] Setting up conv5\n",
      "I0430 07:35:58.824651  6252 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:35:58.824653  6252 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:35:58.824664  6252 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:35:58.824671  6252 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:35:58.824674  6252 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:35:58.824679  6252 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:35:58.824684  6252 net.cpp:124] Setting up relu5\n",
      "I0430 07:35:58.824689  6252 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:35:58.824692  6252 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:35:58.824695  6252 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:35:58.824702  6252 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:35:58.824703  6252 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:35:58.824708  6252 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:35:58.824717  6252 net.cpp:124] Setting up pool5\n",
      "I0430 07:35:58.824720  6252 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:35:58.824723  6252 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:35:58.824726  6252 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:35:58.824734  6252 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:35:58.824738  6252 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:35:58.824743  6252 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:35:58.847838  6252 net.cpp:124] Setting up fc6\n",
      "I0430 07:35:58.847872  6252 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:35:58.847877  6252 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:35:58.847892  6252 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:35:58.847901  6252 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:35:58.847905  6252 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:35:58.847913  6252 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:35:58.847920  6252 net.cpp:124] Setting up relu6\n",
      "I0430 07:35:58.847923  6252 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:35:58.847926  6252 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:35:58.847929  6252 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:35:58.847934  6252 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:35:58.847941  6252 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:35:58.847946  6252 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:35:58.847954  6252 net.cpp:124] Setting up drop6\n",
      "I0430 07:35:58.847959  6252 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:35:58.847961  6252 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:35:58.847965  6252 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:35:58.847970  6252 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:35:58.847973  6252 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:35:58.847978  6252 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:35:58.857898  6252 net.cpp:124] Setting up fc7\n",
      "I0430 07:35:58.857923  6252 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:35:58.857926  6252 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:35:58.857947  6252 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:35:58.857962  6252 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:35:58.857980  6252 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:35:58.857988  6252 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:35:58.857997  6252 net.cpp:124] Setting up relu7\n",
      "I0430 07:35:58.858002  6252 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:35:58.858006  6252 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:35:58.858008  6252 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:35:58.858013  6252 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:35:58.858016  6252 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:35:58.858021  6252 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:35:58.858026  6252 net.cpp:124] Setting up drop7\n",
      "I0430 07:35:58.858027  6252 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:35:58.858031  6252 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:35:58.858033  6252 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:35:58.858037  6252 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:35:58.858041  6252 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:35:58.858043  6252 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:35:58.858750  6252 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:35:58.858765  6252 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:35:58.858769  6252 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:35:58.858777  6252 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:35:58.858783  6252 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:35:58.858786  6252 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:35:58.858789  6252 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:35:58.858793  6252 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:35:58.858796  6252 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:35:58.858800  6252 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:35:58.858803  6252 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:35:58.858808  6252 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:35:58.858810  6252 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:35:58.858814  6252 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:35:58.858817  6252 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:35:58.858821  6252 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:35:58.858825  6252 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:35:58.858829  6252 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:35:58.858832  6252 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:35:58.858835  6252 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:35:58.858839  6252 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:35:58.858842  6252 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:35:58.858846  6252 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:35:58.858850  6252 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:35:58.858852  6252 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:35:58.858855  6252 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:35:58.858858  6252 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:35:58.858875  6252 net.cpp:257] Network initialization done.\n",
      "I0430 07:35:58.944063  6252 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:35:59.040202  6252 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:35:59.041101  6252 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:35:59.041111  6252 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:35:59.041116  6252 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/298382.jpg'}, '/tmp/tmpGv1N3V.mat')\n",
      "Processed 2962 windows in 338.069 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.52638, -2.3205, -3.47861, -3.38466, -2.397...\n",
      "ymin                                                        140\n",
      "xmin                                                         66\n",
      "ymax                                                        335\n",
      "xmax                                                        232\n",
      "Name: /home/ambika/INF_project/data/horse/298382.jpg, dtype: object\n",
      "prediction    [-2.19367, -1.55006, -2.77847, -2.50524, -1.80...\n",
      "ymin                                                        184\n",
      "xmin                                                        189\n",
      "ymax                                                        317\n",
      "xmax                                                        383\n",
      "Name: /home/ambika/INF_project/data/horse/298382.jpg, dtype: object\n",
      "horse\n",
      "66\t140\t232\t335\n",
      "cattle\n",
      "189\t184\t383\t317\n",
      "298382\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:41:38.705770  6612 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:41:38.705785  6612 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:41:38.705787  6612 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:41:38.706871  6612 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:41:38.707036  6612 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:41:38.707042  6612 net.cpp:86] Creating Layer data\n",
      "I0430 07:41:38.707046  6612 net.cpp:382] data -> data\n",
      "I0430 07:41:38.707058  6612 net.cpp:124] Setting up data\n",
      "I0430 07:41:38.707063  6612 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:41:38.707067  6612 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:41:38.707072  6612 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:41:38.707080  6612 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:41:38.707084  6612 net.cpp:408] conv1 <- data\n",
      "I0430 07:41:38.707090  6612 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:41:38.707154  6612 net.cpp:124] Setting up conv1\n",
      "I0430 07:41:38.707159  6612 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:41:38.707161  6612 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:41:38.707168  6612 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:41:38.707173  6612 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:41:38.707175  6612 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:41:38.707180  6612 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:41:38.707183  6612 net.cpp:124] Setting up relu1\n",
      "I0430 07:41:38.707187  6612 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:41:38.707190  6612 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:41:38.707191  6612 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:41:38.707195  6612 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:41:38.707197  6612 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:41:38.707201  6612 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:41:38.707231  6612 net.cpp:124] Setting up pool1\n",
      "I0430 07:41:38.707236  6612 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:41:38.707237  6612 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:41:38.707240  6612 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:41:38.707245  6612 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:41:38.707247  6612 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:41:38.707250  6612 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:41:38.707257  6612 net.cpp:124] Setting up norm1\n",
      "I0430 07:41:38.707260  6612 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:41:38.707264  6612 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:41:38.707268  6612 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:41:38.707274  6612 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:41:38.707278  6612 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:41:38.707283  6612 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:41:38.707633  6612 net.cpp:124] Setting up conv2\n",
      "I0430 07:41:38.707641  6612 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:41:38.707644  6612 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:41:38.707653  6612 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:41:38.707659  6612 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:41:38.707660  6612 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:41:38.707664  6612 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:41:38.707669  6612 net.cpp:124] Setting up relu2\n",
      "I0430 07:41:38.707672  6612 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:41:38.707674  6612 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:41:38.707676  6612 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:41:38.707680  6612 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:41:38.707682  6612 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:41:38.707686  6612 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:41:38.707691  6612 net.cpp:124] Setting up pool2\n",
      "I0430 07:41:38.707695  6612 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:41:38.707696  6612 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:41:38.707700  6612 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:41:38.707705  6612 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:41:38.707707  6612 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:41:38.707710  6612 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:41:38.707715  6612 net.cpp:124] Setting up norm2\n",
      "I0430 07:41:38.707718  6612 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:41:38.707720  6612 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:41:38.707723  6612 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:41:38.707729  6612 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:41:38.707732  6612 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:41:38.707736  6612 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:41:38.708423  6612 net.cpp:124] Setting up conv3\n",
      "I0430 07:41:38.708434  6612 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:41:38.708437  6612 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:41:38.708447  6612 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:41:38.708454  6612 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:41:38.708457  6612 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:41:38.708462  6612 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:41:38.708467  6612 net.cpp:124] Setting up relu3\n",
      "I0430 07:41:38.708470  6612 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:41:38.708472  6612 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:41:38.708475  6612 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:41:38.708482  6612 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:41:38.708483  6612 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:41:38.708487  6612 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:41:38.709229  6612 net.cpp:124] Setting up conv4\n",
      "I0430 07:41:38.709239  6612 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:41:38.709241  6612 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:41:38.709249  6612 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:41:38.709254  6612 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:41:38.709257  6612 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:41:38.709261  6612 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:41:38.709266  6612 net.cpp:124] Setting up relu4\n",
      "I0430 07:41:38.709270  6612 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:41:38.709272  6612 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:41:38.709275  6612 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:41:38.709280  6612 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:41:38.709282  6612 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:41:38.709286  6612 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:41:38.709800  6612 net.cpp:124] Setting up conv5\n",
      "I0430 07:41:38.709805  6612 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:41:38.709808  6612 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:41:38.709820  6612 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:41:38.709825  6612 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:41:38.709827  6612 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:41:38.709830  6612 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:41:38.709834  6612 net.cpp:124] Setting up relu5\n",
      "I0430 07:41:38.709837  6612 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:41:38.709841  6612 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:41:38.709842  6612 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:41:38.709847  6612 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:41:38.709849  6612 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:41:38.709853  6612 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:41:38.709859  6612 net.cpp:124] Setting up pool5\n",
      "I0430 07:41:38.709863  6612 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:41:38.709867  6612 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:41:38.709868  6612 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:41:38.709873  6612 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:41:38.709875  6612 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:41:38.709879  6612 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:41:38.733785  6612 net.cpp:124] Setting up fc6\n",
      "I0430 07:41:38.733809  6612 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:41:38.733814  6612 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:41:38.733824  6612 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:41:38.733834  6612 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:41:38.733837  6612 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:41:38.733842  6612 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:41:38.733850  6612 net.cpp:124] Setting up relu6\n",
      "I0430 07:41:38.733855  6612 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:41:38.733856  6612 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:41:38.733860  6612 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:41:38.733863  6612 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:41:38.733866  6612 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:41:38.733872  6612 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:41:38.733878  6612 net.cpp:124] Setting up drop6\n",
      "I0430 07:41:38.733882  6612 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:41:38.733886  6612 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:41:38.733888  6612 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:41:38.733894  6612 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:41:38.733896  6612 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:41:38.733901  6612 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:41:38.743569  6612 net.cpp:124] Setting up fc7\n",
      "I0430 07:41:38.743589  6612 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:41:38.743593  6612 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:41:38.743613  6612 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:41:38.743621  6612 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:41:38.743625  6612 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:41:38.743633  6612 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:41:38.743641  6612 net.cpp:124] Setting up relu7\n",
      "I0430 07:41:38.743644  6612 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:41:38.743646  6612 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:41:38.743649  6612 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:41:38.743655  6612 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:41:38.743659  6612 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:41:38.743665  6612 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:41:38.743671  6612 net.cpp:124] Setting up drop7\n",
      "I0430 07:41:38.743675  6612 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:41:38.743679  6612 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:41:38.743681  6612 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:41:38.743686  6612 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:41:38.743690  6612 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:41:38.743695  6612 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:41:38.744607  6612 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:41:38.744618  6612 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:41:38.744622  6612 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:41:38.744629  6612 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:41:38.744632  6612 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:41:38.744635  6612 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:41:38.744639  6612 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:41:38.744643  6612 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:41:38.744647  6612 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:41:38.744649  6612 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:41:38.744652  6612 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:41:38.744657  6612 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:41:38.744659  6612 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:41:38.744663  6612 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:41:38.744666  6612 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:41:38.744669  6612 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:41:38.744673  6612 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:41:38.744676  6612 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:41:38.744679  6612 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:41:38.744683  6612 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:41:38.744685  6612 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:41:38.744689  6612 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:41:38.744693  6612 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:41:38.744696  6612 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:41:38.744699  6612 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:41:38.744702  6612 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:41:38.744705  6612 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:41:38.744716  6612 net.cpp:257] Network initialization done.\n",
      "I0430 07:41:38.828063  6612 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:41:38.925900  6612 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:41:38.926880  6612 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:41:38.926889  6612 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:41:38.926894  6612 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/192858.jpg'}, '/tmp/tmpkgGZTD.mat')\n",
      "Processed 2838 windows in 322.887 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.22882, -2.36234, -2.1368, -2.43033, -1.852...\n",
      "ymin                                                         36\n",
      "xmin                                                          0\n",
      "ymax                                                        260\n",
      "xmax                                                         89\n",
      "Name: /home/ambika/INF_project/data/person/192858.jpg, dtype: object\n",
      "prediction    [-1.3185, -2.23834, -2.50079, -2.81569, -2.230...\n",
      "ymin                                                        156\n",
      "xmin                                                         49\n",
      "ymax                                                        319\n",
      "xmax                                                        353\n",
      "Name: /home/ambika/INF_project/data/person/192858.jpg, dtype: object\n",
      "person\n",
      "0\t36\t89\t260\n",
      "frying pan\n",
      "49\t156\t353\t319\n",
      "192858\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:47:03.441143  6831 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:47:03.441161  6831 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:47:03.441165  6831 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:47:03.442252  6831 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:47:03.442411  6831 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:47:03.442420  6831 net.cpp:86] Creating Layer data\n",
      "I0430 07:47:03.442425  6831 net.cpp:382] data -> data\n",
      "I0430 07:47:03.442437  6831 net.cpp:124] Setting up data\n",
      "I0430 07:47:03.442443  6831 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:47:03.442446  6831 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:47:03.442451  6831 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:47:03.442458  6831 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:47:03.442461  6831 net.cpp:408] conv1 <- data\n",
      "I0430 07:47:03.442466  6831 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:47:03.442524  6831 net.cpp:124] Setting up conv1\n",
      "I0430 07:47:03.442530  6831 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:47:03.442533  6831 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:47:03.442540  6831 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:47:03.442545  6831 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:47:03.442548  6831 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:47:03.442553  6831 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:47:03.442559  6831 net.cpp:124] Setting up relu1\n",
      "I0430 07:47:03.442562  6831 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:47:03.442564  6831 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:47:03.442567  6831 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:47:03.442572  6831 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:47:03.442575  6831 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:47:03.442579  6831 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:47:03.442586  6831 net.cpp:124] Setting up pool1\n",
      "I0430 07:47:03.442590  6831 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:47:03.442594  6831 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:47:03.442596  6831 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:47:03.442601  6831 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:47:03.442605  6831 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:47:03.442608  6831 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:47:03.442615  6831 net.cpp:124] Setting up norm1\n",
      "I0430 07:47:03.442618  6831 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:47:03.442621  6831 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:47:03.442625  6831 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:47:03.442629  6831 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:47:03.442631  6831 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:47:03.442636  6831 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:47:03.442989  6831 net.cpp:124] Setting up conv2\n",
      "I0430 07:47:03.442996  6831 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:47:03.442999  6831 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:47:03.443006  6831 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:47:03.443011  6831 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:47:03.443013  6831 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:47:03.443017  6831 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:47:03.443022  6831 net.cpp:124] Setting up relu2\n",
      "I0430 07:47:03.443027  6831 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:47:03.443028  6831 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:47:03.443032  6831 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:47:03.443037  6831 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:47:03.443038  6831 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:47:03.443043  6831 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:47:03.443048  6831 net.cpp:124] Setting up pool2\n",
      "I0430 07:47:03.443053  6831 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:47:03.443055  6831 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:47:03.443058  6831 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:47:03.443064  6831 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:47:03.443068  6831 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:47:03.443071  6831 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:47:03.443078  6831 net.cpp:124] Setting up norm2\n",
      "I0430 07:47:03.443081  6831 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:47:03.443084  6831 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:47:03.443086  6831 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:47:03.443094  6831 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:47:03.443096  6831 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:47:03.443100  6831 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:47:03.444072  6831 net.cpp:124] Setting up conv3\n",
      "I0430 07:47:03.444083  6831 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:47:03.444087  6831 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:47:03.444095  6831 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:47:03.444102  6831 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:47:03.444104  6831 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:47:03.444108  6831 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:47:03.444114  6831 net.cpp:124] Setting up relu3\n",
      "I0430 07:47:03.444118  6831 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:47:03.444120  6831 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:47:03.444123  6831 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:47:03.444129  6831 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:47:03.444133  6831 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:47:03.444138  6831 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:47:03.444635  6831 net.cpp:124] Setting up conv4\n",
      "I0430 07:47:03.444643  6831 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:47:03.444646  6831 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:47:03.444653  6831 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:47:03.444656  6831 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:47:03.444659  6831 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:47:03.444664  6831 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:47:03.444669  6831 net.cpp:124] Setting up relu4\n",
      "I0430 07:47:03.444672  6831 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:47:03.444674  6831 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:47:03.444679  6831 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:47:03.444684  6831 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:47:03.444686  6831 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:47:03.444691  6831 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:47:03.445174  6831 net.cpp:124] Setting up conv5\n",
      "I0430 07:47:03.445181  6831 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:47:03.445184  6831 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:47:03.445194  6831 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:47:03.445199  6831 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:47:03.445201  6831 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:47:03.445205  6831 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:47:03.445210  6831 net.cpp:124] Setting up relu5\n",
      "I0430 07:47:03.445214  6831 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:47:03.445217  6831 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:47:03.445220  6831 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:47:03.445225  6831 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:47:03.445227  6831 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:47:03.445232  6831 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:47:03.445240  6831 net.cpp:124] Setting up pool5\n",
      "I0430 07:47:03.445245  6831 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:47:03.445246  6831 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:47:03.445250  6831 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:47:03.445257  6831 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:47:03.445261  6831 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:47:03.445264  6831 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:47:03.468716  6831 net.cpp:124] Setting up fc6\n",
      "I0430 07:47:03.468741  6831 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:47:03.468746  6831 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:47:03.468757  6831 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:47:03.468766  6831 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:47:03.468770  6831 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:47:03.468776  6831 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:47:03.468783  6831 net.cpp:124] Setting up relu6\n",
      "I0430 07:47:03.468788  6831 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:47:03.468791  6831 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:47:03.468794  6831 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:47:03.468801  6831 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:47:03.468802  6831 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:47:03.468806  6831 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:47:03.468812  6831 net.cpp:124] Setting up drop6\n",
      "I0430 07:47:03.468816  6831 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:47:03.468818  6831 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:47:03.468822  6831 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:47:03.468827  6831 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:47:03.468830  6831 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:47:03.468835  6831 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:47:03.478358  6831 net.cpp:124] Setting up fc7\n",
      "I0430 07:47:03.478377  6831 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:47:03.478380  6831 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:47:03.478391  6831 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:47:03.478400  6831 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:47:03.478404  6831 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:47:03.478410  6831 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:47:03.478417  6831 net.cpp:124] Setting up relu7\n",
      "I0430 07:47:03.478421  6831 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:47:03.478425  6831 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:47:03.478427  6831 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:47:03.478435  6831 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:47:03.478437  6831 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:47:03.478441  6831 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:47:03.478446  6831 net.cpp:124] Setting up drop7\n",
      "I0430 07:47:03.478451  6831 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:47:03.478453  6831 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:47:03.478456  6831 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:47:03.478461  6831 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:47:03.478464  6831 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:47:03.478469  6831 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:47:03.479148  6831 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:47:03.479161  6831 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:47:03.479164  6831 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:47:03.479171  6831 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:47:03.479176  6831 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:47:03.479178  6831 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:47:03.479182  6831 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:47:03.479185  6831 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:47:03.479188  6831 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:47:03.479192  6831 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:47:03.479195  6831 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:47:03.479199  6831 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:47:03.479202  6831 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:47:03.479212  6831 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:47:03.479215  6831 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:47:03.479218  6831 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:47:03.479223  6831 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:47:03.479225  6831 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:47:03.479229  6831 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:47:03.479233  6831 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:47:03.479235  6831 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:47:03.479239  6831 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:47:03.479243  6831 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:47:03.479246  6831 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:47:03.479249  6831 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:47:03.479252  6831 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:47:03.479255  6831 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:47:03.479266  6831 net.cpp:257] Network initialization done.\n",
      "I0430 07:47:03.564627  6831 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:47:03.666891  6831 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:47:03.667853  6831 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:47:03.667866  6831 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:47:03.667868  6831 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/563665.jpg'}, '/tmp/tmpbPK8zO.mat')\n",
      "Processed 2592 windows in 300.325 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.47508, -1.78375, -2.07366, -2.0512, -1.698...\n",
      "ymin                                                         62\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/train/563665.jpg, dtype: object\n",
      "prediction    [-2.2226, -2.27207, -2.36265, -2.07779, -2.012...\n",
      "ymin                                                         70\n",
      "xmin                                                        177\n",
      "ymax                                                        362\n",
      "xmax                                                        423\n",
      "Name: /home/ambika/INF_project/data/train/563665.jpg, dtype: object\n",
      "train\n",
      "0\t62\t500\t375\n",
      "bus\n",
      "177\t70\t423\t362\n",
      "563665\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:52:05.545648  7029 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:52:05.545670  7029 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:52:05.545673  7029 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:52:05.546835  7029 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:52:05.546932  7029 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:52:05.546941  7029 net.cpp:86] Creating Layer data\n",
      "I0430 07:52:05.546949  7029 net.cpp:382] data -> data\n",
      "I0430 07:52:05.546965  7029 net.cpp:124] Setting up data\n",
      "I0430 07:52:05.546972  7029 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:52:05.546974  7029 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:52:05.546977  7029 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:52:05.546984  7029 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:52:05.546988  7029 net.cpp:408] conv1 <- data\n",
      "I0430 07:52:05.546993  7029 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:52:05.547051  7029 net.cpp:124] Setting up conv1\n",
      "I0430 07:52:05.547057  7029 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:52:05.547061  7029 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:52:05.547071  7029 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:52:05.547077  7029 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:52:05.547080  7029 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:52:05.547086  7029 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:52:05.547091  7029 net.cpp:124] Setting up relu1\n",
      "I0430 07:52:05.547096  7029 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:52:05.547101  7029 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:52:05.547104  7029 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:52:05.547109  7029 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:52:05.547113  7029 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:52:05.547118  7029 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:52:05.547127  7029 net.cpp:124] Setting up pool1\n",
      "I0430 07:52:05.547130  7029 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:52:05.547133  7029 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:52:05.547137  7029 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:52:05.547142  7029 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:52:05.547144  7029 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:52:05.547149  7029 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:52:05.547154  7029 net.cpp:124] Setting up norm1\n",
      "I0430 07:52:05.547159  7029 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:52:05.547161  7029 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:52:05.547164  7029 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:52:05.547169  7029 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:52:05.547173  7029 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:52:05.547178  7029 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:52:05.547528  7029 net.cpp:124] Setting up conv2\n",
      "I0430 07:52:05.547534  7029 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:52:05.547538  7029 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:52:05.547544  7029 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:52:05.547549  7029 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:52:05.547551  7029 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:52:05.547556  7029 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:52:05.547561  7029 net.cpp:124] Setting up relu2\n",
      "I0430 07:52:05.547565  7029 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:52:05.547567  7029 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:52:05.547570  7029 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:52:05.547575  7029 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:52:05.547579  7029 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:52:05.547583  7029 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:52:05.547590  7029 net.cpp:124] Setting up pool2\n",
      "I0430 07:52:05.547593  7029 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:52:05.547595  7029 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:52:05.547598  7029 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:52:05.547603  7029 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:52:05.547606  7029 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:52:05.547610  7029 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:52:05.547616  7029 net.cpp:124] Setting up norm2\n",
      "I0430 07:52:05.547621  7029 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:52:05.547622  7029 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:52:05.547626  7029 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:52:05.547631  7029 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:52:05.547634  7029 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:52:05.547639  7029 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:52:05.548377  7029 net.cpp:124] Setting up conv3\n",
      "I0430 07:52:05.548393  7029 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:52:05.548398  7029 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:52:05.548408  7029 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:52:05.548418  7029 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:52:05.548424  7029 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:52:05.548429  7029 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:52:05.548437  7029 net.cpp:124] Setting up relu3\n",
      "I0430 07:52:05.548442  7029 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:52:05.548445  7029 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:52:05.548449  7029 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:52:05.548455  7029 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:52:05.548460  7029 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:52:05.548465  7029 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:52:05.549489  7029 net.cpp:124] Setting up conv4\n",
      "I0430 07:52:05.549512  7029 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:52:05.549516  7029 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:52:05.549525  7029 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:52:05.549535  7029 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:52:05.549540  7029 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:52:05.549546  7029 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:52:05.549556  7029 net.cpp:124] Setting up relu4\n",
      "I0430 07:52:05.549561  7029 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:52:05.549564  7029 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:52:05.549567  7029 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:52:05.549574  7029 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:52:05.549578  7029 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:52:05.549585  7029 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:52:05.550263  7029 net.cpp:124] Setting up conv5\n",
      "I0430 07:52:05.550278  7029 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:52:05.550282  7029 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:52:05.550294  7029 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:52:05.550302  7029 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:52:05.550307  7029 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:52:05.550312  7029 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:52:05.550323  7029 net.cpp:124] Setting up relu5\n",
      "I0430 07:52:05.550326  7029 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:52:05.550330  7029 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:52:05.550333  7029 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:52:05.550344  7029 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:52:05.550348  7029 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:52:05.550353  7029 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:52:05.550364  7029 net.cpp:124] Setting up pool5\n",
      "I0430 07:52:05.550369  7029 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:52:05.550374  7029 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:52:05.550376  7029 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:52:05.550384  7029 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:52:05.550387  7029 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:52:05.550393  7029 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:52:05.573899  7029 net.cpp:124] Setting up fc6\n",
      "I0430 07:52:05.573925  7029 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:52:05.573930  7029 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:52:05.573940  7029 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:52:05.573948  7029 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:52:05.573952  7029 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:52:05.573958  7029 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:52:05.573966  7029 net.cpp:124] Setting up relu6\n",
      "I0430 07:52:05.573971  7029 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:52:05.573973  7029 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:52:05.573976  7029 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:52:05.573982  7029 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:52:05.573984  7029 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:52:05.573990  7029 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:52:05.573995  7029 net.cpp:124] Setting up drop6\n",
      "I0430 07:52:05.573999  7029 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:52:05.574002  7029 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:52:05.574004  7029 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:52:05.574009  7029 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:52:05.574012  7029 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:52:05.574017  7029 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:52:05.583955  7029 net.cpp:124] Setting up fc7\n",
      "I0430 07:52:05.583978  7029 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:52:05.583983  7029 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:52:05.583994  7029 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:52:05.584002  7029 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:52:05.584007  7029 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:52:05.584014  7029 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:52:05.584022  7029 net.cpp:124] Setting up relu7\n",
      "I0430 07:52:05.584026  7029 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:52:05.584030  7029 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:52:05.584033  7029 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:52:05.584039  7029 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:52:05.584041  7029 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:52:05.584048  7029 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:52:05.584053  7029 net.cpp:124] Setting up drop7\n",
      "I0430 07:52:05.584056  7029 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:52:05.584059  7029 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:52:05.584062  7029 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:52:05.584069  7029 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:52:05.584070  7029 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:52:05.584075  7029 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:52:05.584974  7029 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:52:05.584983  7029 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:52:05.584986  7029 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:52:05.584993  7029 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:52:05.584997  7029 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:52:05.585000  7029 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:52:05.585003  7029 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:52:05.585007  7029 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:52:05.585011  7029 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:52:05.585013  7029 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:52:05.585017  7029 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:52:05.585021  7029 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:52:05.585023  7029 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:52:05.585027  7029 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:52:05.585031  7029 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:52:05.585033  7029 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:52:05.585037  7029 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:52:05.585041  7029 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:52:05.585044  7029 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:52:05.585048  7029 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:52:05.585052  7029 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:52:05.585055  7029 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:52:05.585058  7029 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:52:05.585062  7029 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:52:05.585065  7029 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:52:05.585068  7029 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:52:05.585072  7029 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:52:05.585083  7029 net.cpp:257] Network initialization done.\n",
      "I0430 07:52:05.670845  7029 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:52:05.769804  7029 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:52:05.770745  7029 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:52:05.770752  7029 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:52:05.770762  7029 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/279343.jpg'}, '/tmp/tmpiJJ5pe.mat')\n",
      "Processed 1259 windows in 147.807 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-2.67435, 0.936597, -2.85771, -2.24791, -1.94...\n",
      "ymin                                                        174\n",
      "xmin                                                          0\n",
      "ymax                                                        292\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/airplane/279343.jpg, dtype: object\n",
      "prediction    [-2.29982, -1.94833, -2.55286, -1.8949, -2.752...\n",
      "ymin                                                        177\n",
      "xmin                                                        111\n",
      "ymax                                                        225\n",
      "xmax                                                        196\n",
      "Name: /home/ambika/INF_project/data/airplane/279343.jpg, dtype: object\n",
      "airplane\n",
      "0\t174\t500\t292\n",
      "seal\n",
      "111\t177\t196\t225\n",
      "279343\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:54:35.082990  7193 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:54:35.083012  7193 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:54:35.083015  7193 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:54:35.084147  7193 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:54:35.084316  7193 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:54:35.084324  7193 net.cpp:86] Creating Layer data\n",
      "I0430 07:54:35.084327  7193 net.cpp:382] data -> data\n",
      "I0430 07:54:35.084341  7193 net.cpp:124] Setting up data\n",
      "I0430 07:54:35.084348  7193 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:54:35.084350  7193 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:54:35.084353  7193 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:54:35.084358  7193 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:54:35.084360  7193 net.cpp:408] conv1 <- data\n",
      "I0430 07:54:35.084363  7193 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:54:35.084420  7193 net.cpp:124] Setting up conv1\n",
      "I0430 07:54:35.084425  7193 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:54:35.084427  7193 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:54:35.084434  7193 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:54:35.084439  7193 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:54:35.084442  7193 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:54:35.084445  7193 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:54:35.084450  7193 net.cpp:124] Setting up relu1\n",
      "I0430 07:54:35.084453  7193 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:54:35.084455  7193 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:54:35.084458  7193 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:54:35.084461  7193 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:54:35.084463  7193 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:54:35.084467  7193 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:54:35.084473  7193 net.cpp:124] Setting up pool1\n",
      "I0430 07:54:35.084477  7193 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:54:35.084480  7193 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:54:35.084481  7193 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:54:35.084486  7193 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:54:35.084488  7193 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:54:35.084491  7193 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:54:35.084496  7193 net.cpp:124] Setting up norm1\n",
      "I0430 07:54:35.084501  7193 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:54:35.084502  7193 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:54:35.084504  7193 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:54:35.084508  7193 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:54:35.084511  7193 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:54:35.084514  7193 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:54:35.084862  7193 net.cpp:124] Setting up conv2\n",
      "I0430 07:54:35.084867  7193 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:54:35.084869  7193 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:54:35.084875  7193 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:54:35.084878  7193 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:54:35.084882  7193 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:54:35.084884  7193 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:54:35.084888  7193 net.cpp:124] Setting up relu2\n",
      "I0430 07:54:35.084892  7193 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:54:35.084894  7193 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:54:35.084898  7193 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:54:35.084903  7193 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:54:35.084906  7193 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:54:35.084911  7193 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:54:35.084918  7193 net.cpp:124] Setting up pool2\n",
      "I0430 07:54:35.084923  7193 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:54:35.084925  7193 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:54:35.084928  7193 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:54:35.084935  7193 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:54:35.084939  7193 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:54:35.084944  7193 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:54:35.084949  7193 net.cpp:124] Setting up norm2\n",
      "I0430 07:54:35.084954  7193 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:54:35.084955  7193 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:54:35.084959  7193 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:54:35.084965  7193 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:54:35.084969  7193 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:54:35.084974  7193 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:54:35.085935  7193 net.cpp:124] Setting up conv3\n",
      "I0430 07:54:35.085947  7193 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:54:35.085949  7193 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:54:35.085959  7193 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:54:35.085965  7193 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:54:35.085968  7193 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:54:35.085973  7193 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:54:35.085978  7193 net.cpp:124] Setting up relu3\n",
      "I0430 07:54:35.085983  7193 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:54:35.085985  7193 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:54:35.085989  7193 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:54:35.085996  7193 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:54:35.085999  7193 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:54:35.086004  7193 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:54:35.086486  7193 net.cpp:124] Setting up conv4\n",
      "I0430 07:54:35.086495  7193 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:54:35.086498  7193 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:54:35.086505  7193 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:54:35.086510  7193 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:54:35.086513  7193 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:54:35.086519  7193 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:54:35.086524  7193 net.cpp:124] Setting up relu4\n",
      "I0430 07:54:35.086527  7193 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:54:35.086530  7193 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:54:35.086534  7193 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:54:35.086539  7193 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:54:35.086541  7193 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:54:35.086546  7193 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:54:35.087020  7193 net.cpp:124] Setting up conv5\n",
      "I0430 07:54:35.087028  7193 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:54:35.087031  7193 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:54:35.087040  7193 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:54:35.087044  7193 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:54:35.087047  7193 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:54:35.087052  7193 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:54:35.087056  7193 net.cpp:124] Setting up relu5\n",
      "I0430 07:54:35.087061  7193 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:54:35.087064  7193 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:54:35.087066  7193 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:54:35.087072  7193 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:54:35.087075  7193 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:54:35.087080  7193 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:54:35.087087  7193 net.cpp:124] Setting up pool5\n",
      "I0430 07:54:35.087091  7193 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:54:35.087095  7193 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:54:35.087097  7193 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:54:35.087105  7193 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:54:35.087108  7193 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:54:35.087113  7193 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:54:35.110357  7193 net.cpp:124] Setting up fc6\n",
      "I0430 07:54:35.110383  7193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:54:35.110388  7193 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:54:35.110402  7193 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:54:35.110414  7193 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:54:35.110416  7193 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:54:35.110420  7193 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:54:35.110426  7193 net.cpp:124] Setting up relu6\n",
      "I0430 07:54:35.110430  7193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:54:35.110430  7193 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:54:35.110433  7193 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:54:35.110437  7193 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:54:35.110438  7193 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:54:35.110441  7193 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:54:35.110447  7193 net.cpp:124] Setting up drop6\n",
      "I0430 07:54:35.110452  7193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:54:35.110455  7193 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:54:35.110458  7193 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:54:35.110466  7193 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:54:35.110468  7193 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:54:35.110474  7193 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:54:35.120770  7193 net.cpp:124] Setting up fc7\n",
      "I0430 07:54:35.120796  7193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:54:35.120801  7193 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:54:35.120815  7193 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:54:35.120824  7193 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:54:35.120827  7193 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:54:35.120832  7193 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:54:35.120839  7193 net.cpp:124] Setting up relu7\n",
      "I0430 07:54:35.120842  7193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:54:35.120843  7193 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:54:35.120846  7193 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:54:35.120849  7193 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:54:35.120851  7193 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:54:35.120854  7193 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:54:35.120868  7193 net.cpp:124] Setting up drop7\n",
      "I0430 07:54:35.120872  7193 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:54:35.120874  7193 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:54:35.120877  7193 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:54:35.120882  7193 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:54:35.120883  7193 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:54:35.120887  7193 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:54:35.121496  7193 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:54:35.121505  7193 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:54:35.121507  7193 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:54:35.121512  7193 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:54:35.121515  7193 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:54:35.121516  7193 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:54:35.121518  7193 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:54:35.121521  7193 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:54:35.121523  7193 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:54:35.121526  7193 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:54:35.121529  7193 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:54:35.121531  7193 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:54:35.121534  7193 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:54:35.121536  7193 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:54:35.121539  7193 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:54:35.121542  7193 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:54:35.121544  7193 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:54:35.121547  7193 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:54:35.121551  7193 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:54:35.121553  7193 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:54:35.121558  7193 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:54:35.121562  7193 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:54:35.121567  7193 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:54:35.121570  7193 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:54:35.121574  7193 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:54:35.121577  7193 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:54:35.121578  7193 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:54:35.121589  7193 net.cpp:257] Network initialization done.\n",
      "I0430 07:54:35.206477  7193 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:54:35.302669  7193 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:54:35.303553  7193 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:54:35.303561  7193 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:54:35.303563  7193 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/436551.jpg'}, '/tmp/tmpM604II.mat')\n",
      "Processed 1461 windows in 170.066 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.51588, -2.45105, -2.83253, -3.66777, -2.17...\n",
      "ymin                                                         55\n",
      "xmin                                                         49\n",
      "ymax                                                        322\n",
      "xmax                                                        388\n",
      "Name: /home/ambika/INF_project/data/bird/436551.jpg, dtype: object\n",
      "prediction    [-2.16631, -2.12309, -1.57442, -2.79847, -1.87...\n",
      "ymin                                                        211\n",
      "xmin                                                         10\n",
      "ymax                                                        342\n",
      "xmax                                                        354\n",
      "Name: /home/ambika/INF_project/data/bird/436551.jpg, dtype: object\n",
      "bird\n",
      "49\t55\t388\t322\n",
      "dog\n",
      "10\t211\t354\t342\n",
      "436551\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 07:57:26.898986  7350 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 07:57:26.899003  7350 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 07:57:26.899006  7350 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 07:57:26.900161  7350 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 07:57:26.900261  7350 layer_factory.hpp:77] Creating layer data\n",
      "I0430 07:57:26.900270  7350 net.cpp:86] Creating Layer data\n",
      "I0430 07:57:26.900274  7350 net.cpp:382] data -> data\n",
      "I0430 07:57:26.900288  7350 net.cpp:124] Setting up data\n",
      "I0430 07:57:26.900295  7350 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 07:57:26.900297  7350 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 07:57:26.900301  7350 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 07:57:26.900308  7350 net.cpp:86] Creating Layer conv1\n",
      "I0430 07:57:26.900311  7350 net.cpp:408] conv1 <- data\n",
      "I0430 07:57:26.900316  7350 net.cpp:382] conv1 -> conv1\n",
      "I0430 07:57:26.900377  7350 net.cpp:124] Setting up conv1\n",
      "I0430 07:57:26.900382  7350 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:57:26.900385  7350 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 07:57:26.900394  7350 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 07:57:26.900401  7350 net.cpp:86] Creating Layer relu1\n",
      "I0430 07:57:26.900404  7350 net.cpp:408] relu1 <- conv1\n",
      "I0430 07:57:26.900408  7350 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 07:57:26.900414  7350 net.cpp:124] Setting up relu1\n",
      "I0430 07:57:26.900419  7350 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 07:57:26.900423  7350 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 07:57:26.900425  7350 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 07:57:26.900431  7350 net.cpp:86] Creating Layer pool1\n",
      "I0430 07:57:26.900434  7350 net.cpp:408] pool1 <- conv1\n",
      "I0430 07:57:26.900439  7350 net.cpp:382] pool1 -> pool1\n",
      "I0430 07:57:26.900446  7350 net.cpp:124] Setting up pool1\n",
      "I0430 07:57:26.900451  7350 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:57:26.900454  7350 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 07:57:26.900456  7350 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 07:57:26.900462  7350 net.cpp:86] Creating Layer norm1\n",
      "I0430 07:57:26.900465  7350 net.cpp:408] norm1 <- pool1\n",
      "I0430 07:57:26.900470  7350 net.cpp:382] norm1 -> norm1\n",
      "I0430 07:57:26.900475  7350 net.cpp:124] Setting up norm1\n",
      "I0430 07:57:26.900480  7350 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 07:57:26.900482  7350 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 07:57:26.900485  7350 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 07:57:26.900491  7350 net.cpp:86] Creating Layer conv2\n",
      "I0430 07:57:26.900493  7350 net.cpp:408] conv2 <- norm1\n",
      "I0430 07:57:26.900498  7350 net.cpp:382] conv2 -> conv2\n",
      "I0430 07:57:26.900861  7350 net.cpp:124] Setting up conv2\n",
      "I0430 07:57:26.900867  7350 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:57:26.900871  7350 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 07:57:26.900879  7350 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 07:57:26.900884  7350 net.cpp:86] Creating Layer relu2\n",
      "I0430 07:57:26.900887  7350 net.cpp:408] relu2 <- conv2\n",
      "I0430 07:57:26.900892  7350 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 07:57:26.900897  7350 net.cpp:124] Setting up relu2\n",
      "I0430 07:57:26.900902  7350 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 07:57:26.900904  7350 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 07:57:26.900908  7350 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 07:57:26.900913  7350 net.cpp:86] Creating Layer pool2\n",
      "I0430 07:57:26.900916  7350 net.cpp:408] pool2 <- conv2\n",
      "I0430 07:57:26.900921  7350 net.cpp:382] pool2 -> pool2\n",
      "I0430 07:57:26.900928  7350 net.cpp:124] Setting up pool2\n",
      "I0430 07:57:26.900933  7350 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:57:26.900934  7350 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 07:57:26.900938  7350 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 07:57:26.900943  7350 net.cpp:86] Creating Layer norm2\n",
      "I0430 07:57:26.900946  7350 net.cpp:408] norm2 <- pool2\n",
      "I0430 07:57:26.900950  7350 net.cpp:382] norm2 -> norm2\n",
      "I0430 07:57:26.900956  7350 net.cpp:124] Setting up norm2\n",
      "I0430 07:57:26.900960  7350 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:57:26.900964  7350 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 07:57:26.900966  7350 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 07:57:26.900972  7350 net.cpp:86] Creating Layer conv3\n",
      "I0430 07:57:26.900975  7350 net.cpp:408] conv3 <- norm2\n",
      "I0430 07:57:26.900979  7350 net.cpp:382] conv3 -> conv3\n",
      "I0430 07:57:26.901674  7350 net.cpp:124] Setting up conv3\n",
      "I0430 07:57:26.901697  7350 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:57:26.901700  7350 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 07:57:26.901710  7350 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 07:57:26.901715  7350 net.cpp:86] Creating Layer relu3\n",
      "I0430 07:57:26.901720  7350 net.cpp:408] relu3 <- conv3\n",
      "I0430 07:57:26.901724  7350 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 07:57:26.901731  7350 net.cpp:124] Setting up relu3\n",
      "I0430 07:57:26.901734  7350 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:57:26.901737  7350 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 07:57:26.901741  7350 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 07:57:26.901747  7350 net.cpp:86] Creating Layer conv4\n",
      "I0430 07:57:26.901751  7350 net.cpp:408] conv4 <- conv3\n",
      "I0430 07:57:26.901756  7350 net.cpp:382] conv4 -> conv4\n",
      "I0430 07:57:26.902562  7350 net.cpp:124] Setting up conv4\n",
      "I0430 07:57:26.902583  7350 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:57:26.902587  7350 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 07:57:26.902595  7350 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 07:57:26.902604  7350 net.cpp:86] Creating Layer relu4\n",
      "I0430 07:57:26.902608  7350 net.cpp:408] relu4 <- conv4\n",
      "I0430 07:57:26.902613  7350 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 07:57:26.902621  7350 net.cpp:124] Setting up relu4\n",
      "I0430 07:57:26.902624  7350 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 07:57:26.902627  7350 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 07:57:26.902631  7350 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 07:57:26.902637  7350 net.cpp:86] Creating Layer conv5\n",
      "I0430 07:57:26.902639  7350 net.cpp:408] conv5 <- conv4\n",
      "I0430 07:57:26.902644  7350 net.cpp:382] conv5 -> conv5\n",
      "I0430 07:57:26.903149  7350 net.cpp:124] Setting up conv5\n",
      "I0430 07:57:26.903158  7350 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:57:26.903162  7350 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 07:57:26.903173  7350 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 07:57:26.903179  7350 net.cpp:86] Creating Layer relu5\n",
      "I0430 07:57:26.903182  7350 net.cpp:408] relu5 <- conv5\n",
      "I0430 07:57:26.903187  7350 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 07:57:26.903192  7350 net.cpp:124] Setting up relu5\n",
      "I0430 07:57:26.903197  7350 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 07:57:26.903199  7350 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 07:57:26.903203  7350 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 07:57:26.903215  7350 net.cpp:86] Creating Layer pool5\n",
      "I0430 07:57:26.903218  7350 net.cpp:408] pool5 <- conv5\n",
      "I0430 07:57:26.903223  7350 net.cpp:382] pool5 -> pool5\n",
      "I0430 07:57:26.903230  7350 net.cpp:124] Setting up pool5\n",
      "I0430 07:57:26.903235  7350 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 07:57:26.903237  7350 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 07:57:26.903241  7350 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 07:57:26.903249  7350 net.cpp:86] Creating Layer fc6\n",
      "I0430 07:57:26.903252  7350 net.cpp:408] fc6 <- pool5\n",
      "I0430 07:57:26.903257  7350 net.cpp:382] fc6 -> fc6\n",
      "I0430 07:57:26.930603  7350 net.cpp:124] Setting up fc6\n",
      "I0430 07:57:26.930649  7350 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:57:26.930654  7350 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 07:57:26.930665  7350 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 07:57:26.930676  7350 net.cpp:86] Creating Layer relu6\n",
      "I0430 07:57:26.930682  7350 net.cpp:408] relu6 <- fc6\n",
      "I0430 07:57:26.930688  7350 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 07:57:26.930698  7350 net.cpp:124] Setting up relu6\n",
      "I0430 07:57:26.930703  7350 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:57:26.930706  7350 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 07:57:26.930711  7350 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 07:57:26.930717  7350 net.cpp:86] Creating Layer drop6\n",
      "I0430 07:57:26.930721  7350 net.cpp:408] drop6 <- fc6\n",
      "I0430 07:57:26.930727  7350 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 07:57:26.930735  7350 net.cpp:124] Setting up drop6\n",
      "I0430 07:57:26.930739  7350 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:57:26.930743  7350 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 07:57:26.930747  7350 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 07:57:26.930753  7350 net.cpp:86] Creating Layer fc7\n",
      "I0430 07:57:26.930757  7350 net.cpp:408] fc7 <- fc6\n",
      "I0430 07:57:26.930763  7350 net.cpp:382] fc7 -> fc7\n",
      "I0430 07:57:26.941973  7350 net.cpp:124] Setting up fc7\n",
      "I0430 07:57:26.942000  7350 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:57:26.942008  7350 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 07:57:26.942049  7350 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 07:57:26.942059  7350 net.cpp:86] Creating Layer relu7\n",
      "I0430 07:57:26.942062  7350 net.cpp:408] relu7 <- fc7\n",
      "I0430 07:57:26.942068  7350 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 07:57:26.942075  7350 net.cpp:124] Setting up relu7\n",
      "I0430 07:57:26.942080  7350 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:57:26.942081  7350 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 07:57:26.942085  7350 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 07:57:26.942090  7350 net.cpp:86] Creating Layer drop7\n",
      "I0430 07:57:26.942091  7350 net.cpp:408] drop7 <- fc7\n",
      "I0430 07:57:26.942095  7350 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 07:57:26.942101  7350 net.cpp:124] Setting up drop7\n",
      "I0430 07:57:26.942103  7350 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 07:57:26.942106  7350 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 07:57:26.942107  7350 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 07:57:26.942113  7350 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 07:57:26.942117  7350 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 07:57:26.942122  7350 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 07:57:26.942752  7350 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 07:57:26.942764  7350 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 07:57:26.942766  7350 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 07:57:26.942771  7350 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 07:57:26.942775  7350 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 07:57:26.942776  7350 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 07:57:26.942777  7350 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 07:57:26.942780  7350 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 07:57:26.942781  7350 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 07:57:26.942785  7350 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 07:57:26.942787  7350 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 07:57:26.942790  7350 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 07:57:26.942792  7350 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 07:57:26.942795  7350 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 07:57:26.942797  7350 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 07:57:26.942800  7350 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 07:57:26.942803  7350 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 07:57:26.942806  7350 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 07:57:26.942809  7350 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 07:57:26.942811  7350 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 07:57:26.942814  7350 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 07:57:26.942817  7350 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 07:57:26.942819  7350 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 07:57:26.942822  7350 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 07:57:26.942824  7350 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 07:57:26.942827  7350 net.cpp:202] data does not need backward computation.\n",
      "I0430 07:57:26.942829  7350 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 07:57:26.942840  7350 net.cpp:257] Network initialization done.\n",
      "I0430 07:57:27.026195  7350 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:57:27.122826  7350 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 07:57:27.123716  7350 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 07:57:27.123723  7350 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 07:57:27.123728  7350 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/524775.jpg'}, '/tmp/tmpKZ_3EY.mat')\n",
      "Processed 1749 windows in 199.281 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.18726, -2.22741, -2.10326, -2.42934, -1.96...\n",
      "ymin                                                         62\n",
      "xmin                                                        274\n",
      "ymax                                                        281\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/bus/524775.jpg, dtype: object\n",
      "prediction    [-2.04459, -2.54993, -1.85209, -1.62617, -1.76...\n",
      "ymin                                                        156\n",
      "xmin                                                          0\n",
      "ymax                                                        224\n",
      "xmax                                                        106\n",
      "Name: /home/ambika/INF_project/data/bus/524775.jpg, dtype: object\n",
      "bus\n",
      "274\t62\t500\t281\n",
      "car\n",
      "0\t156\t106\t224\n",
      "524775\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:00:47.964994  7518 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:00:47.965014  7518 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:00:47.965018  7518 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:00:47.966382  7518 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:00:47.966490  7518 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:00:47.966503  7518 net.cpp:86] Creating Layer data\n",
      "I0430 08:00:47.966507  7518 net.cpp:382] data -> data\n",
      "I0430 08:00:47.966521  7518 net.cpp:124] Setting up data\n",
      "I0430 08:00:47.966527  7518 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:00:47.966531  7518 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:00:47.966534  7518 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:00:47.966542  7518 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:00:47.966544  7518 net.cpp:408] conv1 <- data\n",
      "I0430 08:00:47.966549  7518 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:00:47.966612  7518 net.cpp:124] Setting up conv1\n",
      "I0430 08:00:47.966619  7518 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:00:47.966621  7518 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:00:47.966630  7518 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:00:47.966636  7518 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:00:47.966639  7518 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:00:47.966644  7518 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:00:47.966648  7518 net.cpp:124] Setting up relu1\n",
      "I0430 08:00:47.966652  7518 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:00:47.966655  7518 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:00:47.966658  7518 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:00:47.966663  7518 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:00:47.966666  7518 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:00:47.966670  7518 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:00:47.966680  7518 net.cpp:124] Setting up pool1\n",
      "I0430 08:00:47.966684  7518 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:00:47.966687  7518 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:00:47.966691  7518 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:00:47.966696  7518 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:00:47.966699  7518 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:00:47.966703  7518 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:00:47.966709  7518 net.cpp:124] Setting up norm1\n",
      "I0430 08:00:47.966714  7518 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:00:47.966717  7518 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:00:47.966719  7518 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:00:47.966725  7518 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:00:47.966727  7518 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:00:47.966732  7518 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:00:47.967097  7518 net.cpp:124] Setting up conv2\n",
      "I0430 08:00:47.967104  7518 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:00:47.967108  7518 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:00:47.967116  7518 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:00:47.967121  7518 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:00:47.967124  7518 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:00:47.967129  7518 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:00:47.967134  7518 net.cpp:124] Setting up relu2\n",
      "I0430 08:00:47.967139  7518 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:00:47.967141  7518 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:00:47.967144  7518 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:00:47.967149  7518 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:00:47.967152  7518 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:00:47.967157  7518 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:00:47.967164  7518 net.cpp:124] Setting up pool2\n",
      "I0430 08:00:47.967167  7518 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:00:47.967170  7518 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:00:47.967173  7518 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:00:47.967180  7518 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:00:47.967183  7518 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:00:47.967188  7518 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:00:47.967193  7518 net.cpp:124] Setting up norm2\n",
      "I0430 08:00:47.967197  7518 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:00:47.967200  7518 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:00:47.967203  7518 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:00:47.967218  7518 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:00:47.967221  7518 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:00:47.967226  7518 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:00:47.968197  7518 net.cpp:124] Setting up conv3\n",
      "I0430 08:00:47.968209  7518 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:00:47.968211  7518 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:00:47.968220  7518 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:00:47.968227  7518 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:00:47.968231  7518 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:00:47.968236  7518 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:00:47.968242  7518 net.cpp:124] Setting up relu3\n",
      "I0430 08:00:47.968246  7518 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:00:47.968250  7518 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:00:47.968252  7518 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:00:47.968260  7518 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:00:47.968262  7518 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:00:47.968267  7518 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:00:47.968761  7518 net.cpp:124] Setting up conv4\n",
      "I0430 08:00:47.968770  7518 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:00:47.968773  7518 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:00:47.968780  7518 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:00:47.968786  7518 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:00:47.968788  7518 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:00:47.968794  7518 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:00:47.968799  7518 net.cpp:124] Setting up relu4\n",
      "I0430 08:00:47.968803  7518 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:00:47.968806  7518 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:00:47.968811  7518 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:00:47.968816  7518 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:00:47.968818  7518 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:00:47.968824  7518 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:00:47.969329  7518 net.cpp:124] Setting up conv5\n",
      "I0430 08:00:47.969341  7518 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:00:47.969342  7518 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:00:47.969352  7518 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:00:47.969357  7518 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:00:47.969360  7518 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:00:47.969364  7518 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:00:47.969369  7518 net.cpp:124] Setting up relu5\n",
      "I0430 08:00:47.969374  7518 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:00:47.969380  7518 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:00:47.969385  7518 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:00:47.969391  7518 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:00:47.969394  7518 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:00:47.969398  7518 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:00:47.969406  7518 net.cpp:124] Setting up pool5\n",
      "I0430 08:00:47.969411  7518 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:00:47.969413  7518 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:00:47.969418  7518 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:00:47.969424  7518 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:00:47.969426  7518 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:00:47.969431  7518 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:00:47.992974  7518 net.cpp:124] Setting up fc6\n",
      "I0430 08:00:47.993000  7518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:00:47.993006  7518 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:00:47.993016  7518 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:00:47.993026  7518 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:00:47.993028  7518 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:00:47.993033  7518 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:00:47.993042  7518 net.cpp:124] Setting up relu6\n",
      "I0430 08:00:47.993046  7518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:00:47.993048  7518 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:00:47.993052  7518 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:00:47.993058  7518 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:00:47.993070  7518 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:00:47.993077  7518 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:00:47.993083  7518 net.cpp:124] Setting up drop6\n",
      "I0430 08:00:47.993088  7518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:00:47.993089  7518 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:00:47.993093  7518 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:00:47.993099  7518 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:00:47.993101  7518 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:00:47.993106  7518 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:00:48.003202  7518 net.cpp:124] Setting up fc7\n",
      "I0430 08:00:48.003239  7518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:00:48.003243  7518 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:00:48.003254  7518 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:00:48.003264  7518 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:00:48.003268  7518 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:00:48.003274  7518 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:00:48.003283  7518 net.cpp:124] Setting up relu7\n",
      "I0430 08:00:48.003288  7518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:00:48.003290  7518 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:00:48.003294  7518 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:00:48.003300  7518 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:00:48.003304  7518 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:00:48.003309  7518 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:00:48.003316  7518 net.cpp:124] Setting up drop7\n",
      "I0430 08:00:48.003321  7518 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:00:48.003324  7518 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:00:48.003327  7518 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:00:48.003334  7518 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:00:48.003336  7518 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:00:48.003341  7518 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:00:48.004155  7518 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:00:48.004176  7518 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:00:48.004180  7518 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:00:48.004189  7518 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:00:48.004194  7518 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:00:48.004196  7518 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:00:48.004199  7518 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:00:48.004202  7518 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:00:48.004204  7518 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:00:48.004207  7518 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:00:48.004211  7518 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:00:48.004215  7518 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:00:48.004217  7518 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:00:48.004221  7518 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:00:48.004225  7518 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:00:48.004228  7518 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:00:48.004231  7518 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:00:48.004235  7518 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:00:48.004238  7518 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:00:48.004241  7518 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:00:48.004245  7518 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:00:48.004248  7518 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:00:48.004251  7518 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:00:48.004254  7518 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:00:48.004257  7518 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:00:48.004261  7518 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:00:48.004263  7518 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:00:48.004276  7518 net.cpp:257] Network initialization done.\n",
      "I0430 08:00:48.089010  7518 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:00:48.191179  7518 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:00:48.192091  7518 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:00:48.192100  7518 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:00:48.192104  7518 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/520979.jpg'}, '/tmp/tmpPsfF1L.mat')\n",
      "Processed 1416 windows in 163.435 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-1.37359, -1.94138, -1.80471, -1.75087, -1.72...\n",
      "ymin                                                         62\n",
      "xmin                                                        320\n",
      "ymax                                                        131\n",
      "xmax                                                        395\n",
      "Name: /home/ambika/INF_project/data/car/520979.jpg, dtype: object\n",
      "prediction    [-2.16919, -1.63979, -1.76546, -1.73785, -1.97...\n",
      "ymin                                                         62\n",
      "xmin                                                         50\n",
      "ymax                                                        218\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/car/520979.jpg, dtype: object\n",
      "zebra\n",
      "320\t62\t395\t131\n",
      "car\n",
      "50\t62\t500\t218\n",
      "520979\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:03:33.133409  7662 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:03:33.133429  7662 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:03:33.133431  7662 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:03:33.134577  7662 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:03:33.134744  7662 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:03:33.134752  7662 net.cpp:86] Creating Layer data\n",
      "I0430 08:03:33.134754  7662 net.cpp:382] data -> data\n",
      "I0430 08:03:33.134768  7662 net.cpp:124] Setting up data\n",
      "I0430 08:03:33.134773  7662 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:03:33.134774  7662 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:03:33.134778  7662 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:03:33.134783  7662 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:03:33.134784  7662 net.cpp:408] conv1 <- data\n",
      "I0430 08:03:33.134788  7662 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:03:33.134846  7662 net.cpp:124] Setting up conv1\n",
      "I0430 08:03:33.134851  7662 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:03:33.134855  7662 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:03:33.134861  7662 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:03:33.134865  7662 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:03:33.134868  7662 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:03:33.134871  7662 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:03:33.134876  7662 net.cpp:124] Setting up relu1\n",
      "I0430 08:03:33.134879  7662 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:03:33.134881  7662 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:03:33.134883  7662 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:03:33.134887  7662 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:03:33.134889  7662 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:03:33.134892  7662 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:03:33.134899  7662 net.cpp:124] Setting up pool1\n",
      "I0430 08:03:33.134902  7662 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:03:33.134904  7662 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:03:33.134907  7662 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:03:33.134912  7662 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:03:33.134913  7662 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:03:33.134917  7662 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:03:33.134922  7662 net.cpp:124] Setting up norm1\n",
      "I0430 08:03:33.134924  7662 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:03:33.134927  7662 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:03:33.134929  7662 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:03:33.134933  7662 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:03:33.134935  7662 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:03:33.134939  7662 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:03:33.135442  7662 net.cpp:124] Setting up conv2\n",
      "I0430 08:03:33.135450  7662 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:03:33.135453  7662 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:03:33.135459  7662 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:03:33.135464  7662 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:03:33.135468  7662 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:03:33.135470  7662 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:03:33.135475  7662 net.cpp:124] Setting up relu2\n",
      "I0430 08:03:33.135479  7662 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:03:33.135481  7662 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:03:33.135483  7662 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:03:33.135488  7662 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:03:33.135489  7662 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:03:33.135493  7662 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:03:33.135499  7662 net.cpp:124] Setting up pool2\n",
      "I0430 08:03:33.135502  7662 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:03:33.135504  7662 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:03:33.135506  7662 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:03:33.135512  7662 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:03:33.135514  7662 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:03:33.135517  7662 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:03:33.135522  7662 net.cpp:124] Setting up norm2\n",
      "I0430 08:03:33.135525  7662 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:03:33.135527  7662 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:03:33.135530  7662 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:03:33.135535  7662 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:03:33.135537  7662 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:03:33.135540  7662 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:03:33.136236  7662 net.cpp:124] Setting up conv3\n",
      "I0430 08:03:33.136246  7662 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:03:33.136248  7662 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:03:33.136255  7662 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:03:33.136260  7662 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:03:33.136263  7662 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:03:33.136267  7662 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:03:33.136271  7662 net.cpp:124] Setting up relu3\n",
      "I0430 08:03:33.136274  7662 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:03:33.136277  7662 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:03:33.136279  7662 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:03:33.136284  7662 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:03:33.136286  7662 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:03:33.136289  7662 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:03:33.137022  7662 net.cpp:124] Setting up conv4\n",
      "I0430 08:03:33.137030  7662 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:03:33.137033  7662 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:03:33.137037  7662 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:03:33.137042  7662 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:03:33.137044  7662 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:03:33.137048  7662 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:03:33.137053  7662 net.cpp:124] Setting up relu4\n",
      "I0430 08:03:33.137055  7662 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:03:33.137058  7662 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:03:33.137059  7662 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:03:33.137064  7662 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:03:33.137066  7662 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:03:33.137071  7662 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:03:33.137554  7662 net.cpp:124] Setting up conv5\n",
      "I0430 08:03:33.137562  7662 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:03:33.137563  7662 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:03:33.137570  7662 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:03:33.137574  7662 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:03:33.137578  7662 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:03:33.137580  7662 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:03:33.137584  7662 net.cpp:124] Setting up relu5\n",
      "I0430 08:03:33.137588  7662 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:03:33.137589  7662 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:03:33.137593  7662 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:03:33.137596  7662 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:03:33.137599  7662 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:03:33.137603  7662 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:03:33.137609  7662 net.cpp:124] Setting up pool5\n",
      "I0430 08:03:33.137611  7662 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:03:33.137614  7662 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:03:33.137616  7662 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:03:33.137622  7662 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:03:33.137625  7662 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:03:33.137629  7662 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:03:33.159118  7662 net.cpp:124] Setting up fc6\n",
      "I0430 08:03:33.159142  7662 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:03:33.159144  7662 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:03:33.159158  7662 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:03:33.159175  7662 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:03:33.159179  7662 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:03:33.159188  7662 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:03:33.159195  7662 net.cpp:124] Setting up relu6\n",
      "I0430 08:03:33.159199  7662 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:03:33.159217  7662 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:03:33.159219  7662 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:03:33.159226  7662 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:03:33.159229  7662 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:03:33.159231  7662 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:03:33.159236  7662 net.cpp:124] Setting up drop6\n",
      "I0430 08:03:33.159240  7662 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:03:33.159241  7662 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:03:33.159243  7662 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:03:33.159250  7662 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:03:33.159252  7662 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:03:33.159255  7662 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:03:33.169256  7662 net.cpp:124] Setting up fc7\n",
      "I0430 08:03:33.169281  7662 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:03:33.169283  7662 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:03:33.169294  7662 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:03:33.169309  7662 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:03:33.169313  7662 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:03:33.169322  7662 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:03:33.169328  7662 net.cpp:124] Setting up relu7\n",
      "I0430 08:03:33.169332  7662 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:03:33.169335  7662 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:03:33.169339  7662 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:03:33.169345  7662 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:03:33.169348  7662 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:03:33.169351  7662 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:03:33.169358  7662 net.cpp:124] Setting up drop7\n",
      "I0430 08:03:33.169361  7662 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:03:33.169363  7662 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:03:33.169366  7662 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:03:33.169373  7662 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:03:33.169374  7662 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:03:33.169379  7662 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:03:33.170037  7662 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:03:33.170047  7662 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:03:33.170049  7662 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:03:33.170056  7662 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:03:33.170060  7662 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:03:33.170063  7662 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:03:33.170066  7662 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:03:33.170070  7662 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:03:33.170073  7662 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:03:33.170076  7662 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:03:33.170080  7662 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:03:33.170083  7662 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:03:33.170087  7662 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:03:33.170090  7662 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:03:33.170094  7662 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:03:33.170097  7662 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:03:33.170100  7662 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:03:33.170104  7662 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:03:33.170107  7662 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:03:33.170110  7662 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:03:33.170114  7662 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:03:33.170117  7662 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:03:33.170120  7662 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:03:33.170125  7662 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:03:33.170127  7662 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:03:33.170130  7662 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:03:33.170133  7662 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:03:33.170145  7662 net.cpp:257] Network initialization done.\n",
      "I0430 08:03:33.254510  7662 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:03:33.351832  7662 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:03:33.352849  7662 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:03:33.352859  7662 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:03:33.352862  7662 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/383406.jpg'}, '/tmp/tmpqc1fuh.mat')\n",
      "Processed 2573 windows in 292.554 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-1.90438, -1.8796, -1.98762, -1.9532, -2.0687...\n",
      "ymin                                                        104\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        288\n",
      "Name: /home/ambika/INF_project/data/cat/383406.jpg, dtype: object\n",
      "prediction    [-1.8292, -2.5837, -2.14579, -2.0609, -2.1564,...\n",
      "ymin                                                        153\n",
      "xmin                                                         40\n",
      "ymax                                                        240\n",
      "xmax                                                        284\n",
      "Name: /home/ambika/INF_project/data/cat/383406.jpg, dtype: object\n",
      "domestic cat\n",
      "0\t104\t288\t375\n",
      "dog\n",
      "40\t153\t284\t240\n",
      "383406\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:08:27.479730  7846 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:08:27.479753  7846 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:08:27.479763  7846 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:08:27.480888  7846 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:08:27.481045  7846 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:08:27.481053  7846 net.cpp:86] Creating Layer data\n",
      "I0430 08:08:27.481057  7846 net.cpp:382] data -> data\n",
      "I0430 08:08:27.481070  7846 net.cpp:124] Setting up data\n",
      "I0430 08:08:27.481077  7846 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:08:27.481079  7846 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:08:27.481083  7846 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:08:27.481091  7846 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:08:27.481093  7846 net.cpp:408] conv1 <- data\n",
      "I0430 08:08:27.481098  7846 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:08:27.481158  7846 net.cpp:124] Setting up conv1\n",
      "I0430 08:08:27.481164  7846 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:08:27.481166  7846 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:08:27.481174  7846 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:08:27.481180  7846 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:08:27.481184  7846 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:08:27.481187  7846 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:08:27.481192  7846 net.cpp:124] Setting up relu1\n",
      "I0430 08:08:27.481196  7846 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:08:27.481199  7846 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:08:27.481202  7846 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:08:27.481207  7846 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:08:27.481209  7846 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:08:27.481215  7846 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:08:27.481221  7846 net.cpp:124] Setting up pool1\n",
      "I0430 08:08:27.481225  7846 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:08:27.481228  7846 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:08:27.481231  7846 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:08:27.481236  7846 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:08:27.481240  7846 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:08:27.481243  7846 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:08:27.481251  7846 net.cpp:124] Setting up norm1\n",
      "I0430 08:08:27.481256  7846 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:08:27.481258  7846 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:08:27.481261  7846 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:08:27.481266  7846 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:08:27.481269  7846 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:08:27.481274  7846 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:08:27.481613  7846 net.cpp:124] Setting up conv2\n",
      "I0430 08:08:27.481621  7846 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:08:27.481622  7846 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:08:27.481629  7846 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:08:27.481634  7846 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:08:27.481637  7846 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:08:27.481642  7846 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:08:27.481647  7846 net.cpp:124] Setting up relu2\n",
      "I0430 08:08:27.481650  7846 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:08:27.481652  7846 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:08:27.481655  7846 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:08:27.481660  7846 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:08:27.481662  7846 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:08:27.481667  7846 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:08:27.481673  7846 net.cpp:124] Setting up pool2\n",
      "I0430 08:08:27.481678  7846 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:08:27.481679  7846 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:08:27.481683  7846 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:08:27.481688  7846 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:08:27.481691  7846 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:08:27.481696  7846 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:08:27.481701  7846 net.cpp:124] Setting up norm2\n",
      "I0430 08:08:27.481705  7846 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:08:27.481709  7846 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:08:27.481711  7846 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:08:27.481716  7846 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:08:27.481719  7846 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:08:27.481724  7846 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:08:27.482416  7846 net.cpp:124] Setting up conv3\n",
      "I0430 08:08:27.482429  7846 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:08:27.482434  7846 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:08:27.482442  7846 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:08:27.482450  7846 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:08:27.482452  7846 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:08:27.482457  7846 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:08:27.482463  7846 net.cpp:124] Setting up relu3\n",
      "I0430 08:08:27.482468  7846 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:08:27.482470  7846 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:08:27.482473  7846 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:08:27.482481  7846 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:08:27.482482  7846 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:08:27.482487  7846 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:08:27.483242  7846 net.cpp:124] Setting up conv4\n",
      "I0430 08:08:27.483250  7846 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:08:27.483253  7846 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:08:27.483260  7846 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:08:27.483265  7846 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:08:27.483268  7846 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:08:27.483273  7846 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:08:27.483278  7846 net.cpp:124] Setting up relu4\n",
      "I0430 08:08:27.483283  7846 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:08:27.483284  7846 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:08:27.483288  7846 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:08:27.483294  7846 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:08:27.483296  7846 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:08:27.483301  7846 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:08:27.483785  7846 net.cpp:124] Setting up conv5\n",
      "I0430 08:08:27.483791  7846 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:08:27.483794  7846 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:08:27.483804  7846 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:08:27.483808  7846 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:08:27.483811  7846 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:08:27.483816  7846 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:08:27.483820  7846 net.cpp:124] Setting up relu5\n",
      "I0430 08:08:27.483824  7846 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:08:27.483827  7846 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:08:27.483830  7846 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:08:27.483835  7846 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:08:27.483839  7846 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:08:27.483844  7846 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:08:27.483850  7846 net.cpp:124] Setting up pool5\n",
      "I0430 08:08:27.483855  7846 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:08:27.483857  7846 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:08:27.483860  7846 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:08:27.483867  7846 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:08:27.483870  7846 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:08:27.483876  7846 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:08:27.506064  7846 net.cpp:124] Setting up fc6\n",
      "I0430 08:08:27.506090  7846 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:08:27.506095  7846 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:08:27.506124  7846 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:08:27.506134  7846 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:08:27.506139  7846 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:08:27.506145  7846 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:08:27.506152  7846 net.cpp:124] Setting up relu6\n",
      "I0430 08:08:27.506156  7846 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:08:27.506160  7846 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:08:27.506163  7846 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:08:27.506170  7846 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:08:27.506172  7846 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:08:27.506178  7846 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:08:27.506184  7846 net.cpp:124] Setting up drop6\n",
      "I0430 08:08:27.506188  7846 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:08:27.506191  7846 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:08:27.506194  7846 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:08:27.506201  7846 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:08:27.506202  7846 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:08:27.506207  7846 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:08:27.515879  7846 net.cpp:124] Setting up fc7\n",
      "I0430 08:08:27.515902  7846 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:08:27.515908  7846 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:08:27.515933  7846 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:08:27.515941  7846 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:08:27.515945  7846 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:08:27.515954  7846 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:08:27.515961  7846 net.cpp:124] Setting up relu7\n",
      "I0430 08:08:27.515965  7846 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:08:27.515969  7846 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:08:27.515972  7846 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:08:27.515979  7846 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:08:27.515981  7846 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:08:27.515986  7846 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:08:27.515992  7846 net.cpp:124] Setting up drop7\n",
      "I0430 08:08:27.515996  7846 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:08:27.515998  7846 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:08:27.516002  7846 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:08:27.516007  7846 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:08:27.516010  7846 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:08:27.516016  7846 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:08:27.516919  7846 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:08:27.516929  7846 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:08:27.516932  7846 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:08:27.516940  7846 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:08:27.516943  7846 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:08:27.516947  7846 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:08:27.516950  7846 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:08:27.516954  7846 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:08:27.516957  7846 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:08:27.516960  7846 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:08:27.516964  7846 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:08:27.516968  7846 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:08:27.516971  7846 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:08:27.516974  7846 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:08:27.516978  7846 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:08:27.516981  7846 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:08:27.516984  7846 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:08:27.516988  7846 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:08:27.516991  7846 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:08:27.516995  7846 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:08:27.516999  7846 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:08:27.517001  7846 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:08:27.517005  7846 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:08:27.517009  7846 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:08:27.517012  7846 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:08:27.517015  7846 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:08:27.517019  7846 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:08:27.517030  7846 net.cpp:257] Network initialization done.\n",
      "I0430 08:08:27.600632  7846 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:08:27.696197  7846 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:08:27.697310  7846 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:08:27.697325  7846 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:08:27.697331  7846 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/56651.jpg'}, '/tmp/tmprJKfYW.mat')\n",
      "Processed 2947 windows in 344.448 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.34006, -2.06955, -2.17467, -2.02148, -2.07...\n",
      "ymin                                                        103\n",
      "xmin                                                        158\n",
      "ymax                                                        303\n",
      "xmax                                                        309\n",
      "Name: /home/ambika/INF_project/data/couch/56651.jpg, dtype: object\n",
      "prediction    [-2.107, -1.70321, -1.67498, -1.80058, -1.2536...\n",
      "ymin                                                          0\n",
      "xmin                                                        410\n",
      "ymax                                                        112\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/couch/56651.jpg, dtype: object\n",
      "person\n",
      "158\t103\t309\t303\n",
      "bagel\n",
      "410\t0\t500\t112\n",
      "56651\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:14:13.714635  8072 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:14:13.714654  8072 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:14:13.714656  8072 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:14:13.715863  8072 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:14:13.715992  8072 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:14:13.716006  8072 net.cpp:86] Creating Layer data\n",
      "I0430 08:14:13.716009  8072 net.cpp:382] data -> data\n",
      "I0430 08:14:13.716027  8072 net.cpp:124] Setting up data\n",
      "I0430 08:14:13.716032  8072 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:14:13.716035  8072 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:14:13.716039  8072 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:14:13.716045  8072 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:14:13.716048  8072 net.cpp:408] conv1 <- data\n",
      "I0430 08:14:13.716053  8072 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:14:13.716127  8072 net.cpp:124] Setting up conv1\n",
      "I0430 08:14:13.716135  8072 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:14:13.716137  8072 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:14:13.716146  8072 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:14:13.716152  8072 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:14:13.716156  8072 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:14:13.716158  8072 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:14:13.716163  8072 net.cpp:124] Setting up relu1\n",
      "I0430 08:14:13.716166  8072 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:14:13.716168  8072 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:14:13.716171  8072 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:14:13.716174  8072 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:14:13.716176  8072 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:14:13.716179  8072 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:14:13.716188  8072 net.cpp:124] Setting up pool1\n",
      "I0430 08:14:13.716192  8072 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:14:13.716193  8072 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:14:13.716197  8072 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:14:13.716202  8072 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:14:13.716212  8072 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:14:13.716226  8072 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:14:13.716235  8072 net.cpp:124] Setting up norm1\n",
      "I0430 08:14:13.716239  8072 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:14:13.716241  8072 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:14:13.716243  8072 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:14:13.716248  8072 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:14:13.716250  8072 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:14:13.716254  8072 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:14:13.716886  8072 net.cpp:124] Setting up conv2\n",
      "I0430 08:14:13.716927  8072 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:14:13.716930  8072 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:14:13.716945  8072 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:14:13.716956  8072 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:14:13.716960  8072 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:14:13.716967  8072 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:14:13.716976  8072 net.cpp:124] Setting up relu2\n",
      "I0430 08:14:13.716980  8072 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:14:13.716982  8072 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:14:13.716985  8072 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:14:13.716994  8072 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:14:13.716996  8072 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:14:13.717000  8072 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:14:13.717012  8072 net.cpp:124] Setting up pool2\n",
      "I0430 08:14:13.717018  8072 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:14:13.717021  8072 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:14:13.717023  8072 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:14:13.717036  8072 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:14:13.717038  8072 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:14:13.717043  8072 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:14:13.717051  8072 net.cpp:124] Setting up norm2\n",
      "I0430 08:14:13.717054  8072 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:14:13.717056  8072 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:14:13.717059  8072 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:14:13.717067  8072 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:14:13.717069  8072 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:14:13.717074  8072 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:14:13.718211  8072 net.cpp:124] Setting up conv3\n",
      "I0430 08:14:13.718227  8072 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:14:13.718231  8072 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:14:13.718241  8072 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:14:13.718251  8072 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:14:13.718255  8072 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:14:13.718260  8072 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:14:13.718266  8072 net.cpp:124] Setting up relu3\n",
      "I0430 08:14:13.718269  8072 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:14:13.718271  8072 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:14:13.718273  8072 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:14:13.718278  8072 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:14:13.718282  8072 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:14:13.718286  8072 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:14:13.719038  8072 net.cpp:124] Setting up conv4\n",
      "I0430 08:14:13.719048  8072 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:14:13.719051  8072 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:14:13.719055  8072 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:14:13.719064  8072 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:14:13.719066  8072 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:14:13.719070  8072 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:14:13.719075  8072 net.cpp:124] Setting up relu4\n",
      "I0430 08:14:13.719079  8072 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:14:13.719082  8072 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:14:13.719084  8072 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:14:13.719089  8072 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:14:13.719091  8072 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:14:13.719095  8072 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:14:13.719614  8072 net.cpp:124] Setting up conv5\n",
      "I0430 08:14:13.719621  8072 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:14:13.719624  8072 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:14:13.719630  8072 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:14:13.719635  8072 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:14:13.719636  8072 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:14:13.719640  8072 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:14:13.719642  8072 net.cpp:124] Setting up relu5\n",
      "I0430 08:14:13.719645  8072 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:14:13.719646  8072 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:14:13.719648  8072 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:14:13.719652  8072 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:14:13.719653  8072 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:14:13.719657  8072 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:14:13.719663  8072 net.cpp:124] Setting up pool5\n",
      "I0430 08:14:13.719667  8072 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:14:13.719669  8072 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:14:13.719672  8072 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:14:13.719679  8072 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:14:13.719683  8072 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:14:13.719686  8072 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:14:13.741834  8072 net.cpp:124] Setting up fc6\n",
      "I0430 08:14:13.741858  8072 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:14:13.741863  8072 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:14:13.741875  8072 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:14:13.741896  8072 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:14:13.741900  8072 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:14:13.741907  8072 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:14:13.741915  8072 net.cpp:124] Setting up relu6\n",
      "I0430 08:14:13.741919  8072 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:14:13.741922  8072 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:14:13.741925  8072 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:14:13.741931  8072 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:14:13.741933  8072 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:14:13.741938  8072 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:14:13.741943  8072 net.cpp:124] Setting up drop6\n",
      "I0430 08:14:13.741946  8072 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:14:13.741950  8072 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:14:13.741952  8072 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:14:13.741958  8072 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:14:13.741961  8072 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:14:13.741966  8072 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:14:13.754153  8072 net.cpp:124] Setting up fc7\n",
      "I0430 08:14:13.754179  8072 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:14:13.754184  8072 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:14:13.754194  8072 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:14:13.754202  8072 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:14:13.754206  8072 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:14:13.754215  8072 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:14:13.754221  8072 net.cpp:124] Setting up relu7\n",
      "I0430 08:14:13.754225  8072 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:14:13.754228  8072 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:14:13.754231  8072 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:14:13.754237  8072 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:14:13.754240  8072 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:14:13.754243  8072 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:14:13.754250  8072 net.cpp:124] Setting up drop7\n",
      "I0430 08:14:13.754252  8072 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:14:13.754256  8072 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:14:13.754258  8072 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:14:13.754263  8072 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:14:13.754266  8072 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:14:13.754271  8072 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:14:13.755167  8072 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:14:13.755177  8072 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:14:13.755180  8072 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:14:13.755187  8072 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:14:13.755190  8072 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:14:13.755193  8072 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:14:13.755197  8072 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:14:13.755199  8072 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:14:13.755203  8072 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:14:13.755213  8072 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:14:13.755216  8072 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:14:13.755219  8072 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:14:13.755223  8072 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:14:13.755225  8072 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:14:13.755228  8072 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:14:13.755231  8072 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:14:13.755234  8072 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:14:13.755237  8072 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:14:13.755241  8072 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:14:13.755244  8072 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:14:13.755247  8072 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:14:13.755250  8072 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:14:13.755254  8072 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:14:13.755256  8072 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:14:13.755259  8072 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:14:13.755262  8072 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:14:13.755265  8072 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:14:13.755276  8072 net.cpp:257] Network initialization done.\n",
      "I0430 08:14:13.840602  8072 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:14:13.945420  8072 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:14:13.947412  8072 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:14:13.947432  8072 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:14:13.947438  8072 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/99996.jpg'}, '/tmp/tmpPefpzN.mat')\n",
      "Processed 2602 windows in 303.355 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-1.96285, -2.74288, -1.7821, -2.58376, -1.671...\n",
      "ymin                                                          0\n",
      "xmin                                                        155\n",
      "ymax                                                        288\n",
      "xmax                                                        332\n",
      "Name: /home/ambika/INF_project/data/dog/99996.jpg, dtype: object\n",
      "prediction    [-2.01432, -3.07834, -1.92957, -2.66313, -1.55...\n",
      "ymin                                                          0\n",
      "xmin                                                        167\n",
      "ymax                                                        243\n",
      "xmax                                                        299\n",
      "Name: /home/ambika/INF_project/data/dog/99996.jpg, dtype: object\n",
      "dog\n",
      "155\t0\t332\t288\n",
      "person\n",
      "167\t0\t299\t243\n",
      "99996\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:19:18.993036  8286 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:19:18.993055  8286 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:19:18.993058  8286 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:19:18.994154  8286 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:19:18.994238  8286 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:19:18.994246  8286 net.cpp:86] Creating Layer data\n",
      "I0430 08:19:18.994254  8286 net.cpp:382] data -> data\n",
      "I0430 08:19:18.994269  8286 net.cpp:124] Setting up data\n",
      "I0430 08:19:18.994277  8286 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:19:18.994279  8286 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:19:18.994283  8286 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:19:18.994290  8286 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:19:18.994293  8286 net.cpp:408] conv1 <- data\n",
      "I0430 08:19:18.994298  8286 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:19:18.994356  8286 net.cpp:124] Setting up conv1\n",
      "I0430 08:19:18.994361  8286 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:19:18.994364  8286 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:19:18.994372  8286 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:19:18.994377  8286 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:19:18.994380  8286 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:19:18.994385  8286 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:19:18.994390  8286 net.cpp:124] Setting up relu1\n",
      "I0430 08:19:18.994395  8286 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:19:18.994396  8286 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:19:18.994400  8286 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:19:18.994405  8286 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:19:18.994406  8286 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:19:18.994410  8286 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:19:18.994417  8286 net.cpp:124] Setting up pool1\n",
      "I0430 08:19:18.994422  8286 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:19:18.994424  8286 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:19:18.994427  8286 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:19:18.994432  8286 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:19:18.994436  8286 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:19:18.994439  8286 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:19:18.994446  8286 net.cpp:124] Setting up norm1\n",
      "I0430 08:19:18.994449  8286 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:19:18.994451  8286 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:19:18.994454  8286 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:19:18.994460  8286 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:19:18.994462  8286 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:19:18.994467  8286 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:19:18.994813  8286 net.cpp:124] Setting up conv2\n",
      "I0430 08:19:18.994820  8286 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:19:18.994823  8286 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:19:18.994830  8286 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:19:18.994834  8286 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:19:18.994837  8286 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:19:18.994841  8286 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:19:18.994846  8286 net.cpp:124] Setting up relu2\n",
      "I0430 08:19:18.994850  8286 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:19:18.994853  8286 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:19:18.994855  8286 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:19:18.994861  8286 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:19:18.994863  8286 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:19:18.994868  8286 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:19:18.994874  8286 net.cpp:124] Setting up pool2\n",
      "I0430 08:19:18.994877  8286 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:19:18.994880  8286 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:19:18.994884  8286 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:19:18.994889  8286 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:19:18.994890  8286 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:19:18.994895  8286 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:19:18.994900  8286 net.cpp:124] Setting up norm2\n",
      "I0430 08:19:18.994904  8286 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:19:18.994907  8286 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:19:18.994910  8286 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:19:18.994915  8286 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:19:18.994918  8286 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:19:18.994922  8286 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:19:18.995672  8286 net.cpp:124] Setting up conv3\n",
      "I0430 08:19:18.995697  8286 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:19:18.995700  8286 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:19:18.995715  8286 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:19:18.995725  8286 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:19:18.995729  8286 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:19:18.995738  8286 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:19:18.995746  8286 net.cpp:124] Setting up relu3\n",
      "I0430 08:19:18.995751  8286 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:19:18.995754  8286 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:19:18.995756  8286 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:19:18.995765  8286 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:19:18.995767  8286 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:19:18.995774  8286 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:19:18.996747  8286 net.cpp:124] Setting up conv4\n",
      "I0430 08:19:18.996767  8286 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:19:18.996770  8286 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:19:18.996779  8286 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:19:18.996789  8286 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:19:18.996793  8286 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:19:18.996798  8286 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:19:18.996804  8286 net.cpp:124] Setting up relu4\n",
      "I0430 08:19:18.996809  8286 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:19:18.996810  8286 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:19:18.996814  8286 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:19:18.996822  8286 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:19:18.996825  8286 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:19:18.996830  8286 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:19:18.997414  8286 net.cpp:124] Setting up conv5\n",
      "I0430 08:19:18.997463  8286 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:19:18.997467  8286 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:19:18.997481  8286 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:19:18.997489  8286 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:19:18.997493  8286 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:19:18.997498  8286 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:19:18.997506  8286 net.cpp:124] Setting up relu5\n",
      "I0430 08:19:18.997511  8286 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:19:18.997514  8286 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:19:18.997519  8286 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:19:18.997524  8286 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:19:18.997527  8286 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:19:18.997532  8286 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:19:18.997541  8286 net.cpp:124] Setting up pool5\n",
      "I0430 08:19:18.997546  8286 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:19:18.997548  8286 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:19:18.997551  8286 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:19:18.997561  8286 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:19:18.997565  8286 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:19:18.997570  8286 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:19:19.020903  8286 net.cpp:124] Setting up fc6\n",
      "I0430 08:19:19.020925  8286 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:19:19.020929  8286 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:19:19.020941  8286 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:19:19.020949  8286 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:19:19.020953  8286 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:19:19.020961  8286 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:19:19.020967  8286 net.cpp:124] Setting up relu6\n",
      "I0430 08:19:19.020972  8286 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:19:19.020974  8286 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:19:19.020977  8286 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:19:19.020983  8286 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:19:19.020987  8286 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:19:19.020990  8286 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:19:19.020997  8286 net.cpp:124] Setting up drop6\n",
      "I0430 08:19:19.020999  8286 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:19:19.021003  8286 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:19:19.021005  8286 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:19:19.021010  8286 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:19:19.021013  8286 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:19:19.021019  8286 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:19:19.031452  8286 net.cpp:124] Setting up fc7\n",
      "I0430 08:19:19.031479  8286 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:19:19.031483  8286 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:19:19.031497  8286 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:19:19.031512  8286 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:19:19.031517  8286 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:19:19.031523  8286 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:19:19.031533  8286 net.cpp:124] Setting up relu7\n",
      "I0430 08:19:19.031536  8286 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:19:19.031539  8286 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:19:19.031543  8286 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:19:19.031549  8286 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:19:19.031551  8286 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:19:19.031556  8286 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:19:19.031561  8286 net.cpp:124] Setting up drop7\n",
      "I0430 08:19:19.031577  8286 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:19:19.031580  8286 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:19:19.031584  8286 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:19:19.031589  8286 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:19:19.031592  8286 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:19:19.031597  8286 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:19:19.032269  8286 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:19:19.032281  8286 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:19:19.032284  8286 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:19:19.032292  8286 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:19:19.032295  8286 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:19:19.032299  8286 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:19:19.032302  8286 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:19:19.032305  8286 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:19:19.032310  8286 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:19:19.032312  8286 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:19:19.032315  8286 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:19:19.032320  8286 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:19:19.032322  8286 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:19:19.032326  8286 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:19:19.032330  8286 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:19:19.032333  8286 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:19:19.032336  8286 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:19:19.032341  8286 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:19:19.032343  8286 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:19:19.032346  8286 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:19:19.032349  8286 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:19:19.032353  8286 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:19:19.032356  8286 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:19:19.032359  8286 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:19:19.032362  8286 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:19:19.032366  8286 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:19:19.032368  8286 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:19:19.032378  8286 net.cpp:257] Network initialization done.\n",
      "I0430 08:19:19.125509  8286 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:19:19.249174  8286 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:19:19.250651  8286 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:19:19.250663  8286 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:19:19.250668  8286 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/196839.jpg'}, '/tmp/tmpgyZuSj.mat')\n",
      "Processed 1745 windows in 216.433 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-1.97398, -2.91082, -1.97849, -2.70352, -1.99...\n",
      "ymin                                                        196\n",
      "xmin                                                        200\n",
      "ymax                                                        307\n",
      "xmax                                                        299\n",
      "Name: /home/ambika/INF_project/data/horse/196839.jpg, dtype: object\n",
      "prediction    [-1.8302, -2.47521, -1.69021, -2.23672, -1.853...\n",
      "ymin                                                        222\n",
      "xmin                                                        206\n",
      "ymax                                                        300\n",
      "xmax                                                        297\n",
      "Name: /home/ambika/INF_project/data/horse/196839.jpg, dtype: object\n",
      "dog\n",
      "200\t196\t299\t307\n",
      "swine\n",
      "206\t222\t297\t300\n",
      "196839\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:22:57.284286  8470 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:22:57.284308  8470 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:22:57.284312  8470 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:22:57.285442  8470 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:22:57.285598  8470 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:22:57.285606  8470 net.cpp:86] Creating Layer data\n",
      "I0430 08:22:57.285612  8470 net.cpp:382] data -> data\n",
      "I0430 08:22:57.285630  8470 net.cpp:124] Setting up data\n",
      "I0430 08:22:57.285637  8470 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:22:57.285641  8470 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:22:57.285646  8470 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:22:57.285655  8470 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:22:57.285660  8470 net.cpp:408] conv1 <- data\n",
      "I0430 08:22:57.285666  8470 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:22:57.285727  8470 net.cpp:124] Setting up conv1\n",
      "I0430 08:22:57.285732  8470 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:22:57.285734  8470 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:22:57.285742  8470 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:22:57.285745  8470 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:22:57.285748  8470 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:22:57.285753  8470 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:22:57.285756  8470 net.cpp:124] Setting up relu1\n",
      "I0430 08:22:57.285759  8470 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:22:57.285763  8470 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:22:57.285765  8470 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:22:57.285769  8470 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:22:57.285771  8470 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:22:57.285774  8470 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:22:57.285781  8470 net.cpp:124] Setting up pool1\n",
      "I0430 08:22:57.285784  8470 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:22:57.285787  8470 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:22:57.285789  8470 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:22:57.285794  8470 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:22:57.285797  8470 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:22:57.285800  8470 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:22:57.285805  8470 net.cpp:124] Setting up norm1\n",
      "I0430 08:22:57.285809  8470 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:22:57.285811  8470 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:22:57.285814  8470 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:22:57.285820  8470 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:22:57.285823  8470 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:22:57.285830  8470 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:22:57.286185  8470 net.cpp:124] Setting up conv2\n",
      "I0430 08:22:57.286195  8470 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:22:57.286198  8470 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:22:57.286207  8470 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:22:57.286213  8470 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:22:57.286216  8470 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:22:57.286219  8470 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:22:57.286224  8470 net.cpp:124] Setting up relu2\n",
      "I0430 08:22:57.286227  8470 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:22:57.286229  8470 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:22:57.286232  8470 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:22:57.286236  8470 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:22:57.286238  8470 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:22:57.286242  8470 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:22:57.286247  8470 net.cpp:124] Setting up pool2\n",
      "I0430 08:22:57.286250  8470 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:22:57.286252  8470 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:22:57.286255  8470 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:22:57.286260  8470 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:22:57.286262  8470 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:22:57.286267  8470 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:22:57.286272  8470 net.cpp:124] Setting up norm2\n",
      "I0430 08:22:57.286275  8470 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:22:57.286278  8470 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:22:57.286280  8470 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:22:57.286285  8470 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:22:57.286288  8470 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:22:57.286293  8470 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:22:57.287319  8470 net.cpp:124] Setting up conv3\n",
      "I0430 08:22:57.287330  8470 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:22:57.287333  8470 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:22:57.287343  8470 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:22:57.287351  8470 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:22:57.287355  8470 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:22:57.287359  8470 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:22:57.287364  8470 net.cpp:124] Setting up relu3\n",
      "I0430 08:22:57.287369  8470 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:22:57.287370  8470 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:22:57.287372  8470 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:22:57.287377  8470 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:22:57.287380  8470 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:22:57.287384  8470 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:22:57.287876  8470 net.cpp:124] Setting up conv4\n",
      "I0430 08:22:57.287884  8470 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:22:57.287889  8470 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:22:57.287895  8470 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:22:57.287901  8470 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:22:57.287905  8470 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:22:57.287909  8470 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:22:57.287914  8470 net.cpp:124] Setting up relu4\n",
      "I0430 08:22:57.287917  8470 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:22:57.287920  8470 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:22:57.287924  8470 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:22:57.287928  8470 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:22:57.287930  8470 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:22:57.287935  8470 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:22:57.288436  8470 net.cpp:124] Setting up conv5\n",
      "I0430 08:22:57.288444  8470 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:22:57.288446  8470 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:22:57.288457  8470 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:22:57.288463  8470 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:22:57.288466  8470 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:22:57.288470  8470 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:22:57.288475  8470 net.cpp:124] Setting up relu5\n",
      "I0430 08:22:57.288478  8470 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:22:57.288481  8470 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:22:57.288483  8470 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:22:57.288487  8470 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:22:57.288491  8470 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:22:57.288493  8470 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:22:57.288501  8470 net.cpp:124] Setting up pool5\n",
      "I0430 08:22:57.288503  8470 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:22:57.288506  8470 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:22:57.288508  8470 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:22:57.288516  8470 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:22:57.288517  8470 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:22:57.288522  8470 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:22:57.310144  8470 net.cpp:124] Setting up fc6\n",
      "I0430 08:22:57.310169  8470 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:22:57.310174  8470 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:22:57.310186  8470 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:22:57.310209  8470 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:22:57.310212  8470 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:22:57.310220  8470 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:22:57.310228  8470 net.cpp:124] Setting up relu6\n",
      "I0430 08:22:57.310232  8470 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:22:57.310235  8470 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:22:57.310237  8470 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:22:57.310242  8470 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:22:57.310245  8470 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:22:57.310247  8470 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:22:57.310252  8470 net.cpp:124] Setting up drop6\n",
      "I0430 08:22:57.310256  8470 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:22:57.310257  8470 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:22:57.310261  8470 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:22:57.310264  8470 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:22:57.310266  8470 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:22:57.310271  8470 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:22:57.322482  8470 net.cpp:124] Setting up fc7\n",
      "I0430 08:22:57.322510  8470 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:22:57.322525  8470 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:22:57.322538  8470 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:22:57.322548  8470 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:22:57.322553  8470 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:22:57.322559  8470 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:22:57.322568  8470 net.cpp:124] Setting up relu7\n",
      "I0430 08:22:57.322573  8470 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:22:57.322576  8470 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:22:57.322580  8470 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:22:57.322587  8470 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:22:57.322589  8470 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:22:57.322595  8470 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:22:57.322602  8470 net.cpp:124] Setting up drop7\n",
      "I0430 08:22:57.322607  8470 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:22:57.322609  8470 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:22:57.322613  8470 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:22:57.322619  8470 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:22:57.322623  8470 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:22:57.322628  8470 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:22:57.323503  8470 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:22:57.323518  8470 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:22:57.323523  8470 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:22:57.323531  8470 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:22:57.323535  8470 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:22:57.323539  8470 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:22:57.323544  8470 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:22:57.323547  8470 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:22:57.323551  8470 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:22:57.323555  8470 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:22:57.323559  8470 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:22:57.323563  8470 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:22:57.323567  8470 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:22:57.323571  8470 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:22:57.323575  8470 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:22:57.323580  8470 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:22:57.323583  8470 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:22:57.323587  8470 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:22:57.323591  8470 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:22:57.323596  8470 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:22:57.323599  8470 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:22:57.323603  8470 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:22:57.323607  8470 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:22:57.323611  8470 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:22:57.323614  8470 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:22:57.323617  8470 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:22:57.323621  8470 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:22:57.323634  8470 net.cpp:257] Network initialization done.\n",
      "I0430 08:22:57.409198  8470 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:22:57.506753  8470 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:22:57.507661  8470 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:22:57.507670  8470 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:22:57.507673  8470 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/167486.jpg'}, '/tmp/tmpuzoNlL.mat')\n",
      "Processed 3102 windows in 361.520 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.036 s.\n",
      "prediction    [-2.10771, -2.28848, -2.16392, -1.79251, -2.05...\n",
      "ymin                                                        148\n",
      "xmin                                                        376\n",
      "ymax                                                        236\n",
      "xmax                                                        412\n",
      "Name: /home/ambika/INF_project/data/person/167486.jpg, dtype: object\n",
      "prediction    [-1.67192, -2.51177, -1.78677, -2.19893, -2.11...\n",
      "ymin                                                        137\n",
      "xmin                                                        170\n",
      "ymax                                                        352\n",
      "xmax                                                        336\n",
      "Name: /home/ambika/INF_project/data/person/167486.jpg, dtype: object\n",
      "person\n",
      "376\t148\t412\t236\n",
      "bicycle\n",
      "170\t137\t336\t352\n",
      "167486\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:29:00.621899  8687 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:29:00.621922  8687 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:29:00.621934  8687 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:29:00.623111  8687 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:29:00.623280  8687 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:29:00.623286  8687 net.cpp:86] Creating Layer data\n",
      "I0430 08:29:00.623291  8687 net.cpp:382] data -> data\n",
      "I0430 08:29:00.623303  8687 net.cpp:124] Setting up data\n",
      "I0430 08:29:00.623311  8687 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:29:00.623314  8687 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:29:00.623318  8687 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:29:00.623327  8687 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:29:00.623330  8687 net.cpp:408] conv1 <- data\n",
      "I0430 08:29:00.623337  8687 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:29:00.623405  8687 net.cpp:124] Setting up conv1\n",
      "I0430 08:29:00.623411  8687 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:29:00.623414  8687 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:29:00.623421  8687 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:29:00.623425  8687 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:29:00.623428  8687 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:29:00.623431  8687 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:29:00.623436  8687 net.cpp:124] Setting up relu1\n",
      "I0430 08:29:00.623440  8687 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:29:00.623442  8687 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:29:00.623445  8687 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:29:00.623448  8687 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:29:00.623450  8687 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:29:00.623453  8687 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:29:00.623461  8687 net.cpp:124] Setting up pool1\n",
      "I0430 08:29:00.623463  8687 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:29:00.623466  8687 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:29:00.623468  8687 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:29:00.623472  8687 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:29:00.623476  8687 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:29:00.623478  8687 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:29:00.623483  8687 net.cpp:124] Setting up norm1\n",
      "I0430 08:29:00.623486  8687 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:29:00.623489  8687 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:29:00.623492  8687 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:29:00.623495  8687 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:29:00.623498  8687 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:29:00.623503  8687 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:29:00.623854  8687 net.cpp:124] Setting up conv2\n",
      "I0430 08:29:00.623862  8687 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:29:00.623867  8687 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:29:00.623875  8687 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:29:00.623881  8687 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:29:00.623885  8687 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:29:00.623889  8687 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:29:00.623893  8687 net.cpp:124] Setting up relu2\n",
      "I0430 08:29:00.623898  8687 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:29:00.623899  8687 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:29:00.623903  8687 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:29:00.623905  8687 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:29:00.623908  8687 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:29:00.623911  8687 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:29:00.623916  8687 net.cpp:124] Setting up pool2\n",
      "I0430 08:29:00.623920  8687 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:29:00.623922  8687 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:29:00.623924  8687 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:29:00.623930  8687 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:29:00.623932  8687 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:29:00.623936  8687 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:29:00.623940  8687 net.cpp:124] Setting up norm2\n",
      "I0430 08:29:00.623944  8687 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:29:00.623946  8687 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:29:00.623949  8687 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:29:00.623955  8687 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:29:00.623957  8687 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:29:00.623960  8687 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:29:00.624641  8687 net.cpp:124] Setting up conv3\n",
      "I0430 08:29:00.624651  8687 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:29:00.624656  8687 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:29:00.624665  8687 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:29:00.624673  8687 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:29:00.624678  8687 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:29:00.624683  8687 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:29:00.624689  8687 net.cpp:124] Setting up relu3\n",
      "I0430 08:29:00.624693  8687 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:29:00.624696  8687 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:29:00.624699  8687 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:29:00.624706  8687 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:29:00.624708  8687 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:29:00.624712  8687 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:29:00.625470  8687 net.cpp:124] Setting up conv4\n",
      "I0430 08:29:00.625483  8687 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:29:00.625486  8687 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:29:00.625493  8687 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:29:00.625499  8687 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:29:00.625502  8687 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:29:00.625509  8687 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:29:00.625514  8687 net.cpp:124] Setting up relu4\n",
      "I0430 08:29:00.625519  8687 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:29:00.625520  8687 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:29:00.625524  8687 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:29:00.625530  8687 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:29:00.625533  8687 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:29:00.625537  8687 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:29:00.626061  8687 net.cpp:124] Setting up conv5\n",
      "I0430 08:29:00.626070  8687 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:29:00.626072  8687 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:29:00.626082  8687 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:29:00.626087  8687 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:29:00.626091  8687 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:29:00.626096  8687 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:29:00.626101  8687 net.cpp:124] Setting up relu5\n",
      "I0430 08:29:00.626104  8687 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:29:00.626107  8687 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:29:00.626111  8687 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:29:00.626116  8687 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:29:00.626119  8687 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:29:00.626123  8687 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:29:00.626130  8687 net.cpp:124] Setting up pool5\n",
      "I0430 08:29:00.626135  8687 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:29:00.626137  8687 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:29:00.626140  8687 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:29:00.626147  8687 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:29:00.626150  8687 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:29:00.626155  8687 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:29:00.649570  8687 net.cpp:124] Setting up fc6\n",
      "I0430 08:29:00.649607  8687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:29:00.649612  8687 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:29:00.649622  8687 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:29:00.649638  8687 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:29:00.649641  8687 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:29:00.649648  8687 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:29:00.649657  8687 net.cpp:124] Setting up relu6\n",
      "I0430 08:29:00.649660  8687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:29:00.649665  8687 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:29:00.649669  8687 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:29:00.649677  8687 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:29:00.649679  8687 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:29:00.649683  8687 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:29:00.649690  8687 net.cpp:124] Setting up drop6\n",
      "I0430 08:29:00.649703  8687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:29:00.649711  8687 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:29:00.649713  8687 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:29:00.649720  8687 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:29:00.649724  8687 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:29:00.649729  8687 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:29:00.661128  8687 net.cpp:124] Setting up fc7\n",
      "I0430 08:29:00.661154  8687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:29:00.661159  8687 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:29:00.661175  8687 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:29:00.661183  8687 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:29:00.661191  8687 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:29:00.661197  8687 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:29:00.661207  8687 net.cpp:124] Setting up relu7\n",
      "I0430 08:29:00.661211  8687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:29:00.661213  8687 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:29:00.661221  8687 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:29:00.661240  8687 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:29:00.661243  8687 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:29:00.661248  8687 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:29:00.661253  8687 net.cpp:124] Setting up drop7\n",
      "I0430 08:29:00.661257  8687 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:29:00.661259  8687 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:29:00.661262  8687 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:29:00.661265  8687 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:29:00.661268  8687 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:29:00.661272  8687 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:29:00.661952  8687 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:29:00.661965  8687 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:29:00.661968  8687 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:29:00.661974  8687 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:29:00.661978  8687 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:29:00.661979  8687 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:29:00.661981  8687 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:29:00.661983  8687 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:29:00.661985  8687 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:29:00.661988  8687 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:29:00.661990  8687 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:29:00.661993  8687 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:29:00.661996  8687 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:29:00.661998  8687 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:29:00.662001  8687 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:29:00.662004  8687 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:29:00.662006  8687 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:29:00.662011  8687 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:29:00.662014  8687 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:29:00.662016  8687 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:29:00.662019  8687 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:29:00.662022  8687 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:29:00.662025  8687 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:29:00.662027  8687 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:29:00.662030  8687 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:29:00.662032  8687 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:29:00.662034  8687 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:29:00.662045  8687 net.cpp:257] Network initialization done.\n",
      "I0430 08:29:00.750726  8687 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:29:00.850911  8687 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:29:00.852039  8687 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:29:00.852057  8687 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:29:00.852063  8687 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/466239.jpg'}, '/tmp/tmpxiuGdm.mat')\n",
      "Processed 2395 windows in 275.727 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.038 s.\n",
      "prediction    [-2.39139, -2.0068, -2.22508, -2.62258, -1.876...\n",
      "ymin                                                         73\n",
      "xmin                                                        282\n",
      "ymax                                                        189\n",
      "xmax                                                        400\n",
      "Name: /home/ambika/INF_project/data/train/466239.jpg, dtype: object\n",
      "prediction    [-1.99099, -2.39995, -2.11679, -2.03694, -1.93...\n",
      "ymin                                                        246\n",
      "xmin                                                        153\n",
      "ymax                                                        286\n",
      "xmax                                                        272\n",
      "Name: /home/ambika/INF_project/data/train/466239.jpg, dtype: object\n",
      "harp\n",
      "282\t73\t400\t189\n",
      "bench\n",
      "153\t246\t272\t286\n",
      "466239\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:33:38.370103  8867 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:33:38.370128  8867 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:33:38.370132  8867 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:33:38.371644  8867 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:33:38.371791  8867 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:33:38.371805  8867 net.cpp:86] Creating Layer data\n",
      "I0430 08:33:38.371810  8867 net.cpp:382] data -> data\n",
      "I0430 08:33:38.371829  8867 net.cpp:124] Setting up data\n",
      "I0430 08:33:38.371840  8867 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:33:38.371846  8867 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:33:38.371851  8867 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:33:38.371862  8867 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:33:38.371867  8867 net.cpp:408] conv1 <- data\n",
      "I0430 08:33:38.371873  8867 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:33:38.371968  8867 net.cpp:124] Setting up conv1\n",
      "I0430 08:33:38.371976  8867 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:33:38.371978  8867 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:33:38.371989  8867 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:33:38.371994  8867 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:33:38.371996  8867 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:33:38.372000  8867 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:33:38.372005  8867 net.cpp:124] Setting up relu1\n",
      "I0430 08:33:38.372009  8867 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:33:38.372012  8867 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:33:38.372016  8867 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:33:38.372021  8867 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:33:38.372026  8867 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:33:38.372031  8867 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:33:38.372041  8867 net.cpp:124] Setting up pool1\n",
      "I0430 08:33:38.372047  8867 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:33:38.372061  8867 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:33:38.372076  8867 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:33:38.372089  8867 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:33:38.372093  8867 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:33:38.372098  8867 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:33:38.372107  8867 net.cpp:124] Setting up norm1\n",
      "I0430 08:33:38.372112  8867 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:33:38.372117  8867 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:33:38.372120  8867 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:33:38.372128  8867 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:33:38.372129  8867 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:33:38.372133  8867 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:33:38.372670  8867 net.cpp:124] Setting up conv2\n",
      "I0430 08:33:38.372712  8867 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:33:38.372717  8867 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:33:38.372742  8867 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:33:38.372764  8867 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:33:38.372773  8867 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:33:38.372786  8867 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:33:38.372800  8867 net.cpp:124] Setting up relu2\n",
      "I0430 08:33:38.372804  8867 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:33:38.372807  8867 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:33:38.372810  8867 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:33:38.372822  8867 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:33:38.372824  8867 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:33:38.372830  8867 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:33:38.372843  8867 net.cpp:124] Setting up pool2\n",
      "I0430 08:33:38.372848  8867 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:33:38.372850  8867 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:33:38.372853  8867 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:33:38.372870  8867 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:33:38.372879  8867 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:33:38.372884  8867 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:33:38.372894  8867 net.cpp:124] Setting up norm2\n",
      "I0430 08:33:38.372902  8867 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:33:38.372905  8867 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:33:38.372911  8867 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:33:38.372921  8867 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:33:38.372925  8867 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:33:38.372931  8867 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:33:38.374248  8867 net.cpp:124] Setting up conv3\n",
      "I0430 08:33:38.374264  8867 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:33:38.374267  8867 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:33:38.374279  8867 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:33:38.374289  8867 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:33:38.374292  8867 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:33:38.374299  8867 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:33:38.374305  8867 net.cpp:124] Setting up relu3\n",
      "I0430 08:33:38.374310  8867 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:33:38.374311  8867 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:33:38.374315  8867 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:33:38.374320  8867 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:33:38.374321  8867 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:33:38.374325  8867 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:33:38.375061  8867 net.cpp:124] Setting up conv4\n",
      "I0430 08:33:38.375069  8867 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:33:38.375073  8867 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:33:38.375079  8867 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:33:38.375087  8867 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:33:38.375090  8867 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:33:38.375093  8867 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:33:38.375097  8867 net.cpp:124] Setting up relu4\n",
      "I0430 08:33:38.375102  8867 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:33:38.375103  8867 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:33:38.375107  8867 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:33:38.375110  8867 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:33:38.375113  8867 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:33:38.375116  8867 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:33:38.375669  8867 net.cpp:124] Setting up conv5\n",
      "I0430 08:33:38.375677  8867 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:33:38.375680  8867 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:33:38.375692  8867 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:33:38.375697  8867 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:33:38.375700  8867 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:33:38.375704  8867 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:33:38.375708  8867 net.cpp:124] Setting up relu5\n",
      "I0430 08:33:38.375711  8867 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:33:38.375713  8867 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:33:38.375716  8867 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:33:38.375721  8867 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:33:38.375723  8867 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:33:38.375727  8867 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:33:38.375733  8867 net.cpp:124] Setting up pool5\n",
      "I0430 08:33:38.375736  8867 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:33:38.375740  8867 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:33:38.375741  8867 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:33:38.375747  8867 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:33:38.375751  8867 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:33:38.375754  8867 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:33:38.402496  8867 net.cpp:124] Setting up fc6\n",
      "I0430 08:33:38.402519  8867 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:33:38.402523  8867 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:33:38.402536  8867 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:33:38.402554  8867 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:33:38.402557  8867 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:33:38.402565  8867 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:33:38.402575  8867 net.cpp:124] Setting up relu6\n",
      "I0430 08:33:38.402578  8867 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:33:38.402581  8867 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:33:38.402583  8867 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:33:38.402587  8867 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:33:38.402590  8867 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:33:38.402593  8867 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:33:38.402598  8867 net.cpp:124] Setting up drop6\n",
      "I0430 08:33:38.402601  8867 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:33:38.402603  8867 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:33:38.402606  8867 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:33:38.402609  8867 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:33:38.402612  8867 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:33:38.402616  8867 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:33:38.415025  8867 net.cpp:124] Setting up fc7\n",
      "I0430 08:33:38.415058  8867 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:33:38.415060  8867 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:33:38.415071  8867 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:33:38.415079  8867 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:33:38.415082  8867 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:33:38.415088  8867 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:33:38.415096  8867 net.cpp:124] Setting up relu7\n",
      "I0430 08:33:38.415098  8867 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:33:38.415099  8867 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:33:38.415102  8867 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:33:38.415107  8867 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:33:38.415108  8867 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:33:38.415112  8867 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:33:38.415117  8867 net.cpp:124] Setting up drop7\n",
      "I0430 08:33:38.415118  8867 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:33:38.415120  8867 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:33:38.415122  8867 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:33:38.415127  8867 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:33:38.415127  8867 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:33:38.415130  8867 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:33:38.416041  8867 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:33:38.416064  8867 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:33:38.416066  8867 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:33:38.416077  8867 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:33:38.416081  8867 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:33:38.416085  8867 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:33:38.416088  8867 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:33:38.416092  8867 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:33:38.416096  8867 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:33:38.416100  8867 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:33:38.416103  8867 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:33:38.416107  8867 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:33:38.416110  8867 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:33:38.416115  8867 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:33:38.416117  8867 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:33:38.416121  8867 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:33:38.416123  8867 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:33:38.416128  8867 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:33:38.416132  8867 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:33:38.416136  8867 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:33:38.416139  8867 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:33:38.416143  8867 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:33:38.416147  8867 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:33:38.416151  8867 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:33:38.416154  8867 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:33:38.416157  8867 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:33:38.416160  8867 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:33:38.416174  8867 net.cpp:257] Network initialization done.\n",
      "I0430 08:33:38.516522  8867 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:33:38.632375  8867 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:33:38.633291  8867 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:33:38.633299  8867 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:33:38.633301  8867 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/441695.jpg'}, '/tmp/tmpzdJe5E.mat')\n",
      "Processed 1437 windows in 183.444 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.034 s.\n",
      "prediction    [-2.65385, 1.76824, -2.20375, -1.95458, -2.289...\n",
      "ymin                                                    225.008\n",
      "xmin                                                          0\n",
      "ymax                                                    402.408\n",
      "xmax                                                     228.36\n",
      "Name: /home/ambika/INF_project/data/airplane/441695.jpg, dtype: object\n",
      "prediction    [-2.21252, -1.37949, -1.76144, -1.73372, -2.04...\n",
      "ymin                                                    280.672\n",
      "xmin                                                    205.408\n",
      "ymax                                                     459.64\n",
      "xmax                                                    392.216\n",
      "Name: /home/ambika/INF_project/data/airplane/441695.jpg, dtype: object\n",
      "airplane\n",
      "0.0\t225.008\t228.36\t402.408\n",
      "sofa\n",
      "205.408\t280.672\t392.216\t459.64\n",
      "441695\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:36:43.727111  9028 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:36:43.727133  9028 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:36:43.727136  9028 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:36:43.728305  9028 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:36:43.728406  9028 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:36:43.728417  9028 net.cpp:86] Creating Layer data\n",
      "I0430 08:36:43.728425  9028 net.cpp:382] data -> data\n",
      "I0430 08:36:43.728446  9028 net.cpp:124] Setting up data\n",
      "I0430 08:36:43.728453  9028 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:36:43.728457  9028 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:36:43.728461  9028 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:36:43.728469  9028 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:36:43.728473  9028 net.cpp:408] conv1 <- data\n",
      "I0430 08:36:43.728479  9028 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:36:43.728598  9028 net.cpp:124] Setting up conv1\n",
      "I0430 08:36:43.728605  9028 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:36:43.728610  9028 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:36:43.728623  9028 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:36:43.728631  9028 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:36:43.728634  9028 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:36:43.728639  9028 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:36:43.728646  9028 net.cpp:124] Setting up relu1\n",
      "I0430 08:36:43.728652  9028 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:36:43.728654  9028 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:36:43.728658  9028 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:36:43.728664  9028 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:36:43.728667  9028 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:36:43.728672  9028 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:36:43.728683  9028 net.cpp:124] Setting up pool1\n",
      "I0430 08:36:43.728688  9028 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:36:43.728693  9028 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:36:43.728695  9028 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:36:43.728703  9028 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:36:43.728706  9028 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:36:43.728711  9028 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:36:43.728719  9028 net.cpp:124] Setting up norm1\n",
      "I0430 08:36:43.728724  9028 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:36:43.728729  9028 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:36:43.728731  9028 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:36:43.728737  9028 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:36:43.728741  9028 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:36:43.728746  9028 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:36:43.729246  9028 net.cpp:124] Setting up conv2\n",
      "I0430 08:36:43.729257  9028 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:36:43.729260  9028 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:36:43.729267  9028 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:36:43.729274  9028 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:36:43.729276  9028 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:36:43.729280  9028 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:36:43.729286  9028 net.cpp:124] Setting up relu2\n",
      "I0430 08:36:43.729290  9028 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:36:43.729292  9028 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:36:43.729296  9028 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:36:43.729301  9028 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:36:43.729303  9028 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:36:43.729308  9028 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:36:43.729315  9028 net.cpp:124] Setting up pool2\n",
      "I0430 08:36:43.729320  9028 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:36:43.729322  9028 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:36:43.729326  9028 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:36:43.729333  9028 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:36:43.729337  9028 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:36:43.729341  9028 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:36:43.729348  9028 net.cpp:124] Setting up norm2\n",
      "I0430 08:36:43.729352  9028 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:36:43.729354  9028 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:36:43.729357  9028 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:36:43.729365  9028 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:36:43.729368  9028 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:36:43.729377  9028 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:36:43.730329  9028 net.cpp:124] Setting up conv3\n",
      "I0430 08:36:43.730350  9028 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:36:43.730355  9028 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:36:43.730365  9028 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:36:43.730373  9028 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:36:43.730376  9028 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:36:43.730383  9028 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:36:43.730392  9028 net.cpp:124] Setting up relu3\n",
      "I0430 08:36:43.730397  9028 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:36:43.730401  9028 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:36:43.730403  9028 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:36:43.730413  9028 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:36:43.730417  9028 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:36:43.730422  9028 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:36:43.731222  9028 net.cpp:124] Setting up conv4\n",
      "I0430 08:36:43.731237  9028 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:36:43.731241  9028 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:36:43.731248  9028 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:36:43.731254  9028 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:36:43.731259  9028 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:36:43.731266  9028 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:36:43.731272  9028 net.cpp:124] Setting up relu4\n",
      "I0430 08:36:43.731277  9028 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:36:43.731281  9028 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:36:43.731284  9028 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:36:43.731292  9028 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:36:43.731294  9028 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:36:43.731299  9028 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:36:43.731909  9028 net.cpp:124] Setting up conv5\n",
      "I0430 08:36:43.731926  9028 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:36:43.731930  9028 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:36:43.731941  9028 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:36:43.731950  9028 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:36:43.731953  9028 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:36:43.731959  9028 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:36:43.731966  9028 net.cpp:124] Setting up relu5\n",
      "I0430 08:36:43.731969  9028 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:36:43.731972  9028 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:36:43.731976  9028 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:36:43.731981  9028 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:36:43.731983  9028 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:36:43.731987  9028 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:36:43.731997  9028 net.cpp:124] Setting up pool5\n",
      "I0430 08:36:43.732000  9028 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:36:43.732003  9028 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:36:43.732005  9028 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:36:43.732014  9028 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:36:43.732018  9028 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:36:43.732023  9028 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:36:43.758967  9028 net.cpp:124] Setting up fc6\n",
      "I0430 08:36:43.758993  9028 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:36:43.758997  9028 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:36:43.759008  9028 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:36:43.759019  9028 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:36:43.759023  9028 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:36:43.759029  9028 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:36:43.759037  9028 net.cpp:124] Setting up relu6\n",
      "I0430 08:36:43.759042  9028 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:36:43.759043  9028 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:36:43.759047  9028 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:36:43.759052  9028 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:36:43.759064  9028 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:36:43.759069  9028 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:36:43.759075  9028 net.cpp:124] Setting up drop6\n",
      "I0430 08:36:43.759079  9028 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:36:43.759081  9028 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:36:43.759085  9028 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:36:43.759090  9028 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:36:43.759093  9028 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:36:43.759099  9028 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:36:43.771121  9028 net.cpp:124] Setting up fc7\n",
      "I0430 08:36:43.771145  9028 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:36:43.771148  9028 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:36:43.771162  9028 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:36:43.771173  9028 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:36:43.771176  9028 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:36:43.771183  9028 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:36:43.771193  9028 net.cpp:124] Setting up relu7\n",
      "I0430 08:36:43.771195  9028 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:36:43.771199  9028 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:36:43.771203  9028 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:36:43.771216  9028 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:36:43.771219  9028 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:36:43.771224  9028 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:36:43.771231  9028 net.cpp:124] Setting up drop7\n",
      "I0430 08:36:43.771235  9028 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:36:43.771237  9028 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:36:43.771241  9028 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:36:43.771246  9028 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:36:43.771250  9028 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:36:43.771255  9028 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:36:43.772568  9028 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:36:43.772619  9028 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:36:43.772622  9028 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:36:43.772655  9028 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:36:43.772661  9028 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:36:43.772665  9028 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:36:43.772670  9028 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:36:43.772672  9028 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:36:43.772676  9028 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:36:43.772680  9028 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:36:43.772689  9028 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:36:43.772693  9028 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:36:43.772697  9028 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:36:43.772701  9028 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:36:43.772703  9028 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:36:43.772707  9028 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:36:43.772711  9028 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:36:43.772716  9028 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:36:43.772720  9028 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:36:43.772725  9028 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:36:43.772728  9028 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:36:43.772734  9028 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:36:43.772739  9028 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:36:43.772742  9028 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:36:43.772747  9028 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:36:43.772749  9028 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:36:43.772753  9028 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:36:43.772768  9028 net.cpp:257] Network initialization done.\n",
      "I0430 08:36:43.869773  9028 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:36:43.986847  9028 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:36:43.988420  9028 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:36:43.988517  9028 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:36:43.988523  9028 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/548780.jpg'}, '/tmp/tmpz1bwHZ.mat')\n",
      "Processed 2819 windows in 323.490 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.3707, -2.61676, -1.90549, -1.73021, -1.961...\n",
      "ymin                                                         57\n",
      "xmin                                                        205\n",
      "ymax                                                        288\n",
      "xmax                                                        349\n",
      "Name: /home/ambika/INF_project/data/bird/548780.jpg, dtype: object\n",
      "prediction    [-1.90992, -1.69198, -1.81891, -2.38881, -1.86...\n",
      "ymin                                                        140\n",
      "xmin                                                        226\n",
      "ymax                                                        163\n",
      "xmax                                                        253\n",
      "Name: /home/ambika/INF_project/data/bird/548780.jpg, dtype: object\n",
      "person\n",
      "205\t57\t349\t288\n",
      "basketball\n",
      "226\t140\t253\t163\n",
      "548780\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:42:09.105722  9222 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:42:09.105742  9222 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:42:09.105746  9222 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:42:09.106923  9222 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:42:09.107079  9222 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:42:09.107087  9222 net.cpp:86] Creating Layer data\n",
      "I0430 08:42:09.107095  9222 net.cpp:382] data -> data\n",
      "I0430 08:42:09.107112  9222 net.cpp:124] Setting up data\n",
      "I0430 08:42:09.107120  9222 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:42:09.107121  9222 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:42:09.107125  9222 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:42:09.107133  9222 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:42:09.107136  9222 net.cpp:408] conv1 <- data\n",
      "I0430 08:42:09.107141  9222 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:42:09.107203  9222 net.cpp:124] Setting up conv1\n",
      "I0430 08:42:09.107213  9222 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:42:09.107216  9222 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:42:09.107224  9222 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:42:09.107230  9222 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:42:09.107233  9222 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:42:09.107237  9222 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:42:09.107242  9222 net.cpp:124] Setting up relu1\n",
      "I0430 08:42:09.107246  9222 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:42:09.107249  9222 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:42:09.107252  9222 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:42:09.107257  9222 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:42:09.107259  9222 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:42:09.107264  9222 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:42:09.107271  9222 net.cpp:124] Setting up pool1\n",
      "I0430 08:42:09.107275  9222 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:42:09.107277  9222 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:42:09.107280  9222 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:42:09.107286  9222 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:42:09.107288  9222 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:42:09.107293  9222 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:42:09.107298  9222 net.cpp:124] Setting up norm1\n",
      "I0430 08:42:09.107302  9222 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:42:09.107306  9222 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:42:09.107308  9222 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:42:09.107313  9222 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:42:09.107316  9222 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:42:09.107321  9222 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:42:09.107667  9222 net.cpp:124] Setting up conv2\n",
      "I0430 08:42:09.107673  9222 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:42:09.107676  9222 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:42:09.107683  9222 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:42:09.107688  9222 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:42:09.107692  9222 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:42:09.107695  9222 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:42:09.107700  9222 net.cpp:124] Setting up relu2\n",
      "I0430 08:42:09.107704  9222 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:42:09.107707  9222 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:42:09.107710  9222 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:42:09.107715  9222 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:42:09.107718  9222 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:42:09.107722  9222 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:42:09.107728  9222 net.cpp:124] Setting up pool2\n",
      "I0430 08:42:09.107733  9222 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:42:09.107735  9222 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:42:09.107738  9222 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:42:09.107743  9222 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:42:09.107745  9222 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:42:09.107749  9222 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:42:09.107754  9222 net.cpp:124] Setting up norm2\n",
      "I0430 08:42:09.107759  9222 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:42:09.107761  9222 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:42:09.107764  9222 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:42:09.107770  9222 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:42:09.107774  9222 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:42:09.107779  9222 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:42:09.108451  9222 net.cpp:124] Setting up conv3\n",
      "I0430 08:42:09.108460  9222 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:42:09.108464  9222 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:42:09.108472  9222 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:42:09.108477  9222 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:42:09.108480  9222 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:42:09.108485  9222 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:42:09.108490  9222 net.cpp:124] Setting up relu3\n",
      "I0430 08:42:09.108494  9222 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:42:09.108496  9222 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:42:09.108500  9222 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:42:09.108505  9222 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:42:09.108508  9222 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:42:09.108512  9222 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:42:09.109246  9222 net.cpp:124] Setting up conv4\n",
      "I0430 08:42:09.109256  9222 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:42:09.109259  9222 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:42:09.109266  9222 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:42:09.109271  9222 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:42:09.109273  9222 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:42:09.109277  9222 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:42:09.109282  9222 net.cpp:124] Setting up relu4\n",
      "I0430 08:42:09.109287  9222 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:42:09.109288  9222 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:42:09.109292  9222 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:42:09.109297  9222 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:42:09.109300  9222 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:42:09.109305  9222 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:42:09.109802  9222 net.cpp:124] Setting up conv5\n",
      "I0430 08:42:09.109812  9222 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:42:09.109815  9222 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:42:09.109824  9222 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:42:09.109829  9222 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:42:09.109833  9222 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:42:09.109836  9222 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:42:09.109841  9222 net.cpp:124] Setting up relu5\n",
      "I0430 08:42:09.109845  9222 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:42:09.109848  9222 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:42:09.109851  9222 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:42:09.109856  9222 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:42:09.109859  9222 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:42:09.109863  9222 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:42:09.109870  9222 net.cpp:124] Setting up pool5\n",
      "I0430 08:42:09.109875  9222 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:42:09.109877  9222 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:42:09.109880  9222 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:42:09.109889  9222 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:42:09.109891  9222 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:42:09.109896  9222 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:42:09.133497  9222 net.cpp:124] Setting up fc6\n",
      "I0430 08:42:09.133523  9222 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:42:09.133540  9222 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:42:09.133550  9222 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:42:09.133558  9222 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:42:09.133561  9222 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:42:09.133569  9222 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:42:09.133587  9222 net.cpp:124] Setting up relu6\n",
      "I0430 08:42:09.133592  9222 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:42:09.133595  9222 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:42:09.133599  9222 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:42:09.133604  9222 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:42:09.133606  9222 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:42:09.133610  9222 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:42:09.133616  9222 net.cpp:124] Setting up drop6\n",
      "I0430 08:42:09.133620  9222 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:42:09.133622  9222 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:42:09.133625  9222 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:42:09.133631  9222 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:42:09.133633  9222 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:42:09.133638  9222 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:42:09.143409  9222 net.cpp:124] Setting up fc7\n",
      "I0430 08:42:09.143434  9222 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:42:09.143437  9222 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:42:09.143447  9222 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:42:09.143456  9222 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:42:09.143460  9222 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:42:09.143467  9222 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:42:09.143476  9222 net.cpp:124] Setting up relu7\n",
      "I0430 08:42:09.143479  9222 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:42:09.143482  9222 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:42:09.143486  9222 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:42:09.143491  9222 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:42:09.143494  9222 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:42:09.143498  9222 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:42:09.143504  9222 net.cpp:124] Setting up drop7\n",
      "I0430 08:42:09.143508  9222 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:42:09.143510  9222 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:42:09.143513  9222 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:42:09.143519  9222 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:42:09.143522  9222 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:42:09.143527  9222 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:42:09.144160  9222 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:42:09.144170  9222 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:42:09.144173  9222 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:42:09.144181  9222 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:42:09.144183  9222 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:42:09.144186  9222 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:42:09.144191  9222 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:42:09.144193  9222 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:42:09.144196  9222 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:42:09.144199  9222 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:42:09.144203  9222 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:42:09.144207  9222 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:42:09.144209  9222 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:42:09.144213  9222 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:42:09.144217  9222 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:42:09.144220  9222 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:42:09.144223  9222 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:42:09.144227  9222 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:42:09.144230  9222 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:42:09.144237  9222 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:42:09.144240  9222 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:42:09.144243  9222 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:42:09.144248  9222 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:42:09.144250  9222 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:42:09.144253  9222 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:42:09.144256  9222 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:42:09.144259  9222 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:42:09.144269  9222 net.cpp:257] Network initialization done.\n",
      "I0430 08:42:09.232432  9222 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:42:09.332278  9222 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:42:09.333195  9222 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:42:09.333204  9222 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:42:09.333209  9222 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/148526.jpg'}, '/tmp/tmpRkqf1i.mat')\n",
      "Processed 2169 windows in 248.892 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.05626, -2.50516, -2.03691, -2.25923, -2.14...\n",
      "ymin                                                         41\n",
      "xmin                                                         67\n",
      "ymax                                                        334\n",
      "xmax                                                        218\n",
      "Name: /home/ambika/INF_project/data/bus/148526.jpg, dtype: object\n",
      "prediction    [-1.88502, -1.99891, -1.81374, -1.65994, -2.12...\n",
      "ymin                                                        178\n",
      "xmin                                                         57\n",
      "ymax                                                        334\n",
      "xmax                                                        172\n",
      "Name: /home/ambika/INF_project/data/bus/148526.jpg, dtype: object\n",
      "person\n",
      "67\t41\t218\t334\n",
      "traffic light\n",
      "57\t178\t172\t334\n",
      "148526\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:46:19.784840  9420 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:46:19.784863  9420 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:46:19.784868  9420 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:46:19.786180  9420 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:46:19.786753  9420 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:46:19.786772  9420 net.cpp:86] Creating Layer data\n",
      "I0430 08:46:19.786782  9420 net.cpp:382] data -> data\n",
      "I0430 08:46:19.786801  9420 net.cpp:124] Setting up data\n",
      "I0430 08:46:19.786811  9420 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:46:19.786818  9420 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:46:19.786824  9420 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:46:19.786835  9420 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:46:19.786841  9420 net.cpp:408] conv1 <- data\n",
      "I0430 08:46:19.786849  9420 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:46:19.786942  9420 net.cpp:124] Setting up conv1\n",
      "I0430 08:46:19.786953  9420 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:46:19.786959  9420 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:46:19.786972  9420 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:46:19.786983  9420 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:46:19.786989  9420 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:46:19.786998  9420 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:46:19.787008  9420 net.cpp:124] Setting up relu1\n",
      "I0430 08:46:19.787015  9420 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:46:19.787021  9420 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:46:19.787027  9420 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:46:19.787035  9420 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:46:19.787042  9420 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:46:19.787050  9420 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:46:19.787062  9420 net.cpp:124] Setting up pool1\n",
      "I0430 08:46:19.787070  9420 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:46:19.787075  9420 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:46:19.787081  9420 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:46:19.787091  9420 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:46:19.787096  9420 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:46:19.787104  9420 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:46:19.787116  9420 net.cpp:124] Setting up norm1\n",
      "I0430 08:46:19.787123  9420 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:46:19.787129  9420 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:46:19.787135  9420 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:46:19.787143  9420 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:46:19.787149  9420 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:46:19.787156  9420 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:46:19.787554  9420 net.cpp:124] Setting up conv2\n",
      "I0430 08:46:19.787565  9420 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:46:19.787569  9420 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:46:19.787576  9420 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:46:19.787582  9420 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:46:19.787585  9420 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:46:19.787591  9420 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:46:19.787596  9420 net.cpp:124] Setting up relu2\n",
      "I0430 08:46:19.787601  9420 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:46:19.787603  9420 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:46:19.787606  9420 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:46:19.787611  9420 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:46:19.787613  9420 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:46:19.787618  9420 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:46:19.787624  9420 net.cpp:124] Setting up pool2\n",
      "I0430 08:46:19.787628  9420 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:46:19.787631  9420 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:46:19.787634  9420 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:46:19.787642  9420 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:46:19.787644  9420 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:46:19.787648  9420 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:46:19.787654  9420 net.cpp:124] Setting up norm2\n",
      "I0430 08:46:19.787658  9420 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:46:19.787660  9420 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:46:19.787663  9420 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:46:19.787670  9420 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:46:19.787673  9420 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:46:19.787678  9420 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:46:19.788728  9420 net.cpp:124] Setting up conv3\n",
      "I0430 08:46:19.788743  9420 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:46:19.788746  9420 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:46:19.788756  9420 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:46:19.788763  9420 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:46:19.788765  9420 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:46:19.788769  9420 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:46:19.788774  9420 net.cpp:124] Setting up relu3\n",
      "I0430 08:46:19.788779  9420 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:46:19.788781  9420 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:46:19.788784  9420 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:46:19.788791  9420 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:46:19.788794  9420 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:46:19.788799  9420 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:46:19.789268  9420 net.cpp:124] Setting up conv4\n",
      "I0430 08:46:19.789276  9420 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:46:19.789279  9420 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:46:19.789284  9420 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:46:19.789289  9420 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:46:19.789293  9420 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:46:19.789296  9420 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:46:19.789300  9420 net.cpp:124] Setting up relu4\n",
      "I0430 08:46:19.789304  9420 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:46:19.789307  9420 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:46:19.789310  9420 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:46:19.789316  9420 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:46:19.789319  9420 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:46:19.789324  9420 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:46:19.789821  9420 net.cpp:124] Setting up conv5\n",
      "I0430 08:46:19.789829  9420 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:46:19.789832  9420 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:46:19.789841  9420 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:46:19.789845  9420 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:46:19.789849  9420 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:46:19.789852  9420 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:46:19.789857  9420 net.cpp:124] Setting up relu5\n",
      "I0430 08:46:19.789861  9420 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:46:19.789863  9420 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:46:19.789866  9420 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:46:19.789872  9420 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:46:19.789875  9420 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:46:19.789880  9420 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:46:19.789887  9420 net.cpp:124] Setting up pool5\n",
      "I0430 08:46:19.789891  9420 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:46:19.789894  9420 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:46:19.789896  9420 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:46:19.789904  9420 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:46:19.789907  9420 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:46:19.789912  9420 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:46:19.811900  9420 net.cpp:124] Setting up fc6\n",
      "I0430 08:46:19.811944  9420 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:46:19.811959  9420 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:46:19.811970  9420 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:46:19.811978  9420 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:46:19.811982  9420 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:46:19.811990  9420 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:46:19.811997  9420 net.cpp:124] Setting up relu6\n",
      "I0430 08:46:19.812001  9420 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:46:19.812003  9420 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:46:19.812007  9420 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:46:19.812013  9420 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:46:19.812016  9420 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:46:19.812021  9420 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:46:19.812027  9420 net.cpp:124] Setting up drop6\n",
      "I0430 08:46:19.812031  9420 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:46:19.812033  9420 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:46:19.812036  9420 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:46:19.812042  9420 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:46:19.812046  9420 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:46:19.812050  9420 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:46:19.823738  9420 net.cpp:124] Setting up fc7\n",
      "I0430 08:46:19.823762  9420 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:46:19.823766  9420 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:46:19.823791  9420 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:46:19.823801  9420 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:46:19.823804  9420 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:46:19.823812  9420 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:46:19.823819  9420 net.cpp:124] Setting up relu7\n",
      "I0430 08:46:19.823823  9420 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:46:19.823827  9420 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:46:19.823830  9420 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:46:19.823837  9420 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:46:19.823838  9420 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:46:19.823844  9420 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:46:19.823850  9420 net.cpp:124] Setting up drop7\n",
      "I0430 08:46:19.823853  9420 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:46:19.823856  9420 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:46:19.823859  9420 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:46:19.823864  9420 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:46:19.823868  9420 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:46:19.823873  9420 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:46:19.824774  9420 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:46:19.824784  9420 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:46:19.824789  9420 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:46:19.824795  9420 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:46:19.824800  9420 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:46:19.824802  9420 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:46:19.824805  9420 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:46:19.824810  9420 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:46:19.824812  9420 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:46:19.824815  9420 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:46:19.824820  9420 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:46:19.824822  9420 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:46:19.824826  9420 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:46:19.824829  9420 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:46:19.824832  9420 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:46:19.824836  9420 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:46:19.824838  9420 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:46:19.824844  9420 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:46:19.824847  9420 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:46:19.824851  9420 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:46:19.824854  9420 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:46:19.824857  9420 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:46:19.824861  9420 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:46:19.824864  9420 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:46:19.824867  9420 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:46:19.824870  9420 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:46:19.824873  9420 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:46:19.824883  9420 net.cpp:257] Network initialization done.\n",
      "I0430 08:46:19.915139  9420 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:46:20.017809  9420 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:46:20.018863  9420 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:46:20.018877  9420 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:46:20.018880  9420 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/31519.jpg'}, '/tmp/tmpFZ4Mgm.mat')\n",
      "Processed 3076 windows in 355.988 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.036 s.\n",
      "prediction    [-2.78126, -2.45556, -1.87826, -2.20432, -2.20...\n",
      "ymin                                                        201\n",
      "xmin                                                          9\n",
      "ymax                                                        281\n",
      "xmax                                                         46\n",
      "Name: /home/ambika/INF_project/data/car/31519.jpg, dtype: object\n",
      "prediction    [-1.84981, -2.19187, -1.97273, -2.01219, -1.86...\n",
      "ymin                                                        222\n",
      "xmin                                                        203\n",
      "ymax                                                        252\n",
      "xmax                                                        262\n",
      "Name: /home/ambika/INF_project/data/car/31519.jpg, dtype: object\n",
      "person\n",
      "9\t201\t46\t281\n",
      "car\n",
      "203\t222\t262\t252\n",
      "31519\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:52:17.641849  9649 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:52:17.641876  9649 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:52:17.641880  9649 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:52:17.643010  9649 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:52:17.643214  9649 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:52:17.643224  9649 net.cpp:86] Creating Layer data\n",
      "I0430 08:52:17.643230  9649 net.cpp:382] data -> data\n",
      "I0430 08:52:17.643244  9649 net.cpp:124] Setting up data\n",
      "I0430 08:52:17.643255  9649 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:52:17.643257  9649 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:52:17.643262  9649 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:52:17.643270  9649 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:52:17.643271  9649 net.cpp:408] conv1 <- data\n",
      "I0430 08:52:17.643275  9649 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:52:17.643332  9649 net.cpp:124] Setting up conv1\n",
      "I0430 08:52:17.643337  9649 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:52:17.643339  9649 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:52:17.643347  9649 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:52:17.643352  9649 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:52:17.643353  9649 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:52:17.643357  9649 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:52:17.643362  9649 net.cpp:124] Setting up relu1\n",
      "I0430 08:52:17.643364  9649 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:52:17.643366  9649 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:52:17.643368  9649 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:52:17.643373  9649 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:52:17.643374  9649 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:52:17.643378  9649 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:52:17.643384  9649 net.cpp:124] Setting up pool1\n",
      "I0430 08:52:17.643388  9649 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:52:17.643391  9649 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:52:17.643394  9649 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:52:17.643401  9649 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:52:17.643405  9649 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:52:17.643411  9649 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:52:17.643419  9649 net.cpp:124] Setting up norm1\n",
      "I0430 08:52:17.643425  9649 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:52:17.643429  9649 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:52:17.643430  9649 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:52:17.643435  9649 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:52:17.643437  9649 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:52:17.643441  9649 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:52:17.643795  9649 net.cpp:124] Setting up conv2\n",
      "I0430 08:52:17.643801  9649 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:52:17.643805  9649 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:52:17.643813  9649 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:52:17.643820  9649 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:52:17.643821  9649 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:52:17.643826  9649 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:52:17.643829  9649 net.cpp:124] Setting up relu2\n",
      "I0430 08:52:17.643832  9649 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:52:17.643836  9649 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:52:17.643837  9649 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:52:17.643842  9649 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:52:17.643844  9649 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:52:17.643847  9649 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:52:17.643852  9649 net.cpp:124] Setting up pool2\n",
      "I0430 08:52:17.643856  9649 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:52:17.643858  9649 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:52:17.643860  9649 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:52:17.643865  9649 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:52:17.643868  9649 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:52:17.643872  9649 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:52:17.643877  9649 net.cpp:124] Setting up norm2\n",
      "I0430 08:52:17.643879  9649 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:52:17.643882  9649 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:52:17.643883  9649 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:52:17.643888  9649 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:52:17.643890  9649 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:52:17.643893  9649 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:52:17.644927  9649 net.cpp:124] Setting up conv3\n",
      "I0430 08:52:17.644942  9649 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:52:17.644946  9649 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:52:17.644958  9649 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:52:17.644968  9649 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:52:17.644971  9649 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:52:17.644976  9649 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:52:17.644981  9649 net.cpp:124] Setting up relu3\n",
      "I0430 08:52:17.644984  9649 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:52:17.644987  9649 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:52:17.644989  9649 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:52:17.644994  9649 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:52:17.644996  9649 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:52:17.645000  9649 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:52:17.645484  9649 net.cpp:124] Setting up conv4\n",
      "I0430 08:52:17.645494  9649 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:52:17.645498  9649 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:52:17.645505  9649 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:52:17.645512  9649 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:52:17.645515  9649 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:52:17.645519  9649 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:52:17.645524  9649 net.cpp:124] Setting up relu4\n",
      "I0430 08:52:17.645526  9649 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:52:17.645529  9649 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:52:17.645531  9649 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:52:17.645535  9649 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:52:17.645537  9649 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:52:17.645541  9649 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:52:17.646088  9649 net.cpp:124] Setting up conv5\n",
      "I0430 08:52:17.646097  9649 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:52:17.646101  9649 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:52:17.646112  9649 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:52:17.646119  9649 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:52:17.646122  9649 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:52:17.646126  9649 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:52:17.646131  9649 net.cpp:124] Setting up relu5\n",
      "I0430 08:52:17.646134  9649 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:52:17.646136  9649 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:52:17.646138  9649 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:52:17.646143  9649 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:52:17.646145  9649 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:52:17.646148  9649 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:52:17.646155  9649 net.cpp:124] Setting up pool5\n",
      "I0430 08:52:17.646158  9649 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:52:17.646160  9649 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:52:17.646163  9649 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:52:17.646170  9649 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:52:17.646173  9649 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:52:17.646176  9649 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:52:17.670348  9649 net.cpp:124] Setting up fc6\n",
      "I0430 08:52:17.670375  9649 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:52:17.670377  9649 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:52:17.670392  9649 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:52:17.670405  9649 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:52:17.670411  9649 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:52:17.670418  9649 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:52:17.670428  9649 net.cpp:124] Setting up relu6\n",
      "I0430 08:52:17.670431  9649 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:52:17.670433  9649 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:52:17.670436  9649 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:52:17.670442  9649 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:52:17.670444  9649 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:52:17.670449  9649 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:52:17.670454  9649 net.cpp:124] Setting up drop6\n",
      "I0430 08:52:17.670459  9649 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:52:17.670460  9649 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:52:17.670465  9649 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:52:17.670475  9649 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:52:17.670476  9649 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:52:17.670482  9649 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:52:17.680428  9649 net.cpp:124] Setting up fc7\n",
      "I0430 08:52:17.680451  9649 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:52:17.680456  9649 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:52:17.680467  9649 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:52:17.680479  9649 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:52:17.680483  9649 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:52:17.680490  9649 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:52:17.680498  9649 net.cpp:124] Setting up relu7\n",
      "I0430 08:52:17.680503  9649 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:52:17.680506  9649 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:52:17.680510  9649 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:52:17.680516  9649 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:52:17.680524  9649 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:52:17.680531  9649 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:52:17.680536  9649 net.cpp:124] Setting up drop7\n",
      "I0430 08:52:17.680541  9649 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:52:17.680543  9649 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:52:17.680546  9649 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:52:17.680552  9649 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:52:17.680555  9649 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:52:17.680559  9649 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:52:17.681203  9649 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:52:17.681215  9649 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:52:17.681218  9649 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:52:17.681226  9649 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:52:17.681231  9649 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:52:17.681234  9649 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:52:17.681237  9649 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:52:17.681241  9649 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:52:17.681244  9649 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:52:17.681248  9649 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:52:17.681253  9649 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:52:17.681257  9649 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:52:17.681259  9649 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:52:17.681263  9649 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:52:17.681267  9649 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:52:17.681269  9649 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:52:17.681273  9649 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:52:17.681277  9649 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:52:17.681280  9649 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:52:17.681283  9649 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:52:17.681287  9649 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:52:17.681290  9649 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:52:17.681293  9649 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:52:17.681298  9649 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:52:17.681300  9649 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:52:17.681303  9649 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:52:17.681306  9649 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:52:17.681318  9649 net.cpp:257] Network initialization done.\n",
      "I0430 08:52:17.767578  9649 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:52:17.867228  9649 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:52:17.868737  9649 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:52:17.868755  9649 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:52:17.868760  9649 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/359710.jpg'}, '/tmp/tmp4LDNUI.mat')\n",
      "Processed 1160 windows in 137.993 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-1.58265, -2.56765, -1.63864, -2.48597, -2.40...\n",
      "ymin                                                         82\n",
      "xmin                                                         99\n",
      "ymax                                                        217\n",
      "xmax                                                        293\n",
      "Name: /home/ambika/INF_project/data/cat/359710.jpg, dtype: object\n",
      "prediction    [-2.12679, -2.50991, -1.80622, -2.20313, -2.17...\n",
      "ymin                                                          0\n",
      "xmin                                                        181\n",
      "ymax                                                        189\n",
      "xmax                                                        293\n",
      "Name: /home/ambika/INF_project/data/cat/359710.jpg, dtype: object\n",
      "domestic cat\n",
      "99\t82\t293\t217\n",
      "rabbit\n",
      "181\t0\t293\t189\n",
      "359710\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:54:37.561441  9808 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:54:37.561465  9808 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:54:37.561472  9808 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:54:37.563151  9808 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:54:37.563294  9808 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:54:37.563308  9808 net.cpp:86] Creating Layer data\n",
      "I0430 08:54:37.563318  9808 net.cpp:382] data -> data\n",
      "I0430 08:54:37.563333  9808 net.cpp:124] Setting up data\n",
      "I0430 08:54:37.563341  9808 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:54:37.563344  9808 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:54:37.563349  9808 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:54:37.563357  9808 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:54:37.563361  9808 net.cpp:408] conv1 <- data\n",
      "I0430 08:54:37.563369  9808 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:54:37.563447  9808 net.cpp:124] Setting up conv1\n",
      "I0430 08:54:37.563454  9808 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:54:37.563458  9808 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:54:37.563468  9808 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:54:37.563474  9808 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:54:37.563478  9808 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:54:37.563484  9808 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:54:37.563490  9808 net.cpp:124] Setting up relu1\n",
      "I0430 08:54:37.563495  9808 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:54:37.563498  9808 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:54:37.563503  9808 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:54:37.563508  9808 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:54:37.563511  9808 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:54:37.563516  9808 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:54:37.563525  9808 net.cpp:124] Setting up pool1\n",
      "I0430 08:54:37.563530  9808 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:54:37.563534  9808 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:54:37.563537  9808 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:54:37.563544  9808 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:54:37.563547  9808 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:54:37.563552  9808 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:54:37.563560  9808 net.cpp:124] Setting up norm1\n",
      "I0430 08:54:37.563565  9808 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:54:37.563568  9808 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:54:37.563571  9808 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:54:37.563577  9808 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:54:37.563581  9808 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:54:37.563586  9808 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:54:37.564056  9808 net.cpp:124] Setting up conv2\n",
      "I0430 08:54:37.564064  9808 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:54:37.564069  9808 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:54:37.564076  9808 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:54:37.564081  9808 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:54:37.564085  9808 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:54:37.564090  9808 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:54:37.564096  9808 net.cpp:124] Setting up relu2\n",
      "I0430 08:54:37.564101  9808 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:54:37.564105  9808 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:54:37.564108  9808 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:54:37.564116  9808 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:54:37.564119  9808 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:54:37.564124  9808 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:54:37.564131  9808 net.cpp:124] Setting up pool2\n",
      "I0430 08:54:37.564137  9808 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:54:37.564141  9808 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:54:37.564144  9808 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:54:37.564151  9808 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:54:37.564154  9808 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:54:37.564159  9808 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:54:37.564167  9808 net.cpp:124] Setting up norm2\n",
      "I0430 08:54:37.564172  9808 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:54:37.564175  9808 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:54:37.564178  9808 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:54:37.564185  9808 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:54:37.564189  9808 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:54:37.564194  9808 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:54:37.565474  9808 net.cpp:124] Setting up conv3\n",
      "I0430 08:54:37.565487  9808 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:54:37.565492  9808 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:54:37.565502  9808 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:54:37.565511  9808 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:54:37.565515  9808 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:54:37.565521  9808 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:54:37.565526  9808 net.cpp:124] Setting up relu3\n",
      "I0430 08:54:37.565532  9808 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:54:37.565536  9808 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:54:37.565539  9808 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:54:37.565546  9808 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:54:37.565549  9808 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:54:37.565554  9808 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:54:37.566167  9808 net.cpp:124] Setting up conv4\n",
      "I0430 08:54:37.566177  9808 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:54:37.566181  9808 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:54:37.566187  9808 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:54:37.566195  9808 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:54:37.566200  9808 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:54:37.566205  9808 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:54:37.566212  9808 net.cpp:124] Setting up relu4\n",
      "I0430 08:54:37.566217  9808 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:54:37.566221  9808 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:54:37.566226  9808 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:54:37.566233  9808 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:54:37.566237  9808 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:54:37.566243  9808 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:54:37.566946  9808 net.cpp:124] Setting up conv5\n",
      "I0430 08:54:37.566962  9808 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:54:37.566965  9808 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:54:37.566979  9808 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:54:37.566987  9808 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:54:37.566992  9808 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:54:37.566998  9808 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:54:37.567006  9808 net.cpp:124] Setting up relu5\n",
      "I0430 08:54:37.567011  9808 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:54:37.567016  9808 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:54:37.567019  9808 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:54:37.567025  9808 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:54:37.567029  9808 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:54:37.567036  9808 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:54:37.567046  9808 net.cpp:124] Setting up pool5\n",
      "I0430 08:54:37.567051  9808 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:54:37.567055  9808 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:54:37.567059  9808 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:54:37.567067  9808 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:54:37.567071  9808 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:54:37.567076  9808 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:54:37.596410  9808 net.cpp:124] Setting up fc6\n",
      "I0430 08:54:37.596432  9808 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:54:37.596436  9808 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:54:37.596446  9808 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:54:37.596453  9808 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:54:37.596457  9808 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:54:37.596467  9808 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:54:37.596477  9808 net.cpp:124] Setting up relu6\n",
      "I0430 08:54:37.596480  9808 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:54:37.596483  9808 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:54:37.596487  9808 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:54:37.596493  9808 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:54:37.596495  9808 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:54:37.596499  9808 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:54:37.596505  9808 net.cpp:124] Setting up drop6\n",
      "I0430 08:54:37.596509  9808 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:54:37.596518  9808 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:54:37.596520  9808 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:54:37.596529  9808 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:54:37.596532  9808 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:54:37.596539  9808 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:54:37.609375  9808 net.cpp:124] Setting up fc7\n",
      "I0430 08:54:37.609396  9808 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:54:37.609400  9808 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:54:37.609411  9808 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:54:37.609421  9808 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:54:37.609424  9808 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:54:37.609431  9808 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:54:37.609439  9808 net.cpp:124] Setting up relu7\n",
      "I0430 08:54:37.609444  9808 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:54:37.609448  9808 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:54:37.609452  9808 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:54:37.609462  9808 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:54:37.609465  9808 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:54:37.609470  9808 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:54:37.609477  9808 net.cpp:124] Setting up drop7\n",
      "I0430 08:54:37.609483  9808 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:54:37.609486  9808 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:54:37.609489  9808 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:54:37.609495  9808 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:54:37.609499  9808 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:54:37.609504  9808 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:54:37.610677  9808 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:54:37.610687  9808 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:54:37.610692  9808 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:54:37.610699  9808 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:54:37.610703  9808 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:54:37.610707  9808 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:54:37.610712  9808 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:54:37.610714  9808 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:54:37.610718  9808 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:54:37.610723  9808 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:54:37.610726  9808 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:54:37.610729  9808 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:54:37.610733  9808 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:54:37.610738  9808 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:54:37.610741  9808 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:54:37.610745  9808 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:54:37.610749  9808 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:54:37.610754  9808 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:54:37.610757  9808 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:54:37.610761  9808 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:54:37.610765  9808 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:54:37.610769  9808 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:54:37.610774  9808 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:54:37.610777  9808 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:54:37.610780  9808 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:54:37.610785  9808 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:54:37.610788  9808 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:54:37.610803  9808 net.cpp:257] Network initialization done.\n",
      "I0430 08:54:37.708845  9808 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:54:37.811596  9808 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:54:37.813107  9808 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:54:37.813122  9808 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:54:37.813124  9808 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/86250.jpg'}, '/tmp/tmpmAWbJv.mat')\n",
      "Processed 1753 windows in 205.357 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-1.98595, -2.45246, -1.80775, -2.10737, -2.09...\n",
      "ymin                                                         68\n",
      "xmin                                                        239\n",
      "ymax                                                        185\n",
      "xmax                                                        345\n",
      "Name: /home/ambika/INF_project/data/couch/86250.jpg, dtype: object\n",
      "prediction    [-1.91699, -1.6436, -2.23525, -2.42983, -1.801...\n",
      "ymin                                                         73\n",
      "xmin                                                          0\n",
      "ymax                                                        246\n",
      "xmax                                                        136\n",
      "Name: /home/ambika/INF_project/data/couch/86250.jpg, dtype: object\n",
      "person\n",
      "239\t68\t345\t185\n",
      "sofa\n",
      "0\t73\t136\t246\n",
      "86250\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 08:58:04.736492  9980 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 08:58:04.736517  9980 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 08:58:04.736522  9980 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 08:58:04.737650  9980 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 08:58:04.737787  9980 layer_factory.hpp:77] Creating layer data\n",
      "I0430 08:58:04.737795  9980 net.cpp:86] Creating Layer data\n",
      "I0430 08:58:04.737798  9980 net.cpp:382] data -> data\n",
      "I0430 08:58:04.737812  9980 net.cpp:124] Setting up data\n",
      "I0430 08:58:04.737819  9980 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 08:58:04.737821  9980 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 08:58:04.737824  9980 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 08:58:04.737831  9980 net.cpp:86] Creating Layer conv1\n",
      "I0430 08:58:04.737835  9980 net.cpp:408] conv1 <- data\n",
      "I0430 08:58:04.737841  9980 net.cpp:382] conv1 -> conv1\n",
      "I0430 08:58:04.737905  9980 net.cpp:124] Setting up conv1\n",
      "I0430 08:58:04.737910  9980 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:58:04.737912  9980 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 08:58:04.737920  9980 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 08:58:04.737924  9980 net.cpp:86] Creating Layer relu1\n",
      "I0430 08:58:04.737927  9980 net.cpp:408] relu1 <- conv1\n",
      "I0430 08:58:04.737931  9980 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 08:58:04.737936  9980 net.cpp:124] Setting up relu1\n",
      "I0430 08:58:04.737938  9980 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 08:58:04.737941  9980 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 08:58:04.737943  9980 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 08:58:04.737947  9980 net.cpp:86] Creating Layer pool1\n",
      "I0430 08:58:04.737949  9980 net.cpp:408] pool1 <- conv1\n",
      "I0430 08:58:04.737953  9980 net.cpp:382] pool1 -> pool1\n",
      "I0430 08:58:04.737959  9980 net.cpp:124] Setting up pool1\n",
      "I0430 08:58:04.737962  9980 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:58:04.737965  9980 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 08:58:04.737967  9980 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 08:58:04.737972  9980 net.cpp:86] Creating Layer norm1\n",
      "I0430 08:58:04.737974  9980 net.cpp:408] norm1 <- pool1\n",
      "I0430 08:58:04.737977  9980 net.cpp:382] norm1 -> norm1\n",
      "I0430 08:58:04.737982  9980 net.cpp:124] Setting up norm1\n",
      "I0430 08:58:04.737987  9980 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 08:58:04.737988  9980 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 08:58:04.737990  9980 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 08:58:04.737994  9980 net.cpp:86] Creating Layer conv2\n",
      "I0430 08:58:04.737998  9980 net.cpp:408] conv2 <- norm1\n",
      "I0430 08:58:04.738000  9980 net.cpp:382] conv2 -> conv2\n",
      "I0430 08:58:04.738359  9980 net.cpp:124] Setting up conv2\n",
      "I0430 08:58:04.738366  9980 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:58:04.738368  9980 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 08:58:04.738374  9980 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 08:58:04.738379  9980 net.cpp:86] Creating Layer relu2\n",
      "I0430 08:58:04.738384  9980 net.cpp:408] relu2 <- conv2\n",
      "I0430 08:58:04.738389  9980 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 08:58:04.738394  9980 net.cpp:124] Setting up relu2\n",
      "I0430 08:58:04.738400  9980 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 08:58:04.738404  9980 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 08:58:04.738407  9980 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 08:58:04.738415  9980 net.cpp:86] Creating Layer pool2\n",
      "I0430 08:58:04.738416  9980 net.cpp:408] pool2 <- conv2\n",
      "I0430 08:58:04.738420  9980 net.cpp:382] pool2 -> pool2\n",
      "I0430 08:58:04.738426  9980 net.cpp:124] Setting up pool2\n",
      "I0430 08:58:04.738430  9980 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:58:04.738432  9980 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 08:58:04.738435  9980 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 08:58:04.738438  9980 net.cpp:86] Creating Layer norm2\n",
      "I0430 08:58:04.738440  9980 net.cpp:408] norm2 <- pool2\n",
      "I0430 08:58:04.738445  9980 net.cpp:382] norm2 -> norm2\n",
      "I0430 08:58:04.738450  9980 net.cpp:124] Setting up norm2\n",
      "I0430 08:58:04.738452  9980 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:58:04.738454  9980 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 08:58:04.738457  9980 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 08:58:04.738462  9980 net.cpp:86] Creating Layer conv3\n",
      "I0430 08:58:04.738464  9980 net.cpp:408] conv3 <- norm2\n",
      "I0430 08:58:04.738468  9980 net.cpp:382] conv3 -> conv3\n",
      "I0430 08:58:04.739509  9980 net.cpp:124] Setting up conv3\n",
      "I0430 08:58:04.739527  9980 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:58:04.739531  9980 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 08:58:04.739543  9980 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 08:58:04.739552  9980 net.cpp:86] Creating Layer relu3\n",
      "I0430 08:58:04.739557  9980 net.cpp:408] relu3 <- conv3\n",
      "I0430 08:58:04.739562  9980 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 08:58:04.739573  9980 net.cpp:124] Setting up relu3\n",
      "I0430 08:58:04.739578  9980 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:58:04.739580  9980 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 08:58:04.739584  9980 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 08:58:04.739591  9980 net.cpp:86] Creating Layer conv4\n",
      "I0430 08:58:04.739594  9980 net.cpp:408] conv4 <- conv3\n",
      "I0430 08:58:04.739600  9980 net.cpp:382] conv4 -> conv4\n",
      "I0430 08:58:04.740411  9980 net.cpp:124] Setting up conv4\n",
      "I0430 08:58:04.740452  9980 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:58:04.740461  9980 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 08:58:04.740475  9980 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 08:58:04.740494  9980 net.cpp:86] Creating Layer relu4\n",
      "I0430 08:58:04.740501  9980 net.cpp:408] relu4 <- conv4\n",
      "I0430 08:58:04.740509  9980 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 08:58:04.740519  9980 net.cpp:124] Setting up relu4\n",
      "I0430 08:58:04.740523  9980 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 08:58:04.740526  9980 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 08:58:04.740530  9980 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 08:58:04.740540  9980 net.cpp:86] Creating Layer conv5\n",
      "I0430 08:58:04.740543  9980 net.cpp:408] conv5 <- conv4\n",
      "I0430 08:58:04.740548  9980 net.cpp:382] conv5 -> conv5\n",
      "I0430 08:58:04.741080  9980 net.cpp:124] Setting up conv5\n",
      "I0430 08:58:04.741088  9980 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:58:04.741091  9980 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 08:58:04.741101  9980 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 08:58:04.741106  9980 net.cpp:86] Creating Layer relu5\n",
      "I0430 08:58:04.741108  9980 net.cpp:408] relu5 <- conv5\n",
      "I0430 08:58:04.741116  9980 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 08:58:04.741119  9980 net.cpp:124] Setting up relu5\n",
      "I0430 08:58:04.741123  9980 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 08:58:04.741125  9980 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 08:58:04.741127  9980 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 08:58:04.741132  9980 net.cpp:86] Creating Layer pool5\n",
      "I0430 08:58:04.741134  9980 net.cpp:408] pool5 <- conv5\n",
      "I0430 08:58:04.741138  9980 net.cpp:382] pool5 -> pool5\n",
      "I0430 08:58:04.741144  9980 net.cpp:124] Setting up pool5\n",
      "I0430 08:58:04.741147  9980 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 08:58:04.741149  9980 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 08:58:04.741153  9980 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 08:58:04.741159  9980 net.cpp:86] Creating Layer fc6\n",
      "I0430 08:58:04.741163  9980 net.cpp:408] fc6 <- pool5\n",
      "I0430 08:58:04.741165  9980 net.cpp:382] fc6 -> fc6\n",
      "I0430 08:58:04.765244  9980 net.cpp:124] Setting up fc6\n",
      "I0430 08:58:04.765293  9980 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:58:04.765297  9980 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 08:58:04.765311  9980 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 08:58:04.765322  9980 net.cpp:86] Creating Layer relu6\n",
      "I0430 08:58:04.765327  9980 net.cpp:408] relu6 <- fc6\n",
      "I0430 08:58:04.765333  9980 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 08:58:04.765342  9980 net.cpp:124] Setting up relu6\n",
      "I0430 08:58:04.765347  9980 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:58:04.765350  9980 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 08:58:04.765354  9980 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 08:58:04.765360  9980 net.cpp:86] Creating Layer drop6\n",
      "I0430 08:58:04.765365  9980 net.cpp:408] drop6 <- fc6\n",
      "I0430 08:58:04.765370  9980 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 08:58:04.765378  9980 net.cpp:124] Setting up drop6\n",
      "I0430 08:58:04.765383  9980 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:58:04.765388  9980 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 08:58:04.765390  9980 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 08:58:04.765396  9980 net.cpp:86] Creating Layer fc7\n",
      "I0430 08:58:04.765399  9980 net.cpp:408] fc7 <- fc6\n",
      "I0430 08:58:04.765404  9980 net.cpp:382] fc7 -> fc7\n",
      "I0430 08:58:04.775141  9980 net.cpp:124] Setting up fc7\n",
      "I0430 08:58:04.775166  9980 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:58:04.775171  9980 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 08:58:04.775180  9980 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 08:58:04.775187  9980 net.cpp:86] Creating Layer relu7\n",
      "I0430 08:58:04.775190  9980 net.cpp:408] relu7 <- fc7\n",
      "I0430 08:58:04.775194  9980 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 08:58:04.775200  9980 net.cpp:124] Setting up relu7\n",
      "I0430 08:58:04.775202  9980 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:58:04.775204  9980 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 08:58:04.775216  9980 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 08:58:04.775223  9980 net.cpp:86] Creating Layer drop7\n",
      "I0430 08:58:04.775225  9980 net.cpp:408] drop7 <- fc7\n",
      "I0430 08:58:04.775230  9980 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 08:58:04.775236  9980 net.cpp:124] Setting up drop7\n",
      "I0430 08:58:04.775240  9980 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 08:58:04.775245  9980 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 08:58:04.775249  9980 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 08:58:04.775254  9980 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 08:58:04.775259  9980 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 08:58:04.775264  9980 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 08:58:04.776160  9980 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 08:58:04.776170  9980 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 08:58:04.776173  9980 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 08:58:04.776180  9980 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 08:58:04.776185  9980 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 08:58:04.776187  9980 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 08:58:04.776190  9980 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 08:58:04.776195  9980 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 08:58:04.776197  9980 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 08:58:04.776201  9980 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 08:58:04.776203  9980 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 08:58:04.776207  9980 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 08:58:04.776211  9980 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 08:58:04.776213  9980 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 08:58:04.776216  9980 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 08:58:04.776221  9980 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 08:58:04.776223  9980 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 08:58:04.776226  9980 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 08:58:04.776231  9980 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 08:58:04.776233  9980 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 08:58:04.776237  9980 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 08:58:04.776239  9980 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 08:58:04.776243  9980 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 08:58:04.776247  9980 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 08:58:04.776249  9980 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 08:58:04.776252  9980 net.cpp:202] data does not need backward computation.\n",
      "I0430 08:58:04.776255  9980 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 08:58:04.776265  9980 net.cpp:257] Network initialization done.\n",
      "I0430 08:58:04.862951  9980 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:58:04.963577  9980 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 08:58:04.964651  9980 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 08:58:04.964663  9980 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 08:58:04.964665  9980 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/469088.jpg'}, '/tmp/tmpzpU6ci.mat')\n",
      "Processed 2825 windows in 328.792 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.036 s.\n",
      "prediction    [-1.8642, -2.20843, -2.08193, -3.18134, -1.645...\n",
      "ymin                                                         63\n",
      "xmin                                                        200\n",
      "ymax                                                        325\n",
      "xmax                                                        355\n",
      "Name: /home/ambika/INF_project/data/dog/469088.jpg, dtype: object\n",
      "prediction    [-1.76781, -2.16071, -1.6325, -2.02785, -1.106...\n",
      "ymin                                                         73\n",
      "xmin                                                         47\n",
      "ymax                                                        361\n",
      "xmax                                                        299\n",
      "Name: /home/ambika/INF_project/data/dog/469088.jpg, dtype: object\n",
      "dog\n",
      "200\t63\t355\t325\n",
      "camel\n",
      "47\t73\t299\t361\n",
      "469088\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:03:35.381073 10163 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:03:35.381098 10163 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:03:35.381103 10163 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:03:35.382750 10163 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:03:35.382917 10163 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:03:35.382930 10163 net.cpp:86] Creating Layer data\n",
      "I0430 09:03:35.382938 10163 net.cpp:382] data -> data\n",
      "I0430 09:03:35.382961 10163 net.cpp:124] Setting up data\n",
      "I0430 09:03:35.382968 10163 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:03:35.382972 10163 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:03:35.382975 10163 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:03:35.382983 10163 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:03:35.382987 10163 net.cpp:408] conv1 <- data\n",
      "I0430 09:03:35.382992 10163 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:03:35.383108 10163 net.cpp:124] Setting up conv1\n",
      "I0430 09:03:35.383121 10163 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:03:35.383126 10163 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:03:35.383141 10163 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:03:35.383148 10163 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:03:35.383152 10163 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:03:35.383157 10163 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:03:35.383162 10163 net.cpp:124] Setting up relu1\n",
      "I0430 09:03:35.383164 10163 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:03:35.383167 10163 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:03:35.383169 10163 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:03:35.383173 10163 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:03:35.383177 10163 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:03:35.383179 10163 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:03:35.383189 10163 net.cpp:124] Setting up pool1\n",
      "I0430 09:03:35.383193 10163 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:03:35.383195 10163 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:03:35.383198 10163 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:03:35.383203 10163 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:03:35.383232 10163 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:03:35.383236 10163 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:03:35.383244 10163 net.cpp:124] Setting up norm1\n",
      "I0430 09:03:35.383249 10163 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:03:35.383251 10163 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:03:35.383255 10163 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:03:35.383260 10163 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:03:35.383262 10163 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:03:35.383266 10163 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:03:35.383713 10163 net.cpp:124] Setting up conv2\n",
      "I0430 09:03:35.383726 10163 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:03:35.383730 10163 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:03:35.383740 10163 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:03:35.383749 10163 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:03:35.383752 10163 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:03:35.383757 10163 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:03:35.383762 10163 net.cpp:124] Setting up relu2\n",
      "I0430 09:03:35.383767 10163 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:03:35.383770 10163 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:03:35.383774 10163 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:03:35.383780 10163 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:03:35.383783 10163 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:03:35.383790 10163 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:03:35.383800 10163 net.cpp:124] Setting up pool2\n",
      "I0430 09:03:35.383806 10163 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:03:35.383810 10163 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:03:35.383812 10163 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:03:35.383821 10163 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:03:35.383823 10163 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:03:35.383827 10163 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:03:35.383834 10163 net.cpp:124] Setting up norm2\n",
      "I0430 09:03:35.383838 10163 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:03:35.383841 10163 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:03:35.383846 10163 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:03:35.383857 10163 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:03:35.383860 10163 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:03:35.383865 10163 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:03:35.384560 10163 net.cpp:124] Setting up conv3\n",
      "I0430 09:03:35.384572 10163 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:03:35.384575 10163 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:03:35.384587 10163 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:03:35.384593 10163 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:03:35.384598 10163 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:03:35.384603 10163 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:03:35.384608 10163 net.cpp:124] Setting up relu3\n",
      "I0430 09:03:35.384610 10163 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:03:35.384613 10163 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:03:35.384616 10163 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:03:35.384621 10163 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:03:35.384624 10163 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:03:35.384627 10163 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:03:35.385382 10163 net.cpp:124] Setting up conv4\n",
      "I0430 09:03:35.385393 10163 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:03:35.385396 10163 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:03:35.385403 10163 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:03:35.385411 10163 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:03:35.385416 10163 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:03:35.385419 10163 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:03:35.385424 10163 net.cpp:124] Setting up relu4\n",
      "I0430 09:03:35.385427 10163 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:03:35.385429 10163 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:03:35.385432 10163 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:03:35.385437 10163 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:03:35.385440 10163 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:03:35.385444 10163 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:03:35.385946 10163 net.cpp:124] Setting up conv5\n",
      "I0430 09:03:35.385953 10163 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:03:35.385957 10163 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:03:35.385967 10163 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:03:35.385973 10163 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:03:35.385977 10163 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:03:35.385982 10163 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:03:35.385985 10163 net.cpp:124] Setting up relu5\n",
      "I0430 09:03:35.385989 10163 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:03:35.385992 10163 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:03:35.385993 10163 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:03:35.386000 10163 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:03:35.386003 10163 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:03:35.386006 10163 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:03:35.386013 10163 net.cpp:124] Setting up pool5\n",
      "I0430 09:03:35.386016 10163 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:03:35.386018 10163 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:03:35.386021 10163 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:03:35.386028 10163 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:03:35.386030 10163 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:03:35.386034 10163 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:03:35.409150 10163 net.cpp:124] Setting up fc6\n",
      "I0430 09:03:35.409170 10163 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:03:35.409174 10163 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:03:35.409185 10163 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:03:35.409196 10163 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:03:35.409201 10163 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:03:35.409207 10163 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:03:35.409217 10163 net.cpp:124] Setting up relu6\n",
      "I0430 09:03:35.409222 10163 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:03:35.409224 10163 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:03:35.409227 10163 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:03:35.409232 10163 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:03:35.409235 10163 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:03:35.409238 10163 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:03:35.409243 10163 net.cpp:124] Setting up drop6\n",
      "I0430 09:03:35.409246 10163 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:03:35.409248 10163 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:03:35.409251 10163 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:03:35.409255 10163 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:03:35.409258 10163 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:03:35.409262 10163 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:03:35.421540 10163 net.cpp:124] Setting up fc7\n",
      "I0430 09:03:35.421566 10163 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:03:35.421571 10163 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:03:35.421597 10163 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:03:35.421608 10163 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:03:35.421612 10163 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:03:35.421619 10163 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:03:35.421627 10163 net.cpp:124] Setting up relu7\n",
      "I0430 09:03:35.421630 10163 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:03:35.421633 10163 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:03:35.421635 10163 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:03:35.421641 10163 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:03:35.421644 10163 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:03:35.421648 10163 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:03:35.421653 10163 net.cpp:124] Setting up drop7\n",
      "I0430 09:03:35.421655 10163 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:03:35.421658 10163 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:03:35.421659 10163 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:03:35.421663 10163 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:03:35.421665 10163 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:03:35.421669 10163 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:03:35.422330 10163 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:03:35.422341 10163 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:03:35.422344 10163 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:03:35.422353 10163 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:03:35.422358 10163 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:03:35.422361 10163 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:03:35.422364 10163 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:03:35.422368 10163 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:03:35.422369 10163 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:03:35.422372 10163 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:03:35.422375 10163 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:03:35.422379 10163 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:03:35.422380 10163 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:03:35.422384 10163 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:03:35.422386 10163 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:03:35.422389 10163 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:03:35.422391 10163 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:03:35.422394 10163 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:03:35.422399 10163 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:03:35.422400 10163 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:03:35.422404 10163 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:03:35.422406 10163 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:03:35.422408 10163 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:03:35.422411 10163 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:03:35.422413 10163 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:03:35.422416 10163 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:03:35.422418 10163 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:03:35.422430 10163 net.cpp:257] Network initialization done.\n",
      "I0430 09:03:35.509050 10163 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:03:35.608872 10163 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:03:35.609926 10163 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:03:35.609938 10163 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:03:35.609941 10163 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/306135.jpg'}, '/tmp/tmpXXuZPM.mat')\n",
      "Processed 1870 windows in 217.404 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.034 s.\n",
      "prediction    [-1.92929, -2.95606, -1.76023, -2.08357, -2.06...\n",
      "ymin                                                        113\n",
      "xmin                                                        316\n",
      "ymax                                                        200\n",
      "xmax                                                        358\n",
      "Name: /home/ambika/INF_project/data/horse/306135.jpg, dtype: object\n",
      "prediction    [-1.45548, -0.954483, -2.1863, -1.73792, -1.30...\n",
      "ymin                                                         15\n",
      "xmin                                                        252\n",
      "ymax                                                         87\n",
      "xmax                                                        311\n",
      "Name: /home/ambika/INF_project/data/horse/306135.jpg, dtype: object\n",
      "person\n",
      "316\t113\t358\t200\n",
      "horse\n",
      "252\t15\t311\t87\n",
      "306135\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:07:14.567963 10324 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:07:14.567987 10324 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:07:14.567991 10324 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:07:14.569133 10324 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:07:14.569296 10324 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:07:14.569303 10324 net.cpp:86] Creating Layer data\n",
      "I0430 09:07:14.569308 10324 net.cpp:382] data -> data\n",
      "I0430 09:07:14.569322 10324 net.cpp:124] Setting up data\n",
      "I0430 09:07:14.569334 10324 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:07:14.569339 10324 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:07:14.569342 10324 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:07:14.569351 10324 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:07:14.569356 10324 net.cpp:408] conv1 <- data\n",
      "I0430 09:07:14.569360 10324 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:07:14.569420 10324 net.cpp:124] Setting up conv1\n",
      "I0430 09:07:14.569425 10324 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:07:14.569428 10324 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:07:14.569435 10324 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:07:14.569440 10324 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:07:14.569443 10324 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:07:14.569447 10324 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:07:14.569452 10324 net.cpp:124] Setting up relu1\n",
      "I0430 09:07:14.569454 10324 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:07:14.569456 10324 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:07:14.569459 10324 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:07:14.569463 10324 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:07:14.569465 10324 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:07:14.569469 10324 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:07:14.569475 10324 net.cpp:124] Setting up pool1\n",
      "I0430 09:07:14.569479 10324 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:07:14.569481 10324 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:07:14.569484 10324 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:07:14.569489 10324 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:07:14.569491 10324 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:07:14.569494 10324 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:07:14.569500 10324 net.cpp:124] Setting up norm1\n",
      "I0430 09:07:14.569505 10324 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:07:14.569509 10324 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:07:14.569514 10324 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:07:14.569519 10324 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:07:14.569524 10324 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:07:14.569530 10324 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:07:14.569890 10324 net.cpp:124] Setting up conv2\n",
      "I0430 09:07:14.569896 10324 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:07:14.569900 10324 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:07:14.569910 10324 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:07:14.569914 10324 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:07:14.569917 10324 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:07:14.569921 10324 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:07:14.569926 10324 net.cpp:124] Setting up relu2\n",
      "I0430 09:07:14.569929 10324 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:07:14.569931 10324 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:07:14.569934 10324 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:07:14.569939 10324 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:07:14.569941 10324 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:07:14.569946 10324 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:07:14.569950 10324 net.cpp:124] Setting up pool2\n",
      "I0430 09:07:14.569954 10324 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:07:14.569957 10324 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:07:14.569959 10324 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:07:14.569963 10324 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:07:14.569967 10324 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:07:14.569972 10324 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:07:14.569977 10324 net.cpp:124] Setting up norm2\n",
      "I0430 09:07:14.569979 10324 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:07:14.569983 10324 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:07:14.569984 10324 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:07:14.569989 10324 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:07:14.569991 10324 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:07:14.569995 10324 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:07:14.570686 10324 net.cpp:124] Setting up conv3\n",
      "I0430 09:07:14.570696 10324 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:07:14.570700 10324 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:07:14.570708 10324 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:07:14.570718 10324 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:07:14.570720 10324 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:07:14.570725 10324 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:07:14.570730 10324 net.cpp:124] Setting up relu3\n",
      "I0430 09:07:14.570734 10324 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:07:14.570736 10324 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:07:14.570739 10324 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:07:14.570744 10324 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:07:14.570746 10324 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:07:14.570750 10324 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:07:14.571529 10324 net.cpp:124] Setting up conv4\n",
      "I0430 09:07:14.571540 10324 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:07:14.571543 10324 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:07:14.571552 10324 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:07:14.571560 10324 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:07:14.571564 10324 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:07:14.571569 10324 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:07:14.571574 10324 net.cpp:124] Setting up relu4\n",
      "I0430 09:07:14.571578 10324 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:07:14.571580 10324 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:07:14.571583 10324 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:07:14.571588 10324 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:07:14.571590 10324 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:07:14.571593 10324 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:07:14.572119 10324 net.cpp:124] Setting up conv5\n",
      "I0430 09:07:14.572127 10324 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:07:14.572131 10324 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:07:14.572142 10324 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:07:14.572147 10324 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:07:14.572150 10324 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:07:14.572154 10324 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:07:14.572160 10324 net.cpp:124] Setting up relu5\n",
      "I0430 09:07:14.572162 10324 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:07:14.572165 10324 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:07:14.572167 10324 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:07:14.572171 10324 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:07:14.572175 10324 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:07:14.572177 10324 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:07:14.572185 10324 net.cpp:124] Setting up pool5\n",
      "I0430 09:07:14.572187 10324 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:07:14.572190 10324 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:07:14.572192 10324 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:07:14.572199 10324 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:07:14.572202 10324 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:07:14.572206 10324 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:07:14.593828 10324 net.cpp:124] Setting up fc6\n",
      "I0430 09:07:14.593854 10324 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:07:14.593859 10324 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:07:14.593885 10324 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:07:14.593897 10324 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:07:14.593901 10324 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:07:14.593909 10324 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:07:14.593916 10324 net.cpp:124] Setting up relu6\n",
      "I0430 09:07:14.593919 10324 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:07:14.593921 10324 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:07:14.593924 10324 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:07:14.593930 10324 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:07:14.593932 10324 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:07:14.593935 10324 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:07:14.593940 10324 net.cpp:124] Setting up drop6\n",
      "I0430 09:07:14.593943 10324 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:07:14.593945 10324 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:07:14.593948 10324 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:07:14.593952 10324 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:07:14.593955 10324 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:07:14.593960 10324 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:07:14.604097 10324 net.cpp:124] Setting up fc7\n",
      "I0430 09:07:14.604125 10324 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:07:14.604130 10324 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:07:14.604141 10324 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:07:14.604152 10324 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:07:14.604158 10324 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:07:14.604164 10324 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:07:14.604173 10324 net.cpp:124] Setting up relu7\n",
      "I0430 09:07:14.604179 10324 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:07:14.604182 10324 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:07:14.604187 10324 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:07:14.604193 10324 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:07:14.604197 10324 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:07:14.604204 10324 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:07:14.604212 10324 net.cpp:124] Setting up drop7\n",
      "I0430 09:07:14.604218 10324 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:07:14.604220 10324 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:07:14.604224 10324 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:07:14.604230 10324 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:07:14.604234 10324 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:07:14.604239 10324 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:07:14.605082 10324 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:07:14.605103 10324 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:07:14.605108 10324 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:07:14.605118 10324 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:07:14.605123 10324 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:07:14.605126 10324 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:07:14.605130 10324 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:07:14.605134 10324 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:07:14.605139 10324 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:07:14.605142 10324 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:07:14.605146 10324 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:07:14.605151 10324 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:07:14.605157 10324 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:07:14.605162 10324 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:07:14.605170 10324 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:07:14.605175 10324 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:07:14.605180 10324 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:07:14.605183 10324 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:07:14.605187 10324 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:07:14.605192 10324 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:07:14.605196 10324 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:07:14.605201 10324 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:07:14.605206 10324 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:07:14.605208 10324 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:07:14.605212 10324 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:07:14.605216 10324 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:07:14.605221 10324 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:07:14.605234 10324 net.cpp:257] Network initialization done.\n",
      "I0430 09:07:14.693825 10324 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:07:14.792011 10324 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:07:14.793004 10324 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:07:14.793012 10324 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:07:14.793017 10324 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/224000.jpg'}, '/tmp/tmp3x39j3.mat')\n",
      "Processed 1205 windows in 142.698 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.07523, -2.27434, -1.74429, -1.25616, -2.12...\n",
      "ymin                                                         80\n",
      "xmin                                                        438\n",
      "ymax                                                        148\n",
      "xmax                                                        488\n",
      "Name: /home/ambika/INF_project/data/person/224000.jpg, dtype: object\n",
      "prediction    [-1.98857, -1.88111, -2.54006, -1.48191, -2.07...\n",
      "ymin                                                        135\n",
      "xmin                                                        145\n",
      "ymax                                                        178\n",
      "xmax                                                        205\n",
      "Name: /home/ambika/INF_project/data/person/224000.jpg, dtype: object\n",
      "person\n",
      "438\t80\t488\t148\n",
      "cattle\n",
      "145\t135\t205\t178\n",
      "224000\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:09:38.974483 10464 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:09:38.974505 10464 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:09:38.974509 10464 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:09:38.975646 10464 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:09:38.975819 10464 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:09:38.975827 10464 net.cpp:86] Creating Layer data\n",
      "I0430 09:09:38.975831 10464 net.cpp:382] data -> data\n",
      "I0430 09:09:38.975847 10464 net.cpp:124] Setting up data\n",
      "I0430 09:09:38.975855 10464 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:09:38.975858 10464 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:09:38.975862 10464 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:09:38.975870 10464 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:09:38.975874 10464 net.cpp:408] conv1 <- data\n",
      "I0430 09:09:38.975880 10464 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:09:38.975940 10464 net.cpp:124] Setting up conv1\n",
      "I0430 09:09:38.975946 10464 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:09:38.975950 10464 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:09:38.975961 10464 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:09:38.975967 10464 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:09:38.975970 10464 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:09:38.975975 10464 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:09:38.975980 10464 net.cpp:124] Setting up relu1\n",
      "I0430 09:09:38.975985 10464 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:09:38.975986 10464 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:09:38.975989 10464 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:09:38.975994 10464 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:09:38.975997 10464 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:09:38.976002 10464 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:09:38.976009 10464 net.cpp:124] Setting up pool1\n",
      "I0430 09:09:38.976014 10464 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:09:38.976016 10464 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:09:38.976019 10464 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:09:38.976027 10464 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:09:38.976029 10464 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:09:38.976033 10464 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:09:38.976040 10464 net.cpp:124] Setting up norm1\n",
      "I0430 09:09:38.976045 10464 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:09:38.976048 10464 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:09:38.976052 10464 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:09:38.976056 10464 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:09:38.976060 10464 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:09:38.976065 10464 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:09:38.976420 10464 net.cpp:124] Setting up conv2\n",
      "I0430 09:09:38.976428 10464 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:09:38.976431 10464 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:09:38.976439 10464 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:09:38.976446 10464 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:09:38.976449 10464 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:09:38.976454 10464 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:09:38.976459 10464 net.cpp:124] Setting up relu2\n",
      "I0430 09:09:38.976464 10464 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:09:38.976466 10464 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:09:38.976469 10464 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:09:38.976475 10464 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:09:38.976477 10464 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:09:38.976481 10464 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:09:38.976488 10464 net.cpp:124] Setting up pool2\n",
      "I0430 09:09:38.976492 10464 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:09:38.976495 10464 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:09:38.976498 10464 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:09:38.976505 10464 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:09:38.976508 10464 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:09:38.976512 10464 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:09:38.976518 10464 net.cpp:124] Setting up norm2\n",
      "I0430 09:09:38.976522 10464 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:09:38.976526 10464 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:09:38.976528 10464 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:09:38.976534 10464 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:09:38.976536 10464 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:09:38.976541 10464 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:09:38.977232 10464 net.cpp:124] Setting up conv3\n",
      "I0430 09:09:38.977243 10464 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:09:38.977247 10464 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:09:38.977257 10464 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:09:38.977263 10464 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:09:38.977267 10464 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:09:38.977272 10464 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:09:38.977278 10464 net.cpp:124] Setting up relu3\n",
      "I0430 09:09:38.977283 10464 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:09:38.977285 10464 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:09:38.977288 10464 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:09:38.977296 10464 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:09:38.977298 10464 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:09:38.977303 10464 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:09:38.978081 10464 net.cpp:124] Setting up conv4\n",
      "I0430 09:09:38.978097 10464 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:09:38.978101 10464 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:09:38.978108 10464 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:09:38.978116 10464 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:09:38.978121 10464 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:09:38.978127 10464 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:09:38.978133 10464 net.cpp:124] Setting up relu4\n",
      "I0430 09:09:38.978139 10464 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:09:38.978142 10464 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:09:38.978147 10464 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:09:38.978154 10464 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:09:38.978157 10464 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:09:38.978163 10464 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:09:38.978677 10464 net.cpp:124] Setting up conv5\n",
      "I0430 09:09:38.978684 10464 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:09:38.978688 10464 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:09:38.978699 10464 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:09:38.978704 10464 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:09:38.978708 10464 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:09:38.978713 10464 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:09:38.978718 10464 net.cpp:124] Setting up relu5\n",
      "I0430 09:09:38.978724 10464 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:09:38.978726 10464 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:09:38.978729 10464 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:09:38.978734 10464 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:09:38.978737 10464 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:09:38.978742 10464 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:09:38.978749 10464 net.cpp:124] Setting up pool5\n",
      "I0430 09:09:38.978754 10464 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:09:38.978757 10464 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:09:38.978760 10464 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:09:38.978768 10464 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:09:38.978771 10464 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:09:38.978776 10464 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:09:39.003733 10464 net.cpp:124] Setting up fc6\n",
      "I0430 09:09:39.003757 10464 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:09:39.003762 10464 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:09:39.003772 10464 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:09:39.003782 10464 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:09:39.003787 10464 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:09:39.003793 10464 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:09:39.003800 10464 net.cpp:124] Setting up relu6\n",
      "I0430 09:09:39.003804 10464 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:09:39.003818 10464 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:09:39.003823 10464 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:09:39.003829 10464 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:09:39.003831 10464 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:09:39.003836 10464 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:09:39.003841 10464 net.cpp:124] Setting up drop6\n",
      "I0430 09:09:39.003845 10464 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:09:39.003849 10464 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:09:39.003851 10464 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:09:39.003857 10464 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:09:39.003859 10464 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:09:39.003865 10464 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:09:39.013823 10464 net.cpp:124] Setting up fc7\n",
      "I0430 09:09:39.013850 10464 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:09:39.013854 10464 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:09:39.013869 10464 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:09:39.013888 10464 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:09:39.013892 10464 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:09:39.013900 10464 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:09:39.013909 10464 net.cpp:124] Setting up relu7\n",
      "I0430 09:09:39.013914 10464 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:09:39.013917 10464 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:09:39.013921 10464 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:09:39.013927 10464 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:09:39.013931 10464 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:09:39.013936 10464 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:09:39.013942 10464 net.cpp:124] Setting up drop7\n",
      "I0430 09:09:39.013945 10464 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:09:39.013948 10464 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:09:39.013952 10464 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:09:39.013957 10464 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:09:39.013959 10464 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:09:39.013964 10464 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:09:39.014878 10464 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:09:39.014890 10464 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:09:39.014894 10464 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:09:39.014901 10464 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:09:39.014904 10464 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:09:39.014907 10464 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:09:39.014911 10464 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:09:39.014916 10464 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:09:39.014919 10464 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:09:39.014922 10464 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:09:39.014926 10464 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:09:39.014930 10464 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:09:39.014933 10464 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:09:39.014936 10464 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:09:39.014940 10464 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:09:39.014943 10464 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:09:39.014946 10464 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:09:39.014950 10464 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:09:39.014953 10464 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:09:39.014957 10464 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:09:39.014961 10464 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:09:39.014963 10464 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:09:39.014967 10464 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:09:39.014971 10464 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:09:39.014973 10464 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:09:39.014977 10464 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:09:39.014981 10464 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:09:39.014991 10464 net.cpp:257] Network initialization done.\n",
      "I0430 09:09:39.100567 10464 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:09:39.201812 10464 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:09:39.202736 10464 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:09:39.202749 10464 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:09:39.202751 10464 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/327352.jpg'}, '/tmp/tmpNCgYoH.mat')\n",
      "Processed 1977 windows in 230.442 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.123, -1.29633, -2.05524, -1.72557, -2.4572...\n",
      "ymin                                                         53\n",
      "xmin                                                          0\n",
      "ymax                                                        238\n",
      "xmax                                                        195\n",
      "Name: /home/ambika/INF_project/data/train/327352.jpg, dtype: object\n",
      "prediction    [-1.41095, -2.53245, -2.51267, -2.38314, -2.31...\n",
      "ymin                                                         54\n",
      "xmin                                                         51\n",
      "ymax                                                        132\n",
      "xmax                                                        176\n",
      "Name: /home/ambika/INF_project/data/train/327352.jpg, dtype: object\n",
      "train\n",
      "0\t53\t195\t238\n",
      "tape player\n",
      "51\t54\t176\t132\n",
      "327352\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:13:31.209265 10646 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:13:31.209287 10646 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:13:31.209290 10646 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:13:31.210463 10646 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:13:31.210611 10646 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:13:31.210621 10646 net.cpp:86] Creating Layer data\n",
      "I0430 09:13:31.210625 10646 net.cpp:382] data -> data\n",
      "I0430 09:13:31.210638 10646 net.cpp:124] Setting up data\n",
      "I0430 09:13:31.210644 10646 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:13:31.210645 10646 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:13:31.210649 10646 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:13:31.210654 10646 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:13:31.210656 10646 net.cpp:408] conv1 <- data\n",
      "I0430 09:13:31.210660 10646 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:13:31.210723 10646 net.cpp:124] Setting up conv1\n",
      "I0430 09:13:31.210728 10646 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:13:31.210731 10646 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:13:31.210737 10646 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:13:31.210742 10646 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:13:31.210744 10646 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:13:31.210748 10646 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:13:31.210752 10646 net.cpp:124] Setting up relu1\n",
      "I0430 09:13:31.210755 10646 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:13:31.210758 10646 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:13:31.210760 10646 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:13:31.210764 10646 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:13:31.210767 10646 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:13:31.210770 10646 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:13:31.210777 10646 net.cpp:124] Setting up pool1\n",
      "I0430 09:13:31.210779 10646 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:13:31.210782 10646 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:13:31.210784 10646 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:13:31.210788 10646 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:13:31.210790 10646 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:13:31.210794 10646 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:13:31.210799 10646 net.cpp:124] Setting up norm1\n",
      "I0430 09:13:31.210803 10646 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:13:31.210804 10646 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:13:31.210808 10646 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:13:31.210811 10646 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:13:31.210813 10646 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:13:31.210816 10646 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:13:31.211156 10646 net.cpp:124] Setting up conv2\n",
      "I0430 09:13:31.211161 10646 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:13:31.211163 10646 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:13:31.211169 10646 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:13:31.211174 10646 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:13:31.211175 10646 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:13:31.211179 10646 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:13:31.211182 10646 net.cpp:124] Setting up relu2\n",
      "I0430 09:13:31.211186 10646 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:13:31.211189 10646 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:13:31.211190 10646 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:13:31.211194 10646 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:13:31.211196 10646 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:13:31.211200 10646 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:13:31.211226 10646 net.cpp:124] Setting up pool2\n",
      "I0430 09:13:31.211232 10646 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:13:31.211235 10646 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:13:31.211237 10646 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:13:31.211241 10646 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:13:31.211244 10646 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:13:31.211248 10646 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:13:31.211253 10646 net.cpp:124] Setting up norm2\n",
      "I0430 09:13:31.211256 10646 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:13:31.211259 10646 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:13:31.211261 10646 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:13:31.211266 10646 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:13:31.211267 10646 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:13:31.211272 10646 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:13:31.212323 10646 net.cpp:124] Setting up conv3\n",
      "I0430 09:13:31.212374 10646 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:13:31.212384 10646 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:13:31.212407 10646 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:13:31.212424 10646 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:13:31.212432 10646 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:13:31.212442 10646 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:13:31.212458 10646 net.cpp:124] Setting up relu3\n",
      "I0430 09:13:31.212466 10646 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:13:31.212471 10646 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:13:31.212477 10646 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:13:31.212492 10646 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:13:31.212499 10646 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:13:31.212525 10646 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:13:31.213475 10646 net.cpp:124] Setting up conv4\n",
      "I0430 09:13:31.213500 10646 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:13:31.213501 10646 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:13:31.213508 10646 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:13:31.213517 10646 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:13:31.213520 10646 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:13:31.213524 10646 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:13:31.213531 10646 net.cpp:124] Setting up relu4\n",
      "I0430 09:13:31.213533 10646 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:13:31.213536 10646 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:13:31.213537 10646 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:13:31.213543 10646 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:13:31.213544 10646 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:13:31.213547 10646 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:13:31.214071 10646 net.cpp:124] Setting up conv5\n",
      "I0430 09:13:31.214078 10646 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:13:31.214082 10646 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:13:31.214088 10646 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:13:31.214093 10646 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:13:31.214097 10646 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:13:31.214100 10646 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:13:31.214105 10646 net.cpp:124] Setting up relu5\n",
      "I0430 09:13:31.214108 10646 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:13:31.214110 10646 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:13:31.214112 10646 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:13:31.214117 10646 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:13:31.214119 10646 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:13:31.214123 10646 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:13:31.214130 10646 net.cpp:124] Setting up pool5\n",
      "I0430 09:13:31.214133 10646 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:13:31.214135 10646 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:13:31.214138 10646 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:13:31.214144 10646 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:13:31.214146 10646 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:13:31.214150 10646 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:13:31.237270 10646 net.cpp:124] Setting up fc6\n",
      "I0430 09:13:31.237293 10646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:13:31.237296 10646 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:13:31.237306 10646 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:13:31.237318 10646 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:13:31.237323 10646 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:13:31.237326 10646 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:13:31.237332 10646 net.cpp:124] Setting up relu6\n",
      "I0430 09:13:31.237334 10646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:13:31.237336 10646 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:13:31.237339 10646 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:13:31.237341 10646 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:13:31.237352 10646 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:13:31.237355 10646 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:13:31.237362 10646 net.cpp:124] Setting up drop6\n",
      "I0430 09:13:31.237365 10646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:13:31.237368 10646 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:13:31.237371 10646 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:13:31.237377 10646 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:13:31.237380 10646 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:13:31.237385 10646 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:13:31.248097 10646 net.cpp:124] Setting up fc7\n",
      "I0430 09:13:31.248121 10646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:13:31.248124 10646 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:13:31.248136 10646 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:13:31.248144 10646 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:13:31.248147 10646 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:13:31.248153 10646 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:13:31.248160 10646 net.cpp:124] Setting up relu7\n",
      "I0430 09:13:31.248164 10646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:13:31.248167 10646 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:13:31.248170 10646 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:13:31.248175 10646 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:13:31.248178 10646 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:13:31.248183 10646 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:13:31.248188 10646 net.cpp:124] Setting up drop7\n",
      "I0430 09:13:31.248193 10646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:13:31.248194 10646 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:13:31.248198 10646 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:13:31.248203 10646 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:13:31.248205 10646 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:13:31.248210 10646 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:13:31.248849 10646 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:13:31.248859 10646 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:13:31.248862 10646 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:13:31.248869 10646 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:13:31.248872 10646 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:13:31.248875 10646 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:13:31.248878 10646 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:13:31.248883 10646 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:13:31.248885 10646 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:13:31.248888 10646 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:13:31.248891 10646 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:13:31.248894 10646 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:13:31.248898 10646 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:13:31.248901 10646 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:13:31.248904 10646 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:13:31.248908 10646 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:13:31.248910 10646 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:13:31.248914 10646 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:13:31.248917 10646 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:13:31.248920 10646 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:13:31.248924 10646 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:13:31.248926 10646 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:13:31.248930 10646 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:13:31.248934 10646 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:13:31.248936 10646 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:13:31.248939 10646 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:13:31.248942 10646 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:13:31.248953 10646 net.cpp:257] Network initialization done.\n",
      "I0430 09:13:31.336521 10646 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:13:31.434769 10646 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:13:31.435719 10646 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:13:31.435729 10646 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:13:31.435730 10646 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/304063.jpg'}, '/tmp/tmpzW4NJq.mat')\n",
      "Processed 872 windows in 106.628 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-2.26011, 1.12694, -1.7027, -1.71058, -1.8377...\n",
      "ymin                                                        113\n",
      "xmin                                                         60\n",
      "ymax                                                        241\n",
      "xmax                                                        461\n",
      "Name: /home/ambika/INF_project/data/airplane/304063.jpg, dtype: object\n",
      "prediction    [-2.10592, -0.309575, -1.30535, -1.06018, -1.3...\n",
      "ymin                                                        108\n",
      "xmin                                                         39\n",
      "ymax                                                        246\n",
      "xmax                                                        142\n",
      "Name: /home/ambika/INF_project/data/airplane/304063.jpg, dtype: object\n",
      "airplane\n",
      "60\t113\t461\t241\n",
      "bird\n",
      "39\t108\t142\t246\n",
      "304063\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:15:19.532902 10765 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:15:19.532938 10765 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:15:19.532940 10765 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:15:19.534893 10765 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:15:19.535042 10765 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:15:19.535056 10765 net.cpp:86] Creating Layer data\n",
      "I0430 09:15:19.535060 10765 net.cpp:382] data -> data\n",
      "I0430 09:15:19.535071 10765 net.cpp:124] Setting up data\n",
      "I0430 09:15:19.535078 10765 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:15:19.535079 10765 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:15:19.535082 10765 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:15:19.535089 10765 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:15:19.535091 10765 net.cpp:408] conv1 <- data\n",
      "I0430 09:15:19.535095 10765 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:15:19.535161 10765 net.cpp:124] Setting up conv1\n",
      "I0430 09:15:19.535166 10765 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:15:19.535167 10765 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:15:19.535174 10765 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:15:19.535179 10765 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:15:19.535181 10765 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:15:19.535184 10765 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:15:19.535189 10765 net.cpp:124] Setting up relu1\n",
      "I0430 09:15:19.535192 10765 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:15:19.535193 10765 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:15:19.535195 10765 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:15:19.535198 10765 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:15:19.535200 10765 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:15:19.535202 10765 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:15:19.535238 10765 net.cpp:124] Setting up pool1\n",
      "I0430 09:15:19.535241 10765 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:15:19.535243 10765 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:15:19.535245 10765 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:15:19.535249 10765 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:15:19.535250 10765 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:15:19.535254 10765 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:15:19.535259 10765 net.cpp:124] Setting up norm1\n",
      "I0430 09:15:19.535262 10765 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:15:19.535265 10765 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:15:19.535267 10765 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:15:19.535271 10765 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:15:19.535274 10765 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:15:19.535277 10765 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:15:19.535622 10765 net.cpp:124] Setting up conv2\n",
      "I0430 09:15:19.535627 10765 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:15:19.535630 10765 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:15:19.535635 10765 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:15:19.535639 10765 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:15:19.535641 10765 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:15:19.535645 10765 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:15:19.535648 10765 net.cpp:124] Setting up relu2\n",
      "I0430 09:15:19.535652 10765 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:15:19.535655 10765 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:15:19.535657 10765 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:15:19.535661 10765 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:15:19.535663 10765 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:15:19.535666 10765 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:15:19.535671 10765 net.cpp:124] Setting up pool2\n",
      "I0430 09:15:19.535676 10765 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:15:19.535677 10765 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:15:19.535679 10765 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:15:19.535686 10765 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:15:19.535687 10765 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:15:19.535691 10765 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:15:19.535694 10765 net.cpp:124] Setting up norm2\n",
      "I0430 09:15:19.535696 10765 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:15:19.535698 10765 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:15:19.535701 10765 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:15:19.535703 10765 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:15:19.535704 10765 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:15:19.535707 10765 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:15:19.536393 10765 net.cpp:124] Setting up conv3\n",
      "I0430 09:15:19.536402 10765 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:15:19.536406 10765 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:15:19.536412 10765 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:15:19.536417 10765 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:15:19.536419 10765 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:15:19.536423 10765 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:15:19.536428 10765 net.cpp:124] Setting up relu3\n",
      "I0430 09:15:19.536432 10765 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:15:19.536434 10765 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:15:19.536437 10765 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:15:19.536440 10765 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:15:19.536443 10765 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:15:19.536447 10765 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:15:19.537181 10765 net.cpp:124] Setting up conv4\n",
      "I0430 09:15:19.537189 10765 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:15:19.537192 10765 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:15:19.537196 10765 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:15:19.537200 10765 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:15:19.537206 10765 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:15:19.537212 10765 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:15:19.537217 10765 net.cpp:124] Setting up relu4\n",
      "I0430 09:15:19.537222 10765 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:15:19.537225 10765 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:15:19.537228 10765 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:15:19.537235 10765 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:15:19.537238 10765 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:15:19.537243 10765 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:15:19.537744 10765 net.cpp:124] Setting up conv5\n",
      "I0430 09:15:19.537752 10765 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:15:19.537755 10765 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:15:19.537765 10765 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:15:19.537770 10765 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:15:19.537772 10765 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:15:19.537778 10765 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:15:19.537782 10765 net.cpp:124] Setting up relu5\n",
      "I0430 09:15:19.537786 10765 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:15:19.537789 10765 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:15:19.537792 10765 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:15:19.537797 10765 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:15:19.537799 10765 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:15:19.537804 10765 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:15:19.537811 10765 net.cpp:124] Setting up pool5\n",
      "I0430 09:15:19.537816 10765 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:15:19.537817 10765 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:15:19.537820 10765 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:15:19.537828 10765 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:15:19.537832 10765 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:15:19.537837 10765 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:15:19.560155 10765 net.cpp:124] Setting up fc6\n",
      "I0430 09:15:19.560181 10765 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:15:19.560184 10765 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:15:19.560195 10765 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:15:19.560205 10765 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:15:19.560209 10765 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:15:19.560214 10765 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:15:19.560222 10765 net.cpp:124] Setting up relu6\n",
      "I0430 09:15:19.560226 10765 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:15:19.560230 10765 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:15:19.560232 10765 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:15:19.560237 10765 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:15:19.560240 10765 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:15:19.560245 10765 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:15:19.560250 10765 net.cpp:124] Setting up drop6\n",
      "I0430 09:15:19.560253 10765 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:15:19.560256 10765 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:15:19.560259 10765 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:15:19.560264 10765 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:15:19.560267 10765 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:15:19.560272 10765 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:15:19.570447 10765 net.cpp:124] Setting up fc7\n",
      "I0430 09:15:19.570473 10765 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:15:19.570477 10765 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:15:19.570488 10765 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:15:19.570498 10765 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:15:19.570502 10765 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:15:19.570508 10765 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:15:19.570516 10765 net.cpp:124] Setting up relu7\n",
      "I0430 09:15:19.570520 10765 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:15:19.570523 10765 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:15:19.570526 10765 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:15:19.570531 10765 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:15:19.570534 10765 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:15:19.570539 10765 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:15:19.570544 10765 net.cpp:124] Setting up drop7\n",
      "I0430 09:15:19.570549 10765 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:15:19.570551 10765 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:15:19.570554 10765 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:15:19.570559 10765 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:15:19.570561 10765 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:15:19.570566 10765 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:15:19.571254 10765 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:15:19.571264 10765 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:15:19.571267 10765 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:15:19.571274 10765 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:15:19.571277 10765 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:15:19.571280 10765 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:15:19.571283 10765 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:15:19.571287 10765 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:15:19.571290 10765 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:15:19.571293 10765 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:15:19.571297 10765 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:15:19.571300 10765 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:15:19.571303 10765 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:15:19.571306 10765 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:15:19.571310 10765 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:15:19.571312 10765 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:15:19.571316 10765 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:15:19.571319 10765 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:15:19.571323 10765 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:15:19.571326 10765 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:15:19.571329 10765 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:15:19.571332 10765 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:15:19.571336 10765 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:15:19.571338 10765 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:15:19.571341 10765 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:15:19.571344 10765 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:15:19.571347 10765 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:15:19.571357 10765 net.cpp:257] Network initialization done.\n",
      "I0430 09:15:19.656972 10765 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:15:19.756583 10765 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:15:19.757514 10765 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:15:19.757522 10765 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:15:19.757526 10765 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/343606.jpg'}, '/tmp/tmpYxRRwL.mat')\n",
      "Processed 2170 windows in 255.372 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.29073, -2.16821, -2.07465, -2.45094, -2.51...\n",
      "ymin                                                         44\n",
      "xmin                                                         39\n",
      "ymax                                                        236\n",
      "xmax                                                        292\n",
      "Name: /home/ambika/INF_project/data/bird/343606.jpg, dtype: object\n",
      "prediction    [-2.51195, -2.02461, -2.44171, -2.19221, -2.32...\n",
      "ymin                                                        149\n",
      "xmin                                                        189\n",
      "ymax                                                        375\n",
      "xmax                                                        472\n",
      "Name: /home/ambika/INF_project/data/bird/343606.jpg, dtype: object\n",
      "bird\n",
      "39\t44\t292\t236\n",
      "armadillo\n",
      "189\t149\t472\t375\n",
      "343606\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:19:36.683815 10969 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:19:36.683831 10969 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:19:36.683833 10969 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:19:36.684965 10969 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:19:36.685137 10969 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:19:36.685145 10969 net.cpp:86] Creating Layer data\n",
      "I0430 09:19:36.685150 10969 net.cpp:382] data -> data\n",
      "I0430 09:19:36.685161 10969 net.cpp:124] Setting up data\n",
      "I0430 09:19:36.685168 10969 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:19:36.685170 10969 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:19:36.685174 10969 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:19:36.685181 10969 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:19:36.685184 10969 net.cpp:408] conv1 <- data\n",
      "I0430 09:19:36.685189 10969 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:19:36.685248 10969 net.cpp:124] Setting up conv1\n",
      "I0430 09:19:36.685255 10969 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:19:36.685257 10969 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:19:36.685266 10969 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:19:36.685271 10969 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:19:36.685273 10969 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:19:36.685278 10969 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:19:36.685283 10969 net.cpp:124] Setting up relu1\n",
      "I0430 09:19:36.685287 10969 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:19:36.685290 10969 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:19:36.685293 10969 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:19:36.685299 10969 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:19:36.685302 10969 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:19:36.685307 10969 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:19:36.685318 10969 net.cpp:124] Setting up pool1\n",
      "I0430 09:19:36.685323 10969 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:19:36.685325 10969 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:19:36.685329 10969 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:19:36.685334 10969 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:19:36.685338 10969 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:19:36.685343 10969 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:19:36.685348 10969 net.cpp:124] Setting up norm1\n",
      "I0430 09:19:36.685353 10969 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:19:36.685355 10969 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:19:36.685359 10969 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:19:36.685364 10969 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:19:36.685366 10969 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:19:36.685371 10969 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:19:36.685708 10969 net.cpp:124] Setting up conv2\n",
      "I0430 09:19:36.685714 10969 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:19:36.685717 10969 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:19:36.685724 10969 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:19:36.685729 10969 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:19:36.685731 10969 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:19:36.685736 10969 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:19:36.685740 10969 net.cpp:124] Setting up relu2\n",
      "I0430 09:19:36.685745 10969 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:19:36.685747 10969 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:19:36.685750 10969 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:19:36.685755 10969 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:19:36.685758 10969 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:19:36.685762 10969 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:19:36.685768 10969 net.cpp:124] Setting up pool2\n",
      "I0430 09:19:36.685772 10969 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:19:36.685775 10969 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:19:36.685778 10969 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:19:36.685784 10969 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:19:36.685787 10969 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:19:36.685792 10969 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:19:36.685797 10969 net.cpp:124] Setting up norm2\n",
      "I0430 09:19:36.685802 10969 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:19:36.685804 10969 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:19:36.685808 10969 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:19:36.685814 10969 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:19:36.685817 10969 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:19:36.685822 10969 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:19:36.686496 10969 net.cpp:124] Setting up conv3\n",
      "I0430 09:19:36.686506 10969 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:19:36.686509 10969 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:19:36.686517 10969 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:19:36.686523 10969 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:19:36.686527 10969 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:19:36.686532 10969 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:19:36.686537 10969 net.cpp:124] Setting up relu3\n",
      "I0430 09:19:36.686542 10969 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:19:36.686544 10969 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:19:36.686547 10969 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:19:36.686553 10969 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:19:36.686556 10969 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:19:36.686563 10969 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:19:36.687294 10969 net.cpp:124] Setting up conv4\n",
      "I0430 09:19:36.687304 10969 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:19:36.687306 10969 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:19:36.687314 10969 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:19:36.687319 10969 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:19:36.687321 10969 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:19:36.687326 10969 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:19:36.687331 10969 net.cpp:124] Setting up relu4\n",
      "I0430 09:19:36.687335 10969 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:19:36.687337 10969 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:19:36.687340 10969 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:19:36.687347 10969 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:19:36.687350 10969 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:19:36.687355 10969 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:19:36.687839 10969 net.cpp:124] Setting up conv5\n",
      "I0430 09:19:36.687845 10969 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:19:36.687849 10969 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:19:36.687858 10969 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:19:36.687862 10969 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:19:36.687865 10969 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:19:36.687870 10969 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:19:36.687875 10969 net.cpp:124] Setting up relu5\n",
      "I0430 09:19:36.687880 10969 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:19:36.687882 10969 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:19:36.687885 10969 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:19:36.687891 10969 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:19:36.687892 10969 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:19:36.687897 10969 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:19:36.687904 10969 net.cpp:124] Setting up pool5\n",
      "I0430 09:19:36.687909 10969 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:19:36.687911 10969 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:19:36.687914 10969 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:19:36.687922 10969 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:19:36.687925 10969 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:19:36.687932 10969 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:19:36.710114 10969 net.cpp:124] Setting up fc6\n",
      "I0430 09:19:36.710139 10969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:19:36.710144 10969 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:19:36.710158 10969 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:19:36.710168 10969 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:19:36.710171 10969 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:19:36.710176 10969 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:19:36.710183 10969 net.cpp:124] Setting up relu6\n",
      "I0430 09:19:36.710186 10969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:19:36.710187 10969 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:19:36.710189 10969 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:19:36.710193 10969 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:19:36.710194 10969 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:19:36.710197 10969 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:19:36.710203 10969 net.cpp:124] Setting up drop6\n",
      "I0430 09:19:36.710209 10969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:19:36.710212 10969 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:19:36.710216 10969 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:19:36.710222 10969 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:19:36.710225 10969 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:19:36.710232 10969 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:19:36.722075 10969 net.cpp:124] Setting up fc7\n",
      "I0430 09:19:36.722100 10969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:19:36.722105 10969 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:19:36.722132 10969 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:19:36.722141 10969 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:19:36.722146 10969 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:19:36.722153 10969 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:19:36.722162 10969 net.cpp:124] Setting up relu7\n",
      "I0430 09:19:36.722165 10969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:19:36.722168 10969 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:19:36.722172 10969 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:19:36.722177 10969 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:19:36.722180 10969 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:19:36.722185 10969 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:19:36.722192 10969 net.cpp:124] Setting up drop7\n",
      "I0430 09:19:36.722194 10969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:19:36.722198 10969 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:19:36.722200 10969 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:19:36.722206 10969 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:19:36.722208 10969 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:19:36.722213 10969 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:19:36.723105 10969 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:19:36.723115 10969 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:19:36.723119 10969 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:19:36.723125 10969 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:19:36.723129 10969 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:19:36.723132 10969 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:19:36.723136 10969 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:19:36.723140 10969 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:19:36.723142 10969 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:19:36.723146 10969 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:19:36.723152 10969 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:19:36.723156 10969 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:19:36.723160 10969 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:19:36.723165 10969 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:19:36.723167 10969 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:19:36.723171 10969 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:19:36.723176 10969 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:19:36.723179 10969 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:19:36.723183 10969 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:19:36.723186 10969 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:19:36.723189 10969 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:19:36.723193 10969 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:19:36.723196 10969 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:19:36.723199 10969 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:19:36.723202 10969 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:19:36.723212 10969 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:19:36.723215 10969 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:19:36.723225 10969 net.cpp:257] Network initialization done.\n",
      "I0430 09:19:36.809654 10969 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:19:36.910181 10969 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:19:36.911098 10969 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:19:36.911118 10969 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:19:36.911126 10969 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/363875.jpg'}, '/tmp/tmpoqEaZM.mat')\n",
      "Processed 3481 windows in 403.731 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.064 s.\n",
      "prediction    [-1.36113, -1.65987, -1.9239, -2.01593, -2.256...\n",
      "ymin                                                    129.056\n",
      "xmin                                                          0\n",
      "ymax                                                    500.656\n",
      "xmax                                                    436.128\n",
      "Name: /home/ambika/INF_project/data/bus/363875.jpg, dtype: object\n",
      "prediction    [-2.33785, -2.66862, -2.03035, -1.69263, -2.19...\n",
      "ymin                                                     10.464\n",
      "xmin                                                     92.432\n",
      "ymax                                                    239.928\n",
      "xmax                                                     310.56\n",
      "Name: /home/ambika/INF_project/data/bus/363875.jpg, dtype: object\n",
      "motorcycle\n",
      "0.0\t129.056\t436.128\t500.656\n",
      "person\n",
      "92.432\t10.464\t310.56\t239.928\n",
      "363875\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:26:22.444718 11191 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:26:22.444737 11191 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:26:22.444739 11191 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:26:22.445904 11191 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:26:22.446053 11191 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:26:22.446061 11191 net.cpp:86] Creating Layer data\n",
      "I0430 09:26:22.446064 11191 net.cpp:382] data -> data\n",
      "I0430 09:26:22.446077 11191 net.cpp:124] Setting up data\n",
      "I0430 09:26:22.446082 11191 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:26:22.446084 11191 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:26:22.446087 11191 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:26:22.446094 11191 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:26:22.446095 11191 net.cpp:408] conv1 <- data\n",
      "I0430 09:26:22.446099 11191 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:26:22.446158 11191 net.cpp:124] Setting up conv1\n",
      "I0430 09:26:22.446163 11191 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:26:22.446166 11191 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:26:22.446172 11191 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:26:22.446177 11191 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:26:22.446179 11191 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:26:22.446182 11191 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:26:22.446187 11191 net.cpp:124] Setting up relu1\n",
      "I0430 09:26:22.446190 11191 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:26:22.446192 11191 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:26:22.446194 11191 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:26:22.446198 11191 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:26:22.446200 11191 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:26:22.446204 11191 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:26:22.446210 11191 net.cpp:124] Setting up pool1\n",
      "I0430 09:26:22.446213 11191 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:26:22.446215 11191 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:26:22.446218 11191 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:26:22.446223 11191 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:26:22.446224 11191 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:26:22.446228 11191 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:26:22.446233 11191 net.cpp:124] Setting up norm1\n",
      "I0430 09:26:22.446235 11191 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:26:22.446238 11191 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:26:22.446239 11191 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:26:22.446244 11191 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:26:22.446246 11191 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:26:22.446249 11191 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:26:22.446575 11191 net.cpp:124] Setting up conv2\n",
      "I0430 09:26:22.446580 11191 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:26:22.446583 11191 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:26:22.446588 11191 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:26:22.446593 11191 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:26:22.446594 11191 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:26:22.446599 11191 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:26:22.446601 11191 net.cpp:124] Setting up relu2\n",
      "I0430 09:26:22.446604 11191 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:26:22.446606 11191 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:26:22.446609 11191 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:26:22.446612 11191 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:26:22.446615 11191 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:26:22.446619 11191 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:26:22.446624 11191 net.cpp:124] Setting up pool2\n",
      "I0430 09:26:22.446626 11191 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:26:22.446629 11191 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:26:22.446630 11191 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:26:22.446635 11191 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:26:22.446636 11191 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:26:22.446640 11191 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:26:22.446642 11191 net.cpp:124] Setting up norm2\n",
      "I0430 09:26:22.446645 11191 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:26:22.446647 11191 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:26:22.446648 11191 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:26:22.446652 11191 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:26:22.446655 11191 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:26:22.446658 11191 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:26:22.447615 11191 net.cpp:124] Setting up conv3\n",
      "I0430 09:26:22.447625 11191 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:26:22.447628 11191 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:26:22.447640 11191 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:26:22.447649 11191 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:26:22.447654 11191 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:26:22.447657 11191 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:26:22.447662 11191 net.cpp:124] Setting up relu3\n",
      "I0430 09:26:22.447667 11191 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:26:22.447669 11191 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:26:22.447672 11191 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:26:22.447679 11191 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:26:22.447682 11191 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:26:22.447687 11191 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:26:22.448179 11191 net.cpp:124] Setting up conv4\n",
      "I0430 09:26:22.448186 11191 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:26:22.448190 11191 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:26:22.448195 11191 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:26:22.448200 11191 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:26:22.448204 11191 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:26:22.448207 11191 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:26:22.448212 11191 net.cpp:124] Setting up relu4\n",
      "I0430 09:26:22.448216 11191 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:26:22.448218 11191 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:26:22.448221 11191 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:26:22.448228 11191 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:26:22.448231 11191 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:26:22.448235 11191 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:26:22.448725 11191 net.cpp:124] Setting up conv5\n",
      "I0430 09:26:22.448737 11191 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:26:22.448740 11191 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:26:22.448751 11191 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:26:22.448758 11191 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:26:22.448761 11191 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:26:22.448767 11191 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:26:22.448772 11191 net.cpp:124] Setting up relu5\n",
      "I0430 09:26:22.448777 11191 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:26:22.448781 11191 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:26:22.448784 11191 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:26:22.448789 11191 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:26:22.448792 11191 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:26:22.448798 11191 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:26:22.448808 11191 net.cpp:124] Setting up pool5\n",
      "I0430 09:26:22.448813 11191 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:26:22.448817 11191 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:26:22.448819 11191 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:26:22.448829 11191 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:26:22.448832 11191 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:26:22.448837 11191 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:26:22.473373 11191 net.cpp:124] Setting up fc6\n",
      "I0430 09:26:22.473395 11191 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:26:22.473399 11191 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:26:22.473410 11191 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:26:22.473419 11191 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:26:22.473423 11191 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:26:22.473428 11191 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:26:22.473435 11191 net.cpp:124] Setting up relu6\n",
      "I0430 09:26:22.473439 11191 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:26:22.473443 11191 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:26:22.473445 11191 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:26:22.473450 11191 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:26:22.473453 11191 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:26:22.473457 11191 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:26:22.473462 11191 net.cpp:124] Setting up drop6\n",
      "I0430 09:26:22.473466 11191 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:26:22.473469 11191 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:26:22.473471 11191 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:26:22.473477 11191 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:26:22.473480 11191 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:26:22.473485 11191 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:26:22.484030 11191 net.cpp:124] Setting up fc7\n",
      "I0430 09:26:22.484055 11191 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:26:22.484058 11191 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:26:22.484069 11191 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:26:22.484078 11191 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:26:22.484082 11191 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:26:22.484087 11191 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:26:22.484096 11191 net.cpp:124] Setting up relu7\n",
      "I0430 09:26:22.484099 11191 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:26:22.484102 11191 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:26:22.484104 11191 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:26:22.484112 11191 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:26:22.484113 11191 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:26:22.484118 11191 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:26:22.484123 11191 net.cpp:124] Setting up drop7\n",
      "I0430 09:26:22.484127 11191 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:26:22.484129 11191 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:26:22.484133 11191 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:26:22.484136 11191 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:26:22.484139 11191 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:26:22.484144 11191 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:26:22.485047 11191 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:26:22.485057 11191 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:26:22.485061 11191 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:26:22.485067 11191 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:26:22.485071 11191 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:26:22.485074 11191 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:26:22.485077 11191 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:26:22.485080 11191 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:26:22.485083 11191 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:26:22.485086 11191 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:26:22.485090 11191 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:26:22.485092 11191 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:26:22.485095 11191 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:26:22.485100 11191 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:26:22.485102 11191 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:26:22.485105 11191 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:26:22.485108 11191 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:26:22.485111 11191 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:26:22.485115 11191 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:26:22.485117 11191 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:26:22.485121 11191 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:26:22.485124 11191 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:26:22.485127 11191 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:26:22.485131 11191 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:26:22.485133 11191 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:26:22.485136 11191 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:26:22.485139 11191 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:26:22.485152 11191 net.cpp:257] Network initialization done.\n",
      "I0430 09:26:22.602134 11191 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:26:22.700508 11191 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:26:22.701730 11191 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:26:22.701745 11191 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:26:22.701750 11191 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/425925.jpg'}, '/tmp/tmpcNcN9Q.mat')\n",
      "Processed 2009 windows in 230.964 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.08842, -1.91288, -1.87348, -2.3987, -1.837...\n",
      "ymin                                                        316\n",
      "xmin                                                         93\n",
      "ymax                                                        361\n",
      "xmax                                                        118\n",
      "Name: /home/ambika/INF_project/data/car/425925.jpg, dtype: object\n",
      "prediction    [-2.09042, -1.63753, -1.8714, -2.21452, -1.844...\n",
      "ymin                                                        316\n",
      "xmin                                                         34\n",
      "ymax                                                        363\n",
      "xmax                                                        118\n",
      "Name: /home/ambika/INF_project/data/car/425925.jpg, dtype: object\n",
      "person\n",
      "93\t316\t118\t361\n",
      "car\n",
      "34\t316\t118\t363\n",
      "425925\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:30:15.398114 11364 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:30:15.398138 11364 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:30:15.398142 11364 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:30:15.399852 11364 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:30:15.399973 11364 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:30:15.399986 11364 net.cpp:86] Creating Layer data\n",
      "I0430 09:30:15.399991 11364 net.cpp:382] data -> data\n",
      "I0430 09:30:15.400007 11364 net.cpp:124] Setting up data\n",
      "I0430 09:30:15.400015 11364 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:30:15.400018 11364 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:30:15.400023 11364 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:30:15.400032 11364 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:30:15.400034 11364 net.cpp:408] conv1 <- data\n",
      "I0430 09:30:15.400039 11364 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:30:15.400111 11364 net.cpp:124] Setting up conv1\n",
      "I0430 09:30:15.400117 11364 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:30:15.400120 11364 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:30:15.400151 11364 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:30:15.400156 11364 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:30:15.400159 11364 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:30:15.400164 11364 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:30:15.400171 11364 net.cpp:124] Setting up relu1\n",
      "I0430 09:30:15.400176 11364 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:30:15.400178 11364 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:30:15.400182 11364 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:30:15.400187 11364 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:30:15.400190 11364 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:30:15.400195 11364 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:30:15.400204 11364 net.cpp:124] Setting up pool1\n",
      "I0430 09:30:15.400209 11364 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:30:15.400213 11364 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:30:15.400216 11364 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:30:15.400228 11364 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:30:15.400233 11364 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:30:15.400238 11364 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:30:15.400246 11364 net.cpp:124] Setting up norm1\n",
      "I0430 09:30:15.400251 11364 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:30:15.400255 11364 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:30:15.400259 11364 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:30:15.400269 11364 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:30:15.400274 11364 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:30:15.400280 11364 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:30:15.400666 11364 net.cpp:124] Setting up conv2\n",
      "I0430 09:30:15.400674 11364 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:30:15.400676 11364 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:30:15.400682 11364 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:30:15.400686 11364 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:30:15.400688 11364 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:30:15.400691 11364 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:30:15.400696 11364 net.cpp:124] Setting up relu2\n",
      "I0430 09:30:15.400697 11364 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:30:15.400701 11364 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:30:15.400702 11364 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:30:15.400709 11364 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:30:15.400712 11364 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:30:15.400715 11364 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:30:15.400722 11364 net.cpp:124] Setting up pool2\n",
      "I0430 09:30:15.400724 11364 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:30:15.400727 11364 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:30:15.400729 11364 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:30:15.400734 11364 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:30:15.400738 11364 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:30:15.400740 11364 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:30:15.400745 11364 net.cpp:124] Setting up norm2\n",
      "I0430 09:30:15.400748 11364 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:30:15.400750 11364 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:30:15.400753 11364 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:30:15.400758 11364 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:30:15.400759 11364 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:30:15.400763 11364 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:30:15.401494 11364 net.cpp:124] Setting up conv3\n",
      "I0430 09:30:15.401505 11364 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:30:15.401509 11364 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:30:15.401518 11364 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:30:15.401525 11364 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:30:15.401527 11364 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:30:15.401531 11364 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:30:15.401536 11364 net.cpp:124] Setting up relu3\n",
      "I0430 09:30:15.401540 11364 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:30:15.401541 11364 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:30:15.401543 11364 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:30:15.401548 11364 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:30:15.401551 11364 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:30:15.401553 11364 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:30:15.402307 11364 net.cpp:124] Setting up conv4\n",
      "I0430 09:30:15.402323 11364 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:30:15.402326 11364 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:30:15.402333 11364 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:30:15.402341 11364 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:30:15.402345 11364 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:30:15.402353 11364 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:30:15.402359 11364 net.cpp:124] Setting up relu4\n",
      "I0430 09:30:15.402362 11364 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:30:15.402364 11364 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:30:15.402367 11364 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:30:15.402372 11364 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:30:15.402375 11364 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:30:15.402379 11364 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:30:15.402865 11364 net.cpp:124] Setting up conv5\n",
      "I0430 09:30:15.402873 11364 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:30:15.402876 11364 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:30:15.402886 11364 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:30:15.402890 11364 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:30:15.402894 11364 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:30:15.402896 11364 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:30:15.402900 11364 net.cpp:124] Setting up relu5\n",
      "I0430 09:30:15.402904 11364 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:30:15.402906 11364 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:30:15.402909 11364 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:30:15.402912 11364 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:30:15.402915 11364 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:30:15.402920 11364 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:30:15.402926 11364 net.cpp:124] Setting up pool5\n",
      "I0430 09:30:15.402930 11364 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:30:15.402931 11364 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:30:15.402933 11364 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:30:15.402940 11364 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:30:15.402942 11364 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:30:15.402945 11364 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:30:15.437402 11364 net.cpp:124] Setting up fc6\n",
      "I0430 09:30:15.437430 11364 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:30:15.437435 11364 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:30:15.437448 11364 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:30:15.437469 11364 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:30:15.437474 11364 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:30:15.437480 11364 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:30:15.437489 11364 net.cpp:124] Setting up relu6\n",
      "I0430 09:30:15.437494 11364 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:30:15.437496 11364 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:30:15.437500 11364 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:30:15.437505 11364 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:30:15.437507 11364 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:30:15.437512 11364 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:30:15.437518 11364 net.cpp:124] Setting up drop6\n",
      "I0430 09:30:15.437521 11364 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:30:15.437525 11364 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:30:15.437527 11364 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:30:15.437535 11364 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:30:15.437537 11364 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:30:15.437542 11364 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:30:15.451294 11364 net.cpp:124] Setting up fc7\n",
      "I0430 09:30:15.451316 11364 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:30:15.451323 11364 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:30:15.451333 11364 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:30:15.451342 11364 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:30:15.451346 11364 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:30:15.451352 11364 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:30:15.451362 11364 net.cpp:124] Setting up relu7\n",
      "I0430 09:30:15.451366 11364 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:30:15.451370 11364 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:30:15.451373 11364 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:30:15.451381 11364 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:30:15.451385 11364 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:30:15.451387 11364 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:30:15.451392 11364 net.cpp:124] Setting up drop7\n",
      "I0430 09:30:15.451395 11364 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:30:15.451398 11364 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:30:15.451400 11364 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:30:15.451405 11364 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:30:15.451407 11364 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:30:15.451411 11364 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:30:15.452078 11364 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:30:15.452093 11364 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:30:15.452097 11364 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:30:15.452107 11364 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:30:15.452112 11364 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:30:15.452116 11364 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:30:15.452119 11364 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:30:15.452123 11364 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:30:15.452126 11364 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:30:15.452129 11364 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:30:15.452132 11364 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:30:15.452134 11364 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:30:15.452137 11364 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:30:15.452141 11364 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:30:15.452142 11364 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:30:15.452145 11364 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:30:15.452148 11364 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:30:15.452152 11364 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:30:15.452154 11364 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:30:15.452157 11364 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:30:15.452160 11364 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:30:15.452163 11364 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:30:15.452165 11364 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:30:15.452168 11364 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:30:15.452172 11364 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:30:15.452173 11364 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:30:15.452177 11364 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:30:15.452188 11364 net.cpp:257] Network initialization done.\n",
      "I0430 09:30:15.564875 11364 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:30:15.707367 11364 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:30:15.708758 11364 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:30:15.708781 11364 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:30:15.708786 11364 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/53457.jpg'}, '/tmp/tmpYiChyP.mat')\n",
      "Processed 1086 windows in 132.996 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.026 s.\n",
      "prediction    [-2.2715, -2.55349, -1.94914, -2.24126, -2.074...\n",
      "ymin                                                     94.248\n",
      "xmin                                                     100.98\n",
      "ymax                                                    217.172\n",
      "xmax                                                     259.06\n",
      "Name: /home/ambika/INF_project/data/cat/53457.jpg, dtype: object\n",
      "prediction    [-2.15143, -1.8495, -2.06782, -1.61816, -2.023...\n",
      "ymin                                                    175.032\n",
      "xmin                                                      8.228\n",
      "ymax                                                    456.532\n",
      "xmax                                                    316.656\n",
      "Name: /home/ambika/INF_project/data/cat/53457.jpg, dtype: object\n",
      "domestic cat\n",
      "100.98\t94.248\t259.06\t217.172\n",
      "tv or monitor\n",
      "8.228\t175.032\t316.656\t456.532\n",
      "53457\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:32:30.238179 11517 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:32:30.238203 11517 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:32:30.238217 11517 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:32:30.239467 11517 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:32:30.239598 11517 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:32:30.239606 11517 net.cpp:86] Creating Layer data\n",
      "I0430 09:32:30.239609 11517 net.cpp:382] data -> data\n",
      "I0430 09:32:30.239621 11517 net.cpp:124] Setting up data\n",
      "I0430 09:32:30.239626 11517 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:32:30.239629 11517 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:32:30.239632 11517 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:32:30.239637 11517 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:32:30.239640 11517 net.cpp:408] conv1 <- data\n",
      "I0430 09:32:30.239645 11517 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:32:30.239727 11517 net.cpp:124] Setting up conv1\n",
      "I0430 09:32:30.239733 11517 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:32:30.239735 11517 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:32:30.239742 11517 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:32:30.239748 11517 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:32:30.239750 11517 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:32:30.239753 11517 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:32:30.239758 11517 net.cpp:124] Setting up relu1\n",
      "I0430 09:32:30.239761 11517 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:32:30.239763 11517 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:32:30.239766 11517 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:32:30.239770 11517 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:32:30.239773 11517 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:32:30.239775 11517 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:32:30.239783 11517 net.cpp:124] Setting up pool1\n",
      "I0430 09:32:30.239785 11517 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:32:30.239787 11517 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:32:30.239790 11517 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:32:30.239794 11517 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:32:30.239796 11517 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:32:30.239800 11517 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:32:30.239805 11517 net.cpp:124] Setting up norm1\n",
      "I0430 09:32:30.239809 11517 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:32:30.239810 11517 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:32:30.239814 11517 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:32:30.239817 11517 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:32:30.239820 11517 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:32:30.239823 11517 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:32:30.240185 11517 net.cpp:124] Setting up conv2\n",
      "I0430 09:32:30.240191 11517 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:32:30.240193 11517 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:32:30.240200 11517 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:32:30.240203 11517 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:32:30.240206 11517 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:32:30.240209 11517 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:32:30.240213 11517 net.cpp:124] Setting up relu2\n",
      "I0430 09:32:30.240217 11517 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:32:30.240219 11517 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:32:30.240221 11517 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:32:30.240226 11517 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:32:30.240229 11517 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:32:30.240236 11517 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:32:30.240244 11517 net.cpp:124] Setting up pool2\n",
      "I0430 09:32:30.240249 11517 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:32:30.240253 11517 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:32:30.240257 11517 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:32:30.240262 11517 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:32:30.240265 11517 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:32:30.240269 11517 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:32:30.240274 11517 net.cpp:124] Setting up norm2\n",
      "I0430 09:32:30.240278 11517 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:32:30.240279 11517 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:32:30.240283 11517 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:32:30.240288 11517 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:32:30.240290 11517 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:32:30.240293 11517 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:32:30.241019 11517 net.cpp:124] Setting up conv3\n",
      "I0430 09:32:30.241029 11517 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:32:30.241034 11517 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:32:30.241042 11517 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:32:30.241050 11517 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:32:30.241053 11517 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:32:30.241057 11517 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:32:30.241061 11517 net.cpp:124] Setting up relu3\n",
      "I0430 09:32:30.241065 11517 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:32:30.241067 11517 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:32:30.241070 11517 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:32:30.241075 11517 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:32:30.241078 11517 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:32:30.241081 11517 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:32:30.241824 11517 net.cpp:124] Setting up conv4\n",
      "I0430 09:32:30.241834 11517 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:32:30.241838 11517 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:32:30.241845 11517 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:32:30.241852 11517 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:32:30.241855 11517 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:32:30.241859 11517 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:32:30.241864 11517 net.cpp:124] Setting up relu4\n",
      "I0430 09:32:30.241868 11517 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:32:30.241869 11517 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:32:30.241873 11517 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:32:30.241878 11517 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:32:30.241880 11517 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:32:30.241884 11517 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:32:30.242398 11517 net.cpp:124] Setting up conv5\n",
      "I0430 09:32:30.242405 11517 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:32:30.242408 11517 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:32:30.242420 11517 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:32:30.242424 11517 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:32:30.242427 11517 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:32:30.242432 11517 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:32:30.242436 11517 net.cpp:124] Setting up relu5\n",
      "I0430 09:32:30.242439 11517 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:32:30.242441 11517 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:32:30.242444 11517 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:32:30.242449 11517 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:32:30.242450 11517 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:32:30.242453 11517 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:32:30.242460 11517 net.cpp:124] Setting up pool5\n",
      "I0430 09:32:30.242463 11517 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:32:30.242465 11517 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:32:30.242467 11517 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:32:30.242475 11517 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:32:30.242477 11517 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:32:30.242481 11517 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:32:30.268285 11517 net.cpp:124] Setting up fc6\n",
      "I0430 09:32:30.268311 11517 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:32:30.268316 11517 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:32:30.268326 11517 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:32:30.268337 11517 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:32:30.268342 11517 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:32:30.268347 11517 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:32:30.268357 11517 net.cpp:124] Setting up relu6\n",
      "I0430 09:32:30.268362 11517 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:32:30.268364 11517 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:32:30.268368 11517 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:32:30.268375 11517 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:32:30.268379 11517 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:32:30.268384 11517 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:32:30.268391 11517 net.cpp:124] Setting up drop6\n",
      "I0430 09:32:30.268396 11517 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:32:30.268399 11517 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:32:30.268404 11517 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:32:30.268409 11517 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:32:30.268414 11517 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:32:30.268420 11517 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:32:30.282342 11517 net.cpp:124] Setting up fc7\n",
      "I0430 09:32:30.282376 11517 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:32:30.282380 11517 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:32:30.282392 11517 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:32:30.282402 11517 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:32:30.282407 11517 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:32:30.282413 11517 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:32:30.282420 11517 net.cpp:124] Setting up relu7\n",
      "I0430 09:32:30.282424 11517 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:32:30.282428 11517 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:32:30.282431 11517 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:32:30.282438 11517 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:32:30.282441 11517 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:32:30.282447 11517 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:32:30.282454 11517 net.cpp:124] Setting up drop7\n",
      "I0430 09:32:30.282459 11517 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:32:30.282462 11517 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:32:30.282466 11517 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:32:30.282472 11517 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:32:30.282476 11517 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:32:30.282482 11517 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:32:30.283370 11517 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:32:30.283401 11517 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:32:30.283403 11517 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:32:30.283412 11517 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:32:30.283416 11517 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:32:30.283417 11517 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:32:30.283418 11517 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:32:30.283422 11517 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:32:30.283426 11517 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:32:30.283427 11517 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:32:30.283429 11517 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:32:30.283432 11517 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:32:30.283435 11517 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:32:30.283438 11517 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:32:30.283442 11517 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:32:30.283444 11517 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:32:30.283447 11517 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:32:30.283455 11517 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:32:30.283458 11517 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:32:30.283463 11517 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:32:30.283466 11517 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:32:30.283470 11517 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:32:30.283473 11517 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:32:30.283478 11517 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:32:30.283480 11517 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:32:30.283483 11517 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:32:30.283486 11517 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:32:30.283496 11517 net.cpp:257] Network initialization done.\n",
      "I0430 09:32:30.387614 11517 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:32:30.500147 11517 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:32:30.501142 11517 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:32:30.501149 11517 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:32:30.501152 11517 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/257971.jpg'}, '/tmp/tmp48AUXL.mat')\n",
      "Processed 2044 windows in 244.098 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-3.12204, -3.17945, -2.06051, -2.45705, -2.37...\n",
      "ymin                                                          0\n",
      "xmin                                                        290\n",
      "ymax                                                        272\n",
      "xmax                                                        431\n",
      "Name: /home/ambika/INF_project/data/couch/257971.jpg, dtype: object\n",
      "prediction    [-1.9231, -2.07316, -1.64176, -1.94975, -1.850...\n",
      "ymin                                                        187\n",
      "xmin                                                          0\n",
      "ymax                                                        228\n",
      "xmax                                                         44\n",
      "Name: /home/ambika/INF_project/data/couch/257971.jpg, dtype: object\n",
      "person\n",
      "290\t0\t431\t272\n",
      "basketball\n",
      "0\t187\t44\t228\n",
      "257971\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:36:36.317977 11696 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:36:36.318001 11696 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:36:36.318004 11696 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:36:36.319720 11696 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:36:36.319865 11696 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:36:36.319875 11696 net.cpp:86] Creating Layer data\n",
      "I0430 09:36:36.319882 11696 net.cpp:382] data -> data\n",
      "I0430 09:36:36.319897 11696 net.cpp:124] Setting up data\n",
      "I0430 09:36:36.319905 11696 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:36:36.319910 11696 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:36:36.319914 11696 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:36:36.319922 11696 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:36:36.319927 11696 net.cpp:408] conv1 <- data\n",
      "I0430 09:36:36.319933 11696 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:36:36.320014 11696 net.cpp:124] Setting up conv1\n",
      "I0430 09:36:36.320022 11696 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:36:36.320026 11696 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:36:36.320036 11696 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:36:36.320044 11696 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:36:36.320047 11696 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:36:36.320052 11696 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:36:36.320060 11696 net.cpp:124] Setting up relu1\n",
      "I0430 09:36:36.320065 11696 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:36:36.320067 11696 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:36:36.320071 11696 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:36:36.320077 11696 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:36:36.320080 11696 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:36:36.320086 11696 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:36:36.320096 11696 net.cpp:124] Setting up pool1\n",
      "I0430 09:36:36.320101 11696 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:36:36.320104 11696 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:36:36.320108 11696 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:36:36.320116 11696 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:36:36.320119 11696 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:36:36.320124 11696 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:36:36.320133 11696 net.cpp:124] Setting up norm1\n",
      "I0430 09:36:36.320138 11696 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:36:36.320142 11696 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:36:36.320147 11696 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:36:36.320153 11696 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:36:36.320158 11696 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:36:36.320163 11696 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:36:36.320616 11696 net.cpp:124] Setting up conv2\n",
      "I0430 09:36:36.320626 11696 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:36:36.320629 11696 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:36:36.320637 11696 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:36:36.320643 11696 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:36:36.320647 11696 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:36:36.320652 11696 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:36:36.320658 11696 net.cpp:124] Setting up relu2\n",
      "I0430 09:36:36.320663 11696 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:36:36.320667 11696 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:36:36.320672 11696 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:36:36.320677 11696 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:36:36.320679 11696 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:36:36.320684 11696 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:36:36.320694 11696 net.cpp:124] Setting up pool2\n",
      "I0430 09:36:36.320699 11696 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:36:36.320703 11696 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:36:36.320706 11696 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:36:36.320713 11696 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:36:36.320718 11696 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:36:36.320722 11696 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:36:36.320729 11696 net.cpp:124] Setting up norm2\n",
      "I0430 09:36:36.320734 11696 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:36:36.320739 11696 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:36:36.320741 11696 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:36:36.320749 11696 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:36:36.320754 11696 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:36:36.320758 11696 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:36:36.321863 11696 net.cpp:124] Setting up conv3\n",
      "I0430 09:36:36.321892 11696 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:36:36.321897 11696 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:36:36.321913 11696 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:36:36.321923 11696 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:36:36.321928 11696 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:36:36.321935 11696 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:36:36.321943 11696 net.cpp:124] Setting up relu3\n",
      "I0430 09:36:36.321949 11696 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:36:36.321954 11696 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:36:36.321957 11696 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:36:36.321969 11696 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:36:36.321974 11696 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:36:36.321980 11696 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:36:36.323024 11696 net.cpp:124] Setting up conv4\n",
      "I0430 09:36:36.323046 11696 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:36:36.323050 11696 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:36:36.323060 11696 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:36:36.323067 11696 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:36:36.323071 11696 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:36:36.323077 11696 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:36:36.323086 11696 net.cpp:124] Setting up relu4\n",
      "I0430 09:36:36.323092 11696 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:36:36.323096 11696 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:36:36.323099 11696 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:36:36.323108 11696 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:36:36.323112 11696 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:36:36.323118 11696 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:36:36.323802 11696 net.cpp:124] Setting up conv5\n",
      "I0430 09:36:36.323815 11696 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:36:36.323820 11696 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:36:36.323832 11696 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:36:36.323839 11696 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:36:36.323843 11696 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:36:36.323850 11696 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:36:36.323856 11696 net.cpp:124] Setting up relu5\n",
      "I0430 09:36:36.323863 11696 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:36:36.323865 11696 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:36:36.323869 11696 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:36:36.323875 11696 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:36:36.323879 11696 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:36:36.323885 11696 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:36:36.323895 11696 net.cpp:124] Setting up pool5\n",
      "I0430 09:36:36.323901 11696 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:36:36.323905 11696 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:36:36.323909 11696 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:36:36.323920 11696 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:36:36.323925 11696 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:36:36.323930 11696 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:36:36.353425 11696 net.cpp:124] Setting up fc6\n",
      "I0430 09:36:36.353456 11696 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:36:36.353461 11696 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:36:36.353471 11696 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:36:36.353482 11696 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:36:36.353485 11696 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:36:36.353492 11696 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:36:36.353502 11696 net.cpp:124] Setting up relu6\n",
      "I0430 09:36:36.353507 11696 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:36:36.353512 11696 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:36:36.353515 11696 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:36:36.353521 11696 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:36:36.353526 11696 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:36:36.353531 11696 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:36:36.353538 11696 net.cpp:124] Setting up drop6\n",
      "I0430 09:36:36.353543 11696 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:36:36.353545 11696 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:36:36.353549 11696 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:36:36.353561 11696 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:36:36.353564 11696 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:36:36.353572 11696 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:36:36.366770 11696 net.cpp:124] Setting up fc7\n",
      "I0430 09:36:36.366844 11696 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:36:36.366854 11696 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:36:36.366880 11696 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:36:36.366904 11696 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:36:36.366914 11696 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:36:36.366926 11696 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:36:36.366945 11696 net.cpp:124] Setting up relu7\n",
      "I0430 09:36:36.366953 11696 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:36:36.366961 11696 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:36:36.366967 11696 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:36:36.366981 11696 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:36:36.366987 11696 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:36:36.367002 11696 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:36:36.367014 11696 net.cpp:124] Setting up drop7\n",
      "I0430 09:36:36.367023 11696 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:36:36.367030 11696 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:36:36.367038 11696 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:36:36.367049 11696 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:36:36.367058 11696 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:36:36.367063 11696 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:36:36.368161 11696 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:36:36.368197 11696 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:36:36.368201 11696 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:36:36.368216 11696 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:36:36.368222 11696 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:36:36.368226 11696 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:36:36.368229 11696 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:36:36.368233 11696 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:36:36.368237 11696 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:36:36.368240 11696 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:36:36.368244 11696 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:36:36.368248 11696 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:36:36.368253 11696 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:36:36.368257 11696 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:36:36.368261 11696 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:36:36.368265 11696 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:36:36.368269 11696 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:36:36.368274 11696 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:36:36.368279 11696 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:36:36.368283 11696 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:36:36.368288 11696 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:36:36.368291 11696 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:36:36.368295 11696 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:36:36.368299 11696 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:36:36.368304 11696 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:36:36.368307 11696 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:36:36.368310 11696 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:36:36.368325 11696 net.cpp:257] Network initialization done.\n",
      "I0430 09:36:36.464637 11696 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:36:36.574340 11696 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:36:36.575266 11696 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:36:36.575273 11696 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:36:36.575275 11696 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/444804.jpg'}, '/tmp/tmpVYIcm4.mat')\n",
      "Processed 2231 windows in 261.402 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.31978, -2.47429, -1.77282, -2.59621, -1.82...\n",
      "ymin                                                        111\n",
      "xmin                                                        161\n",
      "ymax                                                        327\n",
      "xmax                                                        232\n",
      "Name: /home/ambika/INF_project/data/dog/444804.jpg, dtype: object\n",
      "prediction    [-1.80662, -2.16097, -2.07058, -2.55509, -1.60...\n",
      "ymin                                                        153\n",
      "xmin                                                        401\n",
      "ymax                                                        214\n",
      "xmax                                                        471\n",
      "Name: /home/ambika/INF_project/data/dog/444804.jpg, dtype: object\n",
      "person\n",
      "161\t111\t232\t327\n",
      "dog\n",
      "401\t153\t471\t214\n",
      "444804\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:40:59.558308 11896 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:40:59.558331 11896 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:40:59.558333 11896 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:40:59.559538 11896 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:40:59.559643 11896 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:40:59.559651 11896 net.cpp:86] Creating Layer data\n",
      "I0430 09:40:59.559655 11896 net.cpp:382] data -> data\n",
      "I0430 09:40:59.559669 11896 net.cpp:124] Setting up data\n",
      "I0430 09:40:59.559676 11896 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:40:59.559679 11896 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:40:59.559684 11896 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:40:59.559690 11896 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:40:59.559693 11896 net.cpp:408] conv1 <- data\n",
      "I0430 09:40:59.559700 11896 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:40:59.559756 11896 net.cpp:124] Setting up conv1\n",
      "I0430 09:40:59.559762 11896 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:40:59.559767 11896 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:40:59.559775 11896 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:40:59.559782 11896 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:40:59.559784 11896 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:40:59.559788 11896 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:40:59.559793 11896 net.cpp:124] Setting up relu1\n",
      "I0430 09:40:59.559798 11896 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:40:59.559800 11896 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:40:59.559803 11896 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:40:59.559808 11896 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:40:59.559810 11896 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:40:59.559815 11896 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:40:59.559824 11896 net.cpp:124] Setting up pool1\n",
      "I0430 09:40:59.559829 11896 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:40:59.559831 11896 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:40:59.559835 11896 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:40:59.559840 11896 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:40:59.559844 11896 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:40:59.559847 11896 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:40:59.559854 11896 net.cpp:124] Setting up norm1\n",
      "I0430 09:40:59.559859 11896 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:40:59.559860 11896 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:40:59.559864 11896 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:40:59.559870 11896 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:40:59.559871 11896 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:40:59.559876 11896 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:40:59.560247 11896 net.cpp:124] Setting up conv2\n",
      "I0430 09:40:59.560256 11896 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:40:59.560259 11896 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:40:59.560267 11896 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:40:59.560272 11896 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:40:59.560276 11896 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:40:59.560281 11896 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:40:59.560286 11896 net.cpp:124] Setting up relu2\n",
      "I0430 09:40:59.560290 11896 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:40:59.560292 11896 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:40:59.560295 11896 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:40:59.560300 11896 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:40:59.560303 11896 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:40:59.560307 11896 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:40:59.560314 11896 net.cpp:124] Setting up pool2\n",
      "I0430 09:40:59.560318 11896 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:40:59.560322 11896 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:40:59.560324 11896 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:40:59.560334 11896 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:40:59.560338 11896 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:40:59.560343 11896 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:40:59.560348 11896 net.cpp:124] Setting up norm2\n",
      "I0430 09:40:59.560353 11896 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:40:59.560354 11896 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:40:59.560358 11896 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:40:59.560364 11896 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:40:59.560366 11896 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:40:59.560370 11896 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:40:59.561115 11896 net.cpp:124] Setting up conv3\n",
      "I0430 09:40:59.561132 11896 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:40:59.561136 11896 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:40:59.561146 11896 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:40:59.561156 11896 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:40:59.561158 11896 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:40:59.561164 11896 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:40:59.561172 11896 net.cpp:124] Setting up relu3\n",
      "I0430 09:40:59.561175 11896 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:40:59.561178 11896 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:40:59.561182 11896 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:40:59.561187 11896 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:40:59.561190 11896 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:40:59.561195 11896 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:40:59.561971 11896 net.cpp:124] Setting up conv4\n",
      "I0430 09:40:59.561985 11896 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:40:59.561990 11896 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:40:59.561995 11896 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:40:59.562005 11896 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:40:59.562008 11896 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:40:59.562014 11896 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:40:59.562021 11896 net.cpp:124] Setting up relu4\n",
      "I0430 09:40:59.562024 11896 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:40:59.562027 11896 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:40:59.562031 11896 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:40:59.562036 11896 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:40:59.562039 11896 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:40:59.562043 11896 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:40:59.562535 11896 net.cpp:124] Setting up conv5\n",
      "I0430 09:40:59.562543 11896 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:40:59.562547 11896 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:40:59.562559 11896 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:40:59.562566 11896 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:40:59.562568 11896 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:40:59.562573 11896 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:40:59.562578 11896 net.cpp:124] Setting up relu5\n",
      "I0430 09:40:59.562582 11896 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:40:59.562585 11896 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:40:59.562588 11896 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:40:59.562594 11896 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:40:59.562597 11896 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:40:59.562602 11896 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:40:59.562610 11896 net.cpp:124] Setting up pool5\n",
      "I0430 09:40:59.562614 11896 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:40:59.562618 11896 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:40:59.562620 11896 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:40:59.562628 11896 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:40:59.562631 11896 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:40:59.562636 11896 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:40:59.584918 11896 net.cpp:124] Setting up fc6\n",
      "I0430 09:40:59.584947 11896 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:40:59.584951 11896 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:40:59.584961 11896 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:40:59.584970 11896 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:40:59.584974 11896 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:40:59.584980 11896 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:40:59.584987 11896 net.cpp:124] Setting up relu6\n",
      "I0430 09:40:59.584991 11896 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:40:59.584993 11896 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:40:59.584995 11896 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:40:59.585003 11896 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:40:59.585007 11896 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:40:59.585011 11896 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:40:59.585019 11896 net.cpp:124] Setting up drop6\n",
      "I0430 09:40:59.585023 11896 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:40:59.585027 11896 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:40:59.585031 11896 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:40:59.585039 11896 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:40:59.585043 11896 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:40:59.585049 11896 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:40:59.595798 11896 net.cpp:124] Setting up fc7\n",
      "I0430 09:40:59.595826 11896 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:40:59.595831 11896 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:40:59.595842 11896 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:40:59.595852 11896 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:40:59.595856 11896 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:40:59.595861 11896 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:40:59.595870 11896 net.cpp:124] Setting up relu7\n",
      "I0430 09:40:59.595873 11896 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:40:59.595875 11896 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:40:59.595877 11896 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:40:59.595885 11896 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:40:59.595887 11896 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:40:59.595893 11896 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:40:59.595899 11896 net.cpp:124] Setting up drop7\n",
      "I0430 09:40:59.595902 11896 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:40:59.595904 11896 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:40:59.595907 11896 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:40:59.595912 11896 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:40:59.595916 11896 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:40:59.595919 11896 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:40:59.597007 11896 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:40:59.597024 11896 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:40:59.597031 11896 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:40:59.597039 11896 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:40:59.597043 11896 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:40:59.597045 11896 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:40:59.597048 11896 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:40:59.597050 11896 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:40:59.597053 11896 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:40:59.597056 11896 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:40:59.597059 11896 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:40:59.597061 11896 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:40:59.597064 11896 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:40:59.597066 11896 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:40:59.597069 11896 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:40:59.597074 11896 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:40:59.597076 11896 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:40:59.597080 11896 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:40:59.597086 11896 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:40:59.597090 11896 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:40:59.597095 11896 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:40:59.597097 11896 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:40:59.597100 11896 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:40:59.597103 11896 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:40:59.597105 11896 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:40:59.597108 11896 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:40:59.597110 11896 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:40:59.597124 11896 net.cpp:257] Network initialization done.\n",
      "I0430 09:40:59.685024 11896 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:40:59.784638 11896 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:40:59.785464 11896 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:40:59.785471 11896 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:40:59.785476 11896 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/443224.jpg'}, '/tmp/tmpMnIYeY.mat')\n",
      "Processed 3314 windows in 377.522 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.037 s.\n",
      "prediction    [-2.39148, -1.93234, -2.25003, -1.81337, -1.98...\n",
      "ymin                                                    174.492\n",
      "xmin                                                    153.846\n",
      "ymax                                                      500.5\n",
      "xmax                                                    333.334\n",
      "Name: /home/ambika/INF_project/data/horse/443224.jpg, dtype: object\n",
      "prediction    [-1.7611, -1.69818, -1.93842, -2.09489, -1.923...\n",
      "ymin                                                     78.588\n",
      "xmin                                                     98.568\n",
      "ymax                                                    269.398\n",
      "xmax                                                    226.774\n",
      "Name: /home/ambika/INF_project/data/horse/443224.jpg, dtype: object\n",
      "person\n",
      "153.846\t174.492\t333.334\t500.5\n",
      "saxophone\n",
      "98.568\t78.588\t226.774\t269.398\n",
      "443224\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:47:18.905475 12128 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:47:18.905499 12128 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:47:18.905503 12128 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:47:18.906653 12128 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:47:18.906790 12128 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:47:18.906798 12128 net.cpp:86] Creating Layer data\n",
      "I0430 09:47:18.906806 12128 net.cpp:382] data -> data\n",
      "I0430 09:47:18.906826 12128 net.cpp:124] Setting up data\n",
      "I0430 09:47:18.906831 12128 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:47:18.906834 12128 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:47:18.906837 12128 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:47:18.906844 12128 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:47:18.906848 12128 net.cpp:408] conv1 <- data\n",
      "I0430 09:47:18.906854 12128 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:47:18.906949 12128 net.cpp:124] Setting up conv1\n",
      "I0430 09:47:18.906955 12128 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:47:18.906957 12128 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:47:18.906966 12128 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:47:18.906972 12128 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:47:18.906975 12128 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:47:18.906978 12128 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:47:18.906982 12128 net.cpp:124] Setting up relu1\n",
      "I0430 09:47:18.906985 12128 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:47:18.906988 12128 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:47:18.906991 12128 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:47:18.906994 12128 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:47:18.906996 12128 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:47:18.906999 12128 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:47:18.907006 12128 net.cpp:124] Setting up pool1\n",
      "I0430 09:47:18.907009 12128 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:47:18.907011 12128 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:47:18.907014 12128 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:47:18.907018 12128 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:47:18.907021 12128 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:47:18.907024 12128 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:47:18.907029 12128 net.cpp:124] Setting up norm1\n",
      "I0430 09:47:18.907032 12128 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:47:18.907035 12128 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:47:18.907037 12128 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:47:18.907042 12128 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:47:18.907043 12128 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:47:18.907047 12128 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:47:18.907518 12128 net.cpp:124] Setting up conv2\n",
      "I0430 09:47:18.907527 12128 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:47:18.907532 12128 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:47:18.907541 12128 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:47:18.907548 12128 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:47:18.907552 12128 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:47:18.907558 12128 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:47:18.907564 12128 net.cpp:124] Setting up relu2\n",
      "I0430 09:47:18.907570 12128 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:47:18.907574 12128 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:47:18.907578 12128 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:47:18.907583 12128 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:47:18.907588 12128 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:47:18.907593 12128 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:47:18.907603 12128 net.cpp:124] Setting up pool2\n",
      "I0430 09:47:18.907608 12128 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:47:18.907613 12128 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:47:18.907616 12128 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:47:18.907624 12128 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:47:18.907629 12128 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:47:18.907634 12128 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:47:18.907642 12128 net.cpp:124] Setting up norm2\n",
      "I0430 09:47:18.907649 12128 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:47:18.907652 12128 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:47:18.907656 12128 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:47:18.907662 12128 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:47:18.907666 12128 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:47:18.907672 12128 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:47:18.908515 12128 net.cpp:124] Setting up conv3\n",
      "I0430 09:47:18.908529 12128 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:47:18.908531 12128 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:47:18.908538 12128 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:47:18.908545 12128 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:47:18.908546 12128 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:47:18.908551 12128 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:47:18.908556 12128 net.cpp:124] Setting up relu3\n",
      "I0430 09:47:18.908560 12128 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:47:18.908562 12128 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:47:18.908565 12128 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:47:18.908571 12128 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:47:18.908572 12128 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:47:18.908576 12128 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:47:18.909349 12128 net.cpp:124] Setting up conv4\n",
      "I0430 09:47:18.909363 12128 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:47:18.909368 12128 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:47:18.909373 12128 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:47:18.909382 12128 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:47:18.909386 12128 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:47:18.909391 12128 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:47:18.909399 12128 net.cpp:124] Setting up relu4\n",
      "I0430 09:47:18.909404 12128 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:47:18.909407 12128 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:47:18.909411 12128 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:47:18.909420 12128 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:47:18.909423 12128 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:47:18.909428 12128 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:47:18.910198 12128 net.cpp:124] Setting up conv5\n",
      "I0430 09:47:18.910223 12128 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:47:18.910226 12128 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:47:18.910243 12128 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:47:18.910251 12128 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:47:18.910255 12128 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:47:18.910262 12128 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:47:18.910270 12128 net.cpp:124] Setting up relu5\n",
      "I0430 09:47:18.910274 12128 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:47:18.910277 12128 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:47:18.910281 12128 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:47:18.910286 12128 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:47:18.910290 12128 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:47:18.910295 12128 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:47:18.910302 12128 net.cpp:124] Setting up pool5\n",
      "I0430 09:47:18.910307 12128 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:47:18.910310 12128 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:47:18.910313 12128 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:47:18.910322 12128 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:47:18.910326 12128 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:47:18.910329 12128 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:47:18.937052 12128 net.cpp:124] Setting up fc6\n",
      "I0430 09:47:18.937078 12128 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:47:18.937083 12128 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:47:18.937091 12128 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:47:18.937100 12128 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:47:18.937103 12128 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:47:18.937108 12128 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:47:18.937114 12128 net.cpp:124] Setting up relu6\n",
      "I0430 09:47:18.937117 12128 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:47:18.937119 12128 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:47:18.937120 12128 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:47:18.937124 12128 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:47:18.937125 12128 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:47:18.937129 12128 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:47:18.937132 12128 net.cpp:124] Setting up drop6\n",
      "I0430 09:47:18.937134 12128 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:47:18.937150 12128 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:47:18.937151 12128 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:47:18.937155 12128 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:47:18.937157 12128 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:47:18.937162 12128 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:47:18.947511 12128 net.cpp:124] Setting up fc7\n",
      "I0430 09:47:18.947538 12128 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:47:18.947543 12128 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:47:18.947551 12128 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:47:18.947561 12128 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:47:18.947564 12128 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:47:18.947568 12128 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:47:18.947574 12128 net.cpp:124] Setting up relu7\n",
      "I0430 09:47:18.947576 12128 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:47:18.947578 12128 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:47:18.947580 12128 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:47:18.947584 12128 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:47:18.947587 12128 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:47:18.947589 12128 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:47:18.947593 12128 net.cpp:124] Setting up drop7\n",
      "I0430 09:47:18.947597 12128 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:47:18.947597 12128 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:47:18.947599 12128 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:47:18.947603 12128 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:47:18.947605 12128 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:47:18.947607 12128 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:47:18.948284 12128 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:47:18.948294 12128 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:47:18.948298 12128 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:47:18.948305 12128 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:47:18.948308 12128 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:47:18.948310 12128 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:47:18.948312 12128 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:47:18.948314 12128 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:47:18.948317 12128 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:47:18.948318 12128 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:47:18.948321 12128 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:47:18.948334 12128 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:47:18.948336 12128 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:47:18.948339 12128 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:47:18.948343 12128 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:47:18.948345 12128 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:47:18.948348 12128 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:47:18.948350 12128 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:47:18.948354 12128 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:47:18.948355 12128 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:47:18.948359 12128 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:47:18.948361 12128 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:47:18.948364 12128 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:47:18.948366 12128 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:47:18.948369 12128 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:47:18.948371 12128 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:47:18.948374 12128 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:47:18.948385 12128 net.cpp:257] Network initialization done.\n",
      "I0430 09:47:19.043481 12128 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:47:19.144454 12128 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:47:19.145489 12128 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:47:19.145499 12128 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:47:19.145503 12128 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/379837.jpg'}, '/tmp/tmps2VHaq.mat')\n",
      "Processed 1671 windows in 195.024 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.31595, -2.3944, -1.98059, -2.37211, -1.986...\n",
      "ymin                                                        136\n",
      "xmin                                                         52\n",
      "ymax                                                        331\n",
      "xmax                                                        181\n",
      "Name: /home/ambika/INF_project/data/person/379837.jpg, dtype: object\n",
      "prediction    [-2.32599, -2.39391, -2.23281, -1.79533, -2.46...\n",
      "ymin                                                        238\n",
      "xmin                                                         52\n",
      "ymax                                                        334\n",
      "xmax                                                        231\n",
      "Name: /home/ambika/INF_project/data/person/379837.jpg, dtype: object\n",
      "person\n",
      "52\t136\t181\t331\n",
      "table\n",
      "52\t238\t231\t334\n",
      "379837\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:50:35.669644 12302 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:50:35.669672 12302 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:50:35.669675 12302 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:50:35.670830 12302 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:50:35.671039 12302 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:50:35.671051 12302 net.cpp:86] Creating Layer data\n",
      "I0430 09:50:35.671056 12302 net.cpp:382] data -> data\n",
      "I0430 09:50:35.671064 12302 net.cpp:124] Setting up data\n",
      "I0430 09:50:35.671069 12302 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:50:35.671072 12302 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:50:35.671075 12302 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:50:35.671080 12302 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:50:35.671083 12302 net.cpp:408] conv1 <- data\n",
      "I0430 09:50:35.671087 12302 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:50:35.671144 12302 net.cpp:124] Setting up conv1\n",
      "I0430 09:50:35.671147 12302 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:50:35.671149 12302 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:50:35.671156 12302 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:50:35.671161 12302 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:50:35.671164 12302 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:50:35.671167 12302 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:50:35.671171 12302 net.cpp:124] Setting up relu1\n",
      "I0430 09:50:35.671175 12302 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:50:35.671177 12302 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:50:35.671180 12302 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:50:35.671183 12302 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:50:35.671185 12302 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:50:35.671190 12302 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:50:35.671195 12302 net.cpp:124] Setting up pool1\n",
      "I0430 09:50:35.671200 12302 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:50:35.671205 12302 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:50:35.671216 12302 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:50:35.671221 12302 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:50:35.671226 12302 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:50:35.671231 12302 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:50:35.671239 12302 net.cpp:124] Setting up norm1\n",
      "I0430 09:50:35.671244 12302 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:50:35.671248 12302 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:50:35.671252 12302 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:50:35.671257 12302 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:50:35.671258 12302 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:50:35.671262 12302 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:50:35.671617 12302 net.cpp:124] Setting up conv2\n",
      "I0430 09:50:35.671624 12302 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:50:35.671627 12302 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:50:35.671638 12302 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:50:35.671643 12302 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:50:35.671646 12302 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:50:35.671649 12302 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:50:35.671654 12302 net.cpp:124] Setting up relu2\n",
      "I0430 09:50:35.671658 12302 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:50:35.671659 12302 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:50:35.671663 12302 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:50:35.671665 12302 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:50:35.671669 12302 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:50:35.671671 12302 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:50:35.671677 12302 net.cpp:124] Setting up pool2\n",
      "I0430 09:50:35.671680 12302 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:50:35.671682 12302 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:50:35.671684 12302 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:50:35.671690 12302 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:50:35.671692 12302 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:50:35.671695 12302 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:50:35.671700 12302 net.cpp:124] Setting up norm2\n",
      "I0430 09:50:35.671703 12302 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:50:35.671705 12302 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:50:35.671708 12302 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:50:35.671712 12302 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:50:35.671715 12302 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:50:35.671717 12302 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:50:35.672411 12302 net.cpp:124] Setting up conv3\n",
      "I0430 09:50:35.672422 12302 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:50:35.672426 12302 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:50:35.672436 12302 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:50:35.672443 12302 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:50:35.672447 12302 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:50:35.672451 12302 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:50:35.672456 12302 net.cpp:124] Setting up relu3\n",
      "I0430 09:50:35.672458 12302 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:50:35.672461 12302 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:50:35.672463 12302 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:50:35.672469 12302 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:50:35.672472 12302 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:50:35.672475 12302 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:50:35.673228 12302 net.cpp:124] Setting up conv4\n",
      "I0430 09:50:35.673238 12302 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:50:35.673241 12302 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:50:35.673249 12302 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:50:35.673255 12302 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:50:35.673259 12302 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:50:35.673262 12302 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:50:35.673266 12302 net.cpp:124] Setting up relu4\n",
      "I0430 09:50:35.673270 12302 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:50:35.673272 12302 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:50:35.673274 12302 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:50:35.673280 12302 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:50:35.673282 12302 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:50:35.673287 12302 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:50:35.673811 12302 net.cpp:124] Setting up conv5\n",
      "I0430 09:50:35.673820 12302 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:50:35.673825 12302 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:50:35.673836 12302 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:50:35.673843 12302 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:50:35.673847 12302 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:50:35.673852 12302 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:50:35.673858 12302 net.cpp:124] Setting up relu5\n",
      "I0430 09:50:35.673862 12302 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:50:35.673866 12302 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:50:35.673869 12302 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:50:35.673876 12302 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:50:35.673878 12302 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:50:35.673883 12302 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:50:35.673892 12302 net.cpp:124] Setting up pool5\n",
      "I0430 09:50:35.673897 12302 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:50:35.673902 12302 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:50:35.673904 12302 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:50:35.673915 12302 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:50:35.673919 12302 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:50:35.673924 12302 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:50:35.696120 12302 net.cpp:124] Setting up fc6\n",
      "I0430 09:50:35.696144 12302 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:50:35.696149 12302 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:50:35.696158 12302 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:50:35.696166 12302 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:50:35.696168 12302 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:50:35.696174 12302 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:50:35.696180 12302 net.cpp:124] Setting up relu6\n",
      "I0430 09:50:35.696182 12302 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:50:35.696184 12302 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:50:35.696187 12302 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:50:35.696192 12302 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:50:35.696192 12302 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:50:35.696195 12302 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:50:35.696198 12302 net.cpp:124] Setting up drop6\n",
      "I0430 09:50:35.696202 12302 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:50:35.696216 12302 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:50:35.696218 12302 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:50:35.696223 12302 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:50:35.696224 12302 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:50:35.696228 12302 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:50:35.706578 12302 net.cpp:124] Setting up fc7\n",
      "I0430 09:50:35.706600 12302 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:50:35.706605 12302 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:50:35.706614 12302 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:50:35.706620 12302 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:50:35.706624 12302 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:50:35.706629 12302 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:50:35.706634 12302 net.cpp:124] Setting up relu7\n",
      "I0430 09:50:35.706637 12302 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:50:35.706639 12302 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:50:35.706640 12302 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:50:35.706645 12302 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:50:35.706646 12302 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:50:35.706648 12302 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:50:35.706652 12302 net.cpp:124] Setting up drop7\n",
      "I0430 09:50:35.706656 12302 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:50:35.706658 12302 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:50:35.706660 12302 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:50:35.706665 12302 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:50:35.706667 12302 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:50:35.706671 12302 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:50:35.707581 12302 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:50:35.707590 12302 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:50:35.707594 12302 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:50:35.707599 12302 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:50:35.707602 12302 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:50:35.707604 12302 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:50:35.707605 12302 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:50:35.707607 12302 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:50:35.707609 12302 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:50:35.707612 12302 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:50:35.707613 12302 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:50:35.707615 12302 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:50:35.707618 12302 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:50:35.707622 12302 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:50:35.707624 12302 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:50:35.707626 12302 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:50:35.707629 12302 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:50:35.707633 12302 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:50:35.707635 12302 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:50:35.707638 12302 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:50:35.707640 12302 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:50:35.707643 12302 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:50:35.707645 12302 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:50:35.707649 12302 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:50:35.707653 12302 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:50:35.707654 12302 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:50:35.707657 12302 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:50:35.707670 12302 net.cpp:257] Network initialization done.\n",
      "I0430 09:50:35.805567 12302 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:50:35.921236 12302 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:50:35.922183 12302 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:50:35.922191 12302 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:50:35.922197 12302 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/258311.jpg'}, '/tmp/tmp9rPbtp.mat')\n",
      "Processed 3189 windows in 363.721 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.040 s.\n",
      "prediction    [-1.88714, -1.45051, -1.78905, -2.07032, -1.77...\n",
      "ymin                                                        240\n",
      "xmin                                                        401\n",
      "ymax                                                        298\n",
      "xmax                                                        475\n",
      "Name: /home/ambika/INF_project/data/train/258311.jpg, dtype: object\n",
      "prediction    [-2.19289, -1.02666, -2.25356, -2.15569, -1.59...\n",
      "ymin                                                        105\n",
      "xmin                                                         61\n",
      "ymax                                                        364\n",
      "xmax                                                        404\n",
      "Name: /home/ambika/INF_project/data/train/258311.jpg, dtype: object\n",
      "car\n",
      "401\t240\t475\t298\n",
      "train\n",
      "61\t105\t404\t364\n",
      "258311\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:56:41.336868 12527 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:56:41.336901 12527 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:56:41.336905 12527 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:56:41.338569 12527 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:56:41.338701 12527 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:56:41.338716 12527 net.cpp:86] Creating Layer data\n",
      "I0430 09:56:41.338721 12527 net.cpp:382] data -> data\n",
      "I0430 09:56:41.338737 12527 net.cpp:124] Setting up data\n",
      "I0430 09:56:41.338743 12527 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:56:41.338747 12527 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:56:41.338752 12527 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:56:41.338759 12527 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:56:41.338763 12527 net.cpp:408] conv1 <- data\n",
      "I0430 09:56:41.338769 12527 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:56:41.338850 12527 net.cpp:124] Setting up conv1\n",
      "I0430 09:56:41.338858 12527 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:56:41.338861 12527 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:56:41.338872 12527 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:56:41.338879 12527 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:56:41.338882 12527 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:56:41.338888 12527 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:56:41.338894 12527 net.cpp:124] Setting up relu1\n",
      "I0430 09:56:41.338899 12527 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:56:41.338903 12527 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:56:41.338907 12527 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:56:41.338912 12527 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:56:41.338917 12527 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:56:41.338922 12527 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:56:41.338930 12527 net.cpp:124] Setting up pool1\n",
      "I0430 09:56:41.338937 12527 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:56:41.338940 12527 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:56:41.338943 12527 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:56:41.338950 12527 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:56:41.338953 12527 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:56:41.338958 12527 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:56:41.338966 12527 net.cpp:124] Setting up norm1\n",
      "I0430 09:56:41.338971 12527 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:56:41.338974 12527 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:56:41.338979 12527 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:56:41.338984 12527 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:56:41.338987 12527 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:56:41.338992 12527 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:56:41.339505 12527 net.cpp:124] Setting up conv2\n",
      "I0430 09:56:41.339515 12527 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:56:41.339519 12527 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:56:41.339529 12527 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:56:41.339537 12527 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:56:41.339541 12527 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:56:41.339546 12527 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:56:41.339552 12527 net.cpp:124] Setting up relu2\n",
      "I0430 09:56:41.339557 12527 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:56:41.339561 12527 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:56:41.339565 12527 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:56:41.339570 12527 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:56:41.339573 12527 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:56:41.339579 12527 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:56:41.339586 12527 net.cpp:124] Setting up pool2\n",
      "I0430 09:56:41.339592 12527 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:56:41.339596 12527 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:56:41.339599 12527 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:56:41.339607 12527 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:56:41.339612 12527 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:56:41.339617 12527 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:56:41.339623 12527 net.cpp:124] Setting up norm2\n",
      "I0430 09:56:41.339628 12527 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:56:41.339632 12527 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:56:41.339635 12527 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:56:41.339642 12527 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:56:41.339648 12527 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:56:41.339654 12527 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:56:41.340919 12527 net.cpp:124] Setting up conv3\n",
      "I0430 09:56:41.340934 12527 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:56:41.340937 12527 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:56:41.340947 12527 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:56:41.340957 12527 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:56:41.340961 12527 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:56:41.340970 12527 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:56:41.340978 12527 net.cpp:124] Setting up relu3\n",
      "I0430 09:56:41.340983 12527 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:56:41.340986 12527 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:56:41.340991 12527 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:56:41.340998 12527 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:56:41.341002 12527 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:56:41.341007 12527 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:56:41.341615 12527 net.cpp:124] Setting up conv4\n",
      "I0430 09:56:41.341625 12527 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:56:41.341629 12527 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:56:41.341636 12527 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:56:41.341642 12527 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:56:41.341645 12527 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:56:41.341650 12527 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:56:41.341657 12527 net.cpp:124] Setting up relu4\n",
      "I0430 09:56:41.341662 12527 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:56:41.341665 12527 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:56:41.341670 12527 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:56:41.341677 12527 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:56:41.341681 12527 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:56:41.341686 12527 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:56:41.342339 12527 net.cpp:124] Setting up conv5\n",
      "I0430 09:56:41.342347 12527 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:56:41.342351 12527 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:56:41.342363 12527 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:56:41.342370 12527 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:56:41.342373 12527 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:56:41.342380 12527 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:56:41.342386 12527 net.cpp:124] Setting up relu5\n",
      "I0430 09:56:41.342391 12527 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:56:41.342394 12527 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:56:41.342397 12527 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:56:41.342403 12527 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:56:41.342406 12527 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:56:41.342412 12527 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:56:41.342423 12527 net.cpp:124] Setting up pool5\n",
      "I0430 09:56:41.342428 12527 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:56:41.342432 12527 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:56:41.342437 12527 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:56:41.342445 12527 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:56:41.342449 12527 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:56:41.342455 12527 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:56:41.371836 12527 net.cpp:124] Setting up fc6\n",
      "I0430 09:56:41.371865 12527 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:56:41.371867 12527 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:56:41.371877 12527 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:56:41.371888 12527 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:56:41.371892 12527 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:56:41.371901 12527 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:56:41.371912 12527 net.cpp:124] Setting up relu6\n",
      "I0430 09:56:41.371917 12527 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:56:41.371919 12527 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:56:41.371934 12527 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:56:41.371942 12527 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:56:41.371947 12527 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:56:41.371951 12527 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:56:41.371959 12527 net.cpp:124] Setting up drop6\n",
      "I0430 09:56:41.371963 12527 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:56:41.371968 12527 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:56:41.371970 12527 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:56:41.371978 12527 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:56:41.371980 12527 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:56:41.371987 12527 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:56:41.384531 12527 net.cpp:124] Setting up fc7\n",
      "I0430 09:56:41.384558 12527 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:56:41.384563 12527 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:56:41.384574 12527 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:56:41.384584 12527 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:56:41.384590 12527 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:56:41.384596 12527 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:56:41.384605 12527 net.cpp:124] Setting up relu7\n",
      "I0430 09:56:41.384610 12527 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:56:41.384613 12527 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:56:41.384618 12527 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:56:41.384624 12527 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:56:41.384626 12527 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:56:41.384632 12527 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:56:41.384639 12527 net.cpp:124] Setting up drop7\n",
      "I0430 09:56:41.384644 12527 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:56:41.384647 12527 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:56:41.384651 12527 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:56:41.384657 12527 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:56:41.384661 12527 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:56:41.384666 12527 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:56:41.386034 12527 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:56:41.386060 12527 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:56:41.386065 12527 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:56:41.386077 12527 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:56:41.386083 12527 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:56:41.386087 12527 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:56:41.386091 12527 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:56:41.386096 12527 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:56:41.386099 12527 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:56:41.386103 12527 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:56:41.386107 12527 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:56:41.386111 12527 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:56:41.386116 12527 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:56:41.386121 12527 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:56:41.386124 12527 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:56:41.386129 12527 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:56:41.386133 12527 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:56:41.386137 12527 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:56:41.386142 12527 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:56:41.386144 12527 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:56:41.386147 12527 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:56:41.386152 12527 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:56:41.386157 12527 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:56:41.386162 12527 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:56:41.386165 12527 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:56:41.386169 12527 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:56:41.386173 12527 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:56:41.386190 12527 net.cpp:257] Network initialization done.\n",
      "I0430 09:56:41.486637 12527 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:56:41.587198 12527 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:56:41.588343 12527 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:56:41.588352 12527 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:56:41.588356 12527 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/426840.jpg'}, '/tmp/tmpVRjEWh.mat')\n",
      "Processed 909 windows in 108.032 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-2.62387, 2.87029, -2.29478, -1.91078, -1.900...\n",
      "ymin                                                        118\n",
      "xmin                                                        112\n",
      "ymax                                                        236\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/airplane/426840.jpg, dtype: object\n",
      "prediction    [-2.13401, -1.81247, -2.22869, -0.948675, -1.9...\n",
      "ymin                                                        323\n",
      "xmin                                                        105\n",
      "ymax                                                        358\n",
      "xmax                                                        150\n",
      "Name: /home/ambika/INF_project/data/airplane/426840.jpg, dtype: object\n",
      "airplane\n",
      "112\t118\t500\t236\n",
      "bird\n",
      "105\t323\t150\t358\n",
      "426840\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 09:58:31.103888 12665 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 09:58:31.103911 12665 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 09:58:31.103915 12665 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 09:58:31.105057 12665 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 09:58:31.105235 12665 layer_factory.hpp:77] Creating layer data\n",
      "I0430 09:58:31.105245 12665 net.cpp:86] Creating Layer data\n",
      "I0430 09:58:31.105252 12665 net.cpp:382] data -> data\n",
      "I0430 09:58:31.105267 12665 net.cpp:124] Setting up data\n",
      "I0430 09:58:31.105275 12665 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 09:58:31.105278 12665 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 09:58:31.105283 12665 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 09:58:31.105290 12665 net.cpp:86] Creating Layer conv1\n",
      "I0430 09:58:31.105294 12665 net.cpp:408] conv1 <- data\n",
      "I0430 09:58:31.105299 12665 net.cpp:382] conv1 -> conv1\n",
      "I0430 09:58:31.105361 12665 net.cpp:124] Setting up conv1\n",
      "I0430 09:58:31.105366 12665 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:58:31.105370 12665 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 09:58:31.105377 12665 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 09:58:31.105382 12665 net.cpp:86] Creating Layer relu1\n",
      "I0430 09:58:31.105386 12665 net.cpp:408] relu1 <- conv1\n",
      "I0430 09:58:31.105391 12665 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 09:58:31.105396 12665 net.cpp:124] Setting up relu1\n",
      "I0430 09:58:31.105399 12665 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 09:58:31.105402 12665 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 09:58:31.105406 12665 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 09:58:31.105410 12665 net.cpp:86] Creating Layer pool1\n",
      "I0430 09:58:31.105412 12665 net.cpp:408] pool1 <- conv1\n",
      "I0430 09:58:31.105417 12665 net.cpp:382] pool1 -> pool1\n",
      "I0430 09:58:31.105424 12665 net.cpp:124] Setting up pool1\n",
      "I0430 09:58:31.105428 12665 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:58:31.105432 12665 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 09:58:31.105434 12665 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 09:58:31.105440 12665 net.cpp:86] Creating Layer norm1\n",
      "I0430 09:58:31.105443 12665 net.cpp:408] norm1 <- pool1\n",
      "I0430 09:58:31.105448 12665 net.cpp:382] norm1 -> norm1\n",
      "I0430 09:58:31.105455 12665 net.cpp:124] Setting up norm1\n",
      "I0430 09:58:31.105460 12665 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 09:58:31.105463 12665 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 09:58:31.105468 12665 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 09:58:31.105473 12665 net.cpp:86] Creating Layer conv2\n",
      "I0430 09:58:31.105475 12665 net.cpp:408] conv2 <- norm1\n",
      "I0430 09:58:31.105480 12665 net.cpp:382] conv2 -> conv2\n",
      "I0430 09:58:31.105828 12665 net.cpp:124] Setting up conv2\n",
      "I0430 09:58:31.105834 12665 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:58:31.105839 12665 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 09:58:31.105846 12665 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 09:58:31.105851 12665 net.cpp:86] Creating Layer relu2\n",
      "I0430 09:58:31.105854 12665 net.cpp:408] relu2 <- conv2\n",
      "I0430 09:58:31.105859 12665 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 09:58:31.105864 12665 net.cpp:124] Setting up relu2\n",
      "I0430 09:58:31.105867 12665 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 09:58:31.105870 12665 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 09:58:31.105873 12665 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 09:58:31.105880 12665 net.cpp:86] Creating Layer pool2\n",
      "I0430 09:58:31.105882 12665 net.cpp:408] pool2 <- conv2\n",
      "I0430 09:58:31.105886 12665 net.cpp:382] pool2 -> pool2\n",
      "I0430 09:58:31.105893 12665 net.cpp:124] Setting up pool2\n",
      "I0430 09:58:31.105897 12665 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:58:31.105901 12665 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 09:58:31.105903 12665 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 09:58:31.105908 12665 net.cpp:86] Creating Layer norm2\n",
      "I0430 09:58:31.105911 12665 net.cpp:408] norm2 <- pool2\n",
      "I0430 09:58:31.105916 12665 net.cpp:382] norm2 -> norm2\n",
      "I0430 09:58:31.105921 12665 net.cpp:124] Setting up norm2\n",
      "I0430 09:58:31.105926 12665 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:58:31.105927 12665 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 09:58:31.105931 12665 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 09:58:31.105937 12665 net.cpp:86] Creating Layer conv3\n",
      "I0430 09:58:31.105939 12665 net.cpp:408] conv3 <- norm2\n",
      "I0430 09:58:31.105944 12665 net.cpp:382] conv3 -> conv3\n",
      "I0430 09:58:31.106621 12665 net.cpp:124] Setting up conv3\n",
      "I0430 09:58:31.106631 12665 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:58:31.106634 12665 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 09:58:31.106643 12665 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 09:58:31.106652 12665 net.cpp:86] Creating Layer relu3\n",
      "I0430 09:58:31.106655 12665 net.cpp:408] relu3 <- conv3\n",
      "I0430 09:58:31.106663 12665 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 09:58:31.106675 12665 net.cpp:124] Setting up relu3\n",
      "I0430 09:58:31.106680 12665 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:58:31.106683 12665 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 09:58:31.106686 12665 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 09:58:31.106693 12665 net.cpp:86] Creating Layer conv4\n",
      "I0430 09:58:31.106694 12665 net.cpp:408] conv4 <- conv3\n",
      "I0430 09:58:31.106699 12665 net.cpp:382] conv4 -> conv4\n",
      "I0430 09:58:31.107427 12665 net.cpp:124] Setting up conv4\n",
      "I0430 09:58:31.107439 12665 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:58:31.107442 12665 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 09:58:31.107448 12665 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 09:58:31.107455 12665 net.cpp:86] Creating Layer relu4\n",
      "I0430 09:58:31.107460 12665 net.cpp:408] relu4 <- conv4\n",
      "I0430 09:58:31.107465 12665 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 09:58:31.107470 12665 net.cpp:124] Setting up relu4\n",
      "I0430 09:58:31.107473 12665 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 09:58:31.107476 12665 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 09:58:31.107480 12665 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 09:58:31.107486 12665 net.cpp:86] Creating Layer conv5\n",
      "I0430 09:58:31.107488 12665 net.cpp:408] conv5 <- conv4\n",
      "I0430 09:58:31.107493 12665 net.cpp:382] conv5 -> conv5\n",
      "I0430 09:58:31.108032 12665 net.cpp:124] Setting up conv5\n",
      "I0430 09:58:31.108043 12665 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:58:31.108047 12665 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 09:58:31.108060 12665 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 09:58:31.108067 12665 net.cpp:86] Creating Layer relu5\n",
      "I0430 09:58:31.108069 12665 net.cpp:408] relu5 <- conv5\n",
      "I0430 09:58:31.108075 12665 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 09:58:31.108080 12665 net.cpp:124] Setting up relu5\n",
      "I0430 09:58:31.108084 12665 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 09:58:31.108088 12665 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 09:58:31.108090 12665 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 09:58:31.108095 12665 net.cpp:86] Creating Layer pool5\n",
      "I0430 09:58:31.108098 12665 net.cpp:408] pool5 <- conv5\n",
      "I0430 09:58:31.108103 12665 net.cpp:382] pool5 -> pool5\n",
      "I0430 09:58:31.108110 12665 net.cpp:124] Setting up pool5\n",
      "I0430 09:58:31.108115 12665 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 09:58:31.108117 12665 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 09:58:31.108120 12665 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 09:58:31.108129 12665 net.cpp:86] Creating Layer fc6\n",
      "I0430 09:58:31.108131 12665 net.cpp:408] fc6 <- pool5\n",
      "I0430 09:58:31.108136 12665 net.cpp:382] fc6 -> fc6\n",
      "I0430 09:58:31.133236 12665 net.cpp:124] Setting up fc6\n",
      "I0430 09:58:31.133289 12665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:58:31.133298 12665 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 09:58:31.133327 12665 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 09:58:31.133374 12665 net.cpp:86] Creating Layer relu6\n",
      "I0430 09:58:31.133388 12665 net.cpp:408] relu6 <- fc6\n",
      "I0430 09:58:31.133400 12665 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 09:58:31.133415 12665 net.cpp:124] Setting up relu6\n",
      "I0430 09:58:31.133421 12665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:58:31.133425 12665 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 09:58:31.133430 12665 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 09:58:31.133438 12665 net.cpp:86] Creating Layer drop6\n",
      "I0430 09:58:31.133442 12665 net.cpp:408] drop6 <- fc6\n",
      "I0430 09:58:31.133446 12665 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 09:58:31.133452 12665 net.cpp:124] Setting up drop6\n",
      "I0430 09:58:31.133455 12665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:58:31.133457 12665 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 09:58:31.133460 12665 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 09:58:31.133468 12665 net.cpp:86] Creating Layer fc7\n",
      "I0430 09:58:31.133471 12665 net.cpp:408] fc7 <- fc6\n",
      "I0430 09:58:31.133476 12665 net.cpp:382] fc7 -> fc7\n",
      "I0430 09:58:31.143801 12665 net.cpp:124] Setting up fc7\n",
      "I0430 09:58:31.143821 12665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:58:31.143826 12665 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 09:58:31.143836 12665 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 09:58:31.143846 12665 net.cpp:86] Creating Layer relu7\n",
      "I0430 09:58:31.143851 12665 net.cpp:408] relu7 <- fc7\n",
      "I0430 09:58:31.143857 12665 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 09:58:31.143865 12665 net.cpp:124] Setting up relu7\n",
      "I0430 09:58:31.143869 12665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:58:31.143872 12665 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 09:58:31.143875 12665 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 09:58:31.143879 12665 net.cpp:86] Creating Layer drop7\n",
      "I0430 09:58:31.143882 12665 net.cpp:408] drop7 <- fc7\n",
      "I0430 09:58:31.143887 12665 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 09:58:31.143892 12665 net.cpp:124] Setting up drop7\n",
      "I0430 09:58:31.143893 12665 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 09:58:31.143896 12665 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 09:58:31.143898 12665 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 09:58:31.143903 12665 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 09:58:31.143904 12665 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 09:58:31.143908 12665 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 09:58:31.144800 12665 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 09:58:31.144815 12665 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 09:58:31.144819 12665 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 09:58:31.144829 12665 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 09:58:31.144831 12665 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 09:58:31.144834 12665 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 09:58:31.144836 12665 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 09:58:31.144840 12665 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 09:58:31.144841 12665 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 09:58:31.144845 12665 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 09:58:31.144851 12665 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 09:58:31.144855 12665 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 09:58:31.144860 12665 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 09:58:31.144863 12665 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 09:58:31.144866 12665 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 09:58:31.144870 12665 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 09:58:31.144875 12665 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 09:58:31.144878 12665 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 09:58:31.144883 12665 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 09:58:31.144886 12665 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 09:58:31.144891 12665 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 09:58:31.144896 12665 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 09:58:31.144901 12665 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 09:58:31.144904 12665 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 09:58:31.144908 12665 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 09:58:31.144912 12665 net.cpp:202] data does not need backward computation.\n",
      "I0430 09:58:31.144917 12665 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 09:58:31.144928 12665 net.cpp:257] Network initialization done.\n",
      "I0430 09:58:31.239059 12665 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:58:31.351122 12665 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 09:58:31.352059 12665 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 09:58:31.352068 12665 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 09:58:31.352073 12665 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/231685.jpg'}, '/tmp/tmpDCcpMl.mat')\n",
      "Processed 1488 windows in 177.829 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-1.85081, -3.13928, -2.35311, -2.00234, -2.58...\n",
      "ymin                                                         99\n",
      "xmin                                                        112\n",
      "ymax                                                        306\n",
      "xmax                                                        381\n",
      "Name: /home/ambika/INF_project/data/bird/231685.jpg, dtype: object\n",
      "prediction    [-2.35081, -2.59413, -2.13425, -2.63817, -1.88...\n",
      "ymin                                                        204\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/bird/231685.jpg, dtype: object\n",
      "bird\n",
      "112\t99\t381\t306\n",
      "binder\n",
      "0\t204\t500\t375\n",
      "231685\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:01:30.730957 12836 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:01:30.730980 12836 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:01:30.730984 12836 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:01:30.732116 12836 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:01:30.732260 12836 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:01:30.732270 12836 net.cpp:86] Creating Layer data\n",
      "I0430 10:01:30.732275 12836 net.cpp:382] data -> data\n",
      "I0430 10:01:30.732288 12836 net.cpp:124] Setting up data\n",
      "I0430 10:01:30.732293 12836 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:01:30.732296 12836 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:01:30.732300 12836 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:01:30.732308 12836 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:01:30.732313 12836 net.cpp:408] conv1 <- data\n",
      "I0430 10:01:30.732323 12836 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:01:30.732391 12836 net.cpp:124] Setting up conv1\n",
      "I0430 10:01:30.732396 12836 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:01:30.732398 12836 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:01:30.732405 12836 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:01:30.732410 12836 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:01:30.732414 12836 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:01:30.732416 12836 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:01:30.732420 12836 net.cpp:124] Setting up relu1\n",
      "I0430 10:01:30.732424 12836 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:01:30.732426 12836 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:01:30.732429 12836 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:01:30.732432 12836 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:01:30.732434 12836 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:01:30.732437 12836 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:01:30.732445 12836 net.cpp:124] Setting up pool1\n",
      "I0430 10:01:30.732447 12836 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:01:30.732450 12836 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:01:30.732451 12836 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:01:30.732456 12836 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:01:30.732458 12836 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:01:30.732461 12836 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:01:30.732466 12836 net.cpp:124] Setting up norm1\n",
      "I0430 10:01:30.732470 12836 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:01:30.732472 12836 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:01:30.732475 12836 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:01:30.732478 12836 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:01:30.732481 12836 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:01:30.732484 12836 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:01:30.732841 12836 net.cpp:124] Setting up conv2\n",
      "I0430 10:01:30.732849 12836 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:01:30.732853 12836 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:01:30.732862 12836 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:01:30.732868 12836 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:01:30.732872 12836 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:01:30.732878 12836 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:01:30.732883 12836 net.cpp:124] Setting up relu2\n",
      "I0430 10:01:30.732887 12836 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:01:30.732889 12836 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:01:30.732892 12836 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:01:30.732897 12836 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:01:30.732899 12836 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:01:30.732903 12836 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:01:30.732908 12836 net.cpp:124] Setting up pool2\n",
      "I0430 10:01:30.732911 12836 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:01:30.732913 12836 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:01:30.732915 12836 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:01:30.732920 12836 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:01:30.732923 12836 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:01:30.732925 12836 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:01:30.732931 12836 net.cpp:124] Setting up norm2\n",
      "I0430 10:01:30.732934 12836 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:01:30.732938 12836 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:01:30.732939 12836 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:01:30.732944 12836 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:01:30.732947 12836 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:01:30.732950 12836 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:01:30.733666 12836 net.cpp:124] Setting up conv3\n",
      "I0430 10:01:30.733678 12836 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:01:30.733681 12836 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:01:30.733691 12836 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:01:30.733698 12836 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:01:30.733702 12836 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:01:30.733707 12836 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:01:30.733712 12836 net.cpp:124] Setting up relu3\n",
      "I0430 10:01:30.733716 12836 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:01:30.733721 12836 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:01:30.733723 12836 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:01:30.733731 12836 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:01:30.733733 12836 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:01:30.733738 12836 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:01:30.734508 12836 net.cpp:124] Setting up conv4\n",
      "I0430 10:01:30.734519 12836 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:01:30.734524 12836 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:01:30.734530 12836 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:01:30.734539 12836 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:01:30.734541 12836 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:01:30.734547 12836 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:01:30.734552 12836 net.cpp:124] Setting up relu4\n",
      "I0430 10:01:30.734555 12836 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:01:30.734557 12836 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:01:30.734560 12836 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:01:30.734566 12836 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:01:30.734568 12836 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:01:30.734572 12836 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:01:30.735079 12836 net.cpp:124] Setting up conv5\n",
      "I0430 10:01:30.735085 12836 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:01:30.735090 12836 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:01:30.735100 12836 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:01:30.735106 12836 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:01:30.735110 12836 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:01:30.735113 12836 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:01:30.735118 12836 net.cpp:124] Setting up relu5\n",
      "I0430 10:01:30.735121 12836 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:01:30.735123 12836 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:01:30.735126 12836 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:01:30.735131 12836 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:01:30.735132 12836 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:01:30.735136 12836 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:01:30.735142 12836 net.cpp:124] Setting up pool5\n",
      "I0430 10:01:30.735146 12836 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:01:30.735148 12836 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:01:30.735150 12836 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:01:30.735157 12836 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:01:30.735159 12836 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:01:30.735163 12836 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:01:30.757817 12836 net.cpp:124] Setting up fc6\n",
      "I0430 10:01:30.757843 12836 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:01:30.757848 12836 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:01:30.757858 12836 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:01:30.757866 12836 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:01:30.757869 12836 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:01:30.757874 12836 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:01:30.757879 12836 net.cpp:124] Setting up relu6\n",
      "I0430 10:01:30.757882 12836 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:01:30.757884 12836 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:01:30.757886 12836 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:01:30.757889 12836 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:01:30.757891 12836 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:01:30.757894 12836 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:01:30.757897 12836 net.cpp:124] Setting up drop6\n",
      "I0430 10:01:30.757900 12836 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:01:30.757902 12836 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:01:30.757920 12836 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:01:30.757925 12836 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:01:30.757926 12836 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:01:30.757931 12836 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:01:30.770581 12836 net.cpp:124] Setting up fc7\n",
      "I0430 10:01:30.770608 12836 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:01:30.770614 12836 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:01:30.770623 12836 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:01:30.770630 12836 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:01:30.770634 12836 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:01:30.770638 12836 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:01:30.770643 12836 net.cpp:124] Setting up relu7\n",
      "I0430 10:01:30.770647 12836 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:01:30.770648 12836 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:01:30.770649 12836 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:01:30.770653 12836 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:01:30.770654 12836 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:01:30.770658 12836 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:01:30.770663 12836 net.cpp:124] Setting up drop7\n",
      "I0430 10:01:30.770665 12836 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:01:30.770680 12836 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:01:30.770684 12836 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:01:30.770689 12836 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:01:30.770691 12836 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:01:30.770695 12836 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:01:30.771334 12836 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:01:30.771345 12836 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:01:30.771349 12836 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:01:30.771358 12836 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:01:30.771360 12836 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:01:30.771364 12836 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:01:30.771368 12836 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:01:30.771371 12836 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:01:30.771374 12836 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:01:30.771378 12836 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:01:30.771383 12836 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:01:30.771385 12836 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:01:30.771389 12836 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:01:30.771391 12836 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:01:30.771395 12836 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:01:30.771399 12836 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:01:30.771402 12836 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:01:30.771405 12836 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:01:30.771409 12836 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:01:30.771412 12836 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:01:30.771415 12836 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:01:30.771420 12836 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:01:30.771422 12836 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:01:30.771425 12836 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:01:30.771428 12836 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:01:30.771432 12836 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:01:30.771435 12836 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:01:30.771445 12836 net.cpp:257] Network initialization done.\n",
      "I0430 10:01:30.867034 12836 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:01:30.980104 12836 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:01:30.981150 12836 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:01:30.981159 12836 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:01:30.981161 12836 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/270893.jpg'}, '/tmp/tmpDx3bA_.mat')\n",
      "Processed 1838 windows in 210.995 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.16125, -2.5528, -2.38208, -2.6115, -2.1776...\n",
      "ymin                                                         44\n",
      "xmin                                                         61\n",
      "ymax                                                        288\n",
      "xmax                                                        460\n",
      "Name: /home/ambika/INF_project/data/bus/270893.jpg, dtype: object\n",
      "prediction    [-2.28071, -2.03869, -2.09621, -2.11695, -1.83...\n",
      "ymin                                                        124\n",
      "xmin                                                         68\n",
      "ymax                                                        251\n",
      "xmax                                                        224\n",
      "Name: /home/ambika/INF_project/data/bus/270893.jpg, dtype: object\n",
      "bus\n",
      "61\t44\t460\t288\n",
      "snowmobile\n",
      "68\t124\t224\t251\n",
      "270893\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:05:03.520205 13010 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:05:03.520226 13010 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:05:03.520229 13010 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:05:03.521354 13010 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:05:03.521457 13010 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:05:03.521466 13010 net.cpp:86] Creating Layer data\n",
      "I0430 10:05:03.521471 13010 net.cpp:382] data -> data\n",
      "I0430 10:05:03.521484 13010 net.cpp:124] Setting up data\n",
      "I0430 10:05:03.521491 13010 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:05:03.521493 13010 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:05:03.521497 13010 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:05:03.521503 13010 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:05:03.521507 13010 net.cpp:408] conv1 <- data\n",
      "I0430 10:05:03.521512 13010 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:05:03.521577 13010 net.cpp:124] Setting up conv1\n",
      "I0430 10:05:03.521584 13010 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:05:03.521589 13010 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:05:03.521597 13010 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:05:03.521603 13010 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:05:03.521606 13010 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:05:03.521611 13010 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:05:03.521617 13010 net.cpp:124] Setting up relu1\n",
      "I0430 10:05:03.521621 13010 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:05:03.521625 13010 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:05:03.521628 13010 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:05:03.521634 13010 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:05:03.521636 13010 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:05:03.521641 13010 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:05:03.521649 13010 net.cpp:124] Setting up pool1\n",
      "I0430 10:05:03.521653 13010 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:05:03.521656 13010 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:05:03.521659 13010 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:05:03.521664 13010 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:05:03.521667 13010 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:05:03.521672 13010 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:05:03.521677 13010 net.cpp:124] Setting up norm1\n",
      "I0430 10:05:03.521682 13010 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:05:03.521684 13010 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:05:03.521687 13010 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:05:03.521694 13010 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:05:03.521697 13010 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:05:03.521702 13010 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:05:03.522052 13010 net.cpp:124] Setting up conv2\n",
      "I0430 10:05:03.522059 13010 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:05:03.522063 13010 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:05:03.522070 13010 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:05:03.522076 13010 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:05:03.522079 13010 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:05:03.522084 13010 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:05:03.522089 13010 net.cpp:124] Setting up relu2\n",
      "I0430 10:05:03.522094 13010 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:05:03.522096 13010 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:05:03.522099 13010 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:05:03.522105 13010 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:05:03.522109 13010 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:05:03.522112 13010 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:05:03.522119 13010 net.cpp:124] Setting up pool2\n",
      "I0430 10:05:03.522123 13010 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:05:03.522125 13010 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:05:03.522130 13010 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:05:03.522135 13010 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:05:03.522136 13010 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:05:03.522141 13010 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:05:03.522146 13010 net.cpp:124] Setting up norm2\n",
      "I0430 10:05:03.522151 13010 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:05:03.522153 13010 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:05:03.522156 13010 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:05:03.522163 13010 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:05:03.522166 13010 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:05:03.522171 13010 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:05:03.523146 13010 net.cpp:124] Setting up conv3\n",
      "I0430 10:05:03.523159 13010 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:05:03.523162 13010 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:05:03.523170 13010 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:05:03.523177 13010 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:05:03.523180 13010 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:05:03.523186 13010 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:05:03.523192 13010 net.cpp:124] Setting up relu3\n",
      "I0430 10:05:03.523196 13010 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:05:03.523200 13010 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:05:03.523202 13010 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:05:03.523216 13010 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:05:03.523219 13010 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:05:03.523224 13010 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:05:03.523730 13010 net.cpp:124] Setting up conv4\n",
      "I0430 10:05:03.523741 13010 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:05:03.523744 13010 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:05:03.523751 13010 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:05:03.523758 13010 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:05:03.523762 13010 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:05:03.523767 13010 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:05:03.523773 13010 net.cpp:124] Setting up relu4\n",
      "I0430 10:05:03.523777 13010 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:05:03.523779 13010 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:05:03.523783 13010 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:05:03.523788 13010 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:05:03.523792 13010 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:05:03.523797 13010 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:05:03.524302 13010 net.cpp:124] Setting up conv5\n",
      "I0430 10:05:03.524310 13010 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:05:03.524314 13010 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:05:03.524323 13010 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:05:03.524329 13010 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:05:03.524333 13010 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:05:03.524338 13010 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:05:03.524343 13010 net.cpp:124] Setting up relu5\n",
      "I0430 10:05:03.524348 13010 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:05:03.524350 13010 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:05:03.524353 13010 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:05:03.524358 13010 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:05:03.524360 13010 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:05:03.524366 13010 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:05:03.524374 13010 net.cpp:124] Setting up pool5\n",
      "I0430 10:05:03.524379 13010 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:05:03.524381 13010 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:05:03.524384 13010 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:05:03.524391 13010 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:05:03.524394 13010 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:05:03.524399 13010 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:05:03.545809 13010 net.cpp:124] Setting up fc6\n",
      "I0430 10:05:03.545828 13010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:05:03.545832 13010 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:05:03.545842 13010 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:05:03.545851 13010 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:05:03.545855 13010 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:05:03.545861 13010 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:05:03.545868 13010 net.cpp:124] Setting up relu6\n",
      "I0430 10:05:03.545874 13010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:05:03.545876 13010 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:05:03.545881 13010 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:05:03.545886 13010 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:05:03.545888 13010 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:05:03.545893 13010 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:05:03.545899 13010 net.cpp:124] Setting up drop6\n",
      "I0430 10:05:03.545902 13010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:05:03.545905 13010 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:05:03.545908 13010 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:05:03.545913 13010 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:05:03.545915 13010 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:05:03.545922 13010 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:05:03.556898 13010 net.cpp:124] Setting up fc7\n",
      "I0430 10:05:03.556928 13010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:05:03.556932 13010 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:05:03.556959 13010 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:05:03.556969 13010 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:05:03.556973 13010 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:05:03.556980 13010 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:05:03.556988 13010 net.cpp:124] Setting up relu7\n",
      "I0430 10:05:03.556993 13010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:05:03.556995 13010 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:05:03.556998 13010 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:05:03.557004 13010 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:05:03.557008 13010 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:05:03.557016 13010 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:05:03.557024 13010 net.cpp:124] Setting up drop7\n",
      "I0430 10:05:03.557029 13010 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:05:03.557031 13010 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:05:03.557034 13010 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:05:03.557040 13010 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:05:03.557044 13010 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:05:03.557054 13010 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:05:03.558069 13010 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:05:03.558087 13010 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:05:03.558091 13010 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:05:03.558100 13010 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:05:03.558104 13010 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:05:03.558109 13010 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:05:03.558111 13010 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:05:03.558115 13010 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:05:03.558120 13010 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:05:03.558123 13010 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:05:03.558127 13010 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:05:03.558130 13010 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:05:03.558133 13010 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:05:03.558137 13010 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:05:03.558140 13010 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:05:03.558143 13010 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:05:03.558147 13010 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:05:03.558151 13010 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:05:03.558154 13010 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:05:03.558157 13010 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:05:03.558161 13010 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:05:03.558164 13010 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:05:03.558167 13010 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:05:03.558171 13010 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:05:03.558174 13010 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:05:03.558177 13010 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:05:03.558181 13010 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:05:03.558192 13010 net.cpp:257] Network initialization done.\n",
      "I0430 10:05:03.655534 13010 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:05:03.769513 13010 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:05:03.770524 13010 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:05:03.770532 13010 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:05:03.770537 13010 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/577932.jpg'}, '/tmp/tmpFbrbEx.mat')\n",
      "Processed 3954 windows in 451.954 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.084 s.\n",
      "prediction    [-2.22745, -2.3418, -2.15493, -2.41449, -1.850...\n",
      "ymin                                                        118\n",
      "xmin                                                        166\n",
      "ymax                                                        381\n",
      "xmax                                                        297\n",
      "Name: /home/ambika/INF_project/data/car/577932.jpg, dtype: object\n",
      "prediction    [-2.03158, -1.73034, -1.60097, -1.7666, -1.718...\n",
      "ymin                                                        177\n",
      "xmin                                                        391\n",
      "ymax                                                        424\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/car/577932.jpg, dtype: object\n",
      "person\n",
      "166\t118\t297\t381\n",
      "car\n",
      "391\t177\t500\t424\n",
      "577932\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:12:38.058951 13267 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:12:38.058974 13267 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:12:38.058977 13267 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:12:38.060722 13267 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:12:38.061074 13267 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:12:38.061084 13267 net.cpp:86] Creating Layer data\n",
      "I0430 10:12:38.061092 13267 net.cpp:382] data -> data\n",
      "I0430 10:12:38.061112 13267 net.cpp:124] Setting up data\n",
      "I0430 10:12:38.061120 13267 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:12:38.061122 13267 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:12:38.061126 13267 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:12:38.061133 13267 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:12:38.061136 13267 net.cpp:408] conv1 <- data\n",
      "I0430 10:12:38.061141 13267 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:12:38.061203 13267 net.cpp:124] Setting up conv1\n",
      "I0430 10:12:38.061209 13267 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:12:38.061211 13267 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:12:38.061220 13267 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:12:38.061225 13267 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:12:38.061228 13267 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:12:38.061234 13267 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:12:38.061242 13267 net.cpp:124] Setting up relu1\n",
      "I0430 10:12:38.061246 13267 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:12:38.061249 13267 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:12:38.061252 13267 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:12:38.061256 13267 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:12:38.061259 13267 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:12:38.061264 13267 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:12:38.061272 13267 net.cpp:124] Setting up pool1\n",
      "I0430 10:12:38.061277 13267 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:12:38.061280 13267 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:12:38.061283 13267 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:12:38.061290 13267 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:12:38.061292 13267 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:12:38.061297 13267 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:12:38.061305 13267 net.cpp:124] Setting up norm1\n",
      "I0430 10:12:38.061308 13267 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:12:38.061311 13267 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:12:38.061314 13267 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:12:38.061319 13267 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:12:38.061322 13267 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:12:38.061326 13267 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:12:38.061704 13267 net.cpp:124] Setting up conv2\n",
      "I0430 10:12:38.061714 13267 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:12:38.061718 13267 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:12:38.061728 13267 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:12:38.061733 13267 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:12:38.061735 13267 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:12:38.061740 13267 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:12:38.061745 13267 net.cpp:124] Setting up relu2\n",
      "I0430 10:12:38.061750 13267 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:12:38.061753 13267 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:12:38.061755 13267 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:12:38.061761 13267 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:12:38.061764 13267 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:12:38.061769 13267 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:12:38.061775 13267 net.cpp:124] Setting up pool2\n",
      "I0430 10:12:38.061779 13267 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:12:38.061782 13267 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:12:38.061785 13267 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:12:38.061790 13267 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:12:38.061794 13267 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:12:38.061797 13267 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:12:38.061803 13267 net.cpp:124] Setting up norm2\n",
      "I0430 10:12:38.061807 13267 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:12:38.061810 13267 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:12:38.061812 13267 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:12:38.061818 13267 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:12:38.061821 13267 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:12:38.061826 13267 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:12:38.062520 13267 net.cpp:124] Setting up conv3\n",
      "I0430 10:12:38.062530 13267 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:12:38.062533 13267 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:12:38.062542 13267 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:12:38.062551 13267 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:12:38.062553 13267 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:12:38.062559 13267 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:12:38.062564 13267 net.cpp:124] Setting up relu3\n",
      "I0430 10:12:38.062568 13267 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:12:38.062572 13267 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:12:38.062574 13267 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:12:38.062579 13267 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:12:38.062582 13267 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:12:38.062587 13267 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:12:38.063331 13267 net.cpp:124] Setting up conv4\n",
      "I0430 10:12:38.063341 13267 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:12:38.063345 13267 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:12:38.063351 13267 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:12:38.063359 13267 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:12:38.063362 13267 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:12:38.063367 13267 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:12:38.063372 13267 net.cpp:124] Setting up relu4\n",
      "I0430 10:12:38.063377 13267 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:12:38.063380 13267 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:12:38.063382 13267 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:12:38.063390 13267 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:12:38.063392 13267 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:12:38.063396 13267 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:12:38.063894 13267 net.cpp:124] Setting up conv5\n",
      "I0430 10:12:38.063902 13267 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:12:38.063905 13267 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:12:38.063915 13267 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:12:38.063922 13267 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:12:38.063925 13267 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:12:38.063930 13267 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:12:38.063935 13267 net.cpp:124] Setting up relu5\n",
      "I0430 10:12:38.063940 13267 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:12:38.063941 13267 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:12:38.063944 13267 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:12:38.063949 13267 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:12:38.063951 13267 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:12:38.063957 13267 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:12:38.063966 13267 net.cpp:124] Setting up pool5\n",
      "I0430 10:12:38.063969 13267 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:12:38.063971 13267 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:12:38.063974 13267 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:12:38.063982 13267 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:12:38.063985 13267 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:12:38.063989 13267 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:12:38.088186 13267 net.cpp:124] Setting up fc6\n",
      "I0430 10:12:38.088212 13267 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:12:38.088217 13267 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:12:38.088227 13267 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:12:38.088235 13267 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:12:38.088239 13267 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:12:38.088245 13267 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:12:38.088253 13267 net.cpp:124] Setting up relu6\n",
      "I0430 10:12:38.088258 13267 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:12:38.088259 13267 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:12:38.088263 13267 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:12:38.088268 13267 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:12:38.088280 13267 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:12:38.088285 13267 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:12:38.088292 13267 net.cpp:124] Setting up drop6\n",
      "I0430 10:12:38.088295 13267 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:12:38.088299 13267 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:12:38.088301 13267 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:12:38.088309 13267 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:12:38.088311 13267 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:12:38.088316 13267 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:12:38.098742 13267 net.cpp:124] Setting up fc7\n",
      "I0430 10:12:38.098768 13267 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:12:38.098773 13267 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:12:38.098784 13267 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:12:38.098793 13267 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:12:38.098796 13267 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:12:38.098801 13267 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:12:38.098809 13267 net.cpp:124] Setting up relu7\n",
      "I0430 10:12:38.098814 13267 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:12:38.098815 13267 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:12:38.098817 13267 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:12:38.098824 13267 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:12:38.098837 13267 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:12:38.098841 13267 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:12:38.098847 13267 net.cpp:124] Setting up drop7\n",
      "I0430 10:12:38.098851 13267 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:12:38.098855 13267 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:12:38.098857 13267 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:12:38.098862 13267 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:12:38.098865 13267 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:12:38.098870 13267 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:12:38.099534 13267 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:12:38.099545 13267 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:12:38.099550 13267 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:12:38.099556 13267 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:12:38.099560 13267 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:12:38.099563 13267 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:12:38.099567 13267 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:12:38.099570 13267 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:12:38.099573 13267 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:12:38.099576 13267 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:12:38.099580 13267 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:12:38.099583 13267 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:12:38.099586 13267 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:12:38.099589 13267 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:12:38.099592 13267 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:12:38.099596 13267 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:12:38.099599 13267 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:12:38.099602 13267 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:12:38.099606 13267 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:12:38.099608 13267 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:12:38.099612 13267 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:12:38.099616 13267 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:12:38.099618 13267 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:12:38.099622 13267 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:12:38.099624 13267 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:12:38.099628 13267 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:12:38.099630 13267 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:12:38.099642 13267 net.cpp:257] Network initialization done.\n",
      "I0430 10:12:38.350234 13267 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:12:38.452219 13267 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:12:38.453086 13267 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:12:38.453095 13267 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:12:38.453099 13267 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/32597.jpg'}, '/tmp/tmpxD6T1C.mat')\n",
      "Processed 2434 windows in 283.181 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.034 s.\n",
      "prediction    [-2.07521, -2.26571, -2.23301, -1.91772, -2.32...\n",
      "ymin                                                        172\n",
      "xmin                                                         21\n",
      "ymax                                                        319\n",
      "xmax                                                        198\n",
      "Name: /home/ambika/INF_project/data/cat/32597.jpg, dtype: object\n",
      "prediction    [-1.95814, -2.16442, -2.25433, -1.9491, -2.229...\n",
      "ymin                                                        149\n",
      "xmin                                                         12\n",
      "ymax                                                        316\n",
      "xmax                                                        268\n",
      "Name: /home/ambika/INF_project/data/cat/32597.jpg, dtype: object\n",
      "tv or monitor\n",
      "21\t172\t198\t319\n",
      "laptop\n",
      "12\t149\t268\t316\n",
      "32597\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:17:23.206857 13457 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:17:23.206879 13457 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:17:23.206883 13457 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:17:23.208029 13457 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:17:23.208191 13457 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:17:23.208202 13457 net.cpp:86] Creating Layer data\n",
      "I0430 10:17:23.208207 13457 net.cpp:382] data -> data\n",
      "I0430 10:17:23.208221 13457 net.cpp:124] Setting up data\n",
      "I0430 10:17:23.208230 13457 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:17:23.208232 13457 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:17:23.208236 13457 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:17:23.208245 13457 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:17:23.208247 13457 net.cpp:408] conv1 <- data\n",
      "I0430 10:17:23.208253 13457 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:17:23.208318 13457 net.cpp:124] Setting up conv1\n",
      "I0430 10:17:23.208323 13457 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:17:23.208326 13457 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:17:23.208335 13457 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:17:23.208340 13457 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:17:23.208343 13457 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:17:23.208348 13457 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:17:23.208353 13457 net.cpp:124] Setting up relu1\n",
      "I0430 10:17:23.208358 13457 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:17:23.208359 13457 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:17:23.208362 13457 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:17:23.208367 13457 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:17:23.208369 13457 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:17:23.208374 13457 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:17:23.208381 13457 net.cpp:124] Setting up pool1\n",
      "I0430 10:17:23.208385 13457 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:17:23.208389 13457 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:17:23.208391 13457 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:17:23.208396 13457 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:17:23.208400 13457 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:17:23.208403 13457 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:17:23.208410 13457 net.cpp:124] Setting up norm1\n",
      "I0430 10:17:23.208415 13457 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:17:23.208418 13457 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:17:23.208420 13457 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:17:23.208426 13457 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:17:23.208429 13457 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:17:23.208434 13457 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:17:23.208807 13457 net.cpp:124] Setting up conv2\n",
      "I0430 10:17:23.208816 13457 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:17:23.208819 13457 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:17:23.208827 13457 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:17:23.208832 13457 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:17:23.208835 13457 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:17:23.208839 13457 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:17:23.208844 13457 net.cpp:124] Setting up relu2\n",
      "I0430 10:17:23.208849 13457 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:17:23.208851 13457 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:17:23.208854 13457 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:17:23.208859 13457 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:17:23.208861 13457 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:17:23.208866 13457 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:17:23.208873 13457 net.cpp:124] Setting up pool2\n",
      "I0430 10:17:23.208876 13457 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:17:23.208879 13457 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:17:23.208883 13457 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:17:23.208889 13457 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:17:23.208891 13457 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:17:23.208895 13457 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:17:23.208901 13457 net.cpp:124] Setting up norm2\n",
      "I0430 10:17:23.208905 13457 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:17:23.208907 13457 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:17:23.208910 13457 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:17:23.208916 13457 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:17:23.208920 13457 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:17:23.208923 13457 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:17:23.209625 13457 net.cpp:124] Setting up conv3\n",
      "I0430 10:17:23.209636 13457 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:17:23.209640 13457 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:17:23.209650 13457 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:17:23.209656 13457 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:17:23.209659 13457 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:17:23.209664 13457 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:17:23.209671 13457 net.cpp:124] Setting up relu3\n",
      "I0430 10:17:23.209674 13457 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:17:23.209677 13457 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:17:23.209681 13457 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:17:23.209687 13457 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:17:23.209689 13457 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:17:23.209694 13457 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:17:23.210429 13457 net.cpp:124] Setting up conv4\n",
      "I0430 10:17:23.210439 13457 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:17:23.210443 13457 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:17:23.210448 13457 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:17:23.210454 13457 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:17:23.210458 13457 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:17:23.210464 13457 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:17:23.210469 13457 net.cpp:124] Setting up relu4\n",
      "I0430 10:17:23.210472 13457 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:17:23.210475 13457 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:17:23.210479 13457 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:17:23.210484 13457 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:17:23.210487 13457 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:17:23.210492 13457 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:17:23.211006 13457 net.cpp:124] Setting up conv5\n",
      "I0430 10:17:23.211014 13457 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:17:23.211017 13457 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:17:23.211030 13457 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:17:23.211036 13457 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:17:23.211040 13457 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:17:23.211043 13457 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:17:23.211050 13457 net.cpp:124] Setting up relu5\n",
      "I0430 10:17:23.211053 13457 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:17:23.211056 13457 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:17:23.211060 13457 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:17:23.211064 13457 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:17:23.211066 13457 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:17:23.211071 13457 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:17:23.211078 13457 net.cpp:124] Setting up pool5\n",
      "I0430 10:17:23.211082 13457 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:17:23.211086 13457 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:17:23.211088 13457 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:17:23.211097 13457 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:17:23.211099 13457 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:17:23.211104 13457 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:17:23.237665 13457 net.cpp:124] Setting up fc6\n",
      "I0430 10:17:23.237690 13457 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:17:23.237694 13457 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:17:23.237723 13457 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:17:23.237735 13457 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:17:23.237740 13457 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:17:23.237747 13457 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:17:23.237754 13457 net.cpp:124] Setting up relu6\n",
      "I0430 10:17:23.237757 13457 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:17:23.237759 13457 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:17:23.237761 13457 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:17:23.237766 13457 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:17:23.237768 13457 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:17:23.237771 13457 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:17:23.237776 13457 net.cpp:124] Setting up drop6\n",
      "I0430 10:17:23.237778 13457 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:17:23.237781 13457 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:17:23.237783 13457 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:17:23.237787 13457 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:17:23.237789 13457 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:17:23.237793 13457 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:17:23.247419 13457 net.cpp:124] Setting up fc7\n",
      "I0430 10:17:23.247440 13457 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:17:23.247445 13457 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:17:23.247454 13457 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:17:23.247465 13457 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:17:23.247469 13457 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:17:23.247475 13457 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:17:23.247483 13457 net.cpp:124] Setting up relu7\n",
      "I0430 10:17:23.247488 13457 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:17:23.247490 13457 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:17:23.247493 13457 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:17:23.247498 13457 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:17:23.247500 13457 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:17:23.247504 13457 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:17:23.247509 13457 net.cpp:124] Setting up drop7\n",
      "I0430 10:17:23.247512 13457 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:17:23.247514 13457 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:17:23.247516 13457 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:17:23.247520 13457 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:17:23.247522 13457 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:17:23.247525 13457 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:17:23.248435 13457 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:17:23.248445 13457 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:17:23.248448 13457 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:17:23.248456 13457 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:17:23.248461 13457 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:17:23.248463 13457 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:17:23.248466 13457 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:17:23.248469 13457 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:17:23.248473 13457 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:17:23.248477 13457 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:17:23.248481 13457 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:17:23.248486 13457 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:17:23.248488 13457 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:17:23.248492 13457 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:17:23.248494 13457 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:17:23.248497 13457 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:17:23.248499 13457 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:17:23.248502 13457 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:17:23.248505 13457 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:17:23.248508 13457 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:17:23.248510 13457 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:17:23.248513 13457 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:17:23.248517 13457 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:17:23.248518 13457 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:17:23.248522 13457 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:17:23.248523 13457 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:17:23.248527 13457 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:17:23.248535 13457 net.cpp:257] Network initialization done.\n",
      "I0430 10:17:23.342767 13457 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:17:23.463680 13457 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:17:23.464557 13457 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:17:23.464565 13457 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:17:23.464570 13457 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/184994.jpg'}, '/tmp/tmpNOXQVJ.mat')\n",
      "Processed 2226 windows in 256.354 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.33877, -2.34228, -2.25475, -1.7797, -2.167...\n",
      "ymin                                                        180\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        238\n",
      "Name: /home/ambika/INF_project/data/couch/184994.jpg, dtype: object\n",
      "prediction    [-2.20518, -2.0557, -2.17054, -1.82291, -2.078...\n",
      "ymin                                                         17\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        193\n",
      "Name: /home/ambika/INF_project/data/couch/184994.jpg, dtype: object\n",
      "table\n",
      "0\t180\t238\t375\n",
      "piano\n",
      "0\t17\t193\t375\n",
      "184994\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:21:41.438501 13632 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:21:41.438527 13632 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:21:41.438531 13632 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:21:41.439669 13632 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:21:41.439800 13632 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:21:41.439808 13632 net.cpp:86] Creating Layer data\n",
      "I0430 10:21:41.439812 13632 net.cpp:382] data -> data\n",
      "I0430 10:21:41.439826 13632 net.cpp:124] Setting up data\n",
      "I0430 10:21:41.439832 13632 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:21:41.439836 13632 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:21:41.439838 13632 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:21:41.439843 13632 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:21:41.439846 13632 net.cpp:408] conv1 <- data\n",
      "I0430 10:21:41.439852 13632 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:21:41.439921 13632 net.cpp:124] Setting up conv1\n",
      "I0430 10:21:41.439927 13632 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:21:41.439930 13632 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:21:41.439937 13632 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:21:41.439942 13632 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:21:41.439945 13632 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:21:41.439949 13632 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:21:41.439954 13632 net.cpp:124] Setting up relu1\n",
      "I0430 10:21:41.439956 13632 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:21:41.439959 13632 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:21:41.439961 13632 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:21:41.439967 13632 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:21:41.439970 13632 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:21:41.439972 13632 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:21:41.439978 13632 net.cpp:124] Setting up pool1\n",
      "I0430 10:21:41.439982 13632 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:21:41.439985 13632 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:21:41.439987 13632 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:21:41.439991 13632 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:21:41.439993 13632 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:21:41.439996 13632 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:21:41.440001 13632 net.cpp:124] Setting up norm1\n",
      "I0430 10:21:41.440006 13632 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:21:41.440007 13632 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:21:41.440009 13632 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:21:41.440013 13632 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:21:41.440016 13632 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:21:41.440019 13632 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:21:41.440371 13632 net.cpp:124] Setting up conv2\n",
      "I0430 10:21:41.440376 13632 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:21:41.440379 13632 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:21:41.440384 13632 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:21:41.440388 13632 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:21:41.440392 13632 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:21:41.440395 13632 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:21:41.440400 13632 net.cpp:124] Setting up relu2\n",
      "I0430 10:21:41.440404 13632 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:21:41.440409 13632 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:21:41.440415 13632 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:21:41.440424 13632 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:21:41.440428 13632 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:21:41.440433 13632 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:21:41.440441 13632 net.cpp:124] Setting up pool2\n",
      "I0430 10:21:41.440448 13632 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:21:41.440449 13632 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:21:41.440452 13632 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:21:41.440456 13632 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:21:41.440459 13632 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:21:41.440462 13632 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:21:41.440467 13632 net.cpp:124] Setting up norm2\n",
      "I0430 10:21:41.440470 13632 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:21:41.440474 13632 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:21:41.440475 13632 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:21:41.440480 13632 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:21:41.440484 13632 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:21:41.440486 13632 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:21:41.441179 13632 net.cpp:124] Setting up conv3\n",
      "I0430 10:21:41.441190 13632 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:21:41.441195 13632 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:21:41.441205 13632 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:21:41.441212 13632 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:21:41.441216 13632 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:21:41.441220 13632 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:21:41.441226 13632 net.cpp:124] Setting up relu3\n",
      "I0430 10:21:41.441228 13632 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:21:41.441231 13632 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:21:41.441233 13632 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:21:41.441238 13632 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:21:41.441241 13632 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:21:41.441243 13632 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:21:41.441993 13632 net.cpp:124] Setting up conv4\n",
      "I0430 10:21:41.442004 13632 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:21:41.442008 13632 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:21:41.442015 13632 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:21:41.442023 13632 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:21:41.442026 13632 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:21:41.442030 13632 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:21:41.442035 13632 net.cpp:124] Setting up relu4\n",
      "I0430 10:21:41.442039 13632 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:21:41.442040 13632 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:21:41.442044 13632 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:21:41.442049 13632 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:21:41.442051 13632 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:21:41.442054 13632 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:21:41.442553 13632 net.cpp:124] Setting up conv5\n",
      "I0430 10:21:41.442560 13632 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:21:41.442564 13632 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:21:41.442575 13632 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:21:41.442580 13632 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:21:41.442584 13632 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:21:41.442589 13632 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:21:41.442596 13632 net.cpp:124] Setting up relu5\n",
      "I0430 10:21:41.442600 13632 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:21:41.442602 13632 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:21:41.442605 13632 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:21:41.442610 13632 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:21:41.442611 13632 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:21:41.442615 13632 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:21:41.442621 13632 net.cpp:124] Setting up pool5\n",
      "I0430 10:21:41.442625 13632 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:21:41.442627 13632 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:21:41.442629 13632 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:21:41.442636 13632 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:21:41.442639 13632 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:21:41.442642 13632 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:21:41.465936 13632 net.cpp:124] Setting up fc6\n",
      "I0430 10:21:41.465977 13632 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:21:41.465982 13632 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:21:41.465998 13632 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:21:41.466014 13632 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:21:41.466020 13632 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:21:41.466028 13632 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:21:41.466038 13632 net.cpp:124] Setting up relu6\n",
      "I0430 10:21:41.466043 13632 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:21:41.466047 13632 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:21:41.466050 13632 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:21:41.466055 13632 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:21:41.466058 13632 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:21:41.466063 13632 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:21:41.466068 13632 net.cpp:124] Setting up drop6\n",
      "I0430 10:21:41.466070 13632 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:21:41.466073 13632 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:21:41.466076 13632 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:21:41.466081 13632 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:21:41.466084 13632 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:21:41.466089 13632 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:21:41.477361 13632 net.cpp:124] Setting up fc7\n",
      "I0430 10:21:41.477388 13632 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:21:41.477391 13632 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:21:41.477401 13632 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:21:41.477413 13632 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:21:41.477418 13632 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:21:41.477425 13632 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:21:41.477434 13632 net.cpp:124] Setting up relu7\n",
      "I0430 10:21:41.477452 13632 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:21:41.477457 13632 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:21:41.477459 13632 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:21:41.477465 13632 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:21:41.477468 13632 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:21:41.477473 13632 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:21:41.477478 13632 net.cpp:124] Setting up drop7\n",
      "I0430 10:21:41.477480 13632 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:21:41.477483 13632 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:21:41.477485 13632 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:21:41.477489 13632 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:21:41.477491 13632 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:21:41.477495 13632 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:21:41.478209 13632 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:21:41.478226 13632 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:21:41.478229 13632 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:21:41.478238 13632 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:21:41.478241 13632 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:21:41.478245 13632 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:21:41.478247 13632 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:21:41.478250 13632 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:21:41.478253 13632 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:21:41.478255 13632 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:21:41.478260 13632 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:21:41.478262 13632 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:21:41.478266 13632 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:21:41.478271 13632 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:21:41.478274 13632 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:21:41.478278 13632 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:21:41.478282 13632 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:21:41.478286 13632 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:21:41.478291 13632 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:21:41.478294 13632 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:21:41.478298 13632 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:21:41.478302 13632 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:21:41.478307 13632 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:21:41.478310 13632 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:21:41.478314 13632 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:21:41.478318 13632 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:21:41.478322 13632 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:21:41.478335 13632 net.cpp:257] Network initialization done.\n",
      "I0430 10:21:41.576377 13632 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:21:41.690311 13632 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:21:41.691265 13632 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:21:41.691273 13632 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:21:41.691277 13632 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/22874.jpg'}, '/tmp/tmpuzbxUl.mat')\n",
      "Processed 1808 windows in 221.596 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.039 s.\n",
      "prediction    [-2.05203, -1.73549, -1.84046, -1.64806, -2.06...\n",
      "ymin                                                         78\n",
      "xmin                                                          0\n",
      "ymax                                                        332\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/dog/22874.jpg, dtype: object\n",
      "prediction    [-2.01727, -1.86591, -1.60367, -2.52305, -1.74...\n",
      "ymin                                                        157\n",
      "xmin                                                         79\n",
      "ymax                                                        332\n",
      "xmax                                                        319\n",
      "Name: /home/ambika/INF_project/data/dog/22874.jpg, dtype: object\n",
      "table\n",
      "0\t78\t500\t332\n",
      "dog\n",
      "79\t157\t319\t332\n",
      "22874\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:25:24.837076 13876 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:25:24.837093 13876 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:25:24.837097 13876 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:25:24.838187 13876 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:25:24.838318 13876 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:25:24.838325 13876 net.cpp:86] Creating Layer data\n",
      "I0430 10:25:24.838330 13876 net.cpp:382] data -> data\n",
      "I0430 10:25:24.838342 13876 net.cpp:124] Setting up data\n",
      "I0430 10:25:24.838348 13876 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:25:24.838351 13876 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:25:24.838354 13876 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:25:24.838361 13876 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:25:24.838363 13876 net.cpp:408] conv1 <- data\n",
      "I0430 10:25:24.838369 13876 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:25:24.838428 13876 net.cpp:124] Setting up conv1\n",
      "I0430 10:25:24.838433 13876 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:25:24.838434 13876 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:25:24.838443 13876 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:25:24.838448 13876 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:25:24.838449 13876 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:25:24.838454 13876 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:25:24.838459 13876 net.cpp:124] Setting up relu1\n",
      "I0430 10:25:24.838461 13876 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:25:24.838464 13876 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:25:24.838466 13876 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:25:24.838470 13876 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:25:24.838474 13876 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:25:24.838477 13876 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:25:24.838485 13876 net.cpp:124] Setting up pool1\n",
      "I0430 10:25:24.838488 13876 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:25:24.838491 13876 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:25:24.838495 13876 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:25:24.838500 13876 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:25:24.838501 13876 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:25:24.838506 13876 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:25:24.838511 13876 net.cpp:124] Setting up norm1\n",
      "I0430 10:25:24.838515 13876 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:25:24.838517 13876 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:25:24.838521 13876 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:25:24.838526 13876 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:25:24.838528 13876 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:25:24.838532 13876 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:25:24.838870 13876 net.cpp:124] Setting up conv2\n",
      "I0430 10:25:24.838874 13876 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:25:24.838878 13876 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:25:24.838883 13876 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:25:24.838887 13876 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:25:24.838891 13876 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:25:24.838894 13876 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:25:24.838899 13876 net.cpp:124] Setting up relu2\n",
      "I0430 10:25:24.838902 13876 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:25:24.838906 13876 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:25:24.838908 13876 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:25:24.838913 13876 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:25:24.838915 13876 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:25:24.838919 13876 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:25:24.838925 13876 net.cpp:124] Setting up pool2\n",
      "I0430 10:25:24.838929 13876 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:25:24.838932 13876 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:25:24.838934 13876 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:25:24.838940 13876 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:25:24.838943 13876 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:25:24.838948 13876 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:25:24.838953 13876 net.cpp:124] Setting up norm2\n",
      "I0430 10:25:24.838956 13876 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:25:24.838959 13876 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:25:24.838963 13876 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:25:24.838968 13876 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:25:24.838970 13876 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:25:24.838975 13876 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:25:24.839705 13876 net.cpp:124] Setting up conv3\n",
      "I0430 10:25:24.839715 13876 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:25:24.839717 13876 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:25:24.839725 13876 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:25:24.839730 13876 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:25:24.839733 13876 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:25:24.839737 13876 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:25:24.839743 13876 net.cpp:124] Setting up relu3\n",
      "I0430 10:25:24.839746 13876 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:25:24.839750 13876 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:25:24.839752 13876 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:25:24.839759 13876 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:25:24.839762 13876 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:25:24.839767 13876 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:25:24.840513 13876 net.cpp:124] Setting up conv4\n",
      "I0430 10:25:24.840523 13876 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:25:24.840524 13876 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:25:24.840529 13876 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:25:24.840535 13876 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:25:24.840538 13876 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:25:24.840543 13876 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:25:24.840548 13876 net.cpp:124] Setting up relu4\n",
      "I0430 10:25:24.840550 13876 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:25:24.840553 13876 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:25:24.840556 13876 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:25:24.840561 13876 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:25:24.840564 13876 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:25:24.840569 13876 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:25:24.841060 13876 net.cpp:124] Setting up conv5\n",
      "I0430 10:25:24.841068 13876 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:25:24.841069 13876 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:25:24.841078 13876 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:25:24.841081 13876 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:25:24.841085 13876 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:25:24.841090 13876 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:25:24.841094 13876 net.cpp:124] Setting up relu5\n",
      "I0430 10:25:24.841099 13876 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:25:24.841100 13876 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:25:24.841104 13876 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:25:24.841109 13876 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:25:24.841110 13876 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:25:24.841115 13876 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:25:24.841122 13876 net.cpp:124] Setting up pool5\n",
      "I0430 10:25:24.841126 13876 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:25:24.841128 13876 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:25:24.841131 13876 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:25:24.841138 13876 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:25:24.841141 13876 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:25:24.841145 13876 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:25:24.865368 13876 net.cpp:124] Setting up fc6\n",
      "I0430 10:25:24.865396 13876 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:25:24.865399 13876 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:25:24.865411 13876 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:25:24.865420 13876 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:25:24.865429 13876 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:25:24.865437 13876 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:25:24.865447 13876 net.cpp:124] Setting up relu6\n",
      "I0430 10:25:24.865452 13876 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:25:24.865454 13876 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:25:24.865458 13876 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:25:24.865464 13876 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:25:24.865468 13876 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:25:24.865473 13876 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:25:24.865478 13876 net.cpp:124] Setting up drop6\n",
      "I0430 10:25:24.865483 13876 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:25:24.865486 13876 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:25:24.865490 13876 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:25:24.865496 13876 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:25:24.865499 13876 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:25:24.865506 13876 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:25:24.877652 13876 net.cpp:124] Setting up fc7\n",
      "I0430 10:25:24.877681 13876 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:25:24.877686 13876 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:25:24.877696 13876 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:25:24.877707 13876 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:25:24.877712 13876 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:25:24.877718 13876 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:25:24.877727 13876 net.cpp:124] Setting up relu7\n",
      "I0430 10:25:24.877732 13876 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:25:24.877735 13876 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:25:24.877738 13876 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:25:24.877744 13876 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:25:24.877748 13876 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:25:24.877753 13876 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:25:24.877759 13876 net.cpp:124] Setting up drop7\n",
      "I0430 10:25:24.877764 13876 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:25:24.877766 13876 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:25:24.877770 13876 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:25:24.877775 13876 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:25:24.877780 13876 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:25:24.877785 13876 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:25:24.878926 13876 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:25:24.878940 13876 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:25:24.878943 13876 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:25:24.878953 13876 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:25:24.878957 13876 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:25:24.878960 13876 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:25:24.878963 13876 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:25:24.878967 13876 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:25:24.878969 13876 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:25:24.878973 13876 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:25:24.878975 13876 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:25:24.878979 13876 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:25:24.878983 13876 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:25:24.878985 13876 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:25:24.878988 13876 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:25:24.878993 13876 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:25:24.878995 13876 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:25:24.878998 13876 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:25:24.879003 13876 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:25:24.879005 13876 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:25:24.879009 13876 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:25:24.879011 13876 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:25:24.879014 13876 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:25:24.879017 13876 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:25:24.879020 13876 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:25:24.879024 13876 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:25:24.879025 13876 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:25:24.879040 13876 net.cpp:257] Network initialization done.\n",
      "I0430 10:25:24.975893 13876 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:25:25.079346 13876 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:25:25.080412 13876 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:25:25.080420 13876 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:25:25.080423 13876 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/368153.jpg'}, '/tmp/tmpMOHtfD.mat')\n",
      "Processed 1905 windows in 214.456 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-1.9347, -2.26776, -1.652, -0.512765, -1.6876...\n",
      "ymin                                                        148\n",
      "xmin                                                        248\n",
      "ymax                                                        259\n",
      "xmax                                                        400\n",
      "Name: /home/ambika/INF_project/data/horse/368153.jpg, dtype: object\n",
      "prediction    [-1.68693, -2.24523, -1.78304, -2.32176, -1.70...\n",
      "ymin                                                        161\n",
      "xmin                                                         89\n",
      "ymax                                                        238\n",
      "xmax                                                        189\n",
      "Name: /home/ambika/INF_project/data/horse/368153.jpg, dtype: object\n",
      "camel\n",
      "248\t148\t400\t259\n",
      "horse\n",
      "89\t161\t189\t238\n",
      "368153\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:29:01.073276 14063 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:29:01.073295 14063 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:29:01.073299 14063 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:29:01.074384 14063 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:29:01.074486 14063 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:29:01.074493 14063 net.cpp:86] Creating Layer data\n",
      "I0430 10:29:01.074497 14063 net.cpp:382] data -> data\n",
      "I0430 10:29:01.074512 14063 net.cpp:124] Setting up data\n",
      "I0430 10:29:01.074517 14063 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:29:01.074519 14063 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:29:01.074523 14063 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:29:01.074530 14063 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:29:01.074533 14063 net.cpp:408] conv1 <- data\n",
      "I0430 10:29:01.074538 14063 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:29:01.074604 14063 net.cpp:124] Setting up conv1\n",
      "I0430 10:29:01.074609 14063 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:29:01.074612 14063 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:29:01.074620 14063 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:29:01.074627 14063 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:29:01.074630 14063 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:29:01.074635 14063 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:29:01.074642 14063 net.cpp:124] Setting up relu1\n",
      "I0430 10:29:01.074646 14063 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:29:01.074650 14063 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:29:01.074652 14063 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:29:01.074657 14063 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:29:01.074661 14063 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:29:01.074666 14063 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:29:01.074672 14063 net.cpp:124] Setting up pool1\n",
      "I0430 10:29:01.074676 14063 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:29:01.074679 14063 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:29:01.074682 14063 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:29:01.074687 14063 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:29:01.074690 14063 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:29:01.074695 14063 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:29:01.074700 14063 net.cpp:124] Setting up norm1\n",
      "I0430 10:29:01.074705 14063 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:29:01.074707 14063 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:29:01.074710 14063 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:29:01.074717 14063 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:29:01.074718 14063 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:29:01.074723 14063 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:29:01.075067 14063 net.cpp:124] Setting up conv2\n",
      "I0430 10:29:01.075073 14063 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:29:01.075076 14063 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:29:01.075083 14063 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:29:01.075088 14063 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:29:01.075090 14063 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:29:01.075095 14063 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:29:01.075100 14063 net.cpp:124] Setting up relu2\n",
      "I0430 10:29:01.075104 14063 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:29:01.075106 14063 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:29:01.075110 14063 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:29:01.075114 14063 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:29:01.075117 14063 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:29:01.075122 14063 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:29:01.075129 14063 net.cpp:124] Setting up pool2\n",
      "I0430 10:29:01.075132 14063 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:29:01.075135 14063 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:29:01.075139 14063 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:29:01.075145 14063 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:29:01.075147 14063 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:29:01.075152 14063 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:29:01.075157 14063 net.cpp:124] Setting up norm2\n",
      "I0430 10:29:01.075161 14063 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:29:01.075165 14063 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:29:01.075167 14063 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:29:01.075173 14063 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:29:01.075176 14063 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:29:01.075181 14063 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:29:01.075865 14063 net.cpp:124] Setting up conv3\n",
      "I0430 10:29:01.075876 14063 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:29:01.075880 14063 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:29:01.075888 14063 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:29:01.075893 14063 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:29:01.075896 14063 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:29:01.075901 14063 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:29:01.075906 14063 net.cpp:124] Setting up relu3\n",
      "I0430 10:29:01.075911 14063 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:29:01.075913 14063 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:29:01.075917 14063 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:29:01.075932 14063 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:29:01.075935 14063 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:29:01.075940 14063 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:29:01.076786 14063 net.cpp:124] Setting up conv4\n",
      "I0430 10:29:01.076804 14063 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:29:01.076807 14063 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:29:01.076817 14063 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:29:01.076824 14063 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:29:01.076828 14063 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:29:01.076836 14063 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:29:01.076845 14063 net.cpp:124] Setting up relu4\n",
      "I0430 10:29:01.076849 14063 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:29:01.076853 14063 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:29:01.076855 14063 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:29:01.076863 14063 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:29:01.076865 14063 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:29:01.076871 14063 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:29:01.077390 14063 net.cpp:124] Setting up conv5\n",
      "I0430 10:29:01.077399 14063 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:29:01.077402 14063 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:29:01.077414 14063 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:29:01.077419 14063 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:29:01.077421 14063 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:29:01.077426 14063 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:29:01.077431 14063 net.cpp:124] Setting up relu5\n",
      "I0430 10:29:01.077435 14063 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:29:01.077438 14063 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:29:01.077441 14063 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:29:01.077447 14063 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:29:01.077450 14063 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:29:01.077455 14063 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:29:01.077461 14063 net.cpp:124] Setting up pool5\n",
      "I0430 10:29:01.077466 14063 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:29:01.077468 14063 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:29:01.077471 14063 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:29:01.077479 14063 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:29:01.077482 14063 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:29:01.077486 14063 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:29:01.099350 14063 net.cpp:124] Setting up fc6\n",
      "I0430 10:29:01.099375 14063 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:29:01.099380 14063 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:29:01.099400 14063 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:29:01.099411 14063 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:29:01.099414 14063 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:29:01.099421 14063 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:29:01.099429 14063 net.cpp:124] Setting up relu6\n",
      "I0430 10:29:01.099433 14063 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:29:01.099436 14063 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:29:01.099438 14063 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:29:01.099443 14063 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:29:01.099445 14063 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:29:01.099448 14063 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:29:01.099453 14063 net.cpp:124] Setting up drop6\n",
      "I0430 10:29:01.099457 14063 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:29:01.099458 14063 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:29:01.099460 14063 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:29:01.099467 14063 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:29:01.099468 14063 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:29:01.099472 14063 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:29:01.109473 14063 net.cpp:124] Setting up fc7\n",
      "I0430 10:29:01.109500 14063 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:29:01.109503 14063 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:29:01.109531 14063 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:29:01.109540 14063 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:29:01.109544 14063 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:29:01.109551 14063 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:29:01.109558 14063 net.cpp:124] Setting up relu7\n",
      "I0430 10:29:01.109563 14063 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:29:01.109565 14063 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:29:01.109570 14063 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:29:01.109578 14063 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:29:01.109580 14063 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:29:01.109585 14063 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:29:01.109588 14063 net.cpp:124] Setting up drop7\n",
      "I0430 10:29:01.109592 14063 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:29:01.109594 14063 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:29:01.109597 14063 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:29:01.109601 14063 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:29:01.109603 14063 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:29:01.109606 14063 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:29:01.110647 14063 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:29:01.110667 14063 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:29:01.110671 14063 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:29:01.110677 14063 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:29:01.110680 14063 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:29:01.110682 14063 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:29:01.110684 14063 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:29:01.110687 14063 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:29:01.110688 14063 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:29:01.110692 14063 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:29:01.110693 14063 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:29:01.110695 14063 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:29:01.110697 14063 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:29:01.110699 14063 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:29:01.110702 14063 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:29:01.110703 14063 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:29:01.110707 14063 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:29:01.110709 14063 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:29:01.110713 14063 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:29:01.110715 14063 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:29:01.110718 14063 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:29:01.110720 14063 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:29:01.110723 14063 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:29:01.110726 14063 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:29:01.110728 14063 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:29:01.110731 14063 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:29:01.110733 14063 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:29:01.110744 14063 net.cpp:257] Network initialization done.\n",
      "I0430 10:29:01.197096 14063 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:29:01.299836 14063 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:29:01.300818 14063 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:29:01.300825 14063 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:29:01.300827 14063 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/256197.jpg'}, '/tmp/tmpk15JlJ.mat')\n",
      "Processed 2486 windows in 276.610 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-2.09207, -2.11867, -1.66586, -1.92383, -1.76...\n",
      "ymin                                                        205\n",
      "xmin                                                        336\n",
      "ymax                                                        260\n",
      "xmax                                                        394\n",
      "Name: /home/ambika/INF_project/data/person/256197.jpg, dtype: object\n",
      "prediction    [-1.83204, -2.76785, -2.18751, -2.81282, -2.37...\n",
      "ymin                                                        136\n",
      "xmin                                                         42\n",
      "ymax                                                        324\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/person/256197.jpg, dtype: object\n",
      "strawberry\n",
      "336\t205\t394\t260\n",
      "lobster\n",
      "42\t136\t500\t324\n",
      "256197\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:33:39.463955 14276 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:33:39.463977 14276 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:33:39.463986 14276 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:33:39.465100 14276 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:33:39.465175 14276 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:33:39.465183 14276 net.cpp:86] Creating Layer data\n",
      "I0430 10:33:39.465185 14276 net.cpp:382] data -> data\n",
      "I0430 10:33:39.465198 14276 net.cpp:124] Setting up data\n",
      "I0430 10:33:39.465203 14276 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:33:39.465204 14276 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:33:39.465207 14276 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:33:39.465214 14276 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:33:39.465216 14276 net.cpp:408] conv1 <- data\n",
      "I0430 10:33:39.465220 14276 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:33:39.465282 14276 net.cpp:124] Setting up conv1\n",
      "I0430 10:33:39.465287 14276 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:33:39.465289 14276 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:33:39.465296 14276 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:33:39.465301 14276 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:33:39.465303 14276 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:33:39.465307 14276 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:33:39.465312 14276 net.cpp:124] Setting up relu1\n",
      "I0430 10:33:39.465314 14276 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:33:39.465317 14276 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:33:39.465318 14276 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:33:39.465322 14276 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:33:39.465324 14276 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:33:39.465327 14276 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:33:39.465342 14276 net.cpp:124] Setting up pool1\n",
      "I0430 10:33:39.465345 14276 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:33:39.465348 14276 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:33:39.465349 14276 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:33:39.465353 14276 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:33:39.465356 14276 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:33:39.465359 14276 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:33:39.465364 14276 net.cpp:124] Setting up norm1\n",
      "I0430 10:33:39.465368 14276 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:33:39.465369 14276 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:33:39.465371 14276 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:33:39.465375 14276 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:33:39.465378 14276 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:33:39.465381 14276 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:33:39.465726 14276 net.cpp:124] Setting up conv2\n",
      "I0430 10:33:39.465731 14276 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:33:39.465734 14276 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:33:39.465739 14276 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:33:39.465742 14276 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:33:39.465745 14276 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:33:39.465749 14276 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:33:39.465752 14276 net.cpp:124] Setting up relu2\n",
      "I0430 10:33:39.465755 14276 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:33:39.465759 14276 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:33:39.465760 14276 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:33:39.465765 14276 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:33:39.465767 14276 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:33:39.465770 14276 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:33:39.465775 14276 net.cpp:124] Setting up pool2\n",
      "I0430 10:33:39.465778 14276 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:33:39.465780 14276 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:33:39.465783 14276 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:33:39.465787 14276 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:33:39.465790 14276 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:33:39.465792 14276 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:33:39.465797 14276 net.cpp:124] Setting up norm2\n",
      "I0430 10:33:39.465801 14276 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:33:39.465802 14276 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:33:39.465804 14276 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:33:39.465809 14276 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:33:39.465811 14276 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:33:39.465816 14276 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:33:39.466778 14276 net.cpp:124] Setting up conv3\n",
      "I0430 10:33:39.466789 14276 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:33:39.466790 14276 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:33:39.466797 14276 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:33:39.466804 14276 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:33:39.466805 14276 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:33:39.466809 14276 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:33:39.466814 14276 net.cpp:124] Setting up relu3\n",
      "I0430 10:33:39.466817 14276 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:33:39.466820 14276 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:33:39.466821 14276 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:33:39.466827 14276 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:33:39.466830 14276 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:33:39.466833 14276 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:33:39.467557 14276 net.cpp:124] Setting up conv4\n",
      "I0430 10:33:39.467566 14276 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:33:39.467567 14276 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:33:39.467572 14276 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:33:39.467576 14276 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:33:39.467579 14276 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:33:39.467583 14276 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:33:39.467587 14276 net.cpp:124] Setting up relu4\n",
      "I0430 10:33:39.467591 14276 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:33:39.467593 14276 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:33:39.467595 14276 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:33:39.467600 14276 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:33:39.467602 14276 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:33:39.467607 14276 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:33:39.468103 14276 net.cpp:124] Setting up conv5\n",
      "I0430 10:33:39.468111 14276 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:33:39.468116 14276 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:33:39.468127 14276 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:33:39.468132 14276 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:33:39.468134 14276 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:33:39.468216 14276 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:33:39.468224 14276 net.cpp:124] Setting up relu5\n",
      "I0430 10:33:39.468230 14276 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:33:39.468232 14276 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:33:39.468235 14276 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:33:39.468240 14276 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:33:39.468241 14276 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:33:39.468245 14276 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:33:39.468251 14276 net.cpp:124] Setting up pool5\n",
      "I0430 10:33:39.468255 14276 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:33:39.468257 14276 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:33:39.468260 14276 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:33:39.468266 14276 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:33:39.468269 14276 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:33:39.468272 14276 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:33:39.489434 14276 net.cpp:124] Setting up fc6\n",
      "I0430 10:33:39.489455 14276 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:33:39.489457 14276 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:33:39.489464 14276 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:33:39.489472 14276 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:33:39.489475 14276 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:33:39.489478 14276 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:33:39.489485 14276 net.cpp:124] Setting up relu6\n",
      "I0430 10:33:39.489490 14276 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:33:39.489491 14276 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:33:39.489495 14276 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:33:39.489501 14276 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:33:39.489504 14276 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:33:39.489507 14276 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:33:39.489512 14276 net.cpp:124] Setting up drop6\n",
      "I0430 10:33:39.489516 14276 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:33:39.489517 14276 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:33:39.489519 14276 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:33:39.489523 14276 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:33:39.489526 14276 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:33:39.489531 14276 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:33:39.499070 14276 net.cpp:124] Setting up fc7\n",
      "I0430 10:33:39.499092 14276 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:33:39.499095 14276 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:33:39.499116 14276 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:33:39.499125 14276 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:33:39.499127 14276 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:33:39.499132 14276 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:33:39.499138 14276 net.cpp:124] Setting up relu7\n",
      "I0430 10:33:39.499141 14276 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:33:39.499143 14276 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:33:39.499146 14276 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:33:39.499150 14276 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:33:39.499152 14276 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:33:39.499156 14276 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:33:39.499161 14276 net.cpp:124] Setting up drop7\n",
      "I0430 10:33:39.499164 14276 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:33:39.499166 14276 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:33:39.499168 14276 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:33:39.499172 14276 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:33:39.499174 14276 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:33:39.499177 14276 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:33:39.499800 14276 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:33:39.499809 14276 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:33:39.499810 14276 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:33:39.499815 14276 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:33:39.499819 14276 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:33:39.499821 14276 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:33:39.499824 14276 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:33:39.499826 14276 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:33:39.499830 14276 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:33:39.499831 14276 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:33:39.499835 14276 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:33:39.499837 14276 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:33:39.499840 14276 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:33:39.499842 14276 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:33:39.499845 14276 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:33:39.499847 14276 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:33:39.499850 14276 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:33:39.499852 14276 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:33:39.499855 14276 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:33:39.499858 14276 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:33:39.499861 14276 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:33:39.499863 14276 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:33:39.499866 14276 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:33:39.499868 14276 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:33:39.499871 14276 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:33:39.499873 14276 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:33:39.499876 14276 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:33:39.499886 14276 net.cpp:257] Network initialization done.\n",
      "I0430 10:33:39.587168 14276 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:33:39.691406 14276 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:33:39.692613 14276 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:33:39.692627 14276 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:33:39.692631 14276 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/13415.jpg'}, '/tmp/tmpSHUiWq.mat')\n",
      "Processed 1783 windows in 206.211 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-1.69869, -2.1064, -1.7902, -1.4412, -1.74917...\n",
      "ymin                                                        184\n",
      "xmin                                                        103\n",
      "ymax                                                        224\n",
      "xmax                                                        126\n",
      "Name: /home/ambika/INF_project/data/train/13415.jpg, dtype: object\n",
      "prediction    [-1.91317, -2.37435, -2.15765, -2.48024, -1.99...\n",
      "ymin                                                          0\n",
      "xmin                                                        101\n",
      "ymax                                                        297\n",
      "xmax                                                        398\n",
      "Name: /home/ambika/INF_project/data/train/13415.jpg, dtype: object\n",
      "traffic light\n",
      "103\t184\t126\t224\n",
      "snowplow\n",
      "101\t0\t398\t297\n",
      "13415\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:37:07.427301 14498 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:37:07.427320 14498 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:37:07.427321 14498 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:37:07.428395 14498 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:37:07.428470 14498 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:37:07.428478 14498 net.cpp:86] Creating Layer data\n",
      "I0430 10:37:07.428481 14498 net.cpp:382] data -> data\n",
      "I0430 10:37:07.428490 14498 net.cpp:124] Setting up data\n",
      "I0430 10:37:07.428495 14498 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:37:07.428498 14498 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:37:07.428500 14498 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:37:07.428506 14498 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:37:07.428509 14498 net.cpp:408] conv1 <- data\n",
      "I0430 10:37:07.428514 14498 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:37:07.428570 14498 net.cpp:124] Setting up conv1\n",
      "I0430 10:37:07.428575 14498 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:37:07.428576 14498 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:37:07.428583 14498 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:37:07.428588 14498 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:37:07.428591 14498 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:37:07.428594 14498 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:37:07.428598 14498 net.cpp:124] Setting up relu1\n",
      "I0430 10:37:07.428601 14498 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:37:07.428604 14498 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:37:07.428606 14498 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:37:07.428611 14498 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:37:07.428612 14498 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:37:07.428616 14498 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:37:07.428622 14498 net.cpp:124] Setting up pool1\n",
      "I0430 10:37:07.428625 14498 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:37:07.428627 14498 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:37:07.428629 14498 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:37:07.428633 14498 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:37:07.428637 14498 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:37:07.428639 14498 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:37:07.428644 14498 net.cpp:124] Setting up norm1\n",
      "I0430 10:37:07.428647 14498 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:37:07.428649 14498 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:37:07.428653 14498 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:37:07.428656 14498 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:37:07.428658 14498 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:37:07.428661 14498 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:37:07.429005 14498 net.cpp:124] Setting up conv2\n",
      "I0430 10:37:07.429011 14498 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:37:07.429013 14498 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:37:07.429018 14498 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:37:07.429023 14498 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:37:07.429025 14498 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:37:07.429028 14498 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:37:07.429033 14498 net.cpp:124] Setting up relu2\n",
      "I0430 10:37:07.429035 14498 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:37:07.429038 14498 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:37:07.429040 14498 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:37:07.429044 14498 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:37:07.429045 14498 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:37:07.429049 14498 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:37:07.429054 14498 net.cpp:124] Setting up pool2\n",
      "I0430 10:37:07.429057 14498 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:37:07.429059 14498 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:37:07.429061 14498 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:37:07.429066 14498 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:37:07.429069 14498 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:37:07.429072 14498 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:37:07.429076 14498 net.cpp:124] Setting up norm2\n",
      "I0430 10:37:07.429080 14498 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:37:07.429082 14498 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:37:07.429085 14498 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:37:07.429090 14498 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:37:07.429091 14498 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:37:07.429095 14498 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:37:07.430090 14498 net.cpp:124] Setting up conv3\n",
      "I0430 10:37:07.430105 14498 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:37:07.430109 14498 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:37:07.430117 14498 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:37:07.430124 14498 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:37:07.430126 14498 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:37:07.430131 14498 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:37:07.430137 14498 net.cpp:124] Setting up relu3\n",
      "I0430 10:37:07.430140 14498 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:37:07.430142 14498 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:37:07.430145 14498 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:37:07.430151 14498 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:37:07.430153 14498 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:37:07.430157 14498 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:37:07.430603 14498 net.cpp:124] Setting up conv4\n",
      "I0430 10:37:07.430609 14498 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:37:07.430611 14498 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:37:07.430616 14498 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:37:07.430620 14498 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:37:07.430624 14498 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:37:07.430626 14498 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:37:07.430630 14498 net.cpp:124] Setting up relu4\n",
      "I0430 10:37:07.430634 14498 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:37:07.430635 14498 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:37:07.430639 14498 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:37:07.430642 14498 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:37:07.430645 14498 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:37:07.430649 14498 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:37:07.431124 14498 net.cpp:124] Setting up conv5\n",
      "I0430 10:37:07.431130 14498 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:37:07.431133 14498 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:37:07.431140 14498 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:37:07.431144 14498 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:37:07.431147 14498 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:37:07.431151 14498 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:37:07.431155 14498 net.cpp:124] Setting up relu5\n",
      "I0430 10:37:07.431159 14498 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:37:07.431160 14498 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:37:07.431164 14498 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:37:07.431167 14498 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:37:07.431169 14498 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:37:07.431174 14498 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:37:07.431180 14498 net.cpp:124] Setting up pool5\n",
      "I0430 10:37:07.431183 14498 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:37:07.431185 14498 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:37:07.431188 14498 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:37:07.431197 14498 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:37:07.431200 14498 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:37:07.431203 14498 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:37:07.452347 14498 net.cpp:124] Setting up fc6\n",
      "I0430 10:37:07.452373 14498 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:37:07.452378 14498 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:37:07.452405 14498 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:37:07.452416 14498 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:37:07.452421 14498 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:37:07.452428 14498 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:37:07.452436 14498 net.cpp:124] Setting up relu6\n",
      "I0430 10:37:07.452440 14498 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:37:07.452443 14498 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:37:07.452447 14498 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:37:07.452453 14498 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:37:07.452455 14498 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:37:07.452461 14498 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:37:07.452466 14498 net.cpp:124] Setting up drop6\n",
      "I0430 10:37:07.452469 14498 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:37:07.452471 14498 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:37:07.452474 14498 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:37:07.452479 14498 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:37:07.452482 14498 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:37:07.452487 14498 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:37:07.462273 14498 net.cpp:124] Setting up fc7\n",
      "I0430 10:37:07.462301 14498 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:37:07.462304 14498 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:37:07.462316 14498 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:37:07.462324 14498 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:37:07.462328 14498 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:37:07.462334 14498 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:37:07.462342 14498 net.cpp:124] Setting up relu7\n",
      "I0430 10:37:07.462347 14498 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:37:07.462348 14498 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:37:07.462352 14498 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:37:07.462357 14498 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:37:07.462359 14498 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:37:07.462364 14498 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:37:07.462370 14498 net.cpp:124] Setting up drop7\n",
      "I0430 10:37:07.462374 14498 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:37:07.462376 14498 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:37:07.462379 14498 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:37:07.462384 14498 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:37:07.462386 14498 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:37:07.462391 14498 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:37:07.463027 14498 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:37:07.463040 14498 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:37:07.463043 14498 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:37:07.463052 14498 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:37:07.463054 14498 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:37:07.463057 14498 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:37:07.463060 14498 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:37:07.463063 14498 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:37:07.463066 14498 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:37:07.463069 14498 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:37:07.463073 14498 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:37:07.463076 14498 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:37:07.463079 14498 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:37:07.463083 14498 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:37:07.463085 14498 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:37:07.463088 14498 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:37:07.463091 14498 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:37:07.463094 14498 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:37:07.463098 14498 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:37:07.463101 14498 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:37:07.463104 14498 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:37:07.463107 14498 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:37:07.463110 14498 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:37:07.463114 14498 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:37:07.463116 14498 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:37:07.463119 14498 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:37:07.463122 14498 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:37:07.463135 14498 net.cpp:257] Network initialization done.\n",
      "I0430 10:37:07.547767 14498 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:37:07.645861 14498 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:37:07.647125 14498 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:37:07.647138 14498 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:37:07.647143 14498 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/511469.jpg'}, '/tmp/tmpl51H2I.mat')\n",
      "Processed 1379 windows in 155.465 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-2.39814, -3.00026, -2.19422, -1.94382, -1.81...\n",
      "ymin                                                        203\n",
      "xmin                                                         49\n",
      "ymax                                                        315\n",
      "xmax                                                         79\n",
      "Name: /home/ambika/INF_project/data/airplane/511469.jpg, dtype: object\n",
      "prediction    [-2.65248, 0.821704, -2.26925, -1.8827, -1.956...\n",
      "ymin                                                         72\n",
      "xmin                                                        153\n",
      "ymax                                                        311\n",
      "xmax                                                        447\n",
      "Name: /home/ambika/INF_project/data/airplane/511469.jpg, dtype: object\n",
      "person\n",
      "49\t203\t79\t315\n",
      "airplane\n",
      "153\t72\t447\t311\n",
      "511469\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:39:44.607513 14666 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:39:44.607532 14666 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:39:44.607537 14666 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:39:44.608613 14666 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:39:44.608772 14666 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:39:44.608783 14666 net.cpp:86] Creating Layer data\n",
      "I0430 10:39:44.608788 14666 net.cpp:382] data -> data\n",
      "I0430 10:39:44.608801 14666 net.cpp:124] Setting up data\n",
      "I0430 10:39:44.608806 14666 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:39:44.608808 14666 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:39:44.608811 14666 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:39:44.608817 14666 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:39:44.608820 14666 net.cpp:408] conv1 <- data\n",
      "I0430 10:39:44.608824 14666 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:39:44.608880 14666 net.cpp:124] Setting up conv1\n",
      "I0430 10:39:44.608885 14666 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:39:44.608887 14666 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:39:44.608893 14666 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:39:44.608898 14666 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:39:44.608901 14666 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:39:44.608904 14666 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:39:44.608908 14666 net.cpp:124] Setting up relu1\n",
      "I0430 10:39:44.608911 14666 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:39:44.608913 14666 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:39:44.608916 14666 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:39:44.608919 14666 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:39:44.608922 14666 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:39:44.608924 14666 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:39:44.608932 14666 net.cpp:124] Setting up pool1\n",
      "I0430 10:39:44.608934 14666 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:39:44.608937 14666 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:39:44.608939 14666 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:39:44.608943 14666 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:39:44.608945 14666 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:39:44.608949 14666 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:39:44.608954 14666 net.cpp:124] Setting up norm1\n",
      "I0430 10:39:44.608958 14666 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:39:44.608959 14666 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:39:44.608961 14666 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:39:44.608965 14666 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:39:44.608968 14666 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:39:44.608971 14666 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:39:44.609297 14666 net.cpp:124] Setting up conv2\n",
      "I0430 10:39:44.609302 14666 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:39:44.609304 14666 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:39:44.609309 14666 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:39:44.609313 14666 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:39:44.609315 14666 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:39:44.609318 14666 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:39:44.609323 14666 net.cpp:124] Setting up relu2\n",
      "I0430 10:39:44.609325 14666 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:39:44.609328 14666 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:39:44.609329 14666 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:39:44.609333 14666 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:39:44.609335 14666 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:39:44.609338 14666 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:39:44.609344 14666 net.cpp:124] Setting up pool2\n",
      "I0430 10:39:44.609346 14666 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:39:44.609349 14666 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:39:44.609351 14666 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:39:44.609356 14666 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:39:44.609359 14666 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:39:44.609361 14666 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:39:44.609366 14666 net.cpp:124] Setting up norm2\n",
      "I0430 10:39:44.609369 14666 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:39:44.609371 14666 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:39:44.609374 14666 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:39:44.609378 14666 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:39:44.609381 14666 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:39:44.609385 14666 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:39:44.610052 14666 net.cpp:124] Setting up conv3\n",
      "I0430 10:39:44.610062 14666 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:39:44.610064 14666 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:39:44.610071 14666 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:39:44.610076 14666 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:39:44.610079 14666 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:39:44.610082 14666 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:39:44.610087 14666 net.cpp:124] Setting up relu3\n",
      "I0430 10:39:44.610090 14666 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:39:44.610092 14666 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:39:44.610095 14666 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:39:44.610100 14666 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:39:44.610102 14666 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:39:44.610106 14666 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:39:44.610822 14666 net.cpp:124] Setting up conv4\n",
      "I0430 10:39:44.610828 14666 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:39:44.610831 14666 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:39:44.610836 14666 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:39:44.610841 14666 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:39:44.610842 14666 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:39:44.610846 14666 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:39:44.610849 14666 net.cpp:124] Setting up relu4\n",
      "I0430 10:39:44.610852 14666 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:39:44.610854 14666 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:39:44.610857 14666 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:39:44.610862 14666 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:39:44.610864 14666 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:39:44.610867 14666 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:39:44.611359 14666 net.cpp:124] Setting up conv5\n",
      "I0430 10:39:44.611367 14666 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:39:44.611369 14666 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:39:44.611377 14666 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:39:44.611382 14666 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:39:44.611383 14666 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:39:44.611387 14666 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:39:44.611392 14666 net.cpp:124] Setting up relu5\n",
      "I0430 10:39:44.611394 14666 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:39:44.611397 14666 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:39:44.611398 14666 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:39:44.611405 14666 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:39:44.611407 14666 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:39:44.611412 14666 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:39:44.611418 14666 net.cpp:124] Setting up pool5\n",
      "I0430 10:39:44.611420 14666 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:39:44.611423 14666 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:39:44.611425 14666 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:39:44.611431 14666 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:39:44.611433 14666 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:39:44.611438 14666 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:39:44.632896 14666 net.cpp:124] Setting up fc6\n",
      "I0430 10:39:44.632922 14666 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:39:44.632925 14666 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:39:44.632956 14666 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:39:44.632979 14666 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:39:44.632985 14666 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:39:44.632998 14666 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:39:44.633010 14666 net.cpp:124] Setting up relu6\n",
      "I0430 10:39:44.633018 14666 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:39:44.633028 14666 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:39:44.633033 14666 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:39:44.633040 14666 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:39:44.633045 14666 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:39:44.633051 14666 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:39:44.633060 14666 net.cpp:124] Setting up drop6\n",
      "I0430 10:39:44.633066 14666 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:39:44.633070 14666 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:39:44.633075 14666 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:39:44.633082 14666 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:39:44.633088 14666 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:39:44.633095 14666 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:39:44.642817 14666 net.cpp:124] Setting up fc7\n",
      "I0430 10:39:44.642837 14666 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:39:44.642839 14666 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:39:44.642850 14666 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:39:44.642858 14666 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:39:44.642863 14666 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:39:44.642868 14666 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:39:44.642875 14666 net.cpp:124] Setting up relu7\n",
      "I0430 10:39:44.642879 14666 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:39:44.642882 14666 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:39:44.642885 14666 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:39:44.642890 14666 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:39:44.642894 14666 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:39:44.642899 14666 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:39:44.642904 14666 net.cpp:124] Setting up drop7\n",
      "I0430 10:39:44.642909 14666 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:39:44.642910 14666 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:39:44.642913 14666 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:39:44.642918 14666 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:39:44.642921 14666 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:39:44.642926 14666 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:39:44.643847 14666 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:39:44.643863 14666 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:39:44.643867 14666 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:39:44.643875 14666 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:39:44.643879 14666 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:39:44.643882 14666 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:39:44.643885 14666 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:39:44.643889 14666 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:39:44.643893 14666 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:39:44.643895 14666 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:39:44.643899 14666 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:39:44.643903 14666 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:39:44.643906 14666 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:39:44.643909 14666 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:39:44.643913 14666 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:39:44.643916 14666 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:39:44.643919 14666 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:39:44.643929 14666 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:39:44.643931 14666 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:39:44.643934 14666 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:39:44.643939 14666 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:39:44.643941 14666 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:39:44.643945 14666 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:39:44.643949 14666 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:39:44.643951 14666 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:39:44.643955 14666 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:39:44.643959 14666 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:39:44.643970 14666 net.cpp:257] Network initialization done.\n",
      "I0430 10:39:44.728094 14666 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:39:44.826189 14666 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:39:44.827471 14666 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:39:44.827484 14666 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:39:44.827489 14666 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/265001.jpg'}, '/tmp/tmpUMzBmQ.mat')\n",
      "Processed 1064 windows in 120.625 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.026 s.\n",
      "prediction    [-2.25078, -2.01593, -1.22372, -1.65076, -1.66...\n",
      "ymin                                                        152\n",
      "xmin                                                        215\n",
      "ymax                                                        252\n",
      "xmax                                                        305\n",
      "Name: /home/ambika/INF_project/data/bird/265001.jpg, dtype: object\n",
      "prediction    [-2.25078, -2.01593, -1.22372, -1.65076, -1.66...\n",
      "ymin                                                        152\n",
      "xmin                                                        215\n",
      "ymax                                                        252\n",
      "xmax                                                        305\n",
      "Name: /home/ambika/INF_project/data/bird/265001.jpg, dtype: object\n",
      "bird\n",
      "215\t152\t305\t252\n",
      "ladybug\n",
      "215\t152\t305\t252\n",
      "265001\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:41:46.947356 14817 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:41:46.947373 14817 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:41:46.947376 14817 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:41:46.948454 14817 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:41:46.948528 14817 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:41:46.948536 14817 net.cpp:86] Creating Layer data\n",
      "I0430 10:41:46.948540 14817 net.cpp:382] data -> data\n",
      "I0430 10:41:46.948552 14817 net.cpp:124] Setting up data\n",
      "I0430 10:41:46.948557 14817 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:41:46.948559 14817 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:41:46.948562 14817 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:41:46.948568 14817 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:41:46.948571 14817 net.cpp:408] conv1 <- data\n",
      "I0430 10:41:46.948575 14817 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:41:46.948634 14817 net.cpp:124] Setting up conv1\n",
      "I0430 10:41:46.948638 14817 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:41:46.948642 14817 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:41:46.948648 14817 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:41:46.948652 14817 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:41:46.948655 14817 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:41:46.948658 14817 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:41:46.948662 14817 net.cpp:124] Setting up relu1\n",
      "I0430 10:41:46.948665 14817 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:41:46.948668 14817 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:41:46.948670 14817 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:41:46.948673 14817 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:41:46.948676 14817 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:41:46.948679 14817 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:41:46.948685 14817 net.cpp:124] Setting up pool1\n",
      "I0430 10:41:46.948688 14817 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:41:46.948690 14817 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:41:46.948693 14817 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:41:46.948696 14817 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:41:46.948699 14817 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:41:46.948703 14817 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:41:46.948707 14817 net.cpp:124] Setting up norm1\n",
      "I0430 10:41:46.948710 14817 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:41:46.948712 14817 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:41:46.948714 14817 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:41:46.948719 14817 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:41:46.948721 14817 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:41:46.948724 14817 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:41:46.949067 14817 net.cpp:124] Setting up conv2\n",
      "I0430 10:41:46.949074 14817 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:41:46.949076 14817 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:41:46.949081 14817 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:41:46.949086 14817 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:41:46.949089 14817 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:41:46.949092 14817 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:41:46.949096 14817 net.cpp:124] Setting up relu2\n",
      "I0430 10:41:46.949100 14817 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:41:46.949101 14817 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:41:46.949103 14817 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:41:46.949107 14817 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:41:46.949110 14817 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:41:46.949112 14817 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:41:46.949117 14817 net.cpp:124] Setting up pool2\n",
      "I0430 10:41:46.949120 14817 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:41:46.949123 14817 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:41:46.949126 14817 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:41:46.949133 14817 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:41:46.949136 14817 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:41:46.949138 14817 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:41:46.949143 14817 net.cpp:124] Setting up norm2\n",
      "I0430 10:41:46.949146 14817 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:41:46.949148 14817 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:41:46.949151 14817 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:41:46.949156 14817 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:41:46.949158 14817 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:41:46.949162 14817 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:41:46.949837 14817 net.cpp:124] Setting up conv3\n",
      "I0430 10:41:46.949844 14817 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:41:46.949847 14817 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:41:46.949854 14817 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:41:46.949859 14817 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:41:46.949862 14817 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:41:46.949865 14817 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:41:46.949869 14817 net.cpp:124] Setting up relu3\n",
      "I0430 10:41:46.949873 14817 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:41:46.949875 14817 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:41:46.949877 14817 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:41:46.949883 14817 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:41:46.949885 14817 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:41:46.949889 14817 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:41:46.950601 14817 net.cpp:124] Setting up conv4\n",
      "I0430 10:41:46.950609 14817 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:41:46.950611 14817 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:41:46.950616 14817 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:41:46.950620 14817 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:41:46.950623 14817 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:41:46.950626 14817 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:41:46.950629 14817 net.cpp:124] Setting up relu4\n",
      "I0430 10:41:46.950633 14817 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:41:46.950635 14817 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:41:46.950637 14817 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:41:46.950644 14817 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:41:46.950645 14817 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:41:46.950649 14817 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:41:46.951159 14817 net.cpp:124] Setting up conv5\n",
      "I0430 10:41:46.951169 14817 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:41:46.951171 14817 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:41:46.951180 14817 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:41:46.951184 14817 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:41:46.951187 14817 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:41:46.951191 14817 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:41:46.951195 14817 net.cpp:124] Setting up relu5\n",
      "I0430 10:41:46.951198 14817 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:41:46.951200 14817 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:41:46.951203 14817 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:41:46.951213 14817 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:41:46.951216 14817 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:41:46.951222 14817 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:41:46.951231 14817 net.cpp:124] Setting up pool5\n",
      "I0430 10:41:46.951234 14817 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:41:46.951236 14817 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:41:46.951239 14817 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:41:46.951246 14817 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:41:46.951248 14817 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:41:46.951251 14817 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:41:46.973136 14817 net.cpp:124] Setting up fc6\n",
      "I0430 10:41:46.973161 14817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:41:46.973166 14817 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:41:46.973176 14817 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:41:46.973183 14817 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:41:46.973186 14817 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:41:46.973191 14817 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:41:46.973198 14817 net.cpp:124] Setting up relu6\n",
      "I0430 10:41:46.973201 14817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:41:46.973203 14817 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:41:46.973206 14817 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:41:46.973212 14817 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:41:46.973214 14817 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:41:46.973217 14817 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:41:46.973222 14817 net.cpp:124] Setting up drop6\n",
      "I0430 10:41:46.973225 14817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:41:46.973227 14817 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:41:46.973229 14817 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:41:46.973235 14817 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:41:46.973238 14817 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:41:46.973242 14817 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:41:46.982847 14817 net.cpp:124] Setting up fc7\n",
      "I0430 10:41:46.982870 14817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:41:46.982874 14817 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:41:46.982882 14817 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:41:46.982889 14817 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:41:46.982892 14817 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:41:46.982895 14817 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:41:46.982902 14817 net.cpp:124] Setting up relu7\n",
      "I0430 10:41:46.982903 14817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:41:46.982905 14817 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:41:46.982906 14817 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:41:46.982913 14817 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:41:46.982914 14817 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:41:46.982916 14817 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:41:46.982920 14817 net.cpp:124] Setting up drop7\n",
      "I0430 10:41:46.982923 14817 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:41:46.982924 14817 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:41:46.982925 14817 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:41:46.982929 14817 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:41:46.982944 14817 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:41:46.982947 14817 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:41:46.983853 14817 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:41:46.983863 14817 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:41:46.983866 14817 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:41:46.983873 14817 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:41:46.983875 14817 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:41:46.983877 14817 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:41:46.983880 14817 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:41:46.983881 14817 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:41:46.983883 14817 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:41:46.983886 14817 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:41:46.983887 14817 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:41:46.983889 14817 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:41:46.983892 14817 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:41:46.983896 14817 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:41:46.983897 14817 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:41:46.983901 14817 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:41:46.983903 14817 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:41:46.983906 14817 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:41:46.983909 14817 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:41:46.983911 14817 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:41:46.983914 14817 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:41:46.983917 14817 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:41:46.983919 14817 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:41:46.983922 14817 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:41:46.983925 14817 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:41:46.983927 14817 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:41:46.983930 14817 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:41:46.983940 14817 net.cpp:257] Network initialization done.\n",
      "I0430 10:41:47.070205 14817 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:41:47.171388 14817 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:41:47.172456 14817 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:41:47.172467 14817 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:41:47.172472 14817 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/351554.jpg'}, '/tmp/tmpckuhof.mat')\n",
      "Processed 1266 windows in 141.560 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.027 s.\n",
      "prediction    [-1.59289, -2.65261, -1.99944, -2.08843, -2.12...\n",
      "ymin                                                        164\n",
      "xmin                                                        210\n",
      "ymax                                                        333\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/bus/351554.jpg, dtype: object\n",
      "prediction    [-2.12094, -2.27344, -2.02767, -2.03186, -2.65...\n",
      "ymin                                                        177\n",
      "xmin                                                         26\n",
      "ymax                                                        313\n",
      "xmax                                                        162\n",
      "Name: /home/ambika/INF_project/data/bus/351554.jpg, dtype: object\n",
      "tape player\n",
      "210\t164\t500\t333\n",
      "traffic light\n",
      "26\t177\t162\t313\n",
      "351554\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:44:10.220399 14974 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:44:10.220418 14974 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:44:10.220422 14974 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:44:10.221545 14974 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:44:10.221707 14974 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:44:10.221714 14974 net.cpp:86] Creating Layer data\n",
      "I0430 10:44:10.221717 14974 net.cpp:382] data -> data\n",
      "I0430 10:44:10.221729 14974 net.cpp:124] Setting up data\n",
      "I0430 10:44:10.221735 14974 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:44:10.221736 14974 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:44:10.221740 14974 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:44:10.221745 14974 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:44:10.221747 14974 net.cpp:408] conv1 <- data\n",
      "I0430 10:44:10.221751 14974 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:44:10.221808 14974 net.cpp:124] Setting up conv1\n",
      "I0430 10:44:10.221813 14974 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:44:10.221815 14974 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:44:10.221822 14974 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:44:10.221827 14974 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:44:10.221828 14974 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:44:10.221832 14974 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:44:10.221837 14974 net.cpp:124] Setting up relu1\n",
      "I0430 10:44:10.221839 14974 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:44:10.221842 14974 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:44:10.221844 14974 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:44:10.221848 14974 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:44:10.221850 14974 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:44:10.221853 14974 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:44:10.221859 14974 net.cpp:124] Setting up pool1\n",
      "I0430 10:44:10.221863 14974 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:44:10.221864 14974 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:44:10.221866 14974 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:44:10.221871 14974 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:44:10.221873 14974 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:44:10.221876 14974 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:44:10.221881 14974 net.cpp:124] Setting up norm1\n",
      "I0430 10:44:10.221884 14974 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:44:10.221886 14974 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:44:10.221889 14974 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:44:10.221892 14974 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:44:10.221895 14974 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:44:10.221899 14974 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:44:10.222218 14974 net.cpp:124] Setting up conv2\n",
      "I0430 10:44:10.222223 14974 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:44:10.222226 14974 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:44:10.222231 14974 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:44:10.222234 14974 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:44:10.222237 14974 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:44:10.222240 14974 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:44:10.222244 14974 net.cpp:124] Setting up relu2\n",
      "I0430 10:44:10.222247 14974 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:44:10.222249 14974 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:44:10.222251 14974 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:44:10.222254 14974 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:44:10.222257 14974 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:44:10.222260 14974 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:44:10.222265 14974 net.cpp:124] Setting up pool2\n",
      "I0430 10:44:10.222268 14974 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:44:10.222270 14974 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:44:10.222272 14974 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:44:10.222277 14974 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:44:10.222280 14974 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:44:10.222282 14974 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:44:10.222287 14974 net.cpp:124] Setting up norm2\n",
      "I0430 10:44:10.222290 14974 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:44:10.222292 14974 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:44:10.222295 14974 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:44:10.222299 14974 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:44:10.222301 14974 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:44:10.222304 14974 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:44:10.222981 14974 net.cpp:124] Setting up conv3\n",
      "I0430 10:44:10.222990 14974 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:44:10.222993 14974 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:44:10.223000 14974 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:44:10.223004 14974 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:44:10.223007 14974 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:44:10.223011 14974 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:44:10.223016 14974 net.cpp:124] Setting up relu3\n",
      "I0430 10:44:10.223018 14974 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:44:10.223021 14974 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:44:10.223022 14974 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:44:10.223028 14974 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:44:10.223031 14974 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:44:10.223033 14974 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:44:10.223783 14974 net.cpp:124] Setting up conv4\n",
      "I0430 10:44:10.223793 14974 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:44:10.223794 14974 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:44:10.223800 14974 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:44:10.223804 14974 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:44:10.223806 14974 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:44:10.223811 14974 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:44:10.223815 14974 net.cpp:124] Setting up relu4\n",
      "I0430 10:44:10.223819 14974 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:44:10.223820 14974 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:44:10.223824 14974 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:44:10.223829 14974 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:44:10.223830 14974 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:44:10.223834 14974 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:44:10.224313 14974 net.cpp:124] Setting up conv5\n",
      "I0430 10:44:10.224318 14974 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:44:10.224321 14974 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:44:10.224328 14974 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:44:10.224333 14974 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:44:10.224334 14974 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:44:10.224339 14974 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:44:10.224342 14974 net.cpp:124] Setting up relu5\n",
      "I0430 10:44:10.224345 14974 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:44:10.224347 14974 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:44:10.224350 14974 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:44:10.224354 14974 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:44:10.224356 14974 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:44:10.224359 14974 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:44:10.224365 14974 net.cpp:124] Setting up pool5\n",
      "I0430 10:44:10.224369 14974 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:44:10.224371 14974 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:44:10.224373 14974 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:44:10.224380 14974 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:44:10.224382 14974 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:44:10.224385 14974 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:44:10.245939 14974 net.cpp:124] Setting up fc6\n",
      "I0430 10:44:10.245965 14974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:44:10.245970 14974 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:44:10.245980 14974 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:44:10.245998 14974 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:44:10.246003 14974 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:44:10.246011 14974 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:44:10.246021 14974 net.cpp:124] Setting up relu6\n",
      "I0430 10:44:10.246024 14974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:44:10.246027 14974 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:44:10.246031 14974 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:44:10.246037 14974 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:44:10.246040 14974 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:44:10.246045 14974 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:44:10.246052 14974 net.cpp:124] Setting up drop6\n",
      "I0430 10:44:10.246054 14974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:44:10.246057 14974 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:44:10.246060 14974 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:44:10.246065 14974 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:44:10.246068 14974 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:44:10.246078 14974 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:44:10.255866 14974 net.cpp:124] Setting up fc7\n",
      "I0430 10:44:10.255887 14974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:44:10.255892 14974 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:44:10.255905 14974 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:44:10.255914 14974 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:44:10.255918 14974 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:44:10.255921 14974 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:44:10.255928 14974 net.cpp:124] Setting up relu7\n",
      "I0430 10:44:10.255929 14974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:44:10.255931 14974 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:44:10.255934 14974 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:44:10.255937 14974 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:44:10.255939 14974 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:44:10.255941 14974 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:44:10.255945 14974 net.cpp:124] Setting up drop7\n",
      "I0430 10:44:10.255957 14974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:44:10.255959 14974 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:44:10.255961 14974 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:44:10.255965 14974 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:44:10.255969 14974 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:44:10.255971 14974 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:44:10.256633 14974 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:44:10.256641 14974 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:44:10.256645 14974 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:44:10.256649 14974 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:44:10.256652 14974 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:44:10.256654 14974 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:44:10.256656 14974 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:44:10.256659 14974 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:44:10.256660 14974 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:44:10.256662 14974 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:44:10.256665 14974 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:44:10.256669 14974 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:44:10.256670 14974 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:44:10.256672 14974 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:44:10.256675 14974 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:44:10.256678 14974 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:44:10.256680 14974 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:44:10.256685 14974 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:44:10.256686 14974 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:44:10.256690 14974 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:44:10.256692 14974 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:44:10.256695 14974 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:44:10.256698 14974 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:44:10.256700 14974 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:44:10.256702 14974 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:44:10.256705 14974 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:44:10.256707 14974 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:44:10.256716 14974 net.cpp:257] Network initialization done.\n",
      "I0430 10:44:10.341444 14974 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:44:10.441756 14974 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:44:10.442730 14974 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:44:10.442737 14974 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:44:10.442740 14974 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/27756.jpg'}, '/tmp/tmpxU17Vn.mat')\n",
      "Processed 1901 windows in 212.895 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-2.16628, -2.45875, -1.74426, -1.94475, -1.97...\n",
      "ymin                                                        156\n",
      "xmin                                                        103\n",
      "ymax                                                        202\n",
      "xmax                                                        136\n",
      "Name: /home/ambika/INF_project/data/car/27756.jpg, dtype: object\n",
      "prediction    [-1.68694, -1.94293, -1.86096, -1.82609, -1.81...\n",
      "ymin                                                        288\n",
      "xmin                                                        268\n",
      "ymax                                                        315\n",
      "xmax                                                        299\n",
      "Name: /home/ambika/INF_project/data/car/27756.jpg, dtype: object\n",
      "traffic light\n",
      "103\t156\t136\t202\n",
      "car\n",
      "268\t288\t299\t315\n",
      "27756\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:47:44.847120 15152 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:47:44.847143 15152 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:47:44.847147 15152 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:47:44.848325 15152 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:47:44.848399 15152 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:47:44.848409 15152 net.cpp:86] Creating Layer data\n",
      "I0430 10:47:44.848413 15152 net.cpp:382] data -> data\n",
      "I0430 10:47:44.848426 15152 net.cpp:124] Setting up data\n",
      "I0430 10:47:44.848433 15152 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:47:44.848435 15152 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:47:44.848439 15152 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:47:44.848446 15152 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:47:44.848449 15152 net.cpp:408] conv1 <- data\n",
      "I0430 10:47:44.848454 15152 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:47:44.848515 15152 net.cpp:124] Setting up conv1\n",
      "I0430 10:47:44.848520 15152 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:47:44.848523 15152 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:47:44.848531 15152 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:47:44.848536 15152 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:47:44.848538 15152 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:47:44.848542 15152 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:47:44.848546 15152 net.cpp:124] Setting up relu1\n",
      "I0430 10:47:44.848549 15152 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:47:44.848552 15152 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:47:44.848554 15152 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:47:44.848559 15152 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:47:44.848562 15152 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:47:44.848564 15152 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:47:44.848572 15152 net.cpp:124] Setting up pool1\n",
      "I0430 10:47:44.848575 15152 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:47:44.848578 15152 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:47:44.848582 15152 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:47:44.848587 15152 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:47:44.848588 15152 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:47:44.848592 15152 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:47:44.848598 15152 net.cpp:124] Setting up norm1\n",
      "I0430 10:47:44.848601 15152 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:47:44.848603 15152 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:47:44.848606 15152 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:47:44.848611 15152 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:47:44.848614 15152 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:47:44.848618 15152 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:47:44.848958 15152 net.cpp:124] Setting up conv2\n",
      "I0430 10:47:44.848964 15152 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:47:44.848968 15152 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:47:44.848973 15152 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:47:44.848978 15152 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:47:44.848979 15152 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:47:44.848984 15152 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:47:44.848987 15152 net.cpp:124] Setting up relu2\n",
      "I0430 10:47:44.848991 15152 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:47:44.848994 15152 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:47:44.848997 15152 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:47:44.849001 15152 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:47:44.849004 15152 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:47:44.849009 15152 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:47:44.849014 15152 net.cpp:124] Setting up pool2\n",
      "I0430 10:47:44.849017 15152 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:47:44.849020 15152 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:47:44.849022 15152 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:47:44.849028 15152 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:47:44.849030 15152 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:47:44.849035 15152 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:47:44.849040 15152 net.cpp:124] Setting up norm2\n",
      "I0430 10:47:44.849043 15152 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:47:44.849046 15152 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:47:44.849048 15152 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:47:44.849053 15152 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:47:44.849056 15152 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:47:44.849059 15152 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:47:44.849726 15152 net.cpp:124] Setting up conv3\n",
      "I0430 10:47:44.849733 15152 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:47:44.849737 15152 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:47:44.849743 15152 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:47:44.849748 15152 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:47:44.849751 15152 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:47:44.849756 15152 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:47:44.849761 15152 net.cpp:124] Setting up relu3\n",
      "I0430 10:47:44.849763 15152 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:47:44.849766 15152 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:47:44.849769 15152 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:47:44.849776 15152 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:47:44.849777 15152 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:47:44.849782 15152 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:47:44.850495 15152 net.cpp:124] Setting up conv4\n",
      "I0430 10:47:44.850504 15152 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:47:44.850507 15152 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:47:44.850512 15152 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:47:44.850517 15152 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:47:44.850519 15152 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:47:44.850525 15152 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:47:44.850529 15152 net.cpp:124] Setting up relu4\n",
      "I0430 10:47:44.850533 15152 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:47:44.850536 15152 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:47:44.850538 15152 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:47:44.850544 15152 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:47:44.850546 15152 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:47:44.850553 15152 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:47:44.851033 15152 net.cpp:124] Setting up conv5\n",
      "I0430 10:47:44.851039 15152 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:47:44.851042 15152 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:47:44.851049 15152 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:47:44.851054 15152 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:47:44.851058 15152 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:47:44.851061 15152 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:47:44.851066 15152 net.cpp:124] Setting up relu5\n",
      "I0430 10:47:44.851070 15152 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:47:44.851073 15152 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:47:44.851075 15152 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:47:44.851081 15152 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:47:44.851083 15152 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:47:44.851088 15152 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:47:44.851094 15152 net.cpp:124] Setting up pool5\n",
      "I0430 10:47:44.851099 15152 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:47:44.851101 15152 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:47:44.851104 15152 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:47:44.851111 15152 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:47:44.851114 15152 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:47:44.851117 15152 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:47:44.872665 15152 net.cpp:124] Setting up fc6\n",
      "I0430 10:47:44.872689 15152 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:47:44.872694 15152 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:47:44.872704 15152 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:47:44.872711 15152 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:47:44.872714 15152 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:47:44.872720 15152 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:47:44.872726 15152 net.cpp:124] Setting up relu6\n",
      "I0430 10:47:44.872728 15152 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:47:44.872730 15152 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:47:44.872732 15152 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:47:44.872735 15152 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:47:44.872737 15152 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:47:44.872740 15152 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:47:44.872743 15152 net.cpp:124] Setting up drop6\n",
      "I0430 10:47:44.872745 15152 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:47:44.872748 15152 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:47:44.872750 15152 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:47:44.872761 15152 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:47:44.872763 15152 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:47:44.872766 15152 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:47:44.882625 15152 net.cpp:124] Setting up fc7\n",
      "I0430 10:47:44.882647 15152 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:47:44.882653 15152 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:47:44.882663 15152 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:47:44.882671 15152 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:47:44.882674 15152 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:47:44.882679 15152 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:47:44.882686 15152 net.cpp:124] Setting up relu7\n",
      "I0430 10:47:44.882689 15152 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:47:44.882691 15152 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:47:44.882694 15152 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:47:44.882699 15152 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:47:44.882700 15152 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:47:44.882704 15152 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:47:44.882709 15152 net.cpp:124] Setting up drop7\n",
      "I0430 10:47:44.882711 15152 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:47:44.882714 15152 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:47:44.882716 15152 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:47:44.882721 15152 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:47:44.882724 15152 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:47:44.882727 15152 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:47:44.883383 15152 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:47:44.883393 15152 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:47:44.883396 15152 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:47:44.883402 15152 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:47:44.883405 15152 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:47:44.883409 15152 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:47:44.883410 15152 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:47:44.883414 15152 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:47:44.883415 15152 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:47:44.883419 15152 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:47:44.883421 15152 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:47:44.883424 15152 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:47:44.883426 15152 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:47:44.883430 15152 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:47:44.883431 15152 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:47:44.883435 15152 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:47:44.883442 15152 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:47:44.883446 15152 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:47:44.883450 15152 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:47:44.883451 15152 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:47:44.883455 15152 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:47:44.883456 15152 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:47:44.883460 15152 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:47:44.883463 15152 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:47:44.883467 15152 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:47:44.883469 15152 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:47:44.883471 15152 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:47:44.883481 15152 net.cpp:257] Network initialization done.\n",
      "I0430 10:47:44.973204 15152 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:47:45.072486 15152 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:47:45.073405 15152 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:47:45.073413 15152 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:47:45.073423 15152 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/480720.jpg'}, '/tmp/tmpWFrXVa.mat')\n",
      "Processed 1158 windows in 131.882 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-1.90757, -2.35909, -1.19982, -2.24907, -1.34...\n",
      "ymin                                                         78\n",
      "xmin                                                         52\n",
      "ymax                                                        257\n",
      "xmax                                                        252\n",
      "Name: /home/ambika/INF_project/data/cat/480720.jpg, dtype: object\n",
      "prediction    [-2.25877, -1.81044, -1.51757, -2.01446, -1.61...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                         85\n",
      "xmax                                                        116\n",
      "Name: /home/ambika/INF_project/data/cat/480720.jpg, dtype: object\n",
      "domestic cat\n",
      "52\t78\t252\t257\n",
      "pizza\n",
      "0\t0\t116\t85\n",
      "480720\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:49:58.412992 15304 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:49:58.413012 15304 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:49:58.413023 15304 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:49:58.414101 15304 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:49:58.414172 15304 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:49:58.414182 15304 net.cpp:86] Creating Layer data\n",
      "I0430 10:49:58.414186 15304 net.cpp:382] data -> data\n",
      "I0430 10:49:58.414201 15304 net.cpp:124] Setting up data\n",
      "I0430 10:49:58.414206 15304 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:49:58.414209 15304 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:49:58.414212 15304 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:49:58.414219 15304 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:49:58.414222 15304 net.cpp:408] conv1 <- data\n",
      "I0430 10:49:58.414227 15304 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:49:58.414286 15304 net.cpp:124] Setting up conv1\n",
      "I0430 10:49:58.414291 15304 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:49:58.414294 15304 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:49:58.414302 15304 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:49:58.414307 15304 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:49:58.414310 15304 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:49:58.414314 15304 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:49:58.414319 15304 net.cpp:124] Setting up relu1\n",
      "I0430 10:49:58.414322 15304 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:49:58.414325 15304 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:49:58.414327 15304 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:49:58.414331 15304 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:49:58.414335 15304 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:49:58.414338 15304 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:49:58.414346 15304 net.cpp:124] Setting up pool1\n",
      "I0430 10:49:58.414350 15304 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:49:58.414352 15304 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:49:58.414355 15304 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:49:58.414361 15304 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:49:58.414363 15304 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:49:58.414367 15304 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:49:58.414372 15304 net.cpp:124] Setting up norm1\n",
      "I0430 10:49:58.414376 15304 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:49:58.414378 15304 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:49:58.414381 15304 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:49:58.414386 15304 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:49:58.414388 15304 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:49:58.414392 15304 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:49:58.414729 15304 net.cpp:124] Setting up conv2\n",
      "I0430 10:49:58.414734 15304 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:49:58.414737 15304 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:49:58.414743 15304 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:49:58.414748 15304 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:49:58.414750 15304 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:49:58.414754 15304 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:49:58.414758 15304 net.cpp:124] Setting up relu2\n",
      "I0430 10:49:58.414762 15304 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:49:58.414764 15304 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:49:58.414767 15304 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:49:58.414773 15304 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:49:58.414775 15304 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:49:58.414779 15304 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:49:58.414785 15304 net.cpp:124] Setting up pool2\n",
      "I0430 10:49:58.414788 15304 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:49:58.414791 15304 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:49:58.414794 15304 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:49:58.414799 15304 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:49:58.414801 15304 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:49:58.414805 15304 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:49:58.414811 15304 net.cpp:124] Setting up norm2\n",
      "I0430 10:49:58.414814 15304 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:49:58.414818 15304 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:49:58.414820 15304 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:49:58.414826 15304 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:49:58.414829 15304 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:49:58.414834 15304 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:49:58.415513 15304 net.cpp:124] Setting up conv3\n",
      "I0430 10:49:58.415521 15304 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:49:58.415524 15304 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:49:58.415532 15304 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:49:58.415539 15304 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:49:58.415541 15304 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:49:58.415545 15304 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:49:58.415550 15304 net.cpp:124] Setting up relu3\n",
      "I0430 10:49:58.415555 15304 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:49:58.415557 15304 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:49:58.415560 15304 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:49:58.415565 15304 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:49:58.415567 15304 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:49:58.415571 15304 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:49:58.416296 15304 net.cpp:124] Setting up conv4\n",
      "I0430 10:49:58.416306 15304 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:49:58.416308 15304 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:49:58.416313 15304 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:49:58.416319 15304 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:49:58.416322 15304 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:49:58.416326 15304 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:49:58.416332 15304 net.cpp:124] Setting up relu4\n",
      "I0430 10:49:58.416334 15304 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:49:58.416337 15304 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:49:58.416340 15304 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:49:58.416347 15304 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:49:58.416349 15304 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:49:58.416353 15304 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:49:58.416838 15304 net.cpp:124] Setting up conv5\n",
      "I0430 10:49:58.416844 15304 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:49:58.416847 15304 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:49:58.416856 15304 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:49:58.416859 15304 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:49:58.416862 15304 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:49:58.416867 15304 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:49:58.416872 15304 net.cpp:124] Setting up relu5\n",
      "I0430 10:49:58.416875 15304 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:49:58.416877 15304 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:49:58.416880 15304 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:49:58.416885 15304 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:49:58.416888 15304 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:49:58.416891 15304 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:49:58.416899 15304 net.cpp:124] Setting up pool5\n",
      "I0430 10:49:58.416903 15304 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:49:58.416905 15304 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:49:58.416908 15304 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:49:58.416916 15304 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:49:58.416918 15304 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:49:58.416923 15304 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:49:58.437724 15304 net.cpp:124] Setting up fc6\n",
      "I0430 10:49:58.437744 15304 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:49:58.437747 15304 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:49:58.437757 15304 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:49:58.437765 15304 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:49:58.437769 15304 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:49:58.437774 15304 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:49:58.437780 15304 net.cpp:124] Setting up relu6\n",
      "I0430 10:49:58.437783 15304 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:49:58.437785 15304 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:49:58.437788 15304 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:49:58.437793 15304 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:49:58.437795 15304 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:49:58.437798 15304 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:49:58.437803 15304 net.cpp:124] Setting up drop6\n",
      "I0430 10:49:58.437806 15304 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:49:58.437808 15304 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:49:58.437810 15304 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:49:58.437814 15304 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:49:58.437818 15304 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:49:58.437821 15304 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:49:58.447881 15304 net.cpp:124] Setting up fc7\n",
      "I0430 10:49:58.447904 15304 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:49:58.447909 15304 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:49:58.447919 15304 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:49:58.447926 15304 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:49:58.447931 15304 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:49:58.447935 15304 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:49:58.447942 15304 net.cpp:124] Setting up relu7\n",
      "I0430 10:49:58.447944 15304 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:49:58.447947 15304 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:49:58.447949 15304 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:49:58.447953 15304 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:49:58.447957 15304 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:49:58.447959 15304 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:49:58.447965 15304 net.cpp:124] Setting up drop7\n",
      "I0430 10:49:58.447968 15304 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:49:58.447970 15304 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:49:58.447973 15304 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:49:58.447976 15304 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:49:58.447979 15304 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:49:58.447983 15304 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:49:58.448896 15304 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:49:58.448907 15304 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:49:58.448910 15304 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:49:58.448917 15304 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:49:58.448920 15304 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:49:58.448923 15304 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:49:58.448925 15304 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:49:58.448928 15304 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:49:58.448931 15304 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:49:58.448933 15304 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:49:58.448936 15304 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:49:58.448940 15304 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:49:58.448941 15304 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:49:58.448945 15304 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:49:58.448947 15304 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:49:58.448951 15304 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:49:58.448953 15304 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:49:58.448956 15304 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:49:58.448959 15304 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:49:58.448961 15304 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:49:58.448964 15304 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:49:58.448967 15304 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:49:58.448976 15304 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:49:58.448979 15304 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:49:58.448982 15304 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:49:58.448984 15304 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:49:58.448987 15304 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:49:58.448997 15304 net.cpp:257] Network initialization done.\n",
      "I0430 10:49:58.530834 15304 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:49:58.633698 15304 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:49:58.634781 15304 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:49:58.634793 15304 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:49:58.634795 15304 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/230862.jpg'}, '/tmp/tmpNdD2lv.mat')\n",
      "Processed 1521 windows in 174.564 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.027 s.\n",
      "prediction    [-1.84984, -2.25336, -2.20617, -2.75748, -1.71...\n",
      "ymin                                                         63\n",
      "xmin                                                        183\n",
      "ymax                                                        254\n",
      "xmax                                                        332\n",
      "Name: /home/ambika/INF_project/data/couch/230862.jpg, dtype: object\n",
      "prediction    [-2.12866, -1.40943, -1.84368, -2.3381, -1.837...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                        234\n",
      "xmax                                                        219\n",
      "Name: /home/ambika/INF_project/data/couch/230862.jpg, dtype: object\n",
      "drum\n",
      "183\t63\t332\t254\n",
      "sofa\n",
      "0\t0\t219\t234\n",
      "230862\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:52:55.456392 15484 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:52:55.456406 15484 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:52:55.456408 15484 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:52:55.457485 15484 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:52:55.457617 15484 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:52:55.457626 15484 net.cpp:86] Creating Layer data\n",
      "I0430 10:52:55.457629 15484 net.cpp:382] data -> data\n",
      "I0430 10:52:55.457643 15484 net.cpp:124] Setting up data\n",
      "I0430 10:52:55.457648 15484 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:52:55.457650 15484 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:52:55.457653 15484 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:52:55.457659 15484 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:52:55.457661 15484 net.cpp:408] conv1 <- data\n",
      "I0430 10:52:55.457666 15484 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:52:55.457722 15484 net.cpp:124] Setting up conv1\n",
      "I0430 10:52:55.457727 15484 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:52:55.457729 15484 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:52:55.457736 15484 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:52:55.457746 15484 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:52:55.457747 15484 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:52:55.457751 15484 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:52:55.457758 15484 net.cpp:124] Setting up relu1\n",
      "I0430 10:52:55.457762 15484 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:52:55.457764 15484 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:52:55.457767 15484 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:52:55.457770 15484 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:52:55.457772 15484 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:52:55.457775 15484 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:52:55.457782 15484 net.cpp:124] Setting up pool1\n",
      "I0430 10:52:55.457785 15484 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:52:55.457787 15484 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:52:55.457789 15484 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:52:55.457793 15484 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:52:55.457797 15484 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:52:55.457799 15484 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:52:55.457804 15484 net.cpp:124] Setting up norm1\n",
      "I0430 10:52:55.457808 15484 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:52:55.457809 15484 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:52:55.457813 15484 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:52:55.457816 15484 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:52:55.457818 15484 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:52:55.457821 15484 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:52:55.458158 15484 net.cpp:124] Setting up conv2\n",
      "I0430 10:52:55.458163 15484 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:52:55.458164 15484 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:52:55.458169 15484 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:52:55.458173 15484 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:52:55.458176 15484 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:52:55.458179 15484 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:52:55.458184 15484 net.cpp:124] Setting up relu2\n",
      "I0430 10:52:55.458186 15484 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:52:55.458189 15484 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:52:55.458190 15484 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:52:55.458194 15484 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:52:55.458196 15484 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:52:55.458199 15484 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:52:55.458204 15484 net.cpp:124] Setting up pool2\n",
      "I0430 10:52:55.458209 15484 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:52:55.458210 15484 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:52:55.458212 15484 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:52:55.458217 15484 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:52:55.458220 15484 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:52:55.458223 15484 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:52:55.458228 15484 net.cpp:124] Setting up norm2\n",
      "I0430 10:52:55.458231 15484 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:52:55.458233 15484 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:52:55.458236 15484 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:52:55.458241 15484 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:52:55.458243 15484 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:52:55.458246 15484 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:52:55.459195 15484 net.cpp:124] Setting up conv3\n",
      "I0430 10:52:55.459247 15484 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:52:55.459251 15484 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:52:55.459259 15484 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:52:55.459264 15484 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:52:55.459266 15484 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:52:55.459270 15484 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:52:55.459275 15484 net.cpp:124] Setting up relu3\n",
      "I0430 10:52:55.459278 15484 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:52:55.459281 15484 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:52:55.459283 15484 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:52:55.459290 15484 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:52:55.459291 15484 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:52:55.459295 15484 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:52:55.459771 15484 net.cpp:124] Setting up conv4\n",
      "I0430 10:52:55.459779 15484 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:52:55.459782 15484 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:52:55.459789 15484 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:52:55.459792 15484 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:52:55.459795 15484 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:52:55.459799 15484 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:52:55.459802 15484 net.cpp:124] Setting up relu4\n",
      "I0430 10:52:55.459806 15484 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:52:55.459808 15484 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:52:55.459811 15484 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:52:55.459816 15484 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:52:55.459818 15484 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:52:55.459822 15484 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:52:55.460326 15484 net.cpp:124] Setting up conv5\n",
      "I0430 10:52:55.460336 15484 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:52:55.460338 15484 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:52:55.460346 15484 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:52:55.460350 15484 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:52:55.460352 15484 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:52:55.460355 15484 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:52:55.460360 15484 net.cpp:124] Setting up relu5\n",
      "I0430 10:52:55.460362 15484 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:52:55.460363 15484 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:52:55.460366 15484 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:52:55.460369 15484 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:52:55.460371 15484 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:52:55.460373 15484 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:52:55.460387 15484 net.cpp:124] Setting up pool5\n",
      "I0430 10:52:55.460391 15484 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:52:55.460391 15484 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:52:55.460396 15484 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:52:55.460402 15484 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:52:55.460403 15484 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:52:55.460405 15484 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:52:55.482547 15484 net.cpp:124] Setting up fc6\n",
      "I0430 10:52:55.482569 15484 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:52:55.482574 15484 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:52:55.482585 15484 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:52:55.482594 15484 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:52:55.482597 15484 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:52:55.482602 15484 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:52:55.482609 15484 net.cpp:124] Setting up relu6\n",
      "I0430 10:52:55.482612 15484 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:52:55.482614 15484 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:52:55.482617 15484 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:52:55.482622 15484 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:52:55.482625 15484 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:52:55.482628 15484 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:52:55.482633 15484 net.cpp:124] Setting up drop6\n",
      "I0430 10:52:55.482636 15484 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:52:55.482638 15484 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:52:55.482640 15484 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:52:55.482645 15484 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:52:55.482648 15484 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:52:55.482653 15484 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:52:55.492677 15484 net.cpp:124] Setting up fc7\n",
      "I0430 10:52:55.492702 15484 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:52:55.492705 15484 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:52:55.492712 15484 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:52:55.492720 15484 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:52:55.492723 15484 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:52:55.492728 15484 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:52:55.492733 15484 net.cpp:124] Setting up relu7\n",
      "I0430 10:52:55.492735 15484 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:52:55.492738 15484 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:52:55.492738 15484 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:52:55.492743 15484 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:52:55.492744 15484 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:52:55.492748 15484 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:52:55.492751 15484 net.cpp:124] Setting up drop7\n",
      "I0430 10:52:55.492753 15484 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:52:55.492755 15484 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:52:55.492758 15484 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:52:55.492761 15484 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:52:55.492774 15484 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:52:55.492779 15484 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:52:55.493680 15484 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:52:55.493691 15484 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:52:55.493696 15484 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:52:55.493702 15484 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:52:55.493705 15484 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:52:55.493707 15484 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:52:55.493708 15484 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:52:55.493710 15484 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:52:55.493712 15484 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:52:55.493715 15484 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:52:55.493718 15484 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:52:55.493739 15484 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:52:55.493747 15484 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:52:55.493751 15484 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:52:55.493754 15484 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:52:55.493757 15484 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:52:55.493759 15484 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:52:55.493762 15484 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:52:55.493765 15484 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:52:55.493768 15484 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:52:55.493772 15484 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:52:55.493774 15484 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:52:55.493777 15484 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:52:55.493780 15484 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:52:55.493783 15484 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:52:55.493787 15484 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:52:55.493788 15484 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:52:55.493798 15484 net.cpp:257] Network initialization done.\n",
      "I0430 10:52:55.580814 15484 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:52:55.685072 15484 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:52:55.686034 15484 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:52:55.686043 15484 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:52:55.686046 15484 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/22192.jpg'}, '/tmp/tmp6bbvhA.mat')\n",
      "Processed 1715 windows in 210.146 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-1.74537, -2.24131, -1.89083, -2.7854, -2.021...\n",
      "ymin                                                         92\n",
      "xmin                                                         58\n",
      "ymax                                                        291\n",
      "xmax                                                        175\n",
      "Name: /home/ambika/INF_project/data/dog/22192.jpg, dtype: object\n",
      "prediction    [-1.61976, -2.18674, -1.76228, -2.63849, -2.16...\n",
      "ymin                                                         73\n",
      "xmin                                                         54\n",
      "ymax                                                        279\n",
      "xmax                                                        145\n",
      "Name: /home/ambika/INF_project/data/dog/22192.jpg, dtype: object\n",
      "dog\n",
      "58\t92\t175\t291\n",
      "bear\n",
      "54\t73\t145\t279\n",
      "22192\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 10:56:27.412220 15725 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 10:56:27.412240 15725 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 10:56:27.412243 15725 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 10:56:27.413916 15725 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 10:56:27.414072 15725 layer_factory.hpp:77] Creating layer data\n",
      "I0430 10:56:27.414084 15725 net.cpp:86] Creating Layer data\n",
      "I0430 10:56:27.414089 15725 net.cpp:382] data -> data\n",
      "I0430 10:56:27.414106 15725 net.cpp:124] Setting up data\n",
      "I0430 10:56:27.414114 15725 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 10:56:27.414119 15725 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 10:56:27.414124 15725 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 10:56:27.414132 15725 net.cpp:86] Creating Layer conv1\n",
      "I0430 10:56:27.414136 15725 net.cpp:408] conv1 <- data\n",
      "I0430 10:56:27.414142 15725 net.cpp:382] conv1 -> conv1\n",
      "I0430 10:56:27.414227 15725 net.cpp:124] Setting up conv1\n",
      "I0430 10:56:27.414237 15725 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:56:27.414240 15725 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 10:56:27.414250 15725 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 10:56:27.414258 15725 net.cpp:86] Creating Layer relu1\n",
      "I0430 10:56:27.414263 15725 net.cpp:408] relu1 <- conv1\n",
      "I0430 10:56:27.414269 15725 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 10:56:27.414275 15725 net.cpp:124] Setting up relu1\n",
      "I0430 10:56:27.414281 15725 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 10:56:27.414284 15725 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 10:56:27.414288 15725 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 10:56:27.414294 15725 net.cpp:86] Creating Layer pool1\n",
      "I0430 10:56:27.414297 15725 net.cpp:408] pool1 <- conv1\n",
      "I0430 10:56:27.414302 15725 net.cpp:382] pool1 -> pool1\n",
      "I0430 10:56:27.414314 15725 net.cpp:124] Setting up pool1\n",
      "I0430 10:56:27.414321 15725 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:56:27.414326 15725 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 10:56:27.414330 15725 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 10:56:27.414340 15725 net.cpp:86] Creating Layer norm1\n",
      "I0430 10:56:27.414345 15725 net.cpp:408] norm1 <- pool1\n",
      "I0430 10:56:27.414352 15725 net.cpp:382] norm1 -> norm1\n",
      "I0430 10:56:27.414362 15725 net.cpp:124] Setting up norm1\n",
      "I0430 10:56:27.414367 15725 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 10:56:27.414371 15725 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 10:56:27.414372 15725 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 10:56:27.414379 15725 net.cpp:86] Creating Layer conv2\n",
      "I0430 10:56:27.414382 15725 net.cpp:408] conv2 <- norm1\n",
      "I0430 10:56:27.414386 15725 net.cpp:382] conv2 -> conv2\n",
      "I0430 10:56:27.415065 15725 net.cpp:124] Setting up conv2\n",
      "I0430 10:56:27.415091 15725 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:56:27.415096 15725 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 10:56:27.415107 15725 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 10:56:27.415119 15725 net.cpp:86] Creating Layer relu2\n",
      "I0430 10:56:27.415122 15725 net.cpp:408] relu2 <- conv2\n",
      "I0430 10:56:27.415129 15725 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 10:56:27.415138 15725 net.cpp:124] Setting up relu2\n",
      "I0430 10:56:27.415143 15725 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 10:56:27.415145 15725 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 10:56:27.415148 15725 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 10:56:27.415154 15725 net.cpp:86] Creating Layer pool2\n",
      "I0430 10:56:27.415159 15725 net.cpp:408] pool2 <- conv2\n",
      "I0430 10:56:27.415163 15725 net.cpp:382] pool2 -> pool2\n",
      "I0430 10:56:27.415174 15725 net.cpp:124] Setting up pool2\n",
      "I0430 10:56:27.415179 15725 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:56:27.415182 15725 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 10:56:27.415186 15725 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 10:56:27.415196 15725 net.cpp:86] Creating Layer norm2\n",
      "I0430 10:56:27.415200 15725 net.cpp:408] norm2 <- pool2\n",
      "I0430 10:56:27.415213 15725 net.cpp:382] norm2 -> norm2\n",
      "I0430 10:56:27.415227 15725 net.cpp:124] Setting up norm2\n",
      "I0430 10:56:27.415232 15725 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:56:27.415235 15725 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 10:56:27.415240 15725 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 10:56:27.415248 15725 net.cpp:86] Creating Layer conv3\n",
      "I0430 10:56:27.415252 15725 net.cpp:408] conv3 <- norm2\n",
      "I0430 10:56:27.415257 15725 net.cpp:382] conv3 -> conv3\n",
      "I0430 10:56:27.416050 15725 net.cpp:124] Setting up conv3\n",
      "I0430 10:56:27.416067 15725 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:56:27.416071 15725 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 10:56:27.416082 15725 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 10:56:27.416091 15725 net.cpp:86] Creating Layer relu3\n",
      "I0430 10:56:27.416097 15725 net.cpp:408] relu3 <- conv3\n",
      "I0430 10:56:27.416105 15725 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 10:56:27.416113 15725 net.cpp:124] Setting up relu3\n",
      "I0430 10:56:27.416116 15725 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:56:27.416119 15725 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 10:56:27.416121 15725 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 10:56:27.416128 15725 net.cpp:86] Creating Layer conv4\n",
      "I0430 10:56:27.416131 15725 net.cpp:408] conv4 <- conv3\n",
      "I0430 10:56:27.416134 15725 net.cpp:382] conv4 -> conv4\n",
      "I0430 10:56:27.416899 15725 net.cpp:124] Setting up conv4\n",
      "I0430 10:56:27.416911 15725 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:56:27.416915 15725 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 10:56:27.416923 15725 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 10:56:27.416929 15725 net.cpp:86] Creating Layer relu4\n",
      "I0430 10:56:27.416934 15725 net.cpp:408] relu4 <- conv4\n",
      "I0430 10:56:27.416939 15725 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 10:56:27.416945 15725 net.cpp:124] Setting up relu4\n",
      "I0430 10:56:27.416949 15725 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 10:56:27.416951 15725 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 10:56:27.416954 15725 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 10:56:27.416961 15725 net.cpp:86] Creating Layer conv5\n",
      "I0430 10:56:27.416963 15725 net.cpp:408] conv5 <- conv4\n",
      "I0430 10:56:27.416967 15725 net.cpp:382] conv5 -> conv5\n",
      "I0430 10:56:27.417498 15725 net.cpp:124] Setting up conv5\n",
      "I0430 10:56:27.417506 15725 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:56:27.417510 15725 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 10:56:27.417521 15725 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 10:56:27.417528 15725 net.cpp:86] Creating Layer relu5\n",
      "I0430 10:56:27.417531 15725 net.cpp:408] relu5 <- conv5\n",
      "I0430 10:56:27.417536 15725 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 10:56:27.417541 15725 net.cpp:124] Setting up relu5\n",
      "I0430 10:56:27.417543 15725 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 10:56:27.417546 15725 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 10:56:27.417548 15725 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 10:56:27.417552 15725 net.cpp:86] Creating Layer pool5\n",
      "I0430 10:56:27.417554 15725 net.cpp:408] pool5 <- conv5\n",
      "I0430 10:56:27.417558 15725 net.cpp:382] pool5 -> pool5\n",
      "I0430 10:56:27.417564 15725 net.cpp:124] Setting up pool5\n",
      "I0430 10:56:27.417568 15725 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 10:56:27.417570 15725 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 10:56:27.417572 15725 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 10:56:27.417580 15725 net.cpp:86] Creating Layer fc6\n",
      "I0430 10:56:27.417582 15725 net.cpp:408] fc6 <- pool5\n",
      "I0430 10:56:27.417587 15725 net.cpp:382] fc6 -> fc6\n",
      "I0430 10:56:27.439267 15725 net.cpp:124] Setting up fc6\n",
      "I0430 10:56:27.439290 15725 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:56:27.439291 15725 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 10:56:27.439302 15725 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 10:56:27.439327 15725 net.cpp:86] Creating Layer relu6\n",
      "I0430 10:56:27.439330 15725 net.cpp:408] relu6 <- fc6\n",
      "I0430 10:56:27.439337 15725 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 10:56:27.439345 15725 net.cpp:124] Setting up relu6\n",
      "I0430 10:56:27.439349 15725 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:56:27.439352 15725 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 10:56:27.439357 15725 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 10:56:27.439362 15725 net.cpp:86] Creating Layer drop6\n",
      "I0430 10:56:27.439364 15725 net.cpp:408] drop6 <- fc6\n",
      "I0430 10:56:27.439369 15725 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 10:56:27.439374 15725 net.cpp:124] Setting up drop6\n",
      "I0430 10:56:27.439378 15725 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:56:27.439380 15725 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 10:56:27.439384 15725 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 10:56:27.439389 15725 net.cpp:86] Creating Layer fc7\n",
      "I0430 10:56:27.439391 15725 net.cpp:408] fc7 <- fc6\n",
      "I0430 10:56:27.439398 15725 net.cpp:382] fc7 -> fc7\n",
      "I0430 10:56:27.449833 15725 net.cpp:124] Setting up fc7\n",
      "I0430 10:56:27.449861 15725 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:56:27.449863 15725 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 10:56:27.449875 15725 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 10:56:27.449883 15725 net.cpp:86] Creating Layer relu7\n",
      "I0430 10:56:27.449887 15725 net.cpp:408] relu7 <- fc7\n",
      "I0430 10:56:27.449893 15725 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 10:56:27.449901 15725 net.cpp:124] Setting up relu7\n",
      "I0430 10:56:27.449905 15725 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:56:27.449908 15725 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 10:56:27.449910 15725 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 10:56:27.449916 15725 net.cpp:86] Creating Layer drop7\n",
      "I0430 10:56:27.449918 15725 net.cpp:408] drop7 <- fc7\n",
      "I0430 10:56:27.449923 15725 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 10:56:27.449929 15725 net.cpp:124] Setting up drop7\n",
      "I0430 10:56:27.449932 15725 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 10:56:27.449935 15725 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 10:56:27.449939 15725 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 10:56:27.449944 15725 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 10:56:27.449945 15725 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 10:56:27.449950 15725 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 10:56:27.450860 15725 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 10:56:27.450871 15725 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 10:56:27.450875 15725 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 10:56:27.450881 15725 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 10:56:27.450884 15725 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 10:56:27.450887 15725 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 10:56:27.450891 15725 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 10:56:27.450894 15725 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 10:56:27.450897 15725 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 10:56:27.450901 15725 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 10:56:27.450903 15725 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 10:56:27.450906 15725 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 10:56:27.450909 15725 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 10:56:27.450913 15725 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 10:56:27.450917 15725 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 10:56:27.450919 15725 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 10:56:27.450922 15725 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 10:56:27.450925 15725 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 10:56:27.450928 15725 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 10:56:27.450932 15725 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 10:56:27.450935 15725 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 10:56:27.450938 15725 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 10:56:27.450942 15725 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 10:56:27.450944 15725 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 10:56:27.450947 15725 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 10:56:27.450950 15725 net.cpp:202] data does not need backward computation.\n",
      "I0430 10:56:27.450953 15725 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 10:56:27.450964 15725 net.cpp:257] Network initialization done.\n",
      "I0430 10:56:27.541733 15725 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:56:27.637488 15725 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 10:56:27.638368 15725 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 10:56:27.638375 15725 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 10:56:27.638381 15725 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/181753.jpg'}, '/tmp/tmpXnxiTx.mat')\n",
      "Processed 1903 windows in 235.771 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.039 s.\n",
      "prediction    [-1.79769, -2.36257, -2.23003, -2.03596, -1.86...\n",
      "ymin                                                        183\n",
      "xmin                                                          0\n",
      "ymax                                                        330\n",
      "xmax                                                        162\n",
      "Name: /home/ambika/INF_project/data/horse/181753.jpg, dtype: object\n",
      "prediction    [-1.66114, -2.10421, -2.16106, -2.03937, -2.20...\n",
      "ymin                                                        190\n",
      "xmin                                                         37\n",
      "ymax                                                        288\n",
      "xmax                                                        217\n",
      "Name: /home/ambika/INF_project/data/horse/181753.jpg, dtype: object\n",
      "harp\n",
      "0\t183\t162\t330\n",
      "sofa\n",
      "37\t190\t217\t288\n",
      "181753\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:00:25.060557 15918 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:00:25.060580 15918 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:00:25.060583 15918 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:00:25.062052 15918 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:00:25.062170 15918 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:00:25.062183 15918 net.cpp:86] Creating Layer data\n",
      "I0430 11:00:25.062191 15918 net.cpp:382] data -> data\n",
      "I0430 11:00:25.062217 15918 net.cpp:124] Setting up data\n",
      "I0430 11:00:25.062227 15918 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:00:25.062229 15918 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:00:25.062233 15918 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:00:25.062242 15918 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:00:25.062245 15918 net.cpp:408] conv1 <- data\n",
      "I0430 11:00:25.062250 15918 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:00:25.062366 15918 net.cpp:124] Setting up conv1\n",
      "I0430 11:00:25.062376 15918 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:00:25.062381 15918 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:00:25.062391 15918 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:00:25.062404 15918 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:00:25.062408 15918 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:00:25.062413 15918 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:00:25.062418 15918 net.cpp:124] Setting up relu1\n",
      "I0430 11:00:25.062422 15918 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:00:25.062425 15918 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:00:25.062427 15918 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:00:25.062433 15918 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:00:25.062435 15918 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:00:25.062439 15918 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:00:25.062448 15918 net.cpp:124] Setting up pool1\n",
      "I0430 11:00:25.062453 15918 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:00:25.062455 15918 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:00:25.062458 15918 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:00:25.062465 15918 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:00:25.062467 15918 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:00:25.062472 15918 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:00:25.062479 15918 net.cpp:124] Setting up norm1\n",
      "I0430 11:00:25.062485 15918 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:00:25.062487 15918 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:00:25.062490 15918 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:00:25.062496 15918 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:00:25.062507 15918 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:00:25.062513 15918 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:00:25.063009 15918 net.cpp:124] Setting up conv2\n",
      "I0430 11:00:25.063040 15918 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:00:25.063045 15918 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:00:25.063061 15918 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:00:25.063079 15918 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:00:25.063084 15918 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:00:25.063091 15918 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:00:25.063100 15918 net.cpp:124] Setting up relu2\n",
      "I0430 11:00:25.063105 15918 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:00:25.063108 15918 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:00:25.063112 15918 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:00:25.063117 15918 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:00:25.063120 15918 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:00:25.063127 15918 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:00:25.063134 15918 net.cpp:124] Setting up pool2\n",
      "I0430 11:00:25.063139 15918 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:00:25.063143 15918 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:00:25.063145 15918 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:00:25.063175 15918 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:00:25.063179 15918 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:00:25.063185 15918 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:00:25.063192 15918 net.cpp:124] Setting up norm2\n",
      "I0430 11:00:25.063197 15918 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:00:25.063201 15918 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:00:25.063205 15918 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:00:25.063233 15918 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:00:25.063238 15918 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:00:25.063246 15918 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:00:25.064718 15918 net.cpp:124] Setting up conv3\n",
      "I0430 11:00:25.064759 15918 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:00:25.064766 15918 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:00:25.064787 15918 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:00:25.064808 15918 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:00:25.064815 15918 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:00:25.064824 15918 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:00:25.064838 15918 net.cpp:124] Setting up relu3\n",
      "I0430 11:00:25.064843 15918 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:00:25.064851 15918 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:00:25.064854 15918 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:00:25.064872 15918 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:00:25.064877 15918 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:00:25.064887 15918 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:00:25.065769 15918 net.cpp:124] Setting up conv4\n",
      "I0430 11:00:25.065788 15918 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:00:25.065793 15918 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:00:25.065814 15918 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:00:25.065821 15918 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:00:25.065826 15918 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:00:25.065832 15918 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:00:25.065840 15918 net.cpp:124] Setting up relu4\n",
      "I0430 11:00:25.065843 15918 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:00:25.065846 15918 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:00:25.065850 15918 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:00:25.065857 15918 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:00:25.065860 15918 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:00:25.065865 15918 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:00:25.066372 15918 net.cpp:124] Setting up conv5\n",
      "I0430 11:00:25.066380 15918 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:00:25.066383 15918 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:00:25.066395 15918 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:00:25.066400 15918 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:00:25.066403 15918 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:00:25.066409 15918 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:00:25.066414 15918 net.cpp:124] Setting up relu5\n",
      "I0430 11:00:25.066418 15918 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:00:25.066421 15918 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:00:25.066424 15918 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:00:25.066431 15918 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:00:25.066432 15918 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:00:25.066438 15918 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:00:25.066447 15918 net.cpp:124] Setting up pool5\n",
      "I0430 11:00:25.066450 15918 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:00:25.066453 15918 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:00:25.066457 15918 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:00:25.066464 15918 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:00:25.066468 15918 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:00:25.066474 15918 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:00:25.088840 15918 net.cpp:124] Setting up fc6\n",
      "I0430 11:00:25.088870 15918 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:00:25.088873 15918 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:00:25.088883 15918 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:00:25.088896 15918 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:00:25.088899 15918 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:00:25.088904 15918 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:00:25.088913 15918 net.cpp:124] Setting up relu6\n",
      "I0430 11:00:25.088917 15918 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:00:25.088920 15918 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:00:25.088924 15918 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:00:25.088930 15918 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:00:25.088934 15918 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:00:25.088939 15918 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:00:25.088946 15918 net.cpp:124] Setting up drop6\n",
      "I0430 11:00:25.088951 15918 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:00:25.088954 15918 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:00:25.088958 15918 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:00:25.088963 15918 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:00:25.088966 15918 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:00:25.088973 15918 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:00:25.103615 15918 net.cpp:124] Setting up fc7\n",
      "I0430 11:00:25.103667 15918 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:00:25.103672 15918 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:00:25.103682 15918 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:00:25.103693 15918 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:00:25.103696 15918 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:00:25.103703 15918 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:00:25.103713 15918 net.cpp:124] Setting up relu7\n",
      "I0430 11:00:25.103716 15918 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:00:25.103719 15918 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:00:25.103723 15918 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:00:25.103729 15918 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:00:25.103731 15918 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:00:25.103737 15918 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:00:25.103745 15918 net.cpp:124] Setting up drop7\n",
      "I0430 11:00:25.103749 15918 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:00:25.103751 15918 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:00:25.103754 15918 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:00:25.103760 15918 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:00:25.103763 15918 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:00:25.103768 15918 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:00:25.104460 15918 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:00:25.104473 15918 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:00:25.104477 15918 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:00:25.104485 15918 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:00:25.104490 15918 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:00:25.104495 15918 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:00:25.104497 15918 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:00:25.104511 15918 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:00:25.104514 15918 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:00:25.104519 15918 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:00:25.104523 15918 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:00:25.104527 15918 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:00:25.104531 15918 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:00:25.104534 15918 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:00:25.104538 15918 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:00:25.104542 15918 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:00:25.104545 15918 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:00:25.104549 15918 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:00:25.104552 15918 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:00:25.104555 15918 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:00:25.104558 15918 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:00:25.104562 15918 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:00:25.104565 15918 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:00:25.104568 15918 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:00:25.104571 15918 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:00:25.104574 15918 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:00:25.104576 15918 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:00:25.104588 15918 net.cpp:257] Network initialization done.\n",
      "I0430 11:00:25.195389 15918 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:00:25.297829 15918 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:00:25.298830 15918 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:00:25.298840 15918 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:00:25.298844 15918 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/328430.jpg'}, '/tmp/tmpDnBGT3.mat')\n",
      "Processed 2904 windows in 364.552 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.62793, -2.66612, -1.78193, -1.70464, -2.37...\n",
      "ymin                                                    327.184\n",
      "xmin                                                     182.52\n",
      "ymax                                                    424.176\n",
      "xmax                                                     224.08\n",
      "Name: /home/ambika/INF_project/data/person/328430.jpg, dtype: object\n",
      "prediction    [-2.36475, -2.87157, -2.04206, -1.6048, -1.685...\n",
      "ymin                                                    320.424\n",
      "xmin                                                      70.98\n",
      "ymax                                                    470.144\n",
      "xmax                                                    192.308\n",
      "Name: /home/ambika/INF_project/data/person/328430.jpg, dtype: object\n",
      "person\n",
      "182.52\t327.184\t224.08\t424.176\n",
      "dog\n",
      "70.98\t320.424\t192.308\t470.144\n",
      "328430\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:06:31.585052 16125 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:06:31.585069 16125 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:06:31.585072 16125 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:06:31.586199 16125 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:06:31.586287 16125 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:06:31.586293 16125 net.cpp:86] Creating Layer data\n",
      "I0430 11:06:31.586300 16125 net.cpp:382] data -> data\n",
      "I0430 11:06:31.586315 16125 net.cpp:124] Setting up data\n",
      "I0430 11:06:31.586320 16125 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:06:31.586323 16125 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:06:31.586325 16125 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:06:31.586331 16125 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:06:31.586334 16125 net.cpp:408] conv1 <- data\n",
      "I0430 11:06:31.586338 16125 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:06:31.586397 16125 net.cpp:124] Setting up conv1\n",
      "I0430 11:06:31.586401 16125 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:06:31.586405 16125 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:06:31.586411 16125 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:06:31.586416 16125 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:06:31.586419 16125 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:06:31.586422 16125 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:06:31.586426 16125 net.cpp:124] Setting up relu1\n",
      "I0430 11:06:31.586428 16125 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:06:31.586431 16125 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:06:31.586432 16125 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:06:31.586436 16125 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:06:31.586436 16125 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:06:31.586439 16125 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:06:31.586444 16125 net.cpp:124] Setting up pool1\n",
      "I0430 11:06:31.586447 16125 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:06:31.586449 16125 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:06:31.586452 16125 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:06:31.586455 16125 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:06:31.586458 16125 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:06:31.586462 16125 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:06:31.586467 16125 net.cpp:124] Setting up norm1\n",
      "I0430 11:06:31.586470 16125 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:06:31.586472 16125 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:06:31.586474 16125 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:06:31.586478 16125 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:06:31.586482 16125 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:06:31.586484 16125 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:06:31.586823 16125 net.cpp:124] Setting up conv2\n",
      "I0430 11:06:31.586829 16125 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:06:31.586832 16125 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:06:31.586836 16125 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:06:31.586841 16125 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:06:31.586843 16125 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:06:31.586848 16125 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:06:31.586850 16125 net.cpp:124] Setting up relu2\n",
      "I0430 11:06:31.586853 16125 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:06:31.586856 16125 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:06:31.586858 16125 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:06:31.586863 16125 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:06:31.586864 16125 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:06:31.586868 16125 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:06:31.586872 16125 net.cpp:124] Setting up pool2\n",
      "I0430 11:06:31.586875 16125 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:06:31.586879 16125 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:06:31.586880 16125 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:06:31.586887 16125 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:06:31.586890 16125 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:06:31.586894 16125 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:06:31.586899 16125 net.cpp:124] Setting up norm2\n",
      "I0430 11:06:31.586904 16125 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:06:31.586905 16125 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:06:31.586907 16125 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:06:31.586911 16125 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:06:31.586916 16125 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:06:31.586920 16125 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:06:31.587607 16125 net.cpp:124] Setting up conv3\n",
      "I0430 11:06:31.587618 16125 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:06:31.587620 16125 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:06:31.587627 16125 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:06:31.587635 16125 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:06:31.587638 16125 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:06:31.587642 16125 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:06:31.587646 16125 net.cpp:124] Setting up relu3\n",
      "I0430 11:06:31.587651 16125 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:06:31.587652 16125 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:06:31.587654 16125 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:06:31.587661 16125 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:06:31.587663 16125 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:06:31.587667 16125 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:06:31.588397 16125 net.cpp:124] Setting up conv4\n",
      "I0430 11:06:31.588405 16125 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:06:31.588408 16125 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:06:31.588413 16125 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:06:31.588418 16125 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:06:31.588419 16125 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:06:31.588423 16125 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:06:31.588426 16125 net.cpp:124] Setting up relu4\n",
      "I0430 11:06:31.588429 16125 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:06:31.588433 16125 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:06:31.588434 16125 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:06:31.588439 16125 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:06:31.588443 16125 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:06:31.588445 16125 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:06:31.588938 16125 net.cpp:124] Setting up conv5\n",
      "I0430 11:06:31.588946 16125 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:06:31.588948 16125 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:06:31.588955 16125 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:06:31.588960 16125 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:06:31.588963 16125 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:06:31.588966 16125 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:06:31.588970 16125 net.cpp:124] Setting up relu5\n",
      "I0430 11:06:31.588973 16125 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:06:31.588975 16125 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:06:31.588979 16125 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:06:31.588982 16125 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:06:31.588984 16125 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:06:31.588989 16125 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:06:31.588995 16125 net.cpp:124] Setting up pool5\n",
      "I0430 11:06:31.588999 16125 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:06:31.589001 16125 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:06:31.589004 16125 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:06:31.589010 16125 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:06:31.589012 16125 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:06:31.589015 16125 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:06:31.617497 16125 net.cpp:124] Setting up fc6\n",
      "I0430 11:06:31.617522 16125 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:06:31.617527 16125 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:06:31.617534 16125 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:06:31.617545 16125 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:06:31.617547 16125 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:06:31.617552 16125 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:06:31.617558 16125 net.cpp:124] Setting up relu6\n",
      "I0430 11:06:31.617561 16125 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:06:31.617563 16125 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:06:31.617564 16125 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:06:31.617568 16125 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:06:31.617570 16125 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:06:31.617573 16125 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:06:31.617578 16125 net.cpp:124] Setting up drop6\n",
      "I0430 11:06:31.617579 16125 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:06:31.617594 16125 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:06:31.617594 16125 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:06:31.617601 16125 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:06:31.617604 16125 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:06:31.617610 16125 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:06:31.627903 16125 net.cpp:124] Setting up fc7\n",
      "I0430 11:06:31.627924 16125 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:06:31.627928 16125 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:06:31.627938 16125 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:06:31.627945 16125 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:06:31.627948 16125 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:06:31.627951 16125 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:06:31.627957 16125 net.cpp:124] Setting up relu7\n",
      "I0430 11:06:31.627960 16125 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:06:31.627961 16125 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:06:31.627964 16125 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:06:31.627969 16125 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:06:31.627971 16125 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:06:31.627974 16125 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:06:31.627979 16125 net.cpp:124] Setting up drop7\n",
      "I0430 11:06:31.627981 16125 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:06:31.627984 16125 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:06:31.627986 16125 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:06:31.627990 16125 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:06:31.627993 16125 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:06:31.627996 16125 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:06:31.628897 16125 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:06:31.628906 16125 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:06:31.628909 16125 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:06:31.628916 16125 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:06:31.628917 16125 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:06:31.628919 16125 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:06:31.628921 16125 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:06:31.628923 16125 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:06:31.628926 16125 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:06:31.628928 16125 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:06:31.628931 16125 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:06:31.628933 16125 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:06:31.628937 16125 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:06:31.628938 16125 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:06:31.628942 16125 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:06:31.628944 16125 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:06:31.628947 16125 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:06:31.628950 16125 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:06:31.628953 16125 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:06:31.628955 16125 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:06:31.628958 16125 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:06:31.628962 16125 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:06:31.628963 16125 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:06:31.628967 16125 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:06:31.628968 16125 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:06:31.628971 16125 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:06:31.628973 16125 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:06:31.628983 16125 net.cpp:257] Network initialization done.\n",
      "I0430 11:06:31.728302 16125 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:06:31.833582 16125 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:06:31.834489 16125 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:06:31.834498 16125 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:06:31.834501 16125 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/500335.jpg'}, '/tmp/tmpzLjtb4.mat')\n",
      "Processed 2519 windows in 311.633 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.038 s.\n",
      "prediction    [-2.37495, -2.577, -2.4647, -2.8273, -2.37113,...\n",
      "ymin                                                          6\n",
      "xmin                                                         77\n",
      "ymax                                                        333\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/train/500335.jpg, dtype: object\n",
      "prediction    [-2.30814, -2.35476, -2.7014, -1.72678, -1.856...\n",
      "ymin                                                        222\n",
      "xmin                                                        174\n",
      "ymax                                                        325\n",
      "xmax                                                        305\n",
      "Name: /home/ambika/INF_project/data/train/500335.jpg, dtype: object\n",
      "train\n",
      "77\t6\t500\t333\n",
      "cart\n",
      "174\t222\t305\t325\n",
      "500335\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:11:45.136992 16311 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:11:45.137017 16311 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:11:45.137019 16311 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:11:45.138737 16311 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:11:45.138855 16311 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:11:45.138870 16311 net.cpp:86] Creating Layer data\n",
      "I0430 11:11:45.138881 16311 net.cpp:382] data -> data\n",
      "I0430 11:11:45.138908 16311 net.cpp:124] Setting up data\n",
      "I0430 11:11:45.138917 16311 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:11:45.138921 16311 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:11:45.138926 16311 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:11:45.138934 16311 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:11:45.138938 16311 net.cpp:408] conv1 <- data\n",
      "I0430 11:11:45.138943 16311 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:11:45.139053 16311 net.cpp:124] Setting up conv1\n",
      "I0430 11:11:45.139061 16311 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:11:45.139065 16311 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:11:45.139073 16311 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:11:45.139081 16311 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:11:45.139084 16311 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:11:45.139089 16311 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:11:45.139096 16311 net.cpp:124] Setting up relu1\n",
      "I0430 11:11:45.139101 16311 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:11:45.139104 16311 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:11:45.139108 16311 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:11:45.139113 16311 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:11:45.139117 16311 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:11:45.139122 16311 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:11:45.139132 16311 net.cpp:124] Setting up pool1\n",
      "I0430 11:11:45.139137 16311 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:11:45.139140 16311 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:11:45.139143 16311 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:11:45.139150 16311 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:11:45.139153 16311 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:11:45.139159 16311 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:11:45.139166 16311 net.cpp:124] Setting up norm1\n",
      "I0430 11:11:45.139171 16311 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:11:45.139175 16311 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:11:45.139178 16311 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:11:45.139184 16311 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:11:45.139189 16311 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:11:45.139194 16311 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:11:45.139678 16311 net.cpp:124] Setting up conv2\n",
      "I0430 11:11:45.139689 16311 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:11:45.139693 16311 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:11:45.139703 16311 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:11:45.139709 16311 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:11:45.139714 16311 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:11:45.139717 16311 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:11:45.139724 16311 net.cpp:124] Setting up relu2\n",
      "I0430 11:11:45.139727 16311 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:11:45.139729 16311 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:11:45.139732 16311 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:11:45.139737 16311 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:11:45.139739 16311 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:11:45.139744 16311 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:11:45.139750 16311 net.cpp:124] Setting up pool2\n",
      "I0430 11:11:45.139755 16311 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:11:45.139756 16311 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:11:45.139758 16311 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:11:45.139765 16311 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:11:45.139770 16311 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:11:45.139775 16311 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:11:45.139783 16311 net.cpp:124] Setting up norm2\n",
      "I0430 11:11:45.139788 16311 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:11:45.139791 16311 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:11:45.139796 16311 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:11:45.139806 16311 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:11:45.139809 16311 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:11:45.139814 16311 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:11:45.141242 16311 net.cpp:124] Setting up conv3\n",
      "I0430 11:11:45.141270 16311 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:11:45.141273 16311 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:11:45.141285 16311 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:11:45.141294 16311 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:11:45.141299 16311 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:11:45.141304 16311 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:11:45.141312 16311 net.cpp:124] Setting up relu3\n",
      "I0430 11:11:45.141319 16311 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:11:45.141321 16311 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:11:45.141324 16311 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:11:45.141335 16311 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:11:45.141337 16311 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:11:45.141343 16311 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:11:45.142030 16311 net.cpp:124] Setting up conv4\n",
      "I0430 11:11:45.142047 16311 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:11:45.142051 16311 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:11:45.142060 16311 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:11:45.142068 16311 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:11:45.142072 16311 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:11:45.142078 16311 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:11:45.142086 16311 net.cpp:124] Setting up relu4\n",
      "I0430 11:11:45.142091 16311 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:11:45.142094 16311 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:11:45.142097 16311 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:11:45.142107 16311 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:11:45.142110 16311 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:11:45.142115 16311 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:11:45.142774 16311 net.cpp:124] Setting up conv5\n",
      "I0430 11:11:45.142789 16311 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:11:45.142792 16311 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:11:45.142809 16311 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:11:45.142818 16311 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:11:45.142822 16311 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:11:45.142827 16311 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:11:45.142837 16311 net.cpp:124] Setting up relu5\n",
      "I0430 11:11:45.142841 16311 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:11:45.142843 16311 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:11:45.142848 16311 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:11:45.142854 16311 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:11:45.142858 16311 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:11:45.142863 16311 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:11:45.142873 16311 net.cpp:124] Setting up pool5\n",
      "I0430 11:11:45.142877 16311 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:11:45.142879 16311 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:11:45.142882 16311 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:11:45.142894 16311 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:11:45.142896 16311 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:11:45.142901 16311 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:11:45.167031 16311 net.cpp:124] Setting up fc6\n",
      "I0430 11:11:45.167054 16311 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:11:45.167063 16311 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:11:45.167076 16311 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:11:45.167089 16311 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:11:45.167096 16311 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:11:45.167104 16311 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:11:45.167116 16311 net.cpp:124] Setting up relu6\n",
      "I0430 11:11:45.167122 16311 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:11:45.167125 16311 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:11:45.167129 16311 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:11:45.167135 16311 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:11:45.167137 16311 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:11:45.167142 16311 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:11:45.167148 16311 net.cpp:124] Setting up drop6\n",
      "I0430 11:11:45.167151 16311 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:11:45.167155 16311 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:11:45.167157 16311 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:11:45.167163 16311 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:11:45.167165 16311 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:11:45.167171 16311 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:11:45.176923 16311 net.cpp:124] Setting up fc7\n",
      "I0430 11:11:45.176945 16311 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:11:45.176949 16311 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:11:45.176957 16311 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:11:45.176969 16311 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:11:45.176971 16311 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:11:45.176977 16311 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:11:45.176986 16311 net.cpp:124] Setting up relu7\n",
      "I0430 11:11:45.176990 16311 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:11:45.176991 16311 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:11:45.176993 16311 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:11:45.176998 16311 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:11:45.177001 16311 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:11:45.177009 16311 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:11:45.177016 16311 net.cpp:124] Setting up drop7\n",
      "I0430 11:11:45.177019 16311 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:11:45.177023 16311 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:11:45.177038 16311 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:11:45.177044 16311 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:11:45.177047 16311 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:11:45.177052 16311 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:11:45.177875 16311 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:11:45.177899 16311 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:11:45.177904 16311 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:11:45.177914 16311 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:11:45.177918 16311 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:11:45.177922 16311 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:11:45.177923 16311 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:11:45.177927 16311 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:11:45.177929 16311 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:11:45.177932 16311 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:11:45.177935 16311 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:11:45.177940 16311 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:11:45.177944 16311 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:11:45.177948 16311 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:11:45.177952 16311 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:11:45.177955 16311 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:11:45.177958 16311 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:11:45.177963 16311 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:11:45.177965 16311 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:11:45.177969 16311 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:11:45.177973 16311 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:11:45.177975 16311 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:11:45.177979 16311 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:11:45.177983 16311 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:11:45.177985 16311 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:11:45.177989 16311 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:11:45.177992 16311 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:11:45.178004 16311 net.cpp:257] Network initialization done.\n",
      "I0430 11:11:45.270802 16311 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:11:45.377061 16311 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:11:45.377976 16311 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:11:45.377987 16311 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:11:45.377991 16311 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/183895.jpg'}, '/tmp/tmpQB9rLU.mat')\n",
      "Processed 874 windows in 115.846 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-2.05274, 0.486118, -2.0019, -2.17981, -2.090...\n",
      "ymin                                                        130\n",
      "xmin                                                        133\n",
      "ymax                                                        173\n",
      "xmax                                                        340\n",
      "Name: /home/ambika/INF_project/data/airplane/183895.jpg, dtype: object\n",
      "prediction    [-1.56735, -1.67609, -1.91447, -1.45147, -1.71...\n",
      "ymin                                                        312\n",
      "xmin                                                        234\n",
      "ymax                                                        375\n",
      "xmax                                                        358\n",
      "Name: /home/ambika/INF_project/data/airplane/183895.jpg, dtype: object\n",
      "airplane\n",
      "133\t130\t340\t173\n",
      "seal\n",
      "234\t312\t358\t375\n",
      "183895\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:13:42.955883 16448 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:13:42.955905 16448 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:13:42.955909 16448 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:13:42.957260 16448 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:13:42.957434 16448 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:13:42.957442 16448 net.cpp:86] Creating Layer data\n",
      "I0430 11:13:42.957446 16448 net.cpp:382] data -> data\n",
      "I0430 11:13:42.957459 16448 net.cpp:124] Setting up data\n",
      "I0430 11:13:42.957465 16448 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:13:42.957468 16448 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:13:42.957470 16448 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:13:42.957476 16448 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:13:42.957479 16448 net.cpp:408] conv1 <- data\n",
      "I0430 11:13:42.957482 16448 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:13:42.957554 16448 net.cpp:124] Setting up conv1\n",
      "I0430 11:13:42.957558 16448 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:13:42.957561 16448 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:13:42.957569 16448 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:13:42.957574 16448 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:13:42.957577 16448 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:13:42.957581 16448 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:13:42.957587 16448 net.cpp:124] Setting up relu1\n",
      "I0430 11:13:42.957589 16448 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:13:42.957592 16448 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:13:42.957595 16448 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:13:42.957599 16448 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:13:42.957602 16448 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:13:42.957605 16448 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:13:42.957612 16448 net.cpp:124] Setting up pool1\n",
      "I0430 11:13:42.957617 16448 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:13:42.957618 16448 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:13:42.957623 16448 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:13:42.957625 16448 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:13:42.957628 16448 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:13:42.957630 16448 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:13:42.957635 16448 net.cpp:124] Setting up norm1\n",
      "I0430 11:13:42.957638 16448 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:13:42.957639 16448 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:13:42.957641 16448 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:13:42.957645 16448 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:13:42.957648 16448 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:13:42.957650 16448 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:13:42.958029 16448 net.cpp:124] Setting up conv2\n",
      "I0430 11:13:42.958037 16448 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:13:42.958040 16448 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:13:42.958045 16448 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:13:42.958051 16448 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:13:42.958053 16448 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:13:42.958057 16448 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:13:42.958062 16448 net.cpp:124] Setting up relu2\n",
      "I0430 11:13:42.958066 16448 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:13:42.958068 16448 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:13:42.958071 16448 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:13:42.958076 16448 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:13:42.958078 16448 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:13:42.958082 16448 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:13:42.958088 16448 net.cpp:124] Setting up pool2\n",
      "I0430 11:13:42.958092 16448 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:13:42.958096 16448 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:13:42.958097 16448 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:13:42.958103 16448 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:13:42.958106 16448 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:13:42.958111 16448 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:13:42.958115 16448 net.cpp:124] Setting up norm2\n",
      "I0430 11:13:42.958119 16448 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:13:42.958122 16448 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:13:42.958124 16448 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:13:42.958130 16448 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:13:42.958133 16448 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:13:42.958137 16448 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:13:42.958905 16448 net.cpp:124] Setting up conv3\n",
      "I0430 11:13:42.958914 16448 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:13:42.958919 16448 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:13:42.958930 16448 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:13:42.958937 16448 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:13:42.958940 16448 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:13:42.958945 16448 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:13:42.958950 16448 net.cpp:124] Setting up relu3\n",
      "I0430 11:13:42.958953 16448 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:13:42.958956 16448 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:13:42.958959 16448 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:13:42.958966 16448 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:13:42.958968 16448 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:13:42.958972 16448 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:13:42.959789 16448 net.cpp:124] Setting up conv4\n",
      "I0430 11:13:42.959797 16448 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:13:42.959801 16448 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:13:42.959805 16448 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:13:42.959810 16448 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:13:42.959812 16448 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:13:42.959820 16448 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:13:42.959826 16448 net.cpp:124] Setting up relu4\n",
      "I0430 11:13:42.959831 16448 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:13:42.959834 16448 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:13:42.959837 16448 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:13:42.959846 16448 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:13:42.959848 16448 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:13:42.959854 16448 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:13:42.960413 16448 net.cpp:124] Setting up conv5\n",
      "I0430 11:13:42.960422 16448 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:13:42.960427 16448 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:13:42.960436 16448 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:13:42.960443 16448 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:13:42.960445 16448 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:13:42.960450 16448 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:13:42.960455 16448 net.cpp:124] Setting up relu5\n",
      "I0430 11:13:42.960460 16448 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:13:42.960464 16448 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:13:42.960467 16448 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:13:42.960472 16448 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:13:42.960475 16448 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:13:42.960482 16448 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:13:42.960490 16448 net.cpp:124] Setting up pool5\n",
      "I0430 11:13:42.960495 16448 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:13:42.960497 16448 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:13:42.960501 16448 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:13:42.960510 16448 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:13:42.960512 16448 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:13:42.960518 16448 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:13:42.989125 16448 net.cpp:124] Setting up fc6\n",
      "I0430 11:13:42.989153 16448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:13:42.989158 16448 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:13:42.989171 16448 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:13:42.989187 16448 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:13:42.989192 16448 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:13:42.989199 16448 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:13:42.989208 16448 net.cpp:124] Setting up relu6\n",
      "I0430 11:13:42.989213 16448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:13:42.989217 16448 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:13:42.989220 16448 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:13:42.989228 16448 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:13:42.989230 16448 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:13:42.989234 16448 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:13:42.989241 16448 net.cpp:124] Setting up drop6\n",
      "I0430 11:13:42.989245 16448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:13:42.989248 16448 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:13:42.989253 16448 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:13:42.989260 16448 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:13:42.989264 16448 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:13:42.989269 16448 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:13:43.000933 16448 net.cpp:124] Setting up fc7\n",
      "I0430 11:13:43.000960 16448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:13:43.000967 16448 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:13:43.000995 16448 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:13:43.001005 16448 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:13:43.001010 16448 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:13:43.001018 16448 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:13:43.001027 16448 net.cpp:124] Setting up relu7\n",
      "I0430 11:13:43.001030 16448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:13:43.001034 16448 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:13:43.001036 16448 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:13:43.001044 16448 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:13:43.001047 16448 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:13:43.001052 16448 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:13:43.001058 16448 net.cpp:124] Setting up drop7\n",
      "I0430 11:13:43.001062 16448 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:13:43.001065 16448 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:13:43.001068 16448 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:13:43.001075 16448 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:13:43.001077 16448 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:13:43.001082 16448 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:13:43.001803 16448 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:13:43.001814 16448 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:13:43.001818 16448 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:13:43.001827 16448 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:13:43.001832 16448 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:13:43.001835 16448 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:13:43.001838 16448 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:13:43.001842 16448 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:13:43.001845 16448 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:13:43.001848 16448 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:13:43.001852 16448 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:13:43.001855 16448 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:13:43.001859 16448 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:13:43.001863 16448 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:13:43.001866 16448 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:13:43.001869 16448 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:13:43.001873 16448 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:13:43.001876 16448 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:13:43.001880 16448 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:13:43.001883 16448 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:13:43.001888 16448 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:13:43.001890 16448 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:13:43.001894 16448 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:13:43.001898 16448 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:13:43.001900 16448 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:13:43.001904 16448 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:13:43.001907 16448 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:13:43.001920 16448 net.cpp:257] Network initialization done.\n",
      "I0430 11:13:43.099146 16448 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:13:43.212582 16448 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:13:43.213528 16448 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:13:43.213539 16448 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:13:43.213543 16448 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/388014.jpg'}, '/tmp/tmpu4LwGd.mat')\n",
      "Processed 2265 windows in 282.561 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.2613, -2.14356, -2.13552, -2.09975, -1.576...\n",
      "ymin                                                         68\n",
      "xmin                                                          0\n",
      "ymax                                                        352\n",
      "xmax                                                        146\n",
      "Name: /home/ambika/INF_project/data/bird/388014.jpg, dtype: object\n",
      "prediction    [-2.31982, -2.32746, -2.36013, -2.41079, -1.10...\n",
      "ymin                                                         90\n",
      "xmin                                                          0\n",
      "ymax                                                        325\n",
      "xmax                                                        128\n",
      "Name: /home/ambika/INF_project/data/bird/388014.jpg, dtype: object\n",
      "bird\n",
      "0\t68\t146\t352\n",
      "diaper\n",
      "0\t90\t128\t325\n",
      "388014\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:18:27.461848 16646 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:18:27.461875 16646 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:18:27.461879 16646 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:18:27.463022 16646 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:18:27.463124 16646 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:18:27.463134 16646 net.cpp:86] Creating Layer data\n",
      "I0430 11:18:27.463137 16646 net.cpp:382] data -> data\n",
      "I0430 11:18:27.463147 16646 net.cpp:124] Setting up data\n",
      "I0430 11:18:27.463153 16646 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:18:27.463156 16646 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:18:27.463161 16646 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:18:27.463167 16646 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:18:27.463171 16646 net.cpp:408] conv1 <- data\n",
      "I0430 11:18:27.463176 16646 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:18:27.463244 16646 net.cpp:124] Setting up conv1\n",
      "I0430 11:18:27.463251 16646 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:18:27.463254 16646 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:18:27.463263 16646 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:18:27.463269 16646 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:18:27.463273 16646 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:18:27.463277 16646 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:18:27.463284 16646 net.cpp:124] Setting up relu1\n",
      "I0430 11:18:27.463289 16646 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:18:27.463291 16646 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:18:27.463295 16646 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:18:27.463300 16646 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:18:27.463304 16646 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:18:27.463307 16646 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:18:27.463315 16646 net.cpp:124] Setting up pool1\n",
      "I0430 11:18:27.463320 16646 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:18:27.463322 16646 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:18:27.463325 16646 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:18:27.463330 16646 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:18:27.463333 16646 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:18:27.463338 16646 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:18:27.463345 16646 net.cpp:124] Setting up norm1\n",
      "I0430 11:18:27.463348 16646 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:18:27.463351 16646 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:18:27.463353 16646 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:18:27.463359 16646 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:18:27.463362 16646 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:18:27.463366 16646 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:18:27.463733 16646 net.cpp:124] Setting up conv2\n",
      "I0430 11:18:27.463743 16646 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:18:27.463747 16646 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:18:27.463755 16646 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:18:27.463762 16646 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:18:27.463766 16646 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:18:27.463770 16646 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:18:27.463776 16646 net.cpp:124] Setting up relu2\n",
      "I0430 11:18:27.463781 16646 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:18:27.463785 16646 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:18:27.463789 16646 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:18:27.463795 16646 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:18:27.463799 16646 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:18:27.463804 16646 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:18:27.463811 16646 net.cpp:124] Setting up pool2\n",
      "I0430 11:18:27.463816 16646 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:18:27.463819 16646 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:18:27.463822 16646 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:18:27.463829 16646 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:18:27.463834 16646 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:18:27.463838 16646 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:18:27.463845 16646 net.cpp:124] Setting up norm2\n",
      "I0430 11:18:27.463850 16646 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:18:27.463855 16646 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:18:27.463857 16646 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:18:27.463863 16646 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:18:27.463867 16646 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:18:27.463872 16646 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:18:27.464668 16646 net.cpp:124] Setting up conv3\n",
      "I0430 11:18:27.464691 16646 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:18:27.464695 16646 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:18:27.464705 16646 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:18:27.464715 16646 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:18:27.464720 16646 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:18:27.464725 16646 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:18:27.464732 16646 net.cpp:124] Setting up relu3\n",
      "I0430 11:18:27.464736 16646 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:18:27.464740 16646 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:18:27.464743 16646 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:18:27.464750 16646 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:18:27.464753 16646 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:18:27.464758 16646 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:18:27.465495 16646 net.cpp:124] Setting up conv4\n",
      "I0430 11:18:27.465505 16646 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:18:27.465508 16646 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:18:27.465515 16646 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:18:27.465523 16646 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:18:27.465526 16646 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:18:27.465531 16646 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:18:27.465540 16646 net.cpp:124] Setting up relu4\n",
      "I0430 11:18:27.465544 16646 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:18:27.465548 16646 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:18:27.465553 16646 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:18:27.465560 16646 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:18:27.465564 16646 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:18:27.465569 16646 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:18:27.466066 16646 net.cpp:124] Setting up conv5\n",
      "I0430 11:18:27.466074 16646 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:18:27.466078 16646 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:18:27.466089 16646 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:18:27.466094 16646 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:18:27.466097 16646 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:18:27.466102 16646 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:18:27.466107 16646 net.cpp:124] Setting up relu5\n",
      "I0430 11:18:27.466111 16646 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:18:27.466114 16646 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:18:27.466117 16646 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:18:27.466123 16646 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:18:27.466125 16646 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:18:27.466130 16646 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:18:27.466138 16646 net.cpp:124] Setting up pool5\n",
      "I0430 11:18:27.466142 16646 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:18:27.466145 16646 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:18:27.466148 16646 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:18:27.466157 16646 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:18:27.466161 16646 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:18:27.466166 16646 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:18:27.490324 16646 net.cpp:124] Setting up fc6\n",
      "I0430 11:18:27.490357 16646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:18:27.490360 16646 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:18:27.490371 16646 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:18:27.490382 16646 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:18:27.490386 16646 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:18:27.490392 16646 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:18:27.490401 16646 net.cpp:124] Setting up relu6\n",
      "I0430 11:18:27.490403 16646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:18:27.490406 16646 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:18:27.490411 16646 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:18:27.490417 16646 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:18:27.490419 16646 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:18:27.490424 16646 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:18:27.490430 16646 net.cpp:124] Setting up drop6\n",
      "I0430 11:18:27.490434 16646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:18:27.490437 16646 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:18:27.490440 16646 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:18:27.490447 16646 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:18:27.490449 16646 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:18:27.490455 16646 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:18:27.503777 16646 net.cpp:124] Setting up fc7\n",
      "I0430 11:18:27.503803 16646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:18:27.503806 16646 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:18:27.503818 16646 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:18:27.503829 16646 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:18:27.503832 16646 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:18:27.503839 16646 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:18:27.503846 16646 net.cpp:124] Setting up relu7\n",
      "I0430 11:18:27.503849 16646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:18:27.503851 16646 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:18:27.503865 16646 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:18:27.503871 16646 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:18:27.503875 16646 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:18:27.503880 16646 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:18:27.503886 16646 net.cpp:124] Setting up drop7\n",
      "I0430 11:18:27.503890 16646 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:18:27.503892 16646 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:18:27.503895 16646 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:18:27.503901 16646 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:18:27.503903 16646 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:18:27.503908 16646 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:18:27.504823 16646 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:18:27.504837 16646 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:18:27.504840 16646 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:18:27.504848 16646 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:18:27.504853 16646 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:18:27.504855 16646 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:18:27.504858 16646 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:18:27.504863 16646 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:18:27.504865 16646 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:18:27.504868 16646 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:18:27.504873 16646 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:18:27.504875 16646 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:18:27.504878 16646 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:18:27.504883 16646 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:18:27.504885 16646 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:18:27.504889 16646 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:18:27.504891 16646 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:18:27.504895 16646 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:18:27.504899 16646 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:18:27.504901 16646 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:18:27.504904 16646 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:18:27.504909 16646 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:18:27.504911 16646 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:18:27.504914 16646 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:18:27.504917 16646 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:18:27.504920 16646 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:18:27.504923 16646 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:18:27.504933 16646 net.cpp:257] Network initialization done.\n",
      "I0430 11:18:27.594434 16646 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:18:27.703598 16646 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:18:27.704607 16646 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:18:27.704618 16646 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:18:27.704623 16646 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/176037.jpg'}, '/tmp/tmpD5dmwl.mat')\n",
      "Processed 2457 windows in 311.318 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-2.23078, -2.31393, -1.94556, -2.59112, -2.05...\n",
      "ymin                                                        106\n",
      "xmin                                                        197\n",
      "ymax                                                        250\n",
      "xmax                                                        417\n",
      "Name: /home/ambika/INF_project/data/bus/176037.jpg, dtype: object\n",
      "prediction    [-2.52257, -0.594921, -2.33767, -2.57056, -2.1...\n",
      "ymin                                                          0\n",
      "xmin                                                        265\n",
      "ymax                                                        188\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/bus/176037.jpg, dtype: object\n",
      "bus\n",
      "197\t106\t417\t250\n",
      "airplane\n",
      "265\t0\t500\t188\n",
      "176037\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:23:40.704054 16844 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:23:40.704075 16844 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:23:40.704087 16844 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:23:40.705168 16844 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:23:40.705327 16844 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:23:40.705340 16844 net.cpp:86] Creating Layer data\n",
      "I0430 11:23:40.705346 16844 net.cpp:382] data -> data\n",
      "I0430 11:23:40.705363 16844 net.cpp:124] Setting up data\n",
      "I0430 11:23:40.705370 16844 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:23:40.705374 16844 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:23:40.705377 16844 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:23:40.705384 16844 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:23:40.705389 16844 net.cpp:408] conv1 <- data\n",
      "I0430 11:23:40.705394 16844 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:23:40.705469 16844 net.cpp:124] Setting up conv1\n",
      "I0430 11:23:40.705477 16844 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:23:40.705482 16844 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:23:40.705490 16844 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:23:40.705497 16844 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:23:40.705499 16844 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:23:40.705504 16844 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:23:40.705509 16844 net.cpp:124] Setting up relu1\n",
      "I0430 11:23:40.705513 16844 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:23:40.705516 16844 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:23:40.705519 16844 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:23:40.705524 16844 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:23:40.705528 16844 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:23:40.705533 16844 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:23:40.705539 16844 net.cpp:124] Setting up pool1\n",
      "I0430 11:23:40.705543 16844 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:23:40.705546 16844 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:23:40.705549 16844 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:23:40.705555 16844 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:23:40.705557 16844 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:23:40.705562 16844 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:23:40.705569 16844 net.cpp:124] Setting up norm1\n",
      "I0430 11:23:40.705574 16844 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:23:40.705575 16844 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:23:40.705579 16844 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:23:40.705585 16844 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:23:40.705586 16844 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:23:40.705591 16844 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:23:40.705974 16844 net.cpp:124] Setting up conv2\n",
      "I0430 11:23:40.705988 16844 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:23:40.705992 16844 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:23:40.706001 16844 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:23:40.706008 16844 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:23:40.706012 16844 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:23:40.706017 16844 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:23:40.706023 16844 net.cpp:124] Setting up relu2\n",
      "I0430 11:23:40.706027 16844 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:23:40.706030 16844 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:23:40.706033 16844 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:23:40.706040 16844 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:23:40.706043 16844 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:23:40.706048 16844 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:23:40.706056 16844 net.cpp:124] Setting up pool2\n",
      "I0430 11:23:40.706061 16844 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:23:40.706064 16844 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:23:40.706068 16844 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:23:40.706073 16844 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:23:40.706077 16844 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:23:40.706082 16844 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:23:40.706089 16844 net.cpp:124] Setting up norm2\n",
      "I0430 11:23:40.706094 16844 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:23:40.706097 16844 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:23:40.706101 16844 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:23:40.706110 16844 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:23:40.706113 16844 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:23:40.706120 16844 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:23:40.707134 16844 net.cpp:124] Setting up conv3\n",
      "I0430 11:23:40.707150 16844 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:23:40.707154 16844 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:23:40.707165 16844 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:23:40.707173 16844 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:23:40.707177 16844 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:23:40.707183 16844 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:23:40.707190 16844 net.cpp:124] Setting up relu3\n",
      "I0430 11:23:40.707195 16844 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:23:40.707198 16844 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:23:40.707201 16844 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:23:40.707217 16844 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:23:40.707222 16844 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:23:40.707227 16844 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:23:40.708019 16844 net.cpp:124] Setting up conv4\n",
      "I0430 11:23:40.708034 16844 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:23:40.708037 16844 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:23:40.708045 16844 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:23:40.708052 16844 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:23:40.708055 16844 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:23:40.708062 16844 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:23:40.708070 16844 net.cpp:124] Setting up relu4\n",
      "I0430 11:23:40.708075 16844 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:23:40.708076 16844 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:23:40.708079 16844 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:23:40.708086 16844 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:23:40.708089 16844 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:23:40.708093 16844 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:23:40.708575 16844 net.cpp:124] Setting up conv5\n",
      "I0430 11:23:40.708583 16844 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:23:40.708586 16844 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:23:40.708595 16844 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:23:40.708600 16844 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:23:40.708603 16844 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:23:40.708609 16844 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:23:40.708613 16844 net.cpp:124] Setting up relu5\n",
      "I0430 11:23:40.708618 16844 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:23:40.708621 16844 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:23:40.708623 16844 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:23:40.708629 16844 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:23:40.708632 16844 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:23:40.708636 16844 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:23:40.708643 16844 net.cpp:124] Setting up pool5\n",
      "I0430 11:23:40.708648 16844 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:23:40.708650 16844 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:23:40.708653 16844 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:23:40.708662 16844 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:23:40.708664 16844 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:23:40.708669 16844 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:23:40.735985 16844 net.cpp:124] Setting up fc6\n",
      "I0430 11:23:40.736008 16844 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:23:40.736013 16844 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:23:40.736022 16844 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:23:40.736032 16844 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:23:40.736035 16844 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:23:40.736042 16844 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:23:40.736049 16844 net.cpp:124] Setting up relu6\n",
      "I0430 11:23:40.736053 16844 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:23:40.736055 16844 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:23:40.736059 16844 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:23:40.736076 16844 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:23:40.736079 16844 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:23:40.736084 16844 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:23:40.736090 16844 net.cpp:124] Setting up drop6\n",
      "I0430 11:23:40.736093 16844 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:23:40.736096 16844 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:23:40.736100 16844 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:23:40.736105 16844 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:23:40.736109 16844 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:23:40.736114 16844 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:23:40.745797 16844 net.cpp:124] Setting up fc7\n",
      "I0430 11:23:40.745818 16844 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:23:40.745822 16844 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:23:40.745831 16844 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:23:40.745841 16844 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:23:40.745844 16844 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:23:40.745849 16844 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:23:40.745857 16844 net.cpp:124] Setting up relu7\n",
      "I0430 11:23:40.745860 16844 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:23:40.745862 16844 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:23:40.745865 16844 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:23:40.745870 16844 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:23:40.745883 16844 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:23:40.745889 16844 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:23:40.745896 16844 net.cpp:124] Setting up drop7\n",
      "I0430 11:23:40.745900 16844 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:23:40.745903 16844 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:23:40.745906 16844 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:23:40.745911 16844 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:23:40.745914 16844 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:23:40.745919 16844 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:23:40.746554 16844 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:23:40.746565 16844 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:23:40.746568 16844 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:23:40.746575 16844 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:23:40.746579 16844 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:23:40.746583 16844 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:23:40.746587 16844 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:23:40.746590 16844 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:23:40.746593 16844 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:23:40.746597 16844 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:23:40.746600 16844 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:23:40.746603 16844 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:23:40.746606 16844 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:23:40.746610 16844 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:23:40.746613 16844 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:23:40.746616 16844 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:23:40.746620 16844 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:23:40.746623 16844 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:23:40.746628 16844 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:23:40.746632 16844 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:23:40.746636 16844 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:23:40.746641 16844 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:23:40.746644 16844 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:23:40.746649 16844 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:23:40.746654 16844 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:23:40.746657 16844 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:23:40.746660 16844 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:23:40.746671 16844 net.cpp:257] Network initialization done.\n",
      "I0430 11:23:40.837461 16844 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:23:40.944578 16844 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:23:40.945783 16844 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:23:40.945801 16844 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:23:40.945806 16844 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/43202.jpg'}, '/tmp/tmp1Snhzq.mat')\n",
      "Processed 2903 windows in 356.107 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.18399, -2.28518, -1.82084, -1.95511, -1.73...\n",
      "ymin                                                        213\n",
      "xmin                                                        256\n",
      "ymax                                                        260\n",
      "xmax                                                        277\n",
      "Name: /home/ambika/INF_project/data/car/43202.jpg, dtype: object\n",
      "prediction    [-1.9339, -2.31174, -2.18532, -2.40474, -1.758...\n",
      "ymin                                                        248\n",
      "xmin                                                        293\n",
      "ymax                                                        307\n",
      "xmax                                                        396\n",
      "Name: /home/ambika/INF_project/data/car/43202.jpg, dtype: object\n",
      "person\n",
      "256\t213\t277\t260\n",
      "bicycle\n",
      "293\t248\t396\t307\n",
      "43202\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:29:38.745169 17062 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:29:38.745188 17062 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:29:38.745190 17062 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:29:38.746273 17062 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:29:38.746443 17062 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:29:38.746451 17062 net.cpp:86] Creating Layer data\n",
      "I0430 11:29:38.746454 17062 net.cpp:382] data -> data\n",
      "I0430 11:29:38.746475 17062 net.cpp:124] Setting up data\n",
      "I0430 11:29:38.746485 17062 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:29:38.746490 17062 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:29:38.746495 17062 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:29:38.746502 17062 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:29:38.746506 17062 net.cpp:408] conv1 <- data\n",
      "I0430 11:29:38.746513 17062 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:29:38.746577 17062 net.cpp:124] Setting up conv1\n",
      "I0430 11:29:38.746582 17062 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:29:38.746584 17062 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:29:38.746592 17062 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:29:38.746597 17062 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:29:38.746599 17062 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:29:38.746603 17062 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:29:38.746606 17062 net.cpp:124] Setting up relu1\n",
      "I0430 11:29:38.746609 17062 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:29:38.746613 17062 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:29:38.746614 17062 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:29:38.746618 17062 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:29:38.746620 17062 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:29:38.746624 17062 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:29:38.746630 17062 net.cpp:124] Setting up pool1\n",
      "I0430 11:29:38.746634 17062 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:29:38.746636 17062 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:29:38.746639 17062 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:29:38.746642 17062 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:29:38.746645 17062 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:29:38.746649 17062 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:29:38.746654 17062 net.cpp:124] Setting up norm1\n",
      "I0430 11:29:38.746656 17062 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:29:38.746659 17062 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:29:38.746661 17062 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:29:38.746665 17062 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:29:38.746667 17062 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:29:38.746671 17062 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:29:38.747018 17062 net.cpp:124] Setting up conv2\n",
      "I0430 11:29:38.747025 17062 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:29:38.747028 17062 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:29:38.747036 17062 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:29:38.747042 17062 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:29:38.747046 17062 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:29:38.747051 17062 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:29:38.747058 17062 net.cpp:124] Setting up relu2\n",
      "I0430 11:29:38.747062 17062 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:29:38.747064 17062 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:29:38.747066 17062 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:29:38.747072 17062 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:29:38.747074 17062 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:29:38.747077 17062 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:29:38.747083 17062 net.cpp:124] Setting up pool2\n",
      "I0430 11:29:38.747087 17062 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:29:38.747088 17062 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:29:38.747092 17062 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:29:38.747095 17062 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:29:38.747097 17062 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:29:38.747102 17062 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:29:38.747105 17062 net.cpp:124] Setting up norm2\n",
      "I0430 11:29:38.747108 17062 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:29:38.747112 17062 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:29:38.747113 17062 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:29:38.747118 17062 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:29:38.747120 17062 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:29:38.747124 17062 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:29:38.747869 17062 net.cpp:124] Setting up conv3\n",
      "I0430 11:29:38.747882 17062 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:29:38.747889 17062 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:29:38.747900 17062 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:29:38.747908 17062 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:29:38.747912 17062 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:29:38.747917 17062 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:29:38.747925 17062 net.cpp:124] Setting up relu3\n",
      "I0430 11:29:38.747928 17062 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:29:38.747931 17062 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:29:38.747934 17062 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:29:38.747941 17062 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:29:38.747943 17062 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:29:38.747947 17062 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:29:38.748725 17062 net.cpp:124] Setting up conv4\n",
      "I0430 11:29:38.748740 17062 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:29:38.748744 17062 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:29:38.748750 17062 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:29:38.748759 17062 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:29:38.748764 17062 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:29:38.748769 17062 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:29:38.748776 17062 net.cpp:124] Setting up relu4\n",
      "I0430 11:29:38.748780 17062 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:29:38.748782 17062 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:29:38.748785 17062 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:29:38.748793 17062 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:29:38.748795 17062 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:29:38.748800 17062 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:29:38.749325 17062 net.cpp:124] Setting up conv5\n",
      "I0430 11:29:38.749335 17062 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:29:38.749338 17062 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:29:38.749348 17062 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:29:38.749354 17062 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:29:38.749357 17062 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:29:38.749362 17062 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:29:38.749368 17062 net.cpp:124] Setting up relu5\n",
      "I0430 11:29:38.749372 17062 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:29:38.749374 17062 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:29:38.749377 17062 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:29:38.749382 17062 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:29:38.749385 17062 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:29:38.749389 17062 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:29:38.749397 17062 net.cpp:124] Setting up pool5\n",
      "I0430 11:29:38.749402 17062 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:29:38.749403 17062 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:29:38.749406 17062 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:29:38.749414 17062 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:29:38.749418 17062 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:29:38.749423 17062 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:29:38.773025 17062 net.cpp:124] Setting up fc6\n",
      "I0430 11:29:38.773061 17062 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:29:38.773064 17062 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:29:38.773074 17062 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:29:38.773084 17062 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:29:38.773087 17062 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:29:38.773093 17062 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:29:38.773100 17062 net.cpp:124] Setting up relu6\n",
      "I0430 11:29:38.773104 17062 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:29:38.773106 17062 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:29:38.773110 17062 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:29:38.773118 17062 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:29:38.773120 17062 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:29:38.773125 17062 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:29:38.773133 17062 net.cpp:124] Setting up drop6\n",
      "I0430 11:29:38.773138 17062 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:29:38.773140 17062 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:29:38.773144 17062 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:29:38.773149 17062 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:29:38.773154 17062 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:29:38.773160 17062 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:29:38.788573 17062 net.cpp:124] Setting up fc7\n",
      "I0430 11:29:38.788599 17062 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:29:38.788604 17062 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:29:38.788614 17062 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:29:38.788622 17062 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:29:38.788626 17062 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:29:38.788631 17062 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:29:38.788640 17062 net.cpp:124] Setting up relu7\n",
      "I0430 11:29:38.788645 17062 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:29:38.788648 17062 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:29:38.788651 17062 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:29:38.788657 17062 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:29:38.788661 17062 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:29:38.788666 17062 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:29:38.788673 17062 net.cpp:124] Setting up drop7\n",
      "I0430 11:29:38.788677 17062 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:29:38.788681 17062 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:29:38.788683 17062 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:29:38.788689 17062 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:29:38.788692 17062 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:29:38.788697 17062 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:29:38.789652 17062 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:29:38.789667 17062 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:29:38.789671 17062 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:29:38.789680 17062 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:29:38.789683 17062 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:29:38.789686 17062 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:29:38.789690 17062 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:29:38.789700 17062 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:29:38.789703 17062 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:29:38.789706 17062 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:29:38.789710 17062 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:29:38.789713 17062 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:29:38.789717 17062 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:29:38.789721 17062 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:29:38.789723 17062 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:29:38.789727 17062 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:29:38.789731 17062 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:29:38.789734 17062 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:29:38.789737 17062 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:29:38.789741 17062 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:29:38.789743 17062 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:29:38.789747 17062 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:29:38.789750 17062 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:29:38.789753 17062 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:29:38.789757 17062 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:29:38.789760 17062 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:29:38.789762 17062 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:29:38.789773 17062 net.cpp:257] Network initialization done.\n",
      "I0430 11:29:38.884443 17062 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:29:38.996345 17062 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:29:38.997344 17062 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:29:38.997354 17062 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:29:38.997356 17062 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/264976.jpg'}, '/tmp/tmpxCOIdw.mat')\n",
      "Processed 709 windows in 98.595 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.038 s.\n",
      "prediction    [-2.42704, -2.04746, -2.06626, -1.79, -2.43691...\n",
      "ymin                                                        185\n",
      "xmin                                                          0\n",
      "ymax                                                        320\n",
      "xmax                                                        114\n",
      "Name: /home/ambika/INF_project/data/cat/264976.jpg, dtype: object\n",
      "prediction    [-2.23336, -1.65279, -1.98721, -1.62866, -1.44...\n",
      "ymin                                                         13\n",
      "xmin                                                        136\n",
      "ymax                                                        343\n",
      "xmax                                                        390\n",
      "Name: /home/ambika/INF_project/data/cat/264976.jpg, dtype: object\n",
      "ray\n",
      "0\t185\t114\t320\n",
      "goldfish\n",
      "136\t13\t390\t343\n",
      "264976\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:31:19.186429 17210 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:31:19.186450 17210 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:31:19.186453 17210 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:31:19.187652 17210 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:31:19.187757 17210 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:31:19.187765 17210 net.cpp:86] Creating Layer data\n",
      "I0430 11:31:19.187770 17210 net.cpp:382] data -> data\n",
      "I0430 11:31:19.187783 17210 net.cpp:124] Setting up data\n",
      "I0430 11:31:19.187789 17210 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:31:19.187791 17210 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:31:19.187795 17210 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:31:19.187803 17210 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:31:19.187805 17210 net.cpp:408] conv1 <- data\n",
      "I0430 11:31:19.187810 17210 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:31:19.187870 17210 net.cpp:124] Setting up conv1\n",
      "I0430 11:31:19.187875 17210 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:31:19.187878 17210 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:31:19.187887 17210 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:31:19.187893 17210 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:31:19.187896 17210 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:31:19.187901 17210 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:31:19.187906 17210 net.cpp:124] Setting up relu1\n",
      "I0430 11:31:19.187909 17210 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:31:19.187912 17210 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:31:19.187916 17210 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:31:19.187921 17210 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:31:19.187923 17210 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:31:19.187928 17210 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:31:19.187937 17210 net.cpp:124] Setting up pool1\n",
      "I0430 11:31:19.187942 17210 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:31:19.187944 17210 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:31:19.187947 17210 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:31:19.187952 17210 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:31:19.187955 17210 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:31:19.187959 17210 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:31:19.187965 17210 net.cpp:124] Setting up norm1\n",
      "I0430 11:31:19.187970 17210 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:31:19.187973 17210 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:31:19.187975 17210 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:31:19.187980 17210 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:31:19.187983 17210 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:31:19.187988 17210 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:31:19.188349 17210 net.cpp:124] Setting up conv2\n",
      "I0430 11:31:19.188356 17210 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:31:19.188360 17210 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:31:19.188369 17210 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:31:19.188374 17210 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:31:19.188376 17210 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:31:19.188381 17210 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:31:19.188386 17210 net.cpp:124] Setting up relu2\n",
      "I0430 11:31:19.188390 17210 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:31:19.188393 17210 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:31:19.188396 17210 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:31:19.188402 17210 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:31:19.188405 17210 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:31:19.188410 17210 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:31:19.188416 17210 net.cpp:124] Setting up pool2\n",
      "I0430 11:31:19.188421 17210 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:31:19.188422 17210 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:31:19.188426 17210 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:31:19.188431 17210 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:31:19.188433 17210 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:31:19.188438 17210 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:31:19.188444 17210 net.cpp:124] Setting up norm2\n",
      "I0430 11:31:19.188448 17210 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:31:19.188450 17210 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:31:19.188453 17210 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:31:19.188459 17210 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:31:19.188462 17210 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:31:19.188467 17210 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:31:19.189301 17210 net.cpp:124] Setting up conv3\n",
      "I0430 11:31:19.189332 17210 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:31:19.189335 17210 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:31:19.189347 17210 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:31:19.189357 17210 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:31:19.189359 17210 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:31:19.189366 17210 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:31:19.189376 17210 net.cpp:124] Setting up relu3\n",
      "I0430 11:31:19.189381 17210 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:31:19.189384 17210 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:31:19.189388 17210 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:31:19.189396 17210 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:31:19.189400 17210 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:31:19.189405 17210 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:31:19.190459 17210 net.cpp:124] Setting up conv4\n",
      "I0430 11:31:19.190479 17210 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:31:19.190482 17210 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:31:19.190490 17210 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:31:19.190498 17210 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:31:19.190502 17210 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:31:19.190510 17210 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:31:19.190517 17210 net.cpp:124] Setting up relu4\n",
      "I0430 11:31:19.190522 17210 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:31:19.190526 17210 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:31:19.190529 17210 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:31:19.190537 17210 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:31:19.190541 17210 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:31:19.190546 17210 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:31:19.191284 17210 net.cpp:124] Setting up conv5\n",
      "I0430 11:31:19.191298 17210 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:31:19.191301 17210 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:31:19.191315 17210 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:31:19.191323 17210 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:31:19.191326 17210 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:31:19.191331 17210 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:31:19.191339 17210 net.cpp:124] Setting up relu5\n",
      "I0430 11:31:19.191345 17210 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:31:19.191349 17210 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:31:19.191352 17210 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:31:19.191357 17210 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:31:19.191361 17210 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:31:19.191366 17210 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:31:19.191375 17210 net.cpp:124] Setting up pool5\n",
      "I0430 11:31:19.191380 17210 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:31:19.191383 17210 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:31:19.191387 17210 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:31:19.191396 17210 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:31:19.191401 17210 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:31:19.191406 17210 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:31:19.216630 17210 net.cpp:124] Setting up fc6\n",
      "I0430 11:31:19.216655 17210 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:31:19.216661 17210 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:31:19.216672 17210 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:31:19.216682 17210 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:31:19.216686 17210 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:31:19.216691 17210 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:31:19.216699 17210 net.cpp:124] Setting up relu6\n",
      "I0430 11:31:19.216703 17210 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:31:19.216706 17210 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:31:19.216708 17210 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:31:19.216713 17210 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:31:19.216729 17210 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:31:19.216734 17210 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:31:19.216740 17210 net.cpp:124] Setting up drop6\n",
      "I0430 11:31:19.216744 17210 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:31:19.216747 17210 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:31:19.216750 17210 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:31:19.216755 17210 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:31:19.216758 17210 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:31:19.216763 17210 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:31:19.230096 17210 net.cpp:124] Setting up fc7\n",
      "I0430 11:31:19.230144 17210 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:31:19.230146 17210 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:31:19.230160 17210 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:31:19.230195 17210 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:31:19.230198 17210 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:31:19.230206 17210 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:31:19.230216 17210 net.cpp:124] Setting up relu7\n",
      "I0430 11:31:19.230219 17210 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:31:19.230221 17210 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:31:19.230224 17210 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:31:19.230232 17210 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:31:19.230234 17210 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:31:19.230239 17210 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:31:19.230247 17210 net.cpp:124] Setting up drop7\n",
      "I0430 11:31:19.230249 17210 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:31:19.230252 17210 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:31:19.230255 17210 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:31:19.230262 17210 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:31:19.230264 17210 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:31:19.230268 17210 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:31:19.231221 17210 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:31:19.231242 17210 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:31:19.231245 17210 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:31:19.231256 17210 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:31:19.231261 17210 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:31:19.231264 17210 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:31:19.231267 17210 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:31:19.231271 17210 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:31:19.231274 17210 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:31:19.231277 17210 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:31:19.231281 17210 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:31:19.231284 17210 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:31:19.231288 17210 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:31:19.231293 17210 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:31:19.231297 17210 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:31:19.231300 17210 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:31:19.231304 17210 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:31:19.231308 17210 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:31:19.231312 17210 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:31:19.231315 17210 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:31:19.231318 17210 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:31:19.231323 17210 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:31:19.231325 17210 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:31:19.231329 17210 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:31:19.231333 17210 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:31:19.231336 17210 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:31:19.231339 17210 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:31:19.231351 17210 net.cpp:257] Network initialization done.\n",
      "I0430 11:31:19.324573 17210 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:31:19.429729 17210 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:31:19.431118 17210 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:31:19.431135 17210 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:31:19.431140 17210 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/106712.jpg'}, '/tmp/tmpIDvInd.mat')\n",
      "Processed 2725 windows in 333.750 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.045 s.\n",
      "prediction    [-1.7384, -1.82117, -1.59092, -2.35883, -1.502...\n",
      "ymin                                                        278\n",
      "xmin                                                        320\n",
      "ymax                                                        301\n",
      "xmax                                                        348\n",
      "Name: /home/ambika/INF_project/data/couch/106712.jpg, dtype: object\n",
      "prediction    [-2.14777, -2.14918, -2.48826, -1.86536, -2.22...\n",
      "ymin                                                        217\n",
      "xmin                                                        383\n",
      "ymax                                                        259\n",
      "xmax                                                        437\n",
      "Name: /home/ambika/INF_project/data/couch/106712.jpg, dtype: object\n",
      "basketball\n",
      "320\t278\t348\t301\n",
      "face powder\n",
      "383\t217\t437\t259\n",
      "106712\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:36:55.035652 17400 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:36:55.035681 17400 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:36:55.035683 17400 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:36:55.036953 17400 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:36:55.037181 17400 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:36:55.037192 17400 net.cpp:86] Creating Layer data\n",
      "I0430 11:36:55.037197 17400 net.cpp:382] data -> data\n",
      "I0430 11:36:55.037209 17400 net.cpp:124] Setting up data\n",
      "I0430 11:36:55.037215 17400 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:36:55.037219 17400 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:36:55.037223 17400 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:36:55.037230 17400 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:36:55.037235 17400 net.cpp:408] conv1 <- data\n",
      "I0430 11:36:55.037240 17400 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:36:55.037302 17400 net.cpp:124] Setting up conv1\n",
      "I0430 11:36:55.037308 17400 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:36:55.037312 17400 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:36:55.037320 17400 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:36:55.037328 17400 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:36:55.037331 17400 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:36:55.037336 17400 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:36:55.037343 17400 net.cpp:124] Setting up relu1\n",
      "I0430 11:36:55.037348 17400 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:36:55.037351 17400 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:36:55.037354 17400 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:36:55.037359 17400 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:36:55.037364 17400 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:36:55.037369 17400 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:36:55.037379 17400 net.cpp:124] Setting up pool1\n",
      "I0430 11:36:55.037384 17400 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:36:55.037386 17400 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:36:55.037389 17400 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:36:55.037396 17400 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:36:55.037400 17400 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:36:55.037405 17400 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:36:55.037411 17400 net.cpp:124] Setting up norm1\n",
      "I0430 11:36:55.037416 17400 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:36:55.037420 17400 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:36:55.037423 17400 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:36:55.037430 17400 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:36:55.037432 17400 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:36:55.037437 17400 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:36:55.037828 17400 net.cpp:124] Setting up conv2\n",
      "I0430 11:36:55.037837 17400 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:36:55.037840 17400 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:36:55.037849 17400 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:36:55.037855 17400 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:36:55.037858 17400 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:36:55.037864 17400 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:36:55.037869 17400 net.cpp:124] Setting up relu2\n",
      "I0430 11:36:55.037874 17400 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:36:55.037878 17400 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:36:55.037881 17400 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:36:55.037888 17400 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:36:55.037891 17400 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:36:55.037896 17400 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:36:55.037904 17400 net.cpp:124] Setting up pool2\n",
      "I0430 11:36:55.037909 17400 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:36:55.037912 17400 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:36:55.037915 17400 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:36:55.037921 17400 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:36:55.037925 17400 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:36:55.037930 17400 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:36:55.037936 17400 net.cpp:124] Setting up norm2\n",
      "I0430 11:36:55.037941 17400 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:36:55.037943 17400 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:36:55.037947 17400 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:36:55.037955 17400 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:36:55.037957 17400 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:36:55.037963 17400 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:36:55.038740 17400 net.cpp:124] Setting up conv3\n",
      "I0430 11:36:55.038758 17400 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:36:55.038761 17400 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:36:55.038774 17400 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:36:55.038791 17400 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:36:55.038797 17400 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:36:55.038806 17400 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:36:55.038815 17400 net.cpp:124] Setting up relu3\n",
      "I0430 11:36:55.038820 17400 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:36:55.038823 17400 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:36:55.038826 17400 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:36:55.038835 17400 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:36:55.038837 17400 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:36:55.038843 17400 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:36:55.039721 17400 net.cpp:124] Setting up conv4\n",
      "I0430 11:36:55.039734 17400 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:36:55.039738 17400 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:36:55.039746 17400 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:36:55.039755 17400 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:36:55.039759 17400 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:36:55.039765 17400 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:36:55.039772 17400 net.cpp:124] Setting up relu4\n",
      "I0430 11:36:55.039777 17400 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:36:55.039779 17400 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:36:55.039783 17400 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:36:55.039791 17400 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:36:55.039794 17400 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:36:55.039800 17400 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:36:55.040359 17400 net.cpp:124] Setting up conv5\n",
      "I0430 11:36:55.040367 17400 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:36:55.040371 17400 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:36:55.040383 17400 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:36:55.040390 17400 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:36:55.040392 17400 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:36:55.040400 17400 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:36:55.040405 17400 net.cpp:124] Setting up relu5\n",
      "I0430 11:36:55.040410 17400 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:36:55.040412 17400 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:36:55.040416 17400 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:36:55.040422 17400 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:36:55.040426 17400 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:36:55.040431 17400 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:36:55.040439 17400 net.cpp:124] Setting up pool5\n",
      "I0430 11:36:55.040444 17400 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:36:55.040447 17400 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:36:55.040451 17400 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:36:55.040462 17400 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:36:55.040465 17400 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:36:55.040472 17400 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:36:55.069516 17400 net.cpp:124] Setting up fc6\n",
      "I0430 11:36:55.069542 17400 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:36:55.069548 17400 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:36:55.069560 17400 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:36:55.069571 17400 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:36:55.069576 17400 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:36:55.069581 17400 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:36:55.069591 17400 net.cpp:124] Setting up relu6\n",
      "I0430 11:36:55.069594 17400 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:36:55.069612 17400 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:36:55.069615 17400 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:36:55.069622 17400 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:36:55.069625 17400 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:36:55.069630 17400 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:36:55.069638 17400 net.cpp:124] Setting up drop6\n",
      "I0430 11:36:55.069641 17400 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:36:55.069644 17400 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:36:55.069648 17400 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:36:55.069654 17400 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:36:55.069658 17400 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:36:55.069664 17400 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:36:55.081208 17400 net.cpp:124] Setting up fc7\n",
      "I0430 11:36:55.081233 17400 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:36:55.081238 17400 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:36:55.081248 17400 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:36:55.081259 17400 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:36:55.081262 17400 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:36:55.081269 17400 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:36:55.081284 17400 net.cpp:124] Setting up relu7\n",
      "I0430 11:36:55.081288 17400 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:36:55.081291 17400 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:36:55.081295 17400 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:36:55.081305 17400 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:36:55.081306 17400 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:36:55.081311 17400 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:36:55.081318 17400 net.cpp:124] Setting up drop7\n",
      "I0430 11:36:55.081321 17400 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:36:55.081324 17400 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:36:55.081327 17400 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:36:55.081333 17400 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:36:55.081336 17400 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:36:55.081341 17400 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:36:55.082427 17400 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:36:55.082449 17400 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:36:55.082453 17400 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:36:55.082464 17400 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:36:55.082468 17400 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:36:55.082471 17400 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:36:55.082474 17400 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:36:55.082480 17400 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:36:55.082484 17400 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:36:55.082486 17400 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:36:55.082490 17400 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:36:55.082504 17400 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:36:55.082509 17400 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:36:55.082512 17400 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:36:55.082516 17400 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:36:55.082520 17400 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:36:55.082523 17400 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:36:55.082527 17400 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:36:55.082531 17400 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:36:55.082535 17400 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:36:55.082537 17400 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:36:55.082541 17400 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:36:55.082545 17400 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:36:55.082548 17400 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:36:55.082552 17400 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:36:55.082556 17400 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:36:55.082558 17400 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:36:55.082571 17400 net.cpp:257] Network initialization done.\n",
      "I0430 11:36:55.180847 17400 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:36:55.294829 17400 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:36:55.295750 17400 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:36:55.295758 17400 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:36:55.295764 17400 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/102555.jpg'}, '/tmp/tmpisxU1i.mat')\n",
      "Processed 2506 windows in 325.373 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.034 s.\n",
      "prediction    [-1.7053, -2.0599, -1.97526, -2.31901, -1.7841...\n",
      "ymin                                                        262\n",
      "xmin                                                        292\n",
      "ymax                                                        384\n",
      "xmax                                                        474\n",
      "Name: /home/ambika/INF_project/data/dog/102555.jpg, dtype: object\n",
      "prediction    [-1.90261, -1.75479, -1.8928, -1.86483, -1.760...\n",
      "ymin                                                         52\n",
      "xmin                                                          0\n",
      "ymax                                                        418\n",
      "xmax                                                        347\n",
      "Name: /home/ambika/INF_project/data/dog/102555.jpg, dtype: object\n",
      "dog\n",
      "292\t262\t474\t384\n",
      "person\n",
      "0\t52\t347\t418\n",
      "102555\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:42:22.313290 17619 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:42:22.313313 17619 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:42:22.313318 17619 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:42:22.314651 17619 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:42:22.314827 17619 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:42:22.314839 17619 net.cpp:86] Creating Layer data\n",
      "I0430 11:42:22.314846 17619 net.cpp:382] data -> data\n",
      "I0430 11:42:22.314862 17619 net.cpp:124] Setting up data\n",
      "I0430 11:42:22.314870 17619 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:42:22.314874 17619 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:42:22.314878 17619 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:42:22.314888 17619 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:42:22.314891 17619 net.cpp:408] conv1 <- data\n",
      "I0430 11:42:22.314896 17619 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:42:22.315011 17619 net.cpp:124] Setting up conv1\n",
      "I0430 11:42:22.315026 17619 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:42:22.315033 17619 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:42:22.315049 17619 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:42:22.315057 17619 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:42:22.315062 17619 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:42:22.315066 17619 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:42:22.315073 17619 net.cpp:124] Setting up relu1\n",
      "I0430 11:42:22.315076 17619 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:42:22.315079 17619 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:42:22.315083 17619 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:42:22.315089 17619 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:42:22.315093 17619 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:42:22.315099 17619 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:42:22.315109 17619 net.cpp:124] Setting up pool1\n",
      "I0430 11:42:22.315114 17619 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:42:22.315119 17619 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:42:22.315122 17619 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:42:22.315129 17619 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:42:22.315131 17619 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:42:22.315136 17619 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:42:22.315145 17619 net.cpp:124] Setting up norm1\n",
      "I0430 11:42:22.315150 17619 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:42:22.315152 17619 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:42:22.315155 17619 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:42:22.315161 17619 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:42:22.315165 17619 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:42:22.315171 17619 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:42:22.315661 17619 net.cpp:124] Setting up conv2\n",
      "I0430 11:42:22.315675 17619 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:42:22.315680 17619 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:42:22.315687 17619 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:42:22.315696 17619 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:42:22.315698 17619 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:42:22.315706 17619 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:42:22.315712 17619 net.cpp:124] Setting up relu2\n",
      "I0430 11:42:22.315717 17619 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:42:22.315721 17619 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:42:22.315724 17619 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:42:22.315729 17619 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:42:22.315733 17619 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:42:22.315738 17619 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:42:22.315749 17619 net.cpp:124] Setting up pool2\n",
      "I0430 11:42:22.315754 17619 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:42:22.315758 17619 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:42:22.315762 17619 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:42:22.315775 17619 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:42:22.315779 17619 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:42:22.315784 17619 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:42:22.315793 17619 net.cpp:124] Setting up norm2\n",
      "I0430 11:42:22.315798 17619 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:42:22.315803 17619 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:42:22.315807 17619 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:42:22.315819 17619 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:42:22.315824 17619 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:42:22.315829 17619 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:42:22.317433 17619 net.cpp:124] Setting up conv3\n",
      "I0430 11:42:22.317512 17619 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:42:22.317519 17619 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:42:22.317555 17619 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:42:22.317596 17619 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:42:22.317605 17619 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:42:22.317621 17619 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:42:22.317678 17619 net.cpp:124] Setting up relu3\n",
      "I0430 11:42:22.317684 17619 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:42:22.317687 17619 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:42:22.317692 17619 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:42:22.317721 17619 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:42:22.317728 17619 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:42:22.317739 17619 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:42:22.319466 17619 net.cpp:124] Setting up conv4\n",
      "I0430 11:42:22.319492 17619 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:42:22.319497 17619 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:42:22.319506 17619 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:42:22.319515 17619 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:42:22.319519 17619 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:42:22.319525 17619 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:42:22.319533 17619 net.cpp:124] Setting up relu4\n",
      "I0430 11:42:22.319538 17619 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:42:22.319540 17619 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:42:22.319545 17619 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:42:22.319552 17619 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:42:22.319555 17619 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:42:22.319561 17619 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:42:22.320155 17619 net.cpp:124] Setting up conv5\n",
      "I0430 11:42:22.320169 17619 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:42:22.320173 17619 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:42:22.320184 17619 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:42:22.320191 17619 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:42:22.320210 17619 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:42:22.320216 17619 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:42:22.320222 17619 net.cpp:124] Setting up relu5\n",
      "I0430 11:42:22.320227 17619 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:42:22.320230 17619 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:42:22.320233 17619 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:42:22.320238 17619 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:42:22.320242 17619 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:42:22.320251 17619 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:42:22.320261 17619 net.cpp:124] Setting up pool5\n",
      "I0430 11:42:22.320266 17619 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:42:22.320269 17619 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:42:22.320272 17619 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:42:22.320281 17619 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:42:22.320284 17619 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:42:22.320289 17619 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:42:22.341812 17619 net.cpp:124] Setting up fc6\n",
      "I0430 11:42:22.341835 17619 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:42:22.341841 17619 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:42:22.341852 17619 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:42:22.341862 17619 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:42:22.341866 17619 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:42:22.341872 17619 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:42:22.341881 17619 net.cpp:124] Setting up relu6\n",
      "I0430 11:42:22.341884 17619 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:42:22.341886 17619 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:42:22.341891 17619 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:42:22.341895 17619 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:42:22.341898 17619 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:42:22.341902 17619 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:42:22.341908 17619 net.cpp:124] Setting up drop6\n",
      "I0430 11:42:22.341912 17619 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:42:22.341914 17619 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:42:22.341917 17619 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:42:22.341922 17619 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:42:22.341924 17619 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:42:22.341929 17619 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:42:22.352721 17619 net.cpp:124] Setting up fc7\n",
      "I0430 11:42:22.352747 17619 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:42:22.352753 17619 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:42:22.352802 17619 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:42:22.352811 17619 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:42:22.352815 17619 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:42:22.352823 17619 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:42:22.352831 17619 net.cpp:124] Setting up relu7\n",
      "I0430 11:42:22.352835 17619 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:42:22.352838 17619 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:42:22.352843 17619 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:42:22.352854 17619 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:42:22.352857 17619 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:42:22.352864 17619 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:42:22.352869 17619 net.cpp:124] Setting up drop7\n",
      "I0430 11:42:22.352874 17619 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:42:22.352875 17619 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:42:22.352880 17619 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:42:22.352885 17619 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:42:22.352887 17619 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:42:22.352892 17619 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:42:22.353543 17619 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:42:22.353555 17619 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:42:22.353559 17619 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:42:22.353566 17619 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:42:22.353570 17619 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:42:22.353576 17619 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:42:22.353579 17619 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:42:22.353582 17619 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:42:22.353585 17619 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:42:22.353587 17619 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:42:22.353590 17619 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:42:22.353593 17619 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:42:22.353596 17619 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:42:22.353598 17619 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:42:22.353601 17619 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:42:22.353605 17619 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:42:22.353607 17619 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:42:22.353610 17619 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:42:22.353613 17619 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:42:22.353616 17619 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:42:22.353619 17619 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:42:22.353622 17619 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:42:22.353626 17619 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:42:22.353627 17619 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:42:22.353631 17619 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:42:22.353633 17619 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:42:22.353636 17619 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:42:22.353646 17619 net.cpp:257] Network initialization done.\n",
      "I0430 11:42:22.449556 17619 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:42:22.554344 17619 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:42:22.555696 17619 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:42:22.555716 17619 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:42:22.555721 17619 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/508639.jpg'}, '/tmp/tmpoIxcTL.mat')\n",
      "Processed 1989 windows in 258.293 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.047 s.\n",
      "prediction    [-2.40113, -1.71066, -2.30205, -2.45094, -2.32...\n",
      "ymin                                                        165\n",
      "xmin                                                        240\n",
      "ymax                                                        373\n",
      "xmax                                                        483\n",
      "Name: /home/ambika/INF_project/data/horse/508639.jpg, dtype: object\n",
      "prediction    [-2.14855, -1.74118, -2.4112, -1.74508, -2.010...\n",
      "ymin                                                        231\n",
      "xmin                                                        144\n",
      "ymax                                                        312\n",
      "xmax                                                        288\n",
      "Name: /home/ambika/INF_project/data/horse/508639.jpg, dtype: object\n",
      "cart\n",
      "240\t165\t483\t373\n",
      "cattle\n",
      "144\t231\t288\t312\n",
      "508639\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:46:42.663511 17824 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:46:42.663538 17824 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:46:42.663543 17824 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:46:42.665402 17824 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:46:42.665664 17824 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:46:42.665681 17824 net.cpp:86] Creating Layer data\n",
      "I0430 11:46:42.665686 17824 net.cpp:382] data -> data\n",
      "I0430 11:46:42.665705 17824 net.cpp:124] Setting up data\n",
      "I0430 11:46:42.665714 17824 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:46:42.665717 17824 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:46:42.665720 17824 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:46:42.665729 17824 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:46:42.665730 17824 net.cpp:408] conv1 <- data\n",
      "I0430 11:46:42.665735 17824 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:46:42.665822 17824 net.cpp:124] Setting up conv1\n",
      "I0430 11:46:42.665828 17824 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:46:42.665832 17824 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:46:42.665840 17824 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:46:42.665846 17824 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:46:42.665849 17824 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:46:42.665853 17824 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:46:42.665858 17824 net.cpp:124] Setting up relu1\n",
      "I0430 11:46:42.665863 17824 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:46:42.665865 17824 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:46:42.665868 17824 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:46:42.665873 17824 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:46:42.665875 17824 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:46:42.665879 17824 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:46:42.665887 17824 net.cpp:124] Setting up pool1\n",
      "I0430 11:46:42.665891 17824 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:46:42.665894 17824 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:46:42.665897 17824 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:46:42.665902 17824 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:46:42.665905 17824 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:46:42.665910 17824 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:46:42.665915 17824 net.cpp:124] Setting up norm1\n",
      "I0430 11:46:42.665920 17824 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:46:42.665922 17824 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:46:42.665925 17824 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:46:42.665931 17824 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:46:42.665935 17824 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:46:42.665938 17824 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:46:42.666373 17824 net.cpp:124] Setting up conv2\n",
      "I0430 11:46:42.666386 17824 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:46:42.666388 17824 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:46:42.666396 17824 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:46:42.666401 17824 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:46:42.666405 17824 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:46:42.666410 17824 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:46:42.666415 17824 net.cpp:124] Setting up relu2\n",
      "I0430 11:46:42.666419 17824 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:46:42.666421 17824 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:46:42.666424 17824 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:46:42.666430 17824 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:46:42.666432 17824 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:46:42.666436 17824 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:46:42.666443 17824 net.cpp:124] Setting up pool2\n",
      "I0430 11:46:42.666447 17824 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:46:42.666450 17824 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:46:42.666452 17824 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:46:42.666457 17824 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:46:42.666460 17824 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:46:42.666463 17824 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:46:42.666468 17824 net.cpp:124] Setting up norm2\n",
      "I0430 11:46:42.666472 17824 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:46:42.666474 17824 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:46:42.666477 17824 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:46:42.666484 17824 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:46:42.666486 17824 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:46:42.666491 17824 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:46:42.667300 17824 net.cpp:124] Setting up conv3\n",
      "I0430 11:46:42.667312 17824 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:46:42.667315 17824 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:46:42.667323 17824 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:46:42.667330 17824 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:46:42.667332 17824 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:46:42.667337 17824 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:46:42.667342 17824 net.cpp:124] Setting up relu3\n",
      "I0430 11:46:42.667346 17824 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:46:42.667348 17824 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:46:42.667351 17824 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:46:42.667356 17824 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:46:42.667358 17824 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:46:42.667362 17824 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:46:42.668180 17824 net.cpp:124] Setting up conv4\n",
      "I0430 11:46:42.668189 17824 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:46:42.668192 17824 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:46:42.668196 17824 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:46:42.668201 17824 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:46:42.668205 17824 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:46:42.668208 17824 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:46:42.668212 17824 net.cpp:124] Setting up relu4\n",
      "I0430 11:46:42.668217 17824 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:46:42.668220 17824 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:46:42.668222 17824 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:46:42.668227 17824 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:46:42.668229 17824 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:46:42.668233 17824 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:46:42.668772 17824 net.cpp:124] Setting up conv5\n",
      "I0430 11:46:42.668779 17824 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:46:42.668782 17824 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:46:42.668792 17824 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:46:42.668797 17824 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:46:42.668798 17824 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:46:42.668802 17824 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:46:42.668805 17824 net.cpp:124] Setting up relu5\n",
      "I0430 11:46:42.668809 17824 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:46:42.668812 17824 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:46:42.668814 17824 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:46:42.668819 17824 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:46:42.668822 17824 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:46:42.668826 17824 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:46:42.668833 17824 net.cpp:124] Setting up pool5\n",
      "I0430 11:46:42.668838 17824 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:46:42.668840 17824 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:46:42.668843 17824 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:46:42.668849 17824 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:46:42.668853 17824 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:46:42.668856 17824 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:46:42.695806 17824 net.cpp:124] Setting up fc6\n",
      "I0430 11:46:42.695837 17824 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:46:42.695842 17824 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:46:42.695852 17824 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:46:42.695861 17824 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:46:42.695864 17824 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:46:42.695870 17824 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:46:42.695876 17824 net.cpp:124] Setting up relu6\n",
      "I0430 11:46:42.695879 17824 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:46:42.695881 17824 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:46:42.695885 17824 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:46:42.695890 17824 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:46:42.695894 17824 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:46:42.695897 17824 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:46:42.695902 17824 net.cpp:124] Setting up drop6\n",
      "I0430 11:46:42.695905 17824 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:46:42.695909 17824 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:46:42.695911 17824 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:46:42.695917 17824 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:46:42.695919 17824 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:46:42.695924 17824 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:46:42.709728 17824 net.cpp:124] Setting up fc7\n",
      "I0430 11:46:42.709748 17824 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:46:42.709751 17824 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:46:42.709759 17824 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:46:42.709766 17824 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:46:42.709769 17824 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:46:42.709774 17824 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:46:42.709780 17824 net.cpp:124] Setting up relu7\n",
      "I0430 11:46:42.709784 17824 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:46:42.709785 17824 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:46:42.709786 17824 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:46:42.709790 17824 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:46:42.709792 17824 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:46:42.709795 17824 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:46:42.709800 17824 net.cpp:124] Setting up drop7\n",
      "I0430 11:46:42.709801 17824 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:46:42.709803 17824 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:46:42.709806 17824 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:46:42.709810 17824 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:46:42.709811 17824 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:46:42.709815 17824 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:46:42.710522 17824 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:46:42.710536 17824 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:46:42.710537 17824 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:46:42.710543 17824 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:46:42.710546 17824 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:46:42.710547 17824 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:46:42.710549 17824 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:46:42.710552 17824 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:46:42.710554 17824 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:46:42.710556 17824 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:46:42.710558 17824 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:46:42.710561 17824 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:46:42.710563 17824 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:46:42.710566 17824 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:46:42.710567 17824 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:46:42.710571 17824 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:46:42.710574 17824 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:46:42.710577 17824 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:46:42.710580 17824 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:46:42.710582 17824 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:46:42.710584 17824 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:46:42.710587 17824 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:46:42.710589 17824 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:46:42.710592 17824 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:46:42.710595 17824 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:46:42.710597 17824 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:46:42.710600 17824 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:46:42.710611 17824 net.cpp:257] Network initialization done.\n",
      "I0430 11:46:42.808719 17824 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:46:42.919637 17824 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:46:42.920552 17824 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:46:42.920559 17824 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:46:42.920562 17824 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/460652.jpg'}, '/tmp/tmpuQpWIm.mat')\n",
      "Processed 2956 windows in 357.678 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-2.00956, -2.23183, -2.10363, -1.7432, -1.617...\n",
      "ymin                                                        256\n",
      "xmin                                                        250\n",
      "ymax                                                        276\n",
      "xmax                                                        301\n",
      "Name: /home/ambika/INF_project/data/person/460652.jpg, dtype: object\n",
      "prediction    [-2.55797, -2.62254, -1.84109, -2.50132, -2.11...\n",
      "ymin                                                         42\n",
      "xmin                                                        155\n",
      "ymax                                                        120\n",
      "xmax                                                        218\n",
      "Name: /home/ambika/INF_project/data/person/460652.jpg, dtype: object\n",
      "car\n",
      "250\t256\t301\t276\n",
      "traffic light\n",
      "155\t42\t218\t120\n",
      "460652\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:52:42.222184 18026 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:52:42.222201 18026 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:52:42.222204 18026 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:52:42.223381 18026 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:52:42.223522 18026 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:52:42.223532 18026 net.cpp:86] Creating Layer data\n",
      "I0430 11:52:42.223536 18026 net.cpp:382] data -> data\n",
      "I0430 11:52:42.223549 18026 net.cpp:124] Setting up data\n",
      "I0430 11:52:42.223554 18026 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:52:42.223557 18026 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:52:42.223561 18026 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:52:42.223568 18026 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:52:42.223572 18026 net.cpp:408] conv1 <- data\n",
      "I0430 11:52:42.223578 18026 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:52:42.223649 18026 net.cpp:124] Setting up conv1\n",
      "I0430 11:52:42.223655 18026 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:52:42.223657 18026 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:52:42.223665 18026 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:52:42.223670 18026 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:52:42.223672 18026 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:52:42.223676 18026 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:52:42.223680 18026 net.cpp:124] Setting up relu1\n",
      "I0430 11:52:42.223685 18026 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:52:42.223686 18026 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:52:42.223688 18026 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:52:42.223692 18026 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:52:42.223695 18026 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:52:42.223698 18026 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:52:42.223704 18026 net.cpp:124] Setting up pool1\n",
      "I0430 11:52:42.223708 18026 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:52:42.223711 18026 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:52:42.223712 18026 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:52:42.223717 18026 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:52:42.223719 18026 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:52:42.223722 18026 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:52:42.223727 18026 net.cpp:124] Setting up norm1\n",
      "I0430 11:52:42.223731 18026 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:52:42.223733 18026 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:52:42.223736 18026 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:52:42.223740 18026 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:52:42.223742 18026 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:52:42.223745 18026 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:52:42.224099 18026 net.cpp:124] Setting up conv2\n",
      "I0430 11:52:42.224107 18026 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:52:42.224108 18026 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:52:42.224115 18026 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:52:42.224120 18026 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:52:42.224124 18026 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:52:42.224130 18026 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:52:42.224136 18026 net.cpp:124] Setting up relu2\n",
      "I0430 11:52:42.224141 18026 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:52:42.224145 18026 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:52:42.224148 18026 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:52:42.224151 18026 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:52:42.224154 18026 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:52:42.224158 18026 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:52:42.224164 18026 net.cpp:124] Setting up pool2\n",
      "I0430 11:52:42.224166 18026 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:52:42.224169 18026 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:52:42.224171 18026 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:52:42.224179 18026 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:52:42.224181 18026 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:52:42.224185 18026 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:52:42.224189 18026 net.cpp:124] Setting up norm2\n",
      "I0430 11:52:42.224194 18026 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:52:42.224195 18026 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:52:42.224197 18026 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:52:42.224206 18026 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:52:42.224208 18026 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:52:42.224212 18026 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:52:42.225178 18026 net.cpp:124] Setting up conv3\n",
      "I0430 11:52:42.225189 18026 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:52:42.225193 18026 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:52:42.225203 18026 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:52:42.225209 18026 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:52:42.225214 18026 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:52:42.225217 18026 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:52:42.225222 18026 net.cpp:124] Setting up relu3\n",
      "I0430 11:52:42.225226 18026 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:52:42.225229 18026 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:52:42.225231 18026 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:52:42.225236 18026 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:52:42.225239 18026 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:52:42.225241 18026 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:52:42.225736 18026 net.cpp:124] Setting up conv4\n",
      "I0430 11:52:42.225744 18026 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:52:42.225749 18026 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:52:42.225755 18026 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:52:42.225761 18026 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:52:42.225764 18026 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:52:42.225769 18026 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:52:42.225774 18026 net.cpp:124] Setting up relu4\n",
      "I0430 11:52:42.225776 18026 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:52:42.225780 18026 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:52:42.225781 18026 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:52:42.225787 18026 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:52:42.225790 18026 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:52:42.225792 18026 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:52:42.226302 18026 net.cpp:124] Setting up conv5\n",
      "I0430 11:52:42.226310 18026 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:52:42.226313 18026 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:52:42.226325 18026 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:52:42.226330 18026 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:52:42.226332 18026 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:52:42.226337 18026 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:52:42.226341 18026 net.cpp:124] Setting up relu5\n",
      "I0430 11:52:42.226344 18026 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:52:42.226347 18026 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:52:42.226349 18026 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:52:42.226353 18026 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:52:42.226356 18026 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:52:42.226359 18026 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:52:42.226366 18026 net.cpp:124] Setting up pool5\n",
      "I0430 11:52:42.226369 18026 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:52:42.226372 18026 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:52:42.226373 18026 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:52:42.226380 18026 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:52:42.226383 18026 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:52:42.226387 18026 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:52:42.253485 18026 net.cpp:124] Setting up fc6\n",
      "I0430 11:52:42.253545 18026 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:52:42.253553 18026 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:52:42.253576 18026 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:52:42.253613 18026 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:52:42.253621 18026 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:52:42.253630 18026 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:52:42.253643 18026 net.cpp:124] Setting up relu6\n",
      "I0430 11:52:42.253649 18026 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:52:42.253653 18026 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:52:42.253655 18026 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:52:42.253659 18026 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:52:42.253662 18026 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:52:42.253666 18026 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:52:42.253671 18026 net.cpp:124] Setting up drop6\n",
      "I0430 11:52:42.253674 18026 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:52:42.253676 18026 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:52:42.253679 18026 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:52:42.253685 18026 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:52:42.253687 18026 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:52:42.253695 18026 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:52:42.263443 18026 net.cpp:124] Setting up fc7\n",
      "I0430 11:52:42.263466 18026 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:52:42.263469 18026 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:52:42.263479 18026 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:52:42.263489 18026 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:52:42.263492 18026 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:52:42.263499 18026 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:52:42.263506 18026 net.cpp:124] Setting up relu7\n",
      "I0430 11:52:42.263510 18026 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:52:42.263514 18026 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:52:42.263515 18026 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:52:42.263520 18026 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:52:42.263522 18026 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:52:42.263527 18026 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:52:42.263532 18026 net.cpp:124] Setting up drop7\n",
      "I0430 11:52:42.263535 18026 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:52:42.263537 18026 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:52:42.263540 18026 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:52:42.263543 18026 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:52:42.263545 18026 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:52:42.263550 18026 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:52:42.264190 18026 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:52:42.264200 18026 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:52:42.264204 18026 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:52:42.264211 18026 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:52:42.264215 18026 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:52:42.264219 18026 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:52:42.264222 18026 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:52:42.264225 18026 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:52:42.264227 18026 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:52:42.264230 18026 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:52:42.264232 18026 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:52:42.264235 18026 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:52:42.264237 18026 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:52:42.264240 18026 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:52:42.264243 18026 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:52:42.264245 18026 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:52:42.264248 18026 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:52:42.264251 18026 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:52:42.264255 18026 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:52:42.264257 18026 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:52:42.264259 18026 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:52:42.264262 18026 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:52:42.264266 18026 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:52:42.264267 18026 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:52:42.264271 18026 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:52:42.264272 18026 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:52:42.264276 18026 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:52:42.264286 18026 net.cpp:257] Network initialization done.\n",
      "I0430 11:52:42.355655 18026 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:52:42.464429 18026 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:52:42.465354 18026 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:52:42.465363 18026 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:52:42.465368 18026 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/340529.jpg'}, '/tmp/tmpqBwc3b.mat')\n",
      "Processed 2447 windows in 296.682 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.22609, -2.48712, -2.22605, -1.86072, -1.10...\n",
      "ymin                                                        163\n",
      "xmin                                                          0\n",
      "ymax                                                        268\n",
      "xmax                                                         70\n",
      "Name: /home/ambika/INF_project/data/train/340529.jpg, dtype: object\n",
      "prediction    [-1.59368, -1.83852, -1.44261, -2.31541, -1.03...\n",
      "ymin                                                        156\n",
      "xmin                                                        406\n",
      "ymax                                                        187\n",
      "xmax                                                        440\n",
      "Name: /home/ambika/INF_project/data/train/340529.jpg, dtype: object\n",
      "banana\n",
      "0\t163\t70\t268\n",
      "lemon\n",
      "406\t156\t440\t187\n",
      "340529\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:57:40.647202 18258 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:57:40.647229 18258 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:57:40.647243 18258 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:57:40.648599 18258 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:57:40.648710 18258 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:57:40.648723 18258 net.cpp:86] Creating Layer data\n",
      "I0430 11:57:40.648727 18258 net.cpp:382] data -> data\n",
      "I0430 11:57:40.648746 18258 net.cpp:124] Setting up data\n",
      "I0430 11:57:40.648752 18258 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:57:40.648754 18258 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:57:40.648758 18258 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:57:40.648766 18258 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:57:40.648769 18258 net.cpp:408] conv1 <- data\n",
      "I0430 11:57:40.648774 18258 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:57:40.648854 18258 net.cpp:124] Setting up conv1\n",
      "I0430 11:57:40.648862 18258 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:57:40.648866 18258 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:57:40.648875 18258 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:57:40.648881 18258 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:57:40.648886 18258 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:57:40.648890 18258 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:57:40.648896 18258 net.cpp:124] Setting up relu1\n",
      "I0430 11:57:40.648900 18258 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:57:40.648903 18258 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:57:40.648907 18258 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:57:40.648912 18258 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:57:40.648916 18258 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:57:40.648921 18258 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:57:40.648928 18258 net.cpp:124] Setting up pool1\n",
      "I0430 11:57:40.648933 18258 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:57:40.648936 18258 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:57:40.648939 18258 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:57:40.648946 18258 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:57:40.648948 18258 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:57:40.648953 18258 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:57:40.648960 18258 net.cpp:124] Setting up norm1\n",
      "I0430 11:57:40.648964 18258 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:57:40.648967 18258 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:57:40.648970 18258 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:57:40.648977 18258 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:57:40.648980 18258 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:57:40.648985 18258 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:57:40.649343 18258 net.cpp:124] Setting up conv2\n",
      "I0430 11:57:40.649351 18258 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:57:40.649355 18258 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:57:40.649363 18258 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:57:40.649368 18258 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:57:40.649370 18258 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:57:40.649375 18258 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:57:40.649380 18258 net.cpp:124] Setting up relu2\n",
      "I0430 11:57:40.649384 18258 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:57:40.649386 18258 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:57:40.649389 18258 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:57:40.649394 18258 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:57:40.649397 18258 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:57:40.649401 18258 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:57:40.649408 18258 net.cpp:124] Setting up pool2\n",
      "I0430 11:57:40.649412 18258 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:57:40.649415 18258 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:57:40.649417 18258 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:57:40.649426 18258 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:57:40.649430 18258 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:57:40.649433 18258 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:57:40.649440 18258 net.cpp:124] Setting up norm2\n",
      "I0430 11:57:40.649443 18258 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:57:40.649446 18258 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:57:40.649448 18258 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:57:40.649456 18258 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:57:40.649457 18258 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:57:40.649463 18258 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:57:40.650440 18258 net.cpp:124] Setting up conv3\n",
      "I0430 11:57:40.650451 18258 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:57:40.650454 18258 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:57:40.650463 18258 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:57:40.650470 18258 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:57:40.650472 18258 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:57:40.650477 18258 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:57:40.650482 18258 net.cpp:124] Setting up relu3\n",
      "I0430 11:57:40.650486 18258 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:57:40.650490 18258 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:57:40.650492 18258 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:57:40.650498 18258 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:57:40.650501 18258 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:57:40.650506 18258 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:57:40.650976 18258 net.cpp:124] Setting up conv4\n",
      "I0430 11:57:40.650985 18258 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:57:40.650988 18258 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:57:40.650995 18258 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:57:40.651000 18258 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:57:40.651002 18258 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:57:40.651007 18258 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:57:40.651012 18258 net.cpp:124] Setting up relu4\n",
      "I0430 11:57:40.651016 18258 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:57:40.651018 18258 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:57:40.651021 18258 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:57:40.651027 18258 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:57:40.651031 18258 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:57:40.651036 18258 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:57:40.651543 18258 net.cpp:124] Setting up conv5\n",
      "I0430 11:57:40.651552 18258 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:57:40.651556 18258 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:57:40.651564 18258 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:57:40.651569 18258 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:57:40.651572 18258 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:57:40.651577 18258 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:57:40.651582 18258 net.cpp:124] Setting up relu5\n",
      "I0430 11:57:40.651587 18258 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:57:40.651589 18258 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:57:40.651592 18258 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:57:40.651597 18258 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:57:40.651599 18258 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:57:40.651604 18258 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:57:40.651612 18258 net.cpp:124] Setting up pool5\n",
      "I0430 11:57:40.651615 18258 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:57:40.651618 18258 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:57:40.651620 18258 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:57:40.651628 18258 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:57:40.651631 18258 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:57:40.651636 18258 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:57:40.673584 18258 net.cpp:124] Setting up fc6\n",
      "I0430 11:57:40.673611 18258 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:57:40.673617 18258 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:57:40.673643 18258 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:57:40.673652 18258 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:57:40.673656 18258 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:57:40.673665 18258 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:57:40.673673 18258 net.cpp:124] Setting up relu6\n",
      "I0430 11:57:40.673677 18258 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:57:40.673681 18258 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:57:40.673684 18258 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:57:40.673691 18258 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:57:40.673693 18258 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:57:40.673697 18258 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:57:40.673703 18258 net.cpp:124] Setting up drop6\n",
      "I0430 11:57:40.673707 18258 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:57:40.673709 18258 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:57:40.673713 18258 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:57:40.673718 18258 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:57:40.673722 18258 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:57:40.673727 18258 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:57:40.683401 18258 net.cpp:124] Setting up fc7\n",
      "I0430 11:57:40.683424 18258 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:57:40.683429 18258 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:57:40.683441 18258 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:57:40.683460 18258 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:57:40.683465 18258 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:57:40.683471 18258 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:57:40.683480 18258 net.cpp:124] Setting up relu7\n",
      "I0430 11:57:40.683483 18258 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:57:40.683487 18258 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:57:40.683490 18258 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:57:40.683496 18258 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:57:40.683500 18258 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:57:40.683504 18258 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:57:40.683511 18258 net.cpp:124] Setting up drop7\n",
      "I0430 11:57:40.683514 18258 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:57:40.683516 18258 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:57:40.683521 18258 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:57:40.683526 18258 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:57:40.683528 18258 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:57:40.683533 18258 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:57:40.684173 18258 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:57:40.684182 18258 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:57:40.684185 18258 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:57:40.684192 18258 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:57:40.684195 18258 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:57:40.684200 18258 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:57:40.684202 18258 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:57:40.684206 18258 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:57:40.684209 18258 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:57:40.684212 18258 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:57:40.684216 18258 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:57:40.684219 18258 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:57:40.684222 18258 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:57:40.684226 18258 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:57:40.684228 18258 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:57:40.684233 18258 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:57:40.684237 18258 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:57:40.684240 18258 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:57:40.684244 18258 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:57:40.684247 18258 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:57:40.684250 18258 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:57:40.684254 18258 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:57:40.684257 18258 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:57:40.684262 18258 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:57:40.684264 18258 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:57:40.684268 18258 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:57:40.684270 18258 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:57:40.684281 18258 net.cpp:257] Network initialization done.\n",
      "I0430 11:57:40.766477 18258 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:57:40.859848 18258 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:57:40.860679 18258 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:57:40.860689 18258 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:57:40.860693 18258 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/403820.jpg'}, '/tmp/tmp4r4Jkp.mat')\n",
      "Processed 342 windows in 46.328 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.025 s.\n",
      "prediction    [-2.28271, 3.65515, -1.6669, -2.4475, -2.05148...\n",
      "ymin                                                         48\n",
      "xmin                                                        148\n",
      "ymax                                                        232\n",
      "xmax                                                        352\n",
      "Name: /home/ambika/INF_project/data/airplane/403820.jpg, dtype: object\n",
      "prediction    [-2.05764, 2.13699, -1.5917, -2.52123, -2.2817...\n",
      "ymin                                                         19\n",
      "xmin                                                        143\n",
      "ymax                                                        218\n",
      "xmax                                                        401\n",
      "Name: /home/ambika/INF_project/data/airplane/403820.jpg, dtype: object\n",
      "airplane\n",
      "148\t48\t352\t232\n",
      "dragonfly\n",
      "143\t19\t401\t218\n",
      "403820\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 11:58:28.652297 18385 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 11:58:28.652317 18385 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 11:58:28.652320 18385 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 11:58:28.653412 18385 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 11:58:28.653573 18385 layer_factory.hpp:77] Creating layer data\n",
      "I0430 11:58:28.653584 18385 net.cpp:86] Creating Layer data\n",
      "I0430 11:58:28.653589 18385 net.cpp:382] data -> data\n",
      "I0430 11:58:28.653604 18385 net.cpp:124] Setting up data\n",
      "I0430 11:58:28.653610 18385 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 11:58:28.653614 18385 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 11:58:28.653619 18385 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 11:58:28.653625 18385 net.cpp:86] Creating Layer conv1\n",
      "I0430 11:58:28.653628 18385 net.cpp:408] conv1 <- data\n",
      "I0430 11:58:28.653633 18385 net.cpp:382] conv1 -> conv1\n",
      "I0430 11:58:28.653700 18385 net.cpp:124] Setting up conv1\n",
      "I0430 11:58:28.653707 18385 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:58:28.653710 18385 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 11:58:28.653718 18385 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 11:58:28.653724 18385 net.cpp:86] Creating Layer relu1\n",
      "I0430 11:58:28.653728 18385 net.cpp:408] relu1 <- conv1\n",
      "I0430 11:58:28.653733 18385 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 11:58:28.653738 18385 net.cpp:124] Setting up relu1\n",
      "I0430 11:58:28.653741 18385 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 11:58:28.653744 18385 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 11:58:28.653748 18385 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 11:58:28.653753 18385 net.cpp:86] Creating Layer pool1\n",
      "I0430 11:58:28.653755 18385 net.cpp:408] pool1 <- conv1\n",
      "I0430 11:58:28.653759 18385 net.cpp:382] pool1 -> pool1\n",
      "I0430 11:58:28.653766 18385 net.cpp:124] Setting up pool1\n",
      "I0430 11:58:28.653771 18385 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:58:28.653774 18385 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 11:58:28.653776 18385 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 11:58:28.653782 18385 net.cpp:86] Creating Layer norm1\n",
      "I0430 11:58:28.653785 18385 net.cpp:408] norm1 <- pool1\n",
      "I0430 11:58:28.653789 18385 net.cpp:382] norm1 -> norm1\n",
      "I0430 11:58:28.653795 18385 net.cpp:124] Setting up norm1\n",
      "I0430 11:58:28.653800 18385 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 11:58:28.653802 18385 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 11:58:28.653805 18385 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 11:58:28.653810 18385 net.cpp:86] Creating Layer conv2\n",
      "I0430 11:58:28.653813 18385 net.cpp:408] conv2 <- norm1\n",
      "I0430 11:58:28.653818 18385 net.cpp:382] conv2 -> conv2\n",
      "I0430 11:58:28.654170 18385 net.cpp:124] Setting up conv2\n",
      "I0430 11:58:28.654181 18385 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:58:28.654183 18385 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 11:58:28.654191 18385 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 11:58:28.654197 18385 net.cpp:86] Creating Layer relu2\n",
      "I0430 11:58:28.654202 18385 net.cpp:408] relu2 <- conv2\n",
      "I0430 11:58:28.654206 18385 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 11:58:28.654211 18385 net.cpp:124] Setting up relu2\n",
      "I0430 11:58:28.654214 18385 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 11:58:28.654217 18385 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 11:58:28.654219 18385 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 11:58:28.654223 18385 net.cpp:86] Creating Layer pool2\n",
      "I0430 11:58:28.654225 18385 net.cpp:408] pool2 <- conv2\n",
      "I0430 11:58:28.654229 18385 net.cpp:382] pool2 -> pool2\n",
      "I0430 11:58:28.654235 18385 net.cpp:124] Setting up pool2\n",
      "I0430 11:58:28.654238 18385 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:58:28.654240 18385 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 11:58:28.654243 18385 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 11:58:28.654250 18385 net.cpp:86] Creating Layer norm2\n",
      "I0430 11:58:28.654253 18385 net.cpp:408] norm2 <- pool2\n",
      "I0430 11:58:28.654256 18385 net.cpp:382] norm2 -> norm2\n",
      "I0430 11:58:28.654261 18385 net.cpp:124] Setting up norm2\n",
      "I0430 11:58:28.654264 18385 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:58:28.654266 18385 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 11:58:28.654268 18385 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 11:58:28.654275 18385 net.cpp:86] Creating Layer conv3\n",
      "I0430 11:58:28.654278 18385 net.cpp:408] conv3 <- norm2\n",
      "I0430 11:58:28.654281 18385 net.cpp:382] conv3 -> conv3\n",
      "I0430 11:58:28.654976 18385 net.cpp:124] Setting up conv3\n",
      "I0430 11:58:28.654986 18385 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:58:28.654989 18385 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 11:58:28.655000 18385 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 11:58:28.655007 18385 net.cpp:86] Creating Layer relu3\n",
      "I0430 11:58:28.655011 18385 net.cpp:408] relu3 <- conv3\n",
      "I0430 11:58:28.655015 18385 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 11:58:28.655020 18385 net.cpp:124] Setting up relu3\n",
      "I0430 11:58:28.655023 18385 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:58:28.655026 18385 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 11:58:28.655028 18385 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 11:58:28.655035 18385 net.cpp:86] Creating Layer conv4\n",
      "I0430 11:58:28.655037 18385 net.cpp:408] conv4 <- conv3\n",
      "I0430 11:58:28.655040 18385 net.cpp:382] conv4 -> conv4\n",
      "I0430 11:58:28.655807 18385 net.cpp:124] Setting up conv4\n",
      "I0430 11:58:28.655820 18385 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:58:28.655824 18385 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 11:58:28.655833 18385 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 11:58:28.655840 18385 net.cpp:86] Creating Layer relu4\n",
      "I0430 11:58:28.655845 18385 net.cpp:408] relu4 <- conv4\n",
      "I0430 11:58:28.655850 18385 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 11:58:28.655858 18385 net.cpp:124] Setting up relu4\n",
      "I0430 11:58:28.655861 18385 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 11:58:28.655864 18385 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 11:58:28.655867 18385 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 11:58:28.655874 18385 net.cpp:86] Creating Layer conv5\n",
      "I0430 11:58:28.655877 18385 net.cpp:408] conv5 <- conv4\n",
      "I0430 11:58:28.655882 18385 net.cpp:382] conv5 -> conv5\n",
      "I0430 11:58:28.656451 18385 net.cpp:124] Setting up conv5\n",
      "I0430 11:58:28.656461 18385 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:58:28.656466 18385 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 11:58:28.656478 18385 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 11:58:28.656484 18385 net.cpp:86] Creating Layer relu5\n",
      "I0430 11:58:28.656487 18385 net.cpp:408] relu5 <- conv5\n",
      "I0430 11:58:28.656492 18385 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 11:58:28.656497 18385 net.cpp:124] Setting up relu5\n",
      "I0430 11:58:28.656500 18385 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 11:58:28.656503 18385 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 11:58:28.656505 18385 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 11:58:28.656509 18385 net.cpp:86] Creating Layer pool5\n",
      "I0430 11:58:28.656512 18385 net.cpp:408] pool5 <- conv5\n",
      "I0430 11:58:28.656515 18385 net.cpp:382] pool5 -> pool5\n",
      "I0430 11:58:28.656522 18385 net.cpp:124] Setting up pool5\n",
      "I0430 11:58:28.656524 18385 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 11:58:28.656527 18385 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 11:58:28.656529 18385 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 11:58:28.656536 18385 net.cpp:86] Creating Layer fc6\n",
      "I0430 11:58:28.656539 18385 net.cpp:408] fc6 <- pool5\n",
      "I0430 11:58:28.656543 18385 net.cpp:382] fc6 -> fc6\n",
      "I0430 11:58:28.679095 18385 net.cpp:124] Setting up fc6\n",
      "I0430 11:58:28.679119 18385 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:58:28.679123 18385 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 11:58:28.679133 18385 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 11:58:28.679144 18385 net.cpp:86] Creating Layer relu6\n",
      "I0430 11:58:28.679147 18385 net.cpp:408] relu6 <- fc6\n",
      "I0430 11:58:28.679152 18385 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 11:58:28.679160 18385 net.cpp:124] Setting up relu6\n",
      "I0430 11:58:28.679164 18385 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:58:28.679167 18385 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 11:58:28.679168 18385 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 11:58:28.679174 18385 net.cpp:86] Creating Layer drop6\n",
      "I0430 11:58:28.679177 18385 net.cpp:408] drop6 <- fc6\n",
      "I0430 11:58:28.679193 18385 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 11:58:28.679200 18385 net.cpp:124] Setting up drop6\n",
      "I0430 11:58:28.679204 18385 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:58:28.679214 18385 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 11:58:28.679217 18385 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 11:58:28.679222 18385 net.cpp:86] Creating Layer fc7\n",
      "I0430 11:58:28.679225 18385 net.cpp:408] fc7 <- fc6\n",
      "I0430 11:58:28.679232 18385 net.cpp:382] fc7 -> fc7\n",
      "I0430 11:58:28.688701 18385 net.cpp:124] Setting up fc7\n",
      "I0430 11:58:28.688725 18385 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:58:28.688730 18385 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 11:58:28.688740 18385 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 11:58:28.688750 18385 net.cpp:86] Creating Layer relu7\n",
      "I0430 11:58:28.688755 18385 net.cpp:408] relu7 <- fc7\n",
      "I0430 11:58:28.688760 18385 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 11:58:28.688766 18385 net.cpp:124] Setting up relu7\n",
      "I0430 11:58:28.688771 18385 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:58:28.688772 18385 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 11:58:28.688774 18385 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 11:58:28.688781 18385 net.cpp:86] Creating Layer drop7\n",
      "I0430 11:58:28.688793 18385 net.cpp:408] drop7 <- fc7\n",
      "I0430 11:58:28.688799 18385 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 11:58:28.688807 18385 net.cpp:124] Setting up drop7\n",
      "I0430 11:58:28.688809 18385 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 11:58:28.688812 18385 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 11:58:28.688815 18385 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 11:58:28.688822 18385 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 11:58:28.688824 18385 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 11:58:28.688829 18385 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 11:58:28.689481 18385 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 11:58:28.689491 18385 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 11:58:28.689496 18385 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 11:58:28.689503 18385 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 11:58:28.689508 18385 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 11:58:28.689522 18385 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 11:58:28.689524 18385 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 11:58:28.689527 18385 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 11:58:28.689530 18385 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 11:58:28.689532 18385 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 11:58:28.689535 18385 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 11:58:28.689539 18385 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 11:58:28.689543 18385 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 11:58:28.689546 18385 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 11:58:28.689549 18385 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 11:58:28.689553 18385 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 11:58:28.689556 18385 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 11:58:28.689559 18385 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 11:58:28.689563 18385 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 11:58:28.689566 18385 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 11:58:28.689569 18385 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 11:58:28.689574 18385 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 11:58:28.689576 18385 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 11:58:28.689579 18385 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 11:58:28.689582 18385 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 11:58:28.689586 18385 net.cpp:202] data does not need backward computation.\n",
      "I0430 11:58:28.689589 18385 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 11:58:28.689600 18385 net.cpp:257] Network initialization done.\n",
      "I0430 11:58:28.773440 18385 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:58:28.868872 18385 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 11:58:28.870304 18385 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 11:58:28.870335 18385 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 11:58:28.870340 18385 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/376767.jpg'}, '/tmp/tmp13dGBG.mat')\n",
      "Processed 2359 windows in 278.774 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.036 s.\n",
      "prediction    [-2.465, -2.7553, -2.22011, -2.01068, -2.28813...\n",
      "ymin                                                     161.25\n",
      "xmin                                                     137.25\n",
      "ymax                                                     336.25\n",
      "xmax                                                     312.25\n",
      "Name: /home/ambika/INF_project/data/bird/376767.jpg, dtype: object\n",
      "prediction    [-1.75879, -2.11436, -1.578, -2.5093, -1.9838,...\n",
      "ymin                                                      15.75\n",
      "xmin                                                        168\n",
      "ymax                                                      125.5\n",
      "xmax                                                      269.5\n",
      "Name: /home/ambika/INF_project/data/bird/376767.jpg, dtype: object\n",
      "washer\n",
      "137.25\t161.25\t312.25\t336.25\n",
      "bird\n",
      "168.0\t15.75\t269.5\t125.5\n",
      "376767\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:03:09.260732 18607 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:03:09.260756 18607 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:03:09.260759 18607 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:03:09.262411 18607 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:03:09.262643 18607 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:03:09.262653 18607 net.cpp:86] Creating Layer data\n",
      "I0430 12:03:09.262658 18607 net.cpp:382] data -> data\n",
      "I0430 12:03:09.262676 18607 net.cpp:124] Setting up data\n",
      "I0430 12:03:09.262682 18607 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:03:09.262686 18607 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:03:09.262691 18607 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:03:09.262698 18607 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:03:09.262702 18607 net.cpp:408] conv1 <- data\n",
      "I0430 12:03:09.262708 18607 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:03:09.262787 18607 net.cpp:124] Setting up conv1\n",
      "I0430 12:03:09.262794 18607 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:03:09.262799 18607 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:03:09.262807 18607 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:03:09.262814 18607 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:03:09.262817 18607 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:03:09.262821 18607 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:03:09.262827 18607 net.cpp:124] Setting up relu1\n",
      "I0430 12:03:09.262832 18607 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:03:09.262836 18607 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:03:09.262840 18607 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:03:09.262846 18607 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:03:09.262850 18607 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:03:09.262856 18607 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:03:09.262864 18607 net.cpp:124] Setting up pool1\n",
      "I0430 12:03:09.262869 18607 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:03:09.262873 18607 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:03:09.262877 18607 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:03:09.262883 18607 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:03:09.262887 18607 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:03:09.262892 18607 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:03:09.262900 18607 net.cpp:124] Setting up norm1\n",
      "I0430 12:03:09.262905 18607 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:03:09.262908 18607 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:03:09.262912 18607 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:03:09.262918 18607 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:03:09.262923 18607 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:03:09.262928 18607 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:03:09.263389 18607 net.cpp:124] Setting up conv2\n",
      "I0430 12:03:09.263399 18607 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:03:09.263403 18607 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:03:09.263411 18607 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:03:09.263417 18607 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:03:09.263422 18607 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:03:09.263427 18607 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:03:09.263433 18607 net.cpp:124] Setting up relu2\n",
      "I0430 12:03:09.263439 18607 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:03:09.263442 18607 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:03:09.263447 18607 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:03:09.263453 18607 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:03:09.263458 18607 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:03:09.263463 18607 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:03:09.263470 18607 net.cpp:124] Setting up pool2\n",
      "I0430 12:03:09.263475 18607 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:03:09.263479 18607 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:03:09.263484 18607 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:03:09.263489 18607 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:03:09.263492 18607 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:03:09.263499 18607 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:03:09.263504 18607 net.cpp:124] Setting up norm2\n",
      "I0430 12:03:09.263510 18607 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:03:09.263514 18607 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:03:09.263517 18607 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:03:09.263525 18607 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:03:09.263528 18607 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:03:09.263533 18607 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:03:09.264474 18607 net.cpp:124] Setting up conv3\n",
      "I0430 12:03:09.264493 18607 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:03:09.264498 18607 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:03:09.264509 18607 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:03:09.264518 18607 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:03:09.264521 18607 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:03:09.264528 18607 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:03:09.264534 18607 net.cpp:124] Setting up relu3\n",
      "I0430 12:03:09.264540 18607 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:03:09.264544 18607 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:03:09.264547 18607 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:03:09.264555 18607 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:03:09.264559 18607 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:03:09.264564 18607 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:03:09.265527 18607 net.cpp:124] Setting up conv4\n",
      "I0430 12:03:09.265540 18607 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:03:09.265544 18607 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:03:09.265552 18607 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:03:09.265558 18607 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:03:09.265563 18607 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:03:09.265569 18607 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:03:09.265576 18607 net.cpp:124] Setting up relu4\n",
      "I0430 12:03:09.265581 18607 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:03:09.265585 18607 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:03:09.265589 18607 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:03:09.265597 18607 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:03:09.265601 18607 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:03:09.265606 18607 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:03:09.266276 18607 net.cpp:124] Setting up conv5\n",
      "I0430 12:03:09.266288 18607 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:03:09.266293 18607 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:03:09.266304 18607 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:03:09.266310 18607 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:03:09.266314 18607 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:03:09.266321 18607 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:03:09.266327 18607 net.cpp:124] Setting up relu5\n",
      "I0430 12:03:09.266331 18607 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:03:09.266335 18607 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:03:09.266337 18607 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:03:09.266342 18607 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:03:09.266345 18607 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:03:09.266350 18607 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:03:09.266360 18607 net.cpp:124] Setting up pool5\n",
      "I0430 12:03:09.266363 18607 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:03:09.266366 18607 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:03:09.266371 18607 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:03:09.266378 18607 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:03:09.266382 18607 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:03:09.266386 18607 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:03:09.287963 18607 net.cpp:124] Setting up fc6\n",
      "I0430 12:03:09.287986 18607 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:03:09.287991 18607 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:03:09.288000 18607 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:03:09.288009 18607 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:03:09.288012 18607 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:03:09.288015 18607 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:03:09.288022 18607 net.cpp:124] Setting up relu6\n",
      "I0430 12:03:09.288024 18607 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:03:09.288025 18607 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:03:09.288028 18607 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:03:09.288033 18607 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:03:09.288033 18607 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:03:09.288036 18607 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:03:09.288040 18607 net.cpp:124] Setting up drop6\n",
      "I0430 12:03:09.288043 18607 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:03:09.288045 18607 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:03:09.288059 18607 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:03:09.288064 18607 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:03:09.288065 18607 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:03:09.288070 18607 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:03:09.298924 18607 net.cpp:124] Setting up fc7\n",
      "I0430 12:03:09.298954 18607 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:03:09.298957 18607 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:03:09.298967 18607 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:03:09.298979 18607 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:03:09.298982 18607 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:03:09.298990 18607 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:03:09.298997 18607 net.cpp:124] Setting up relu7\n",
      "I0430 12:03:09.299001 18607 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:03:09.299005 18607 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:03:09.299007 18607 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:03:09.299013 18607 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:03:09.299017 18607 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:03:09.299024 18607 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:03:09.299032 18607 net.cpp:124] Setting up drop7\n",
      "I0430 12:03:09.299043 18607 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:03:09.299048 18607 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:03:09.299052 18607 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:03:09.299058 18607 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:03:09.299062 18607 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:03:09.299067 18607 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:03:09.300283 18607 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:03:09.300300 18607 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:03:09.300305 18607 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:03:09.300314 18607 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:03:09.300318 18607 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:03:09.300321 18607 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:03:09.300324 18607 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:03:09.300329 18607 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:03:09.300333 18607 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:03:09.300338 18607 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:03:09.300341 18607 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:03:09.300345 18607 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:03:09.300349 18607 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:03:09.300354 18607 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:03:09.300357 18607 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:03:09.300361 18607 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:03:09.300365 18607 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:03:09.300370 18607 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:03:09.300374 18607 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:03:09.300379 18607 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:03:09.300382 18607 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:03:09.300387 18607 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:03:09.300391 18607 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:03:09.300395 18607 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:03:09.300400 18607 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:03:09.300403 18607 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:03:09.300407 18607 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:03:09.300422 18607 net.cpp:257] Network initialization done.\n",
      "I0430 12:03:09.385272 18607 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:03:09.480309 18607 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:03:09.481266 18607 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:03:09.481273 18607 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:03:09.481277 18607 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/18366.jpg'}, '/tmp/tmpID9zRt.mat')\n",
      "Processed 2679 windows in 309.264 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.11531, -2.60611, -2.13431, -2.07166, -1.37...\n",
      "ymin                                                        217\n",
      "xmin                                                        273\n",
      "ymax                                                        348\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/bus/18366.jpg, dtype: object\n",
      "prediction    [-2.04135, -1.95366, -2.12589, -2.16287, -1.54...\n",
      "ymin                                                        275\n",
      "xmin                                                        271\n",
      "ymax                                                        329\n",
      "xmax                                                        414\n",
      "Name: /home/ambika/INF_project/data/bus/18366.jpg, dtype: object\n",
      "bus\n",
      "273\t217\t500\t348\n",
      "car\n",
      "271\t275\t414\t329\n",
      "18366\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:08:20.382257 18807 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:08:20.382279 18807 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:08:20.382282 18807 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:08:20.383481 18807 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:08:20.383680 18807 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:08:20.383690 18807 net.cpp:86] Creating Layer data\n",
      "I0430 12:08:20.383699 18807 net.cpp:382] data -> data\n",
      "I0430 12:08:20.383723 18807 net.cpp:124] Setting up data\n",
      "I0430 12:08:20.383738 18807 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:08:20.383743 18807 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:08:20.383747 18807 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:08:20.383759 18807 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:08:20.383762 18807 net.cpp:408] conv1 <- data\n",
      "I0430 12:08:20.383769 18807 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:08:20.383831 18807 net.cpp:124] Setting up conv1\n",
      "I0430 12:08:20.383837 18807 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:08:20.383841 18807 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:08:20.383848 18807 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:08:20.383854 18807 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:08:20.383857 18807 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:08:20.383862 18807 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:08:20.383867 18807 net.cpp:124] Setting up relu1\n",
      "I0430 12:08:20.383872 18807 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:08:20.383873 18807 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:08:20.383877 18807 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:08:20.383882 18807 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:08:20.383884 18807 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:08:20.383888 18807 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:08:20.383896 18807 net.cpp:124] Setting up pool1\n",
      "I0430 12:08:20.383901 18807 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:08:20.383904 18807 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:08:20.383908 18807 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:08:20.383913 18807 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:08:20.383918 18807 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:08:20.383922 18807 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:08:20.383930 18807 net.cpp:124] Setting up norm1\n",
      "I0430 12:08:20.383935 18807 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:08:20.383939 18807 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:08:20.384030 18807 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:08:20.384038 18807 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:08:20.384042 18807 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:08:20.384047 18807 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:08:20.384505 18807 net.cpp:124] Setting up conv2\n",
      "I0430 12:08:20.384519 18807 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:08:20.384523 18807 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:08:20.384536 18807 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:08:20.384542 18807 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:08:20.384546 18807 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:08:20.384552 18807 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:08:20.384559 18807 net.cpp:124] Setting up relu2\n",
      "I0430 12:08:20.384564 18807 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:08:20.384568 18807 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:08:20.384572 18807 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:08:20.384577 18807 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:08:20.384582 18807 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:08:20.384587 18807 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:08:20.384595 18807 net.cpp:124] Setting up pool2\n",
      "I0430 12:08:20.384600 18807 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:08:20.384604 18807 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:08:20.384608 18807 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:08:20.384623 18807 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:08:20.384626 18807 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:08:20.384631 18807 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:08:20.384641 18807 net.cpp:124] Setting up norm2\n",
      "I0430 12:08:20.384647 18807 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:08:20.384650 18807 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:08:20.384654 18807 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:08:20.384665 18807 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:08:20.384668 18807 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:08:20.384673 18807 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:08:20.385787 18807 net.cpp:124] Setting up conv3\n",
      "I0430 12:08:20.385815 18807 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:08:20.385818 18807 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:08:20.385831 18807 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:08:20.385843 18807 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:08:20.385846 18807 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:08:20.385852 18807 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:08:20.385860 18807 net.cpp:124] Setting up relu3\n",
      "I0430 12:08:20.385866 18807 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:08:20.385869 18807 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:08:20.385874 18807 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:08:20.385886 18807 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:08:20.385890 18807 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:08:20.385895 18807 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:08:20.386870 18807 net.cpp:124] Setting up conv4\n",
      "I0430 12:08:20.386888 18807 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:08:20.386891 18807 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:08:20.386899 18807 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:08:20.386907 18807 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:08:20.386912 18807 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:08:20.386922 18807 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:08:20.386930 18807 net.cpp:124] Setting up relu4\n",
      "I0430 12:08:20.386935 18807 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:08:20.386939 18807 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:08:20.386942 18807 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:08:20.386950 18807 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:08:20.386955 18807 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:08:20.386960 18807 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:08:20.387677 18807 net.cpp:124] Setting up conv5\n",
      "I0430 12:08:20.387691 18807 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:08:20.387694 18807 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:08:20.387706 18807 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:08:20.387713 18807 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:08:20.387718 18807 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:08:20.387725 18807 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:08:20.387732 18807 net.cpp:124] Setting up relu5\n",
      "I0430 12:08:20.387737 18807 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:08:20.387740 18807 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:08:20.387744 18807 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:08:20.387750 18807 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:08:20.387753 18807 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:08:20.387758 18807 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:08:20.387768 18807 net.cpp:124] Setting up pool5\n",
      "I0430 12:08:20.387773 18807 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:08:20.387776 18807 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:08:20.387780 18807 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:08:20.387790 18807 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:08:20.387794 18807 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:08:20.387799 18807 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:08:20.412178 18807 net.cpp:124] Setting up fc6\n",
      "I0430 12:08:20.412204 18807 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:08:20.412210 18807 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:08:20.412220 18807 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:08:20.412231 18807 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:08:20.412235 18807 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:08:20.412240 18807 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:08:20.412248 18807 net.cpp:124] Setting up relu6\n",
      "I0430 12:08:20.412251 18807 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:08:20.412253 18807 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:08:20.412257 18807 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:08:20.412277 18807 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:08:20.412281 18807 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:08:20.412284 18807 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:08:20.412291 18807 net.cpp:124] Setting up drop6\n",
      "I0430 12:08:20.412294 18807 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:08:20.412297 18807 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:08:20.412299 18807 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:08:20.412305 18807 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:08:20.412307 18807 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:08:20.412313 18807 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:08:20.422755 18807 net.cpp:124] Setting up fc7\n",
      "I0430 12:08:20.422781 18807 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:08:20.422787 18807 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:08:20.422797 18807 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:08:20.422808 18807 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:08:20.422812 18807 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:08:20.422818 18807 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:08:20.422827 18807 net.cpp:124] Setting up relu7\n",
      "I0430 12:08:20.422830 18807 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:08:20.422833 18807 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:08:20.422837 18807 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:08:20.422842 18807 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:08:20.422845 18807 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:08:20.422850 18807 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:08:20.422857 18807 net.cpp:124] Setting up drop7\n",
      "I0430 12:08:20.422860 18807 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:08:20.422863 18807 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:08:20.422866 18807 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:08:20.422871 18807 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:08:20.422874 18807 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:08:20.422879 18807 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:08:20.423730 18807 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:08:20.423746 18807 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:08:20.423750 18807 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:08:20.423759 18807 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:08:20.423763 18807 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:08:20.423768 18807 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:08:20.423770 18807 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:08:20.423774 18807 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:08:20.423777 18807 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:08:20.423781 18807 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:08:20.423786 18807 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:08:20.423789 18807 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:08:20.423792 18807 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:08:20.423796 18807 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:08:20.423799 18807 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:08:20.423802 18807 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:08:20.423806 18807 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:08:20.423810 18807 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:08:20.423812 18807 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:08:20.423816 18807 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:08:20.423820 18807 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:08:20.423823 18807 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:08:20.423826 18807 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:08:20.423830 18807 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:08:20.423832 18807 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:08:20.423836 18807 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:08:20.423838 18807 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:08:20.423849 18807 net.cpp:257] Network initialization done.\n",
      "I0430 12:08:20.511842 18807 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:08:20.610874 18807 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:08:20.611843 18807 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:08:20.611851 18807 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:08:20.611853 18807 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/460294.jpg'}, '/tmp/tmpJJVE45.mat')\n",
      "Processed 1678 windows in 199.239 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-3.14519, -3.03917, -2.18868, -2.63037, -2.11...\n",
      "ymin                                                         53\n",
      "xmin                                                        165\n",
      "ymax                                                        323\n",
      "xmax                                                        334\n",
      "Name: /home/ambika/INF_project/data/car/460294.jpg, dtype: object\n",
      "prediction    [-1.962, -2.4761, -1.93079, -1.98101, -1.36881...\n",
      "ymin                                                         86\n",
      "xmin                                                          0\n",
      "ymax                                                        160\n",
      "xmax                                                        211\n",
      "Name: /home/ambika/INF_project/data/car/460294.jpg, dtype: object\n",
      "person\n",
      "165\t53\t334\t323\n",
      "car\n",
      "0\t86\t211\t160\n",
      "460294\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:11:41.424728 18969 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:11:41.424757 18969 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:11:41.424772 18969 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:11:41.426617 18969 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:11:41.426815 18969 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:11:41.426828 18969 net.cpp:86] Creating Layer data\n",
      "I0430 12:11:41.426836 18969 net.cpp:382] data -> data\n",
      "I0430 12:11:41.426851 18969 net.cpp:124] Setting up data\n",
      "I0430 12:11:41.426859 18969 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:11:41.426863 18969 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:11:41.426867 18969 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:11:41.426877 18969 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:11:41.426882 18969 net.cpp:408] conv1 <- data\n",
      "I0430 12:11:41.426887 18969 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:11:41.426970 18969 net.cpp:124] Setting up conv1\n",
      "I0430 12:11:41.426977 18969 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:11:41.426981 18969 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:11:41.426991 18969 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:11:41.427000 18969 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:11:41.427003 18969 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:11:41.427008 18969 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:11:41.427014 18969 net.cpp:124] Setting up relu1\n",
      "I0430 12:11:41.427021 18969 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:11:41.427022 18969 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:11:41.427026 18969 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:11:41.427031 18969 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:11:41.427033 18969 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:11:41.427037 18969 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:11:41.427047 18969 net.cpp:124] Setting up pool1\n",
      "I0430 12:11:41.427052 18969 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:11:41.427057 18969 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:11:41.427060 18969 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:11:41.427067 18969 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:11:41.427070 18969 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:11:41.427076 18969 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:11:41.427084 18969 net.cpp:124] Setting up norm1\n",
      "I0430 12:11:41.427089 18969 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:11:41.427093 18969 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:11:41.427096 18969 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:11:41.427103 18969 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:11:41.427106 18969 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:11:41.427112 18969 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:11:41.427615 18969 net.cpp:124] Setting up conv2\n",
      "I0430 12:11:41.427628 18969 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:11:41.427631 18969 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:11:41.427641 18969 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:11:41.427649 18969 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:11:41.427654 18969 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:11:41.427659 18969 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:11:41.427664 18969 net.cpp:124] Setting up relu2\n",
      "I0430 12:11:41.427670 18969 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:11:41.427673 18969 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:11:41.427677 18969 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:11:41.427682 18969 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:11:41.427686 18969 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:11:41.427691 18969 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:11:41.427700 18969 net.cpp:124] Setting up pool2\n",
      "I0430 12:11:41.427706 18969 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:11:41.427709 18969 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:11:41.427713 18969 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:11:41.427721 18969 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:11:41.427726 18969 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:11:41.427731 18969 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:11:41.427738 18969 net.cpp:124] Setting up norm2\n",
      "I0430 12:11:41.427743 18969 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:11:41.427747 18969 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:11:41.427752 18969 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:11:41.427757 18969 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:11:41.427762 18969 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:11:41.427767 18969 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:11:41.428679 18969 net.cpp:124] Setting up conv3\n",
      "I0430 12:11:41.428699 18969 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:11:41.428704 18969 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:11:41.428717 18969 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:11:41.428726 18969 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:11:41.428730 18969 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:11:41.428736 18969 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:11:41.428745 18969 net.cpp:124] Setting up relu3\n",
      "I0430 12:11:41.428750 18969 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:11:41.428755 18969 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:11:41.428757 18969 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:11:41.428767 18969 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:11:41.428771 18969 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:11:41.428776 18969 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:11:41.429757 18969 net.cpp:124] Setting up conv4\n",
      "I0430 12:11:41.429777 18969 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:11:41.429781 18969 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:11:41.429790 18969 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:11:41.429797 18969 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:11:41.429802 18969 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:11:41.429811 18969 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:11:41.429817 18969 net.cpp:124] Setting up relu4\n",
      "I0430 12:11:41.429823 18969 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:11:41.429827 18969 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:11:41.429831 18969 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:11:41.429839 18969 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:11:41.429843 18969 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:11:41.429849 18969 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:11:41.430526 18969 net.cpp:124] Setting up conv5\n",
      "I0430 12:11:41.430544 18969 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:11:41.430548 18969 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:11:41.430562 18969 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:11:41.430573 18969 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:11:41.430577 18969 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:11:41.430585 18969 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:11:41.430594 18969 net.cpp:124] Setting up relu5\n",
      "I0430 12:11:41.430599 18969 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:11:41.430603 18969 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:11:41.430608 18969 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:11:41.430613 18969 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:11:41.430616 18969 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:11:41.430622 18969 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:11:41.430632 18969 net.cpp:124] Setting up pool5\n",
      "I0430 12:11:41.430639 18969 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:11:41.430642 18969 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:11:41.430646 18969 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:11:41.430656 18969 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:11:41.430661 18969 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:11:41.430667 18969 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:11:41.461314 18969 net.cpp:124] Setting up fc6\n",
      "I0430 12:11:41.461340 18969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:11:41.461344 18969 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:11:41.461354 18969 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:11:41.461364 18969 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:11:41.461370 18969 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:11:41.461379 18969 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:11:41.461387 18969 net.cpp:124] Setting up relu6\n",
      "I0430 12:11:41.461391 18969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:11:41.461393 18969 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:11:41.461396 18969 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:11:41.461402 18969 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:11:41.461405 18969 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:11:41.461410 18969 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:11:41.461416 18969 net.cpp:124] Setting up drop6\n",
      "I0430 12:11:41.461419 18969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:11:41.461422 18969 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:11:41.461436 18969 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:11:41.461441 18969 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:11:41.461446 18969 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:11:41.461452 18969 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:11:41.474587 18969 net.cpp:124] Setting up fc7\n",
      "I0430 12:11:41.474617 18969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:11:41.474622 18969 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:11:41.474634 18969 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:11:41.474645 18969 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:11:41.474650 18969 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:11:41.474656 18969 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:11:41.474665 18969 net.cpp:124] Setting up relu7\n",
      "I0430 12:11:41.474669 18969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:11:41.474674 18969 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:11:41.474679 18969 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:11:41.474686 18969 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:11:41.474690 18969 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:11:41.474697 18969 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:11:41.474705 18969 net.cpp:124] Setting up drop7\n",
      "I0430 12:11:41.474711 18969 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:11:41.474714 18969 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:11:41.474719 18969 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:11:41.474725 18969 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:11:41.474730 18969 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:11:41.474735 18969 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:11:41.475620 18969 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:11:41.475636 18969 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:11:41.475641 18969 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:11:41.475652 18969 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:11:41.475657 18969 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:11:41.475661 18969 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:11:41.475664 18969 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:11:41.475668 18969 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:11:41.475672 18969 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:11:41.475677 18969 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:11:41.475680 18969 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:11:41.475684 18969 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:11:41.475688 18969 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:11:41.475692 18969 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:11:41.475697 18969 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:11:41.475700 18969 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:11:41.475704 18969 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:11:41.475708 18969 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:11:41.475713 18969 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:11:41.475718 18969 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:11:41.475721 18969 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:11:41.475725 18969 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:11:41.475729 18969 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:11:41.475733 18969 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:11:41.475738 18969 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:11:41.475740 18969 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:11:41.475744 18969 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:11:41.475759 18969 net.cpp:257] Network initialization done.\n",
      "I0430 12:11:41.573552 18969 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:11:41.676511 18969 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:11:41.677850 18969 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:11:41.677865 18969 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:11:41.677871 18969 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/149184.jpg'}, '/tmp/tmpS6SL95.mat')\n",
      "Processed 1923 windows in 230.333 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.040 s.\n",
      "prediction    [-2.69073, -2.51071, -2.12262, -2.22263, -2.29...\n",
      "ymin                                                         92\n",
      "xmin                                                         59\n",
      "ymax                                                        143\n",
      "xmax                                                        130\n",
      "Name: /home/ambika/INF_project/data/cat/149184.jpg, dtype: object\n",
      "prediction    [-2.91425, -2.97581, -2.42308, -2.08062, -1.81...\n",
      "ymin                                                         89\n",
      "xmin                                                         41\n",
      "ymax                                                        337\n",
      "xmax                                                        169\n",
      "Name: /home/ambika/INF_project/data/cat/149184.jpg, dtype: object\n",
      "microwave\n",
      "59\t92\t130\t143\n",
      "stove\n",
      "41\t89\t169\t337\n",
      "149184\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:15:33.612614 19159 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:15:33.612642 19159 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:15:33.612646 19159 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:15:33.613768 19159 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:15:33.613960 19159 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:15:33.613970 19159 net.cpp:86] Creating Layer data\n",
      "I0430 12:15:33.613976 19159 net.cpp:382] data -> data\n",
      "I0430 12:15:33.613988 19159 net.cpp:124] Setting up data\n",
      "I0430 12:15:33.613996 19159 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:15:33.613999 19159 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:15:33.614002 19159 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:15:33.614008 19159 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:15:33.614012 19159 net.cpp:408] conv1 <- data\n",
      "I0430 12:15:33.614015 19159 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:15:33.614074 19159 net.cpp:124] Setting up conv1\n",
      "I0430 12:15:33.614078 19159 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:15:33.614081 19159 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:15:33.614087 19159 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:15:33.614092 19159 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:15:33.614095 19159 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:15:33.614099 19159 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:15:33.614104 19159 net.cpp:124] Setting up relu1\n",
      "I0430 12:15:33.614106 19159 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:15:33.614109 19159 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:15:33.614111 19159 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:15:33.614114 19159 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:15:33.614117 19159 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:15:33.614120 19159 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:15:33.614127 19159 net.cpp:124] Setting up pool1\n",
      "I0430 12:15:33.614130 19159 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:15:33.614132 19159 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:15:33.614135 19159 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:15:33.614140 19159 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:15:33.614143 19159 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:15:33.614148 19159 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:15:33.614156 19159 net.cpp:124] Setting up norm1\n",
      "I0430 12:15:33.614162 19159 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:15:33.614166 19159 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:15:33.614169 19159 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:15:33.614176 19159 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:15:33.614181 19159 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:15:33.614187 19159 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:15:33.614543 19159 net.cpp:124] Setting up conv2\n",
      "I0430 12:15:33.614552 19159 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:15:33.614554 19159 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:15:33.614563 19159 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:15:33.614569 19159 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:15:33.614573 19159 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:15:33.614576 19159 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:15:33.614580 19159 net.cpp:124] Setting up relu2\n",
      "I0430 12:15:33.614583 19159 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:15:33.614586 19159 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:15:33.614588 19159 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:15:33.614593 19159 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:15:33.614594 19159 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:15:33.614598 19159 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:15:33.614603 19159 net.cpp:124] Setting up pool2\n",
      "I0430 12:15:33.614608 19159 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:15:33.614609 19159 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:15:33.614611 19159 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:15:33.614619 19159 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:15:33.614620 19159 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:15:33.614624 19159 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:15:33.614629 19159 net.cpp:124] Setting up norm2\n",
      "I0430 12:15:33.614632 19159 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:15:33.614634 19159 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:15:33.614636 19159 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:15:33.614641 19159 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:15:33.614644 19159 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:15:33.614646 19159 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:15:33.615402 19159 net.cpp:124] Setting up conv3\n",
      "I0430 12:15:33.615417 19159 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:15:33.615420 19159 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:15:33.615430 19159 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:15:33.615438 19159 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:15:33.615442 19159 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:15:33.615447 19159 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:15:33.615453 19159 net.cpp:124] Setting up relu3\n",
      "I0430 12:15:33.615456 19159 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:15:33.615458 19159 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:15:33.615461 19159 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:15:33.615468 19159 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:15:33.615469 19159 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:15:33.615473 19159 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:15:33.616235 19159 net.cpp:124] Setting up conv4\n",
      "I0430 12:15:33.616250 19159 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:15:33.616255 19159 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:15:33.616262 19159 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:15:33.616271 19159 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:15:33.616273 19159 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:15:33.616277 19159 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:15:33.616282 19159 net.cpp:124] Setting up relu4\n",
      "I0430 12:15:33.616286 19159 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:15:33.616287 19159 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:15:33.616291 19159 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:15:33.616297 19159 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:15:33.616299 19159 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:15:33.616302 19159 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:15:33.616835 19159 net.cpp:124] Setting up conv5\n",
      "I0430 12:15:33.616847 19159 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:15:33.616849 19159 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:15:33.616866 19159 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:15:33.616873 19159 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:15:33.616876 19159 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:15:33.616881 19159 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:15:33.616886 19159 net.cpp:124] Setting up relu5\n",
      "I0430 12:15:33.616890 19159 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:15:33.616892 19159 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:15:33.616894 19159 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:15:33.616899 19159 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:15:33.616901 19159 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:15:33.616904 19159 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:15:33.616912 19159 net.cpp:124] Setting up pool5\n",
      "I0430 12:15:33.616915 19159 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:15:33.616919 19159 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:15:33.616920 19159 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:15:33.616927 19159 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:15:33.616930 19159 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:15:33.616932 19159 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:15:33.638792 19159 net.cpp:124] Setting up fc6\n",
      "I0430 12:15:33.638818 19159 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:15:33.638821 19159 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:15:33.638833 19159 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:15:33.638864 19159 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:15:33.638869 19159 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:15:33.638875 19159 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:15:33.638883 19159 net.cpp:124] Setting up relu6\n",
      "I0430 12:15:33.638888 19159 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:15:33.638891 19159 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:15:33.638895 19159 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:15:33.638901 19159 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:15:33.638906 19159 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:15:33.638909 19159 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:15:33.638916 19159 net.cpp:124] Setting up drop6\n",
      "I0430 12:15:33.638921 19159 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:15:33.638924 19159 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:15:33.638927 19159 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:15:33.638933 19159 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:15:33.638937 19159 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:15:33.638943 19159 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:15:33.650475 19159 net.cpp:124] Setting up fc7\n",
      "I0430 12:15:33.650502 19159 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:15:33.650506 19159 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:15:33.650517 19159 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:15:33.650527 19159 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:15:33.650532 19159 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:15:33.650538 19159 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:15:33.650548 19159 net.cpp:124] Setting up relu7\n",
      "I0430 12:15:33.650553 19159 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:15:33.650557 19159 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:15:33.650560 19159 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:15:33.650568 19159 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:15:33.650571 19159 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:15:33.650578 19159 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:15:33.650583 19159 net.cpp:124] Setting up drop7\n",
      "I0430 12:15:33.650585 19159 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:15:33.650588 19159 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:15:33.650590 19159 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:15:33.650594 19159 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:15:33.650598 19159 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:15:33.650600 19159 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:15:33.651554 19159 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:15:33.651567 19159 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:15:33.651571 19159 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:15:33.651581 19159 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:15:33.651585 19159 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:15:33.651588 19159 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:15:33.651592 19159 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:15:33.651597 19159 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:15:33.651600 19159 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:15:33.651604 19159 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:15:33.651607 19159 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:15:33.651612 19159 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:15:33.651613 19159 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:15:33.651617 19159 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:15:33.651619 19159 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:15:33.651623 19159 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:15:33.651625 19159 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:15:33.651628 19159 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:15:33.651631 19159 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:15:33.651633 19159 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:15:33.651636 19159 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:15:33.651639 19159 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:15:33.651643 19159 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:15:33.651645 19159 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:15:33.651648 19159 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:15:33.651650 19159 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:15:33.651653 19159 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:15:33.651664 19159 net.cpp:257] Network initialization done.\n",
      "I0430 12:15:33.733985 19159 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:15:33.829407 19159 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:15:33.830629 19159 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:15:33.830647 19159 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:15:33.830655 19159 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/5486.jpg'}, '/tmp/tmpWLBU_Y.mat')\n",
      "Processed 1785 windows in 206.421 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.037 s.\n",
      "prediction    [-2.08361, -2.40199, -2.20939, -2.43895, -2.53...\n",
      "ymin                                                        229\n",
      "xmin                                                        247\n",
      "ymax                                                        289\n",
      "xmax                                                        369\n",
      "Name: /home/ambika/INF_project/data/couch/5486.jpg, dtype: object\n",
      "prediction    [-2.58796, -1.77588, -2.25889, -2.86263, -2.04...\n",
      "ymin                                                        244\n",
      "xmin                                                        306\n",
      "ymax                                                        333\n",
      "xmax                                                        471\n",
      "Name: /home/ambika/INF_project/data/couch/5486.jpg, dtype: object\n",
      "table\n",
      "247\t229\t369\t289\n",
      "balance beam\n",
      "306\t244\t471\t333\n",
      "5486\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:19:01.802913 19336 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:19:01.802937 19336 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:19:01.802939 19336 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:19:01.804074 19336 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:19:01.804258 19336 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:19:01.804267 19336 net.cpp:86] Creating Layer data\n",
      "I0430 12:19:01.804273 19336 net.cpp:382] data -> data\n",
      "I0430 12:19:01.804291 19336 net.cpp:124] Setting up data\n",
      "I0430 12:19:01.804298 19336 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:19:01.804302 19336 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:19:01.804307 19336 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:19:01.804314 19336 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:19:01.804316 19336 net.cpp:408] conv1 <- data\n",
      "I0430 12:19:01.804322 19336 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:19:01.804379 19336 net.cpp:124] Setting up conv1\n",
      "I0430 12:19:01.804384 19336 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:19:01.804386 19336 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:19:01.804394 19336 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:19:01.804399 19336 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:19:01.804402 19336 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:19:01.804405 19336 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:19:01.804410 19336 net.cpp:124] Setting up relu1\n",
      "I0430 12:19:01.804414 19336 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:19:01.804415 19336 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:19:01.804419 19336 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:19:01.804421 19336 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:19:01.804425 19336 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:19:01.804427 19336 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:19:01.804433 19336 net.cpp:124] Setting up pool1\n",
      "I0430 12:19:01.804437 19336 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:19:01.804440 19336 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:19:01.804441 19336 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:19:01.804446 19336 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:19:01.804450 19336 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:19:01.804453 19336 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:19:01.804461 19336 net.cpp:124] Setting up norm1\n",
      "I0430 12:19:01.804466 19336 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:19:01.804469 19336 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:19:01.804473 19336 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:19:01.804481 19336 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:19:01.804484 19336 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:19:01.804489 19336 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:19:01.804841 19336 net.cpp:124] Setting up conv2\n",
      "I0430 12:19:01.804847 19336 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:19:01.804849 19336 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:19:01.804857 19336 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:19:01.804864 19336 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:19:01.804867 19336 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:19:01.804870 19336 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:19:01.804874 19336 net.cpp:124] Setting up relu2\n",
      "I0430 12:19:01.804878 19336 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:19:01.804880 19336 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:19:01.804883 19336 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:19:01.804888 19336 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:19:01.804890 19336 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:19:01.804894 19336 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:19:01.804899 19336 net.cpp:124] Setting up pool2\n",
      "I0430 12:19:01.804903 19336 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:19:01.804905 19336 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:19:01.804908 19336 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:19:01.804913 19336 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:19:01.804915 19336 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:19:01.804919 19336 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:19:01.804926 19336 net.cpp:124] Setting up norm2\n",
      "I0430 12:19:01.804929 19336 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:19:01.804931 19336 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:19:01.804934 19336 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:19:01.804940 19336 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:19:01.804942 19336 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:19:01.804946 19336 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:19:01.805637 19336 net.cpp:124] Setting up conv3\n",
      "I0430 12:19:01.805649 19336 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:19:01.805651 19336 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:19:01.805661 19336 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:19:01.805670 19336 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:19:01.805673 19336 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:19:01.805677 19336 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:19:01.805682 19336 net.cpp:124] Setting up relu3\n",
      "I0430 12:19:01.805686 19336 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:19:01.805688 19336 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:19:01.805691 19336 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:19:01.805696 19336 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:19:01.805698 19336 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:19:01.805701 19336 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:19:01.806440 19336 net.cpp:124] Setting up conv4\n",
      "I0430 12:19:01.806450 19336 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:19:01.806453 19336 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:19:01.806460 19336 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:19:01.806468 19336 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:19:01.806471 19336 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:19:01.806474 19336 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:19:01.806479 19336 net.cpp:124] Setting up relu4\n",
      "I0430 12:19:01.806483 19336 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:19:01.806485 19336 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:19:01.806488 19336 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:19:01.806494 19336 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:19:01.806496 19336 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:19:01.806500 19336 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:19:01.807008 19336 net.cpp:124] Setting up conv5\n",
      "I0430 12:19:01.807015 19336 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:19:01.807019 19336 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:19:01.807029 19336 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:19:01.807035 19336 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:19:01.807039 19336 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:19:01.807042 19336 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:19:01.807047 19336 net.cpp:124] Setting up relu5\n",
      "I0430 12:19:01.807051 19336 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:19:01.807054 19336 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:19:01.807056 19336 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:19:01.807060 19336 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:19:01.807063 19336 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:19:01.807066 19336 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:19:01.807073 19336 net.cpp:124] Setting up pool5\n",
      "I0430 12:19:01.807076 19336 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:19:01.807080 19336 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:19:01.807081 19336 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:19:01.807090 19336 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:19:01.807093 19336 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:19:01.807097 19336 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:19:01.829980 19336 net.cpp:124] Setting up fc6\n",
      "I0430 12:19:01.830006 19336 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:19:01.830010 19336 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:19:01.830021 19336 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:19:01.830034 19336 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:19:01.830039 19336 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:19:01.830044 19336 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:19:01.830051 19336 net.cpp:124] Setting up relu6\n",
      "I0430 12:19:01.830054 19336 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:19:01.830055 19336 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:19:01.830057 19336 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:19:01.830061 19336 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:19:01.830063 19336 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:19:01.830066 19336 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:19:01.830070 19336 net.cpp:124] Setting up drop6\n",
      "I0430 12:19:01.830072 19336 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:19:01.830073 19336 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:19:01.830080 19336 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:19:01.830085 19336 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:19:01.830090 19336 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:19:01.830092 19336 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:19:01.839676 19336 net.cpp:124] Setting up fc7\n",
      "I0430 12:19:01.839699 19336 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:19:01.839700 19336 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:19:01.839710 19336 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:19:01.839733 19336 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:19:01.839738 19336 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:19:01.839745 19336 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:19:01.839752 19336 net.cpp:124] Setting up relu7\n",
      "I0430 12:19:01.839756 19336 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:19:01.839761 19336 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:19:01.839763 19336 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:19:01.839769 19336 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:19:01.839771 19336 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:19:01.839777 19336 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:19:01.839783 19336 net.cpp:124] Setting up drop7\n",
      "I0430 12:19:01.839787 19336 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:19:01.839789 19336 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:19:01.839792 19336 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:19:01.839798 19336 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:19:01.839800 19336 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:19:01.839805 19336 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:19:01.840695 19336 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:19:01.840706 19336 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:19:01.840710 19336 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:19:01.840718 19336 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:19:01.840720 19336 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:19:01.840723 19336 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:19:01.840728 19336 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:19:01.840730 19336 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:19:01.840734 19336 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:19:01.840737 19336 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:19:01.840740 19336 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:19:01.840744 19336 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:19:01.840747 19336 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:19:01.840752 19336 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:19:01.840755 19336 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:19:01.840759 19336 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:19:01.840762 19336 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:19:01.840766 19336 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:19:01.840770 19336 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:19:01.840773 19336 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:19:01.840776 19336 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:19:01.840780 19336 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:19:01.840783 19336 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:19:01.840786 19336 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:19:01.840790 19336 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:19:01.840793 19336 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:19:01.840796 19336 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:19:01.840806 19336 net.cpp:257] Network initialization done.\n",
      "I0430 12:19:01.921471 19336 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:19:02.014346 19336 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:19:02.015282 19336 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:19:02.015290 19336 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:19:02.015293 19336 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/43734.jpg'}, '/tmp/tmpt79R2H.mat')\n",
      "Processed 1419 windows in 163.569 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-1.78787, -2.10452, -1.6083, -1.91686, -1.832...\n",
      "ymin                                                         43\n",
      "xmin                                                          0\n",
      "ymax                                                        164\n",
      "xmax                                                        194\n",
      "Name: /home/ambika/INF_project/data/dog/43734.jpg, dtype: object\n",
      "prediction    [-2.00766, -2.14589, -1.96266, -2.08217, -1.76...\n",
      "ymin                                                         36\n",
      "xmin                                                          0\n",
      "ymax                                                        192\n",
      "xmax                                                        327\n",
      "Name: /home/ambika/INF_project/data/dog/43734.jpg, dtype: object\n",
      "dog\n",
      "0\t43\t194\t164\n",
      "cattle\n",
      "0\t36\t327\t192\n",
      "43734\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:21:47.022207 19537 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:21:47.022228 19537 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:21:47.022230 19537 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:21:47.023378 19537 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:21:47.023555 19537 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:21:47.023566 19537 net.cpp:86] Creating Layer data\n",
      "I0430 12:21:47.023573 19537 net.cpp:382] data -> data\n",
      "I0430 12:21:47.023586 19537 net.cpp:124] Setting up data\n",
      "I0430 12:21:47.023593 19537 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:21:47.023596 19537 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:21:47.023599 19537 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:21:47.023607 19537 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:21:47.023609 19537 net.cpp:408] conv1 <- data\n",
      "I0430 12:21:47.023614 19537 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:21:47.023676 19537 net.cpp:124] Setting up conv1\n",
      "I0430 12:21:47.023681 19537 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:21:47.023684 19537 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:21:47.023692 19537 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:21:47.023699 19537 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:21:47.023701 19537 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:21:47.023705 19537 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:21:47.023710 19537 net.cpp:124] Setting up relu1\n",
      "I0430 12:21:47.023715 19537 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:21:47.023717 19537 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:21:47.023720 19537 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:21:47.023725 19537 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:21:47.023728 19537 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:21:47.023732 19537 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:21:47.023741 19537 net.cpp:124] Setting up pool1\n",
      "I0430 12:21:47.023744 19537 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:21:47.023747 19537 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:21:47.023751 19537 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:21:47.023756 19537 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:21:47.023758 19537 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:21:47.023762 19537 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:21:47.023768 19537 net.cpp:124] Setting up norm1\n",
      "I0430 12:21:47.023773 19537 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:21:47.023775 19537 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:21:47.023778 19537 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:21:47.023784 19537 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:21:47.023787 19537 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:21:47.023792 19537 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:21:47.024119 19537 net.cpp:124] Setting up conv2\n",
      "I0430 12:21:47.024125 19537 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:21:47.024128 19537 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:21:47.024135 19537 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:21:47.024142 19537 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:21:47.024145 19537 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:21:47.024149 19537 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:21:47.024154 19537 net.cpp:124] Setting up relu2\n",
      "I0430 12:21:47.024158 19537 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:21:47.024161 19537 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:21:47.024164 19537 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:21:47.024168 19537 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:21:47.024171 19537 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:21:47.024175 19537 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:21:47.024183 19537 net.cpp:124] Setting up pool2\n",
      "I0430 12:21:47.024186 19537 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:21:47.024189 19537 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:21:47.024193 19537 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:21:47.024199 19537 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:21:47.024201 19537 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:21:47.024205 19537 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:21:47.024211 19537 net.cpp:124] Setting up norm2\n",
      "I0430 12:21:47.024215 19537 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:21:47.024219 19537 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:21:47.024221 19537 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:21:47.024226 19537 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:21:47.024230 19537 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:21:47.024235 19537 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:21:47.024933 19537 net.cpp:124] Setting up conv3\n",
      "I0430 12:21:47.024946 19537 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:21:47.024950 19537 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:21:47.024960 19537 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:21:47.024968 19537 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:21:47.024971 19537 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:21:47.024976 19537 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:21:47.024983 19537 net.cpp:124] Setting up relu3\n",
      "I0430 12:21:47.024987 19537 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:21:47.024991 19537 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:21:47.024993 19537 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:21:47.024999 19537 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:21:47.025002 19537 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:21:47.025007 19537 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:21:47.025753 19537 net.cpp:124] Setting up conv4\n",
      "I0430 12:21:47.025763 19537 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:21:47.025765 19537 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:21:47.025773 19537 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:21:47.025779 19537 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:21:47.025780 19537 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:21:47.025786 19537 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:21:47.025790 19537 net.cpp:124] Setting up relu4\n",
      "I0430 12:21:47.025794 19537 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:21:47.025797 19537 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:21:47.025800 19537 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:21:47.025807 19537 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:21:47.025810 19537 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:21:47.025815 19537 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:21:47.026295 19537 net.cpp:124] Setting up conv5\n",
      "I0430 12:21:47.026304 19537 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:21:47.026306 19537 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:21:47.026314 19537 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:21:47.026320 19537 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:21:47.026324 19537 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:21:47.026329 19537 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:21:47.026334 19537 net.cpp:124] Setting up relu5\n",
      "I0430 12:21:47.026337 19537 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:21:47.026340 19537 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:21:47.026343 19537 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:21:47.026350 19537 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:21:47.026353 19537 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:21:47.026360 19537 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:21:47.026371 19537 net.cpp:124] Setting up pool5\n",
      "I0430 12:21:47.026374 19537 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:21:47.026377 19537 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:21:47.026381 19537 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:21:47.026388 19537 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:21:47.026391 19537 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:21:47.026396 19537 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:21:47.048439 19537 net.cpp:124] Setting up fc6\n",
      "I0430 12:21:47.048465 19537 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:21:47.048466 19537 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:21:47.048480 19537 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:21:47.048493 19537 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:21:47.048497 19537 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:21:47.048501 19537 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:21:47.048508 19537 net.cpp:124] Setting up relu6\n",
      "I0430 12:21:47.048511 19537 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:21:47.048512 19537 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:21:47.048514 19537 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:21:47.048517 19537 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:21:47.048519 19537 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:21:47.048521 19537 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:21:47.048526 19537 net.cpp:124] Setting up drop6\n",
      "I0430 12:21:47.048527 19537 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:21:47.048540 19537 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:21:47.048543 19537 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:21:47.048550 19537 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:21:47.048553 19537 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:21:47.048558 19537 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:21:47.058248 19537 net.cpp:124] Setting up fc7\n",
      "I0430 12:21:47.058269 19537 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:21:47.058271 19537 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:21:47.058282 19537 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:21:47.058295 19537 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:21:47.058298 19537 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:21:47.058305 19537 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:21:47.058311 19537 net.cpp:124] Setting up relu7\n",
      "I0430 12:21:47.058313 19537 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:21:47.058315 19537 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:21:47.058316 19537 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:21:47.058321 19537 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:21:47.058323 19537 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:21:47.058326 19537 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:21:47.058331 19537 net.cpp:124] Setting up drop7\n",
      "I0430 12:21:47.058332 19537 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:21:47.058343 19537 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:21:47.058346 19537 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:21:47.058349 19537 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:21:47.058352 19537 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:21:47.058356 19537 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:21:47.059257 19537 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:21:47.059264 19537 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:21:47.059268 19537 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:21:47.059278 19537 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:21:47.059288 19537 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:21:47.059290 19537 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:21:47.059294 19537 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:21:47.059296 19537 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:21:47.059299 19537 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:21:47.059303 19537 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:21:47.059305 19537 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:21:47.059307 19537 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:21:47.059310 19537 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:21:47.059312 19537 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:21:47.059315 19537 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:21:47.059317 19537 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:21:47.059320 19537 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:21:47.059324 19537 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:21:47.059325 19537 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:21:47.059329 19537 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:21:47.059331 19537 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:21:47.059334 19537 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:21:47.059336 19537 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:21:47.059340 19537 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:21:47.059341 19537 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:21:47.059345 19537 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:21:47.059346 19537 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:21:47.059356 19537 net.cpp:257] Network initialization done.\n",
      "I0430 12:21:47.140244 19537 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:21:47.231864 19537 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:21:47.232800 19537 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:21:47.232807 19537 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:21:47.232811 19537 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/296886.jpg'}, '/tmp/tmpRhMU9C.mat')\n",
      "Processed 2106 windows in 243.054 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-2.16795, -2.2558, -1.90245, -2.39924, -1.977...\n",
      "ymin                                                        318\n",
      "xmin                                                        405\n",
      "ymax                                                        357\n",
      "xmax                                                        433\n",
      "Name: /home/ambika/INF_project/data/horse/296886.jpg, dtype: object\n",
      "prediction    [-2.19115, -2.40834, -1.68206, -0.590519, -2.1...\n",
      "ymin                                                        266\n",
      "xmin                                                        434\n",
      "ymax                                                        294\n",
      "xmax                                                        467\n",
      "Name: /home/ambika/INF_project/data/horse/296886.jpg, dtype: object\n",
      "person\n",
      "405\t318\t433\t357\n",
      "horse\n",
      "434\t266\t467\t294\n",
      "296886\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:25:51.884091 19750 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:25:51.884110 19750 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:25:51.884112 19750 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:25:51.885223 19750 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:25:51.885327 19750 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:25:51.885337 19750 net.cpp:86] Creating Layer data\n",
      "I0430 12:25:51.885341 19750 net.cpp:382] data -> data\n",
      "I0430 12:25:51.885354 19750 net.cpp:124] Setting up data\n",
      "I0430 12:25:51.885359 19750 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:25:51.885360 19750 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:25:51.885365 19750 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:25:51.885370 19750 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:25:51.885373 19750 net.cpp:408] conv1 <- data\n",
      "I0430 12:25:51.885378 19750 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:25:51.885439 19750 net.cpp:124] Setting up conv1\n",
      "I0430 12:25:51.885444 19750 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:25:51.885447 19750 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:25:51.885453 19750 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:25:51.885457 19750 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:25:51.885460 19750 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:25:51.885464 19750 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:25:51.885468 19750 net.cpp:124] Setting up relu1\n",
      "I0430 12:25:51.885470 19750 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:25:51.885473 19750 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:25:51.885473 19750 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:25:51.885476 19750 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:25:51.885478 19750 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:25:51.885481 19750 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:25:51.885486 19750 net.cpp:124] Setting up pool1\n",
      "I0430 12:25:51.885489 19750 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:25:51.885490 19750 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:25:51.885493 19750 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:25:51.885496 19750 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:25:51.885499 19750 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:25:51.885502 19750 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:25:51.885509 19750 net.cpp:124] Setting up norm1\n",
      "I0430 12:25:51.885511 19750 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:25:51.885514 19750 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:25:51.885516 19750 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:25:51.885520 19750 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:25:51.885522 19750 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:25:51.885525 19750 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:25:51.885875 19750 net.cpp:124] Setting up conv2\n",
      "I0430 12:25:51.885882 19750 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:25:51.885885 19750 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:25:51.885890 19750 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:25:51.885893 19750 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:25:51.885897 19750 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:25:51.885900 19750 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:25:51.885905 19750 net.cpp:124] Setting up relu2\n",
      "I0430 12:25:51.885907 19750 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:25:51.885910 19750 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:25:51.885912 19750 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:25:51.885916 19750 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:25:51.885918 19750 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:25:51.885921 19750 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:25:51.885927 19750 net.cpp:124] Setting up pool2\n",
      "I0430 12:25:51.885931 19750 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:25:51.885932 19750 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:25:51.885934 19750 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:25:51.885941 19750 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:25:51.885942 19750 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:25:51.885946 19750 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:25:51.885951 19750 net.cpp:124] Setting up norm2\n",
      "I0430 12:25:51.885953 19750 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:25:51.885957 19750 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:25:51.885959 19750 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:25:51.885965 19750 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:25:51.885969 19750 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:25:51.885974 19750 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:25:51.886653 19750 net.cpp:124] Setting up conv3\n",
      "I0430 12:25:51.886662 19750 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:25:51.886667 19750 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:25:51.886675 19750 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:25:51.886683 19750 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:25:51.886687 19750 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:25:51.886692 19750 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:25:51.886698 19750 net.cpp:124] Setting up relu3\n",
      "I0430 12:25:51.886703 19750 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:25:51.886705 19750 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:25:51.886708 19750 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:25:51.886714 19750 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:25:51.886718 19750 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:25:51.886723 19750 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:25:51.887536 19750 net.cpp:124] Setting up conv4\n",
      "I0430 12:25:51.887550 19750 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:25:51.887553 19750 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:25:51.887558 19750 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:25:51.887564 19750 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:25:51.887567 19750 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:25:51.887570 19750 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:25:51.887574 19750 net.cpp:124] Setting up relu4\n",
      "I0430 12:25:51.887578 19750 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:25:51.887580 19750 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:25:51.887583 19750 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:25:51.887589 19750 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:25:51.887591 19750 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:25:51.887595 19750 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:25:51.888095 19750 net.cpp:124] Setting up conv5\n",
      "I0430 12:25:51.888101 19750 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:25:51.888104 19750 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:25:51.888113 19750 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:25:51.888115 19750 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:25:51.888119 19750 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:25:51.888123 19750 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:25:51.888128 19750 net.cpp:124] Setting up relu5\n",
      "I0430 12:25:51.888131 19750 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:25:51.888134 19750 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:25:51.888135 19750 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:25:51.888139 19750 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:25:51.888142 19750 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:25:51.888146 19750 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:25:51.888152 19750 net.cpp:124] Setting up pool5\n",
      "I0430 12:25:51.888155 19750 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:25:51.888159 19750 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:25:51.888160 19750 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:25:51.888169 19750 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:25:51.888171 19750 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:25:51.888175 19750 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:25:51.912578 19750 net.cpp:124] Setting up fc6\n",
      "I0430 12:25:51.912607 19750 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:25:51.912612 19750 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:25:51.912624 19750 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:25:51.912637 19750 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:25:51.912642 19750 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:25:51.912649 19750 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:25:51.912658 19750 net.cpp:124] Setting up relu6\n",
      "I0430 12:25:51.912663 19750 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:25:51.912667 19750 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:25:51.912672 19750 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:25:51.912678 19750 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:25:51.912693 19750 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:25:51.912698 19750 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:25:51.912704 19750 net.cpp:124] Setting up drop6\n",
      "I0430 12:25:51.912709 19750 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:25:51.912711 19750 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:25:51.912714 19750 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:25:51.912720 19750 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:25:51.912724 19750 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:25:51.912730 19750 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:25:51.924232 19750 net.cpp:124] Setting up fc7\n",
      "I0430 12:25:51.924266 19750 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:25:51.924273 19750 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:25:51.924286 19750 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:25:51.924299 19750 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:25:51.924304 19750 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:25:51.924309 19750 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:25:51.924319 19750 net.cpp:124] Setting up relu7\n",
      "I0430 12:25:51.924324 19750 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:25:51.924329 19750 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:25:51.924331 19750 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:25:51.924338 19750 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:25:51.924342 19750 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:25:51.924348 19750 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:25:51.924355 19750 net.cpp:124] Setting up drop7\n",
      "I0430 12:25:51.924358 19750 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:25:51.924361 19750 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:25:51.924365 19750 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:25:51.924371 19750 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:25:51.924373 19750 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:25:51.924378 19750 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:25:51.925143 19750 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:25:51.925163 19750 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:25:51.925168 19750 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:25:51.925180 19750 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:25:51.925185 19750 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:25:51.925189 19750 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:25:51.925192 19750 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:25:51.925199 19750 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:25:51.925201 19750 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:25:51.925205 19750 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:25:51.925209 19750 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:25:51.925213 19750 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:25:51.925216 19750 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:25:51.925220 19750 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:25:51.925225 19750 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:25:51.925228 19750 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:25:51.925232 19750 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:25:51.925236 19750 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:25:51.925240 19750 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:25:51.925245 19750 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:25:51.925248 19750 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:25:51.925252 19750 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:25:51.925256 19750 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:25:51.925259 19750 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:25:51.925262 19750 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:25:51.925266 19750 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:25:51.925268 19750 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:25:51.925282 19750 net.cpp:257] Network initialization done.\n",
      "I0430 12:25:52.012822 19750 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:25:52.105685 19750 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:25:52.106627 19750 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:25:52.106637 19750 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:25:52.106639 19750 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/490320.jpg'}, '/tmp/tmpAK84LD.mat')\n",
      "Processed 2151 windows in 251.101 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.034 s.\n",
      "prediction    [-0.821214, -2.51646, -2.43418, -1.90807, -1.7...\n",
      "ymin                                                        205\n",
      "xmin                                                         98\n",
      "ymax                                                        359\n",
      "xmax                                                        310\n",
      "Name: /home/ambika/INF_project/data/person/490320.jpg, dtype: object\n",
      "prediction    [-1.80653, -2.40325, -2.32757, -1.49557, -2.68...\n",
      "ymin                                                         43\n",
      "xmin                                                         62\n",
      "ymax                                                        124\n",
      "xmax                                                        249\n",
      "Name: /home/ambika/INF_project/data/person/490320.jpg, dtype: object\n",
      "laptop\n",
      "98\t205\t310\t359\n",
      "tape player\n",
      "62\t43\t249\t124\n",
      "490320\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:30:04.884634 19974 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:30:04.884654 19974 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:30:04.884658 19974 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:30:04.885871 19974 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:30:04.886068 19974 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:30:04.886076 19974 net.cpp:86] Creating Layer data\n",
      "I0430 12:30:04.886083 19974 net.cpp:382] data -> data\n",
      "I0430 12:30:04.886113 19974 net.cpp:124] Setting up data\n",
      "I0430 12:30:04.886119 19974 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:30:04.886122 19974 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:30:04.886126 19974 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:30:04.886132 19974 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:30:04.886134 19974 net.cpp:408] conv1 <- data\n",
      "I0430 12:30:04.886139 19974 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:30:04.886203 19974 net.cpp:124] Setting up conv1\n",
      "I0430 12:30:04.886207 19974 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:30:04.886210 19974 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:30:04.886217 19974 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:30:04.886222 19974 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:30:04.886225 19974 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:30:04.886229 19974 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:30:04.886234 19974 net.cpp:124] Setting up relu1\n",
      "I0430 12:30:04.886237 19974 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:30:04.886240 19974 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:30:04.886242 19974 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:30:04.886246 19974 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:30:04.886248 19974 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:30:04.886251 19974 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:30:04.886257 19974 net.cpp:124] Setting up pool1\n",
      "I0430 12:30:04.886260 19974 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:30:04.886262 19974 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:30:04.886265 19974 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:30:04.886268 19974 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:30:04.886270 19974 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:30:04.886276 19974 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:30:04.886283 19974 net.cpp:124] Setting up norm1\n",
      "I0430 12:30:04.886288 19974 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:30:04.886291 19974 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:30:04.886296 19974 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:30:04.886301 19974 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:30:04.886304 19974 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:30:04.886310 19974 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:30:04.886684 19974 net.cpp:124] Setting up conv2\n",
      "I0430 12:30:04.886692 19974 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:30:04.886695 19974 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:30:04.886703 19974 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:30:04.886708 19974 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:30:04.886711 19974 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:30:04.886718 19974 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:30:04.886723 19974 net.cpp:124] Setting up relu2\n",
      "I0430 12:30:04.886726 19974 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:30:04.886729 19974 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:30:04.886734 19974 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:30:04.886739 19974 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:30:04.886742 19974 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:30:04.886747 19974 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:30:04.886754 19974 net.cpp:124] Setting up pool2\n",
      "I0430 12:30:04.886759 19974 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:30:04.886762 19974 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:30:04.886765 19974 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:30:04.886771 19974 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:30:04.886775 19974 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:30:04.886780 19974 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:30:04.886786 19974 net.cpp:124] Setting up norm2\n",
      "I0430 12:30:04.886790 19974 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:30:04.886793 19974 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:30:04.886797 19974 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:30:04.886806 19974 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:30:04.886808 19974 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:30:04.886813 19974 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:30:04.887574 19974 net.cpp:124] Setting up conv3\n",
      "I0430 12:30:04.887588 19974 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:30:04.887591 19974 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:30:04.887600 19974 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:30:04.887608 19974 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:30:04.887610 19974 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:30:04.887616 19974 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:30:04.887624 19974 net.cpp:124] Setting up relu3\n",
      "I0430 12:30:04.887627 19974 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:30:04.887630 19974 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:30:04.887634 19974 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:30:04.887641 19974 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:30:04.887645 19974 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:30:04.887650 19974 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:30:04.888463 19974 net.cpp:124] Setting up conv4\n",
      "I0430 12:30:04.888473 19974 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:30:04.888476 19974 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:30:04.888484 19974 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:30:04.888489 19974 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:30:04.888492 19974 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:30:04.888499 19974 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:30:04.888504 19974 net.cpp:124] Setting up relu4\n",
      "I0430 12:30:04.888509 19974 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:30:04.888511 19974 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:30:04.888515 19974 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:30:04.888521 19974 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:30:04.888525 19974 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:30:04.888531 19974 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:30:04.889094 19974 net.cpp:124] Setting up conv5\n",
      "I0430 12:30:04.889104 19974 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:30:04.889107 19974 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:30:04.889118 19974 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:30:04.889123 19974 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:30:04.889127 19974 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:30:04.889132 19974 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:30:04.889137 19974 net.cpp:124] Setting up relu5\n",
      "I0430 12:30:04.889142 19974 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:30:04.889144 19974 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:30:04.889148 19974 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:30:04.889155 19974 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:30:04.889158 19974 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:30:04.889163 19974 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:30:04.889171 19974 net.cpp:124] Setting up pool5\n",
      "I0430 12:30:04.889176 19974 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:30:04.889179 19974 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:30:04.889183 19974 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:30:04.889191 19974 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:30:04.889194 19974 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:30:04.889199 19974 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:30:04.912729 19974 net.cpp:124] Setting up fc6\n",
      "I0430 12:30:04.912750 19974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:30:04.912757 19974 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:30:04.912768 19974 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:30:04.912781 19974 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:30:04.912786 19974 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:30:04.912794 19974 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:30:04.912806 19974 net.cpp:124] Setting up relu6\n",
      "I0430 12:30:04.912811 19974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:30:04.912827 19974 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:30:04.912830 19974 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:30:04.912837 19974 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:30:04.912842 19974 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:30:04.912847 19974 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:30:04.912854 19974 net.cpp:124] Setting up drop6\n",
      "I0430 12:30:04.912860 19974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:30:04.912863 19974 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:30:04.912868 19974 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:30:04.912873 19974 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:30:04.912876 19974 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:30:04.912883 19974 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:30:04.925621 19974 net.cpp:124] Setting up fc7\n",
      "I0430 12:30:04.925647 19974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:30:04.925652 19974 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:30:04.925662 19974 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:30:04.925673 19974 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:30:04.925678 19974 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:30:04.925688 19974 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:30:04.925698 19974 net.cpp:124] Setting up relu7\n",
      "I0430 12:30:04.925704 19974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:30:04.925706 19974 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:30:04.925710 19974 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:30:04.925719 19974 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:30:04.925722 19974 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:30:04.925727 19974 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:30:04.925735 19974 net.cpp:124] Setting up drop7\n",
      "I0430 12:30:04.925740 19974 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:30:04.925741 19974 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:30:04.925745 19974 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:30:04.925750 19974 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:30:04.925752 19974 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:30:04.925756 19974 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:30:04.926491 19974 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:30:04.926506 19974 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:30:04.926509 19974 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:30:04.926520 19974 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:30:04.926525 19974 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:30:04.926530 19974 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:30:04.926534 19974 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:30:04.926538 19974 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:30:04.926542 19974 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:30:04.926544 19974 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:30:04.926548 19974 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:30:04.926550 19974 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:30:04.926553 19974 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:30:04.926556 19974 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:30:04.926559 19974 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:30:04.926563 19974 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:30:04.926566 19974 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:30:04.926569 19974 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:30:04.926573 19974 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:30:04.926578 19974 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:30:04.926580 19974 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:30:04.926584 19974 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:30:04.926586 19974 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:30:04.926590 19974 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:30:04.926594 19974 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:30:04.926596 19974 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:30:04.926599 19974 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:30:04.926609 19974 net.cpp:257] Network initialization done.\n",
      "I0430 12:30:05.014027 19974 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:30:05.114246 19974 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:30:05.115317 19974 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:30:05.115327 19974 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:30:05.115334 19974 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/555267.jpg'}, '/tmp/tmpS82PSL.mat')\n",
      "Processed 1743 windows in 200.811 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-2.42473, -0.887733, -2.39524, -2.67923, -2.0...\n",
      "ymin                                                          0\n",
      "xmin                                                         30\n",
      "ymax                                                        281\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/train/555267.jpg, dtype: object\n",
      "prediction    [-1.86985, -2.54798, -1.79021, -2.13442, -1.64...\n",
      "ymin                                                        120\n",
      "xmin                                                         13\n",
      "ymax                                                        140\n",
      "xmax                                                         41\n",
      "Name: /home/ambika/INF_project/data/train/555267.jpg, dtype: object\n",
      "train\n",
      "30\t0\t500\t281\n",
      "person\n",
      "13\t120\t41\t140\n",
      "555267\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:33:27.497479 20148 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:33:27.497498 20148 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:33:27.497503 20148 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:33:27.498597 20148 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:33:27.498734 20148 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:33:27.498742 20148 net.cpp:86] Creating Layer data\n",
      "I0430 12:33:27.498749 20148 net.cpp:382] data -> data\n",
      "I0430 12:33:27.498766 20148 net.cpp:124] Setting up data\n",
      "I0430 12:33:27.498772 20148 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:33:27.498775 20148 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:33:27.498778 20148 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:33:27.498785 20148 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:33:27.498788 20148 net.cpp:408] conv1 <- data\n",
      "I0430 12:33:27.498793 20148 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:33:27.498869 20148 net.cpp:124] Setting up conv1\n",
      "I0430 12:33:27.498878 20148 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:33:27.498880 20148 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:33:27.498890 20148 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:33:27.498896 20148 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:33:27.498899 20148 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:33:27.498904 20148 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:33:27.498910 20148 net.cpp:124] Setting up relu1\n",
      "I0430 12:33:27.498914 20148 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:33:27.498916 20148 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:33:27.498919 20148 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:33:27.498924 20148 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:33:27.498927 20148 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:33:27.498932 20148 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:33:27.498939 20148 net.cpp:124] Setting up pool1\n",
      "I0430 12:33:27.498944 20148 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:33:27.498945 20148 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:33:27.498949 20148 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:33:27.498955 20148 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:33:27.498956 20148 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:33:27.498961 20148 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:33:27.498966 20148 net.cpp:124] Setting up norm1\n",
      "I0430 12:33:27.498971 20148 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:33:27.498973 20148 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:33:27.498976 20148 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:33:27.498981 20148 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:33:27.498984 20148 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:33:27.498988 20148 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:33:27.499372 20148 net.cpp:124] Setting up conv2\n",
      "I0430 12:33:27.499379 20148 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:33:27.499382 20148 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:33:27.499389 20148 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:33:27.499394 20148 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:33:27.499397 20148 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:33:27.499402 20148 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:33:27.499408 20148 net.cpp:124] Setting up relu2\n",
      "I0430 12:33:27.499413 20148 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:33:27.499416 20148 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:33:27.499418 20148 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:33:27.499423 20148 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:33:27.499426 20148 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:33:27.499431 20148 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:33:27.499439 20148 net.cpp:124] Setting up pool2\n",
      "I0430 12:33:27.499444 20148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:33:27.499445 20148 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:33:27.499449 20148 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:33:27.499455 20148 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:33:27.499459 20148 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:33:27.499464 20148 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:33:27.499469 20148 net.cpp:124] Setting up norm2\n",
      "I0430 12:33:27.499474 20148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:33:27.499475 20148 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:33:27.499478 20148 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:33:27.499487 20148 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:33:27.499490 20148 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:33:27.499495 20148 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:33:27.500223 20148 net.cpp:124] Setting up conv3\n",
      "I0430 12:33:27.500236 20148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:33:27.500239 20148 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:33:27.500249 20148 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:33:27.500257 20148 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:33:27.500259 20148 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:33:27.500264 20148 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:33:27.500270 20148 net.cpp:124] Setting up relu3\n",
      "I0430 12:33:27.500274 20148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:33:27.500277 20148 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:33:27.500280 20148 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:33:27.500288 20148 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:33:27.500290 20148 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:33:27.500295 20148 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:33:27.501096 20148 net.cpp:124] Setting up conv4\n",
      "I0430 12:33:27.501109 20148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:33:27.501112 20148 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:33:27.501119 20148 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:33:27.501126 20148 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:33:27.501128 20148 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:33:27.501133 20148 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:33:27.501139 20148 net.cpp:124] Setting up relu4\n",
      "I0430 12:33:27.501143 20148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:33:27.501147 20148 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:33:27.501149 20148 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:33:27.501157 20148 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:33:27.501159 20148 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:33:27.501163 20148 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:33:27.501665 20148 net.cpp:124] Setting up conv5\n",
      "I0430 12:33:27.501672 20148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:33:27.501677 20148 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:33:27.501684 20148 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:33:27.501690 20148 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:33:27.501693 20148 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:33:27.501698 20148 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:33:27.501703 20148 net.cpp:124] Setting up relu5\n",
      "I0430 12:33:27.501706 20148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:33:27.501709 20148 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:33:27.501713 20148 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:33:27.501718 20148 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:33:27.501720 20148 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:33:27.501724 20148 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:33:27.501732 20148 net.cpp:124] Setting up pool5\n",
      "I0430 12:33:27.501736 20148 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:33:27.501739 20148 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:33:27.501742 20148 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:33:27.501750 20148 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:33:27.501754 20148 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:33:27.501758 20148 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:33:27.524078 20148 net.cpp:124] Setting up fc6\n",
      "I0430 12:33:27.524103 20148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:33:27.524111 20148 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:33:27.524121 20148 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:33:27.524132 20148 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:33:27.524134 20148 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:33:27.524140 20148 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:33:27.524147 20148 net.cpp:124] Setting up relu6\n",
      "I0430 12:33:27.524152 20148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:33:27.524154 20148 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:33:27.524157 20148 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:33:27.524161 20148 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:33:27.524176 20148 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:33:27.524180 20148 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:33:27.524186 20148 net.cpp:124] Setting up drop6\n",
      "I0430 12:33:27.524190 20148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:33:27.524194 20148 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:33:27.524196 20148 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:33:27.524202 20148 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:33:27.524204 20148 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:33:27.524211 20148 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:33:27.533682 20148 net.cpp:124] Setting up fc7\n",
      "I0430 12:33:27.533707 20148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:33:27.533712 20148 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:33:27.533723 20148 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:33:27.533732 20148 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:33:27.533736 20148 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:33:27.533741 20148 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:33:27.533749 20148 net.cpp:124] Setting up relu7\n",
      "I0430 12:33:27.533753 20148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:33:27.533756 20148 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:33:27.533759 20148 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:33:27.533778 20148 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:33:27.533782 20148 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:33:27.533787 20148 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:33:27.533793 20148 net.cpp:124] Setting up drop7\n",
      "I0430 12:33:27.533797 20148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:33:27.533799 20148 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:33:27.533802 20148 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:33:27.533808 20148 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:33:27.533812 20148 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:33:27.533815 20148 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:33:27.534736 20148 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:33:27.534750 20148 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:33:27.534754 20148 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:33:27.534760 20148 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:33:27.534765 20148 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:33:27.534768 20148 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:33:27.534771 20148 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:33:27.534777 20148 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:33:27.534782 20148 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:33:27.534787 20148 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:33:27.534791 20148 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:33:27.534795 20148 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:33:27.534797 20148 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:33:27.534801 20148 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:33:27.534804 20148 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:33:27.534807 20148 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:33:27.534811 20148 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:33:27.534814 20148 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:33:27.534818 20148 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:33:27.534821 20148 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:33:27.534824 20148 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:33:27.534827 20148 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:33:27.534832 20148 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:33:27.534834 20148 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:33:27.534837 20148 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:33:27.534838 20148 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:33:27.534840 20148 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:33:27.534852 20148 net.cpp:257] Network initialization done.\n",
      "I0430 12:33:27.615144 20148 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:33:27.715345 20148 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:33:27.716316 20148 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:33:27.716326 20148 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:33:27.716331 20148 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/424776.jpg'}, '/tmp/tmp_N_VZG.mat')\n",
      "Processed 2315 windows in 260.279 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-1.76983, -1.89149, -1.699, -1.80431, -1.5955...\n",
      "ymin                                                        118\n",
      "xmin                                                        332\n",
      "ymax                                                        140\n",
      "xmax                                                        353\n",
      "Name: /home/ambika/INF_project/data/airplane/424776.jpg, dtype: object\n",
      "prediction    [-2.14681, -1.5658, -2.12795, -2.15427, -1.861...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                        231\n",
      "xmax                                                        234\n",
      "Name: /home/ambika/INF_project/data/airplane/424776.jpg, dtype: object\n",
      "person\n",
      "332\t118\t353\t140\n",
      "ski\n",
      "0\t0\t234\t231\n",
      "424776\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:37:49.488652 20339 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:37:49.488677 20339 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:37:49.488679 20339 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:37:49.490243 20339 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:37:49.490404 20339 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:37:49.490417 20339 net.cpp:86] Creating Layer data\n",
      "I0430 12:37:49.490422 20339 net.cpp:382] data -> data\n",
      "I0430 12:37:49.490439 20339 net.cpp:124] Setting up data\n",
      "I0430 12:37:49.490447 20339 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:37:49.490452 20339 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:37:49.490456 20339 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:37:49.490465 20339 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:37:49.490470 20339 net.cpp:408] conv1 <- data\n",
      "I0430 12:37:49.490476 20339 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:37:49.490561 20339 net.cpp:124] Setting up conv1\n",
      "I0430 12:37:49.490571 20339 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:37:49.490573 20339 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:37:49.490583 20339 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:37:49.490592 20339 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:37:49.490597 20339 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:37:49.490602 20339 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:37:49.490608 20339 net.cpp:124] Setting up relu1\n",
      "I0430 12:37:49.490613 20339 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:37:49.490617 20339 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:37:49.490620 20339 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:37:49.490627 20339 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:37:49.490630 20339 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:37:49.490636 20339 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:37:49.490646 20339 net.cpp:124] Setting up pool1\n",
      "I0430 12:37:49.490653 20339 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:37:49.490655 20339 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:37:49.490659 20339 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:37:49.490665 20339 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:37:49.490669 20339 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:37:49.490674 20339 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:37:49.490682 20339 net.cpp:124] Setting up norm1\n",
      "I0430 12:37:49.490689 20339 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:37:49.490692 20339 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:37:49.490696 20339 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:37:49.490703 20339 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:37:49.490707 20339 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:37:49.490712 20339 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:37:49.491176 20339 net.cpp:124] Setting up conv2\n",
      "I0430 12:37:49.491190 20339 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:37:49.491195 20339 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:37:49.491425 20339 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:37:49.491438 20339 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:37:49.491444 20339 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:37:49.491451 20339 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:37:49.491461 20339 net.cpp:124] Setting up relu2\n",
      "I0430 12:37:49.491466 20339 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:37:49.491470 20339 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:37:49.491474 20339 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:37:49.491482 20339 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:37:49.491487 20339 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:37:49.491492 20339 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:37:49.491503 20339 net.cpp:124] Setting up pool2\n",
      "I0430 12:37:49.491508 20339 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:37:49.491513 20339 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:37:49.491516 20339 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:37:49.491524 20339 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:37:49.491529 20339 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:37:49.491535 20339 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:37:49.491544 20339 net.cpp:124] Setting up norm2\n",
      "I0430 12:37:49.491549 20339 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:37:49.491552 20339 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:37:49.491555 20339 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:37:49.491562 20339 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:37:49.491566 20339 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:37:49.491572 20339 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:37:49.492497 20339 net.cpp:124] Setting up conv3\n",
      "I0430 12:37:49.492519 20339 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:37:49.492524 20339 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:37:49.492538 20339 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:37:49.492549 20339 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:37:49.492553 20339 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:37:49.492560 20339 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:37:49.492569 20339 net.cpp:124] Setting up relu3\n",
      "I0430 12:37:49.492575 20339 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:37:49.492579 20339 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:37:49.492583 20339 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:37:49.492590 20339 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:37:49.492594 20339 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:37:49.492600 20339 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:37:49.493569 20339 net.cpp:124] Setting up conv4\n",
      "I0430 12:37:49.493590 20339 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:37:49.493595 20339 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:37:49.493603 20339 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:37:49.493614 20339 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:37:49.493619 20339 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:37:49.493626 20339 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:37:49.493634 20339 net.cpp:124] Setting up relu4\n",
      "I0430 12:37:49.493639 20339 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:37:49.493643 20339 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:37:49.493646 20339 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:37:49.493654 20339 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:37:49.493659 20339 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:37:49.493664 20339 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:37:49.494349 20339 net.cpp:124] Setting up conv5\n",
      "I0430 12:37:49.494361 20339 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:37:49.494366 20339 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:37:49.494379 20339 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:37:49.494385 20339 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:37:49.494390 20339 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:37:49.494395 20339 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:37:49.494402 20339 net.cpp:124] Setting up relu5\n",
      "I0430 12:37:49.494408 20339 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:37:49.494411 20339 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:37:49.494415 20339 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:37:49.494422 20339 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:37:49.494426 20339 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:37:49.494432 20339 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:37:49.494442 20339 net.cpp:124] Setting up pool5\n",
      "I0430 12:37:49.494448 20339 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:37:49.494452 20339 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:37:49.494455 20339 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:37:49.494464 20339 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:37:49.494468 20339 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:37:49.494475 20339 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:37:49.521905 20339 net.cpp:124] Setting up fc6\n",
      "I0430 12:37:49.521939 20339 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:37:49.521945 20339 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:37:49.521956 20339 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:37:49.521966 20339 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:37:49.521970 20339 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:37:49.521977 20339 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:37:49.521987 20339 net.cpp:124] Setting up relu6\n",
      "I0430 12:37:49.521991 20339 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:37:49.521996 20339 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:37:49.521999 20339 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:37:49.522006 20339 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:37:49.522011 20339 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:37:49.522016 20339 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:37:49.522023 20339 net.cpp:124] Setting up drop6\n",
      "I0430 12:37:49.522028 20339 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:37:49.522032 20339 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:37:49.522035 20339 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:37:49.522042 20339 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:37:49.522047 20339 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:37:49.522052 20339 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:37:49.534715 20339 net.cpp:124] Setting up fc7\n",
      "I0430 12:37:49.534742 20339 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:37:49.534746 20339 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:37:49.534757 20339 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:37:49.534767 20339 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:37:49.534773 20339 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:37:49.534780 20339 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:37:49.534787 20339 net.cpp:124] Setting up relu7\n",
      "I0430 12:37:49.534792 20339 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:37:49.534796 20339 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:37:49.534801 20339 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:37:49.534806 20339 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:37:49.534811 20339 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:37:49.534816 20339 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:37:49.534824 20339 net.cpp:124] Setting up drop7\n",
      "I0430 12:37:49.534828 20339 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:37:49.534832 20339 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:37:49.534833 20339 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:37:49.534838 20339 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:37:49.534842 20339 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:37:49.534845 20339 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:37:49.535820 20339 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:37:49.535840 20339 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:37:49.535842 20339 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:37:49.535851 20339 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:37:49.535853 20339 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:37:49.535856 20339 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:37:49.535857 20339 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:37:49.535859 20339 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:37:49.535861 20339 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:37:49.535864 20339 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:37:49.535866 20339 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:37:49.535868 20339 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:37:49.535871 20339 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:37:49.535872 20339 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:37:49.535874 20339 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:37:49.535878 20339 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:37:49.535881 20339 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:37:49.535883 20339 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:37:49.535887 20339 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:37:49.535889 20339 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:37:49.535892 20339 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:37:49.535895 20339 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:37:49.535898 20339 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:37:49.535902 20339 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:37:49.535904 20339 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:37:49.535907 20339 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:37:49.535909 20339 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:37:49.535920 20339 net.cpp:257] Network initialization done.\n",
      "I0430 12:37:49.632762 20339 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:37:49.737054 20339 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:37:49.738045 20339 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:37:49.738060 20339 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:37:49.738066 20339 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/497094.jpg'}, '/tmp/tmpCXTL8F.mat')\n",
      "Processed 1894 windows in 218.562 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-1.7783, -2.3618, -2.42888, -2.19743, -2.3215...\n",
      "ymin                                                         73\n",
      "xmin                                                        230\n",
      "ymax                                                        333\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/bird/497094.jpg, dtype: object\n",
      "prediction    [-2.10169, -2.28873, -2.03076, -2.22832, -2.16...\n",
      "ymin                                                         63\n",
      "xmin                                                          0\n",
      "ymax                                                        333\n",
      "xmax                                                        293\n",
      "Name: /home/ambika/INF_project/data/bird/497094.jpg, dtype: object\n",
      "whale\n",
      "230\t73\t500\t333\n",
      "bird\n",
      "0\t63\t293\t333\n",
      "497094\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:41:29.749886 20578 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:41:29.749908 20578 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:41:29.749912 20578 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:41:29.751073 20578 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:41:29.751276 20578 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:41:29.751289 20578 net.cpp:86] Creating Layer data\n",
      "I0430 12:41:29.751293 20578 net.cpp:382] data -> data\n",
      "I0430 12:41:29.751307 20578 net.cpp:124] Setting up data\n",
      "I0430 12:41:29.751314 20578 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:41:29.751317 20578 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:41:29.751320 20578 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:41:29.751327 20578 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:41:29.751330 20578 net.cpp:408] conv1 <- data\n",
      "I0430 12:41:29.751335 20578 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:41:29.751395 20578 net.cpp:124] Setting up conv1\n",
      "I0430 12:41:29.751400 20578 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:41:29.751404 20578 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:41:29.751412 20578 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:41:29.751420 20578 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:41:29.751423 20578 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:41:29.751430 20578 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:41:29.751435 20578 net.cpp:124] Setting up relu1\n",
      "I0430 12:41:29.751441 20578 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:41:29.751444 20578 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:41:29.751447 20578 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:41:29.751453 20578 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:41:29.751458 20578 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:41:29.751462 20578 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:41:29.751471 20578 net.cpp:124] Setting up pool1\n",
      "I0430 12:41:29.751476 20578 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:41:29.751477 20578 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:41:29.751480 20578 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:41:29.751487 20578 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:41:29.751488 20578 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:41:29.751493 20578 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:41:29.751499 20578 net.cpp:124] Setting up norm1\n",
      "I0430 12:41:29.751503 20578 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:41:29.751505 20578 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:41:29.751508 20578 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:41:29.751513 20578 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:41:29.751516 20578 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:41:29.751520 20578 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:41:29.751878 20578 net.cpp:124] Setting up conv2\n",
      "I0430 12:41:29.751886 20578 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:41:29.751890 20578 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:41:29.751899 20578 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:41:29.751904 20578 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:41:29.751907 20578 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:41:29.751911 20578 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:41:29.751916 20578 net.cpp:124] Setting up relu2\n",
      "I0430 12:41:29.751920 20578 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:41:29.751924 20578 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:41:29.751926 20578 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:41:29.751932 20578 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:41:29.751935 20578 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:41:29.751940 20578 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:41:29.751945 20578 net.cpp:124] Setting up pool2\n",
      "I0430 12:41:29.751950 20578 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:41:29.751952 20578 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:41:29.751955 20578 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:41:29.751960 20578 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:41:29.751962 20578 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:41:29.751967 20578 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:41:29.751972 20578 net.cpp:124] Setting up norm2\n",
      "I0430 12:41:29.751976 20578 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:41:29.751979 20578 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:41:29.751981 20578 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:41:29.751988 20578 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:41:29.751991 20578 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:41:29.751996 20578 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:41:29.752693 20578 net.cpp:124] Setting up conv3\n",
      "I0430 12:41:29.752706 20578 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:41:29.752709 20578 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:41:29.752718 20578 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:41:29.752724 20578 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:41:29.752728 20578 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:41:29.752733 20578 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:41:29.752739 20578 net.cpp:124] Setting up relu3\n",
      "I0430 12:41:29.752743 20578 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:41:29.752746 20578 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:41:29.752749 20578 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:41:29.752755 20578 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:41:29.752758 20578 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:41:29.752763 20578 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:41:29.753509 20578 net.cpp:124] Setting up conv4\n",
      "I0430 12:41:29.753520 20578 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:41:29.753523 20578 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:41:29.753530 20578 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:41:29.753538 20578 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:41:29.753541 20578 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:41:29.753546 20578 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:41:29.753551 20578 net.cpp:124] Setting up relu4\n",
      "I0430 12:41:29.753556 20578 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:41:29.753558 20578 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:41:29.753561 20578 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:41:29.753567 20578 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:41:29.753571 20578 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:41:29.753576 20578 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:41:29.754070 20578 net.cpp:124] Setting up conv5\n",
      "I0430 12:41:29.754078 20578 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:41:29.754082 20578 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:41:29.754092 20578 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:41:29.754099 20578 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:41:29.754102 20578 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:41:29.754107 20578 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:41:29.754112 20578 net.cpp:124] Setting up relu5\n",
      "I0430 12:41:29.754117 20578 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:41:29.754118 20578 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:41:29.754122 20578 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:41:29.754127 20578 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:41:29.754128 20578 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:41:29.754134 20578 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:41:29.754142 20578 net.cpp:124] Setting up pool5\n",
      "I0430 12:41:29.754145 20578 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:41:29.754148 20578 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:41:29.754150 20578 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:41:29.754158 20578 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:41:29.754160 20578 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:41:29.754165 20578 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:41:29.775635 20578 net.cpp:124] Setting up fc6\n",
      "I0430 12:41:29.775661 20578 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:41:29.775671 20578 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:41:29.775682 20578 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:41:29.775696 20578 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:41:29.775701 20578 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:41:29.775709 20578 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:41:29.775720 20578 net.cpp:124] Setting up relu6\n",
      "I0430 12:41:29.775727 20578 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:41:29.775730 20578 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:41:29.775734 20578 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:41:29.775740 20578 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:41:29.775743 20578 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:41:29.775748 20578 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:41:29.775753 20578 net.cpp:124] Setting up drop6\n",
      "I0430 12:41:29.775758 20578 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:41:29.775760 20578 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:41:29.775763 20578 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:41:29.775770 20578 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:41:29.775773 20578 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:41:29.775777 20578 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:41:29.787837 20578 net.cpp:124] Setting up fc7\n",
      "I0430 12:41:29.787859 20578 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:41:29.787864 20578 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:41:29.787875 20578 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:41:29.787884 20578 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:41:29.787889 20578 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:41:29.787894 20578 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:41:29.787902 20578 net.cpp:124] Setting up relu7\n",
      "I0430 12:41:29.787907 20578 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:41:29.787909 20578 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:41:29.787914 20578 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:41:29.787920 20578 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:41:29.787930 20578 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:41:29.787935 20578 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:41:29.787940 20578 net.cpp:124] Setting up drop7\n",
      "I0430 12:41:29.787945 20578 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:41:29.787947 20578 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:41:29.787950 20578 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:41:29.787956 20578 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:41:29.787959 20578 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:41:29.787964 20578 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:41:29.788607 20578 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:41:29.788617 20578 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:41:29.788621 20578 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:41:29.788630 20578 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:41:29.788635 20578 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:41:29.788637 20578 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:41:29.788641 20578 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:41:29.788645 20578 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:41:29.788648 20578 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:41:29.788651 20578 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:41:29.788655 20578 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:41:29.788658 20578 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:41:29.788661 20578 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:41:29.788664 20578 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:41:29.788668 20578 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:41:29.788671 20578 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:41:29.788674 20578 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:41:29.788678 20578 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:41:29.788681 20578 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:41:29.788684 20578 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:41:29.788687 20578 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:41:29.788691 20578 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:41:29.788694 20578 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:41:29.788698 20578 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:41:29.788702 20578 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:41:29.788704 20578 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:41:29.788707 20578 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:41:29.788718 20578 net.cpp:257] Network initialization done.\n",
      "I0430 12:41:29.869882 20578 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:41:29.962146 20578 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:41:29.963160 20578 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:41:29.963170 20578 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:41:29.963173 20578 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/182176.jpg'}, '/tmp/tmpt4Lns5.mat')\n",
      "Processed 2042 windows in 227.108 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-1.69042, -2.24752, -1.6829, -1.82436, -1.917...\n",
      "ymin                                                        141\n",
      "xmin                                                        185\n",
      "ymax                                                        233\n",
      "xmax                                                        335\n",
      "Name: /home/ambika/INF_project/data/bus/182176.jpg, dtype: object\n",
      "prediction    [-1.90316, -2.02443, -1.60424, -1.7305, -1.699...\n",
      "ymin                                                        201\n",
      "xmin                                                         16\n",
      "ymax                                                        254\n",
      "xmax                                                         73\n",
      "Name: /home/ambika/INF_project/data/bus/182176.jpg, dtype: object\n",
      "bus\n",
      "185\t141\t335\t233\n",
      "car\n",
      "16\t201\t73\t254\n",
      "182176\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:45:18.660620 20762 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:45:18.660645 20762 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:45:18.660647 20762 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:45:18.661788 20762 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:45:18.661923 20762 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:45:18.661934 20762 net.cpp:86] Creating Layer data\n",
      "I0430 12:45:18.661938 20762 net.cpp:382] data -> data\n",
      "I0430 12:45:18.661952 20762 net.cpp:124] Setting up data\n",
      "I0430 12:45:18.661955 20762 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:45:18.661958 20762 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:45:18.661962 20762 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:45:18.661967 20762 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:45:18.661970 20762 net.cpp:408] conv1 <- data\n",
      "I0430 12:45:18.661976 20762 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:45:18.662045 20762 net.cpp:124] Setting up conv1\n",
      "I0430 12:45:18.662050 20762 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:45:18.662053 20762 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:45:18.662072 20762 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:45:18.662077 20762 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:45:18.662081 20762 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:45:18.662083 20762 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:45:18.662088 20762 net.cpp:124] Setting up relu1\n",
      "I0430 12:45:18.662091 20762 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:45:18.662093 20762 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:45:18.662096 20762 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:45:18.662101 20762 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:45:18.662102 20762 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:45:18.662106 20762 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:45:18.662111 20762 net.cpp:124] Setting up pool1\n",
      "I0430 12:45:18.662116 20762 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:45:18.662117 20762 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:45:18.662119 20762 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:45:18.662124 20762 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:45:18.662127 20762 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:45:18.662129 20762 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:45:18.662134 20762 net.cpp:124] Setting up norm1\n",
      "I0430 12:45:18.662137 20762 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:45:18.662140 20762 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:45:18.662142 20762 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:45:18.662147 20762 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:45:18.662148 20762 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:45:18.662151 20762 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:45:18.662508 20762 net.cpp:124] Setting up conv2\n",
      "I0430 12:45:18.662515 20762 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:45:18.662518 20762 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:45:18.662524 20762 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:45:18.662531 20762 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:45:18.662536 20762 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:45:18.662541 20762 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:45:18.662547 20762 net.cpp:124] Setting up relu2\n",
      "I0430 12:45:18.662552 20762 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:45:18.662555 20762 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:45:18.662557 20762 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:45:18.662561 20762 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:45:18.662564 20762 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:45:18.662567 20762 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:45:18.662572 20762 net.cpp:124] Setting up pool2\n",
      "I0430 12:45:18.662576 20762 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:45:18.662578 20762 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:45:18.662580 20762 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:45:18.662586 20762 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:45:18.662590 20762 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:45:18.662592 20762 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:45:18.662597 20762 net.cpp:124] Setting up norm2\n",
      "I0430 12:45:18.662600 20762 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:45:18.662602 20762 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:45:18.662605 20762 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:45:18.662609 20762 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:45:18.662611 20762 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:45:18.662614 20762 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:45:18.663394 20762 net.cpp:124] Setting up conv3\n",
      "I0430 12:45:18.663415 20762 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:45:18.663419 20762 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:45:18.663434 20762 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:45:18.663444 20762 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:45:18.663449 20762 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:45:18.663455 20762 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:45:18.663463 20762 net.cpp:124] Setting up relu3\n",
      "I0430 12:45:18.663468 20762 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:45:18.663471 20762 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:45:18.663492 20762 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:45:18.663502 20762 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:45:18.663506 20762 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:45:18.663511 20762 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:45:18.664353 20762 net.cpp:124] Setting up conv4\n",
      "I0430 12:45:18.664368 20762 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:45:18.664372 20762 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:45:18.664378 20762 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:45:18.664384 20762 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:45:18.664386 20762 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:45:18.664391 20762 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:45:18.664397 20762 net.cpp:124] Setting up relu4\n",
      "I0430 12:45:18.664399 20762 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:45:18.664402 20762 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:45:18.664404 20762 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:45:18.664410 20762 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:45:18.664413 20762 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:45:18.664417 20762 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:45:18.664932 20762 net.cpp:124] Setting up conv5\n",
      "I0430 12:45:18.664937 20762 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:45:18.664940 20762 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:45:18.664947 20762 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:45:18.664950 20762 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:45:18.664953 20762 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:45:18.664957 20762 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:45:18.664960 20762 net.cpp:124] Setting up relu5\n",
      "I0430 12:45:18.664963 20762 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:45:18.664965 20762 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:45:18.664968 20762 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:45:18.664973 20762 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:45:18.664975 20762 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:45:18.664978 20762 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:45:18.664985 20762 net.cpp:124] Setting up pool5\n",
      "I0430 12:45:18.664988 20762 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:45:18.664990 20762 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:45:18.664994 20762 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:45:18.665000 20762 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:45:18.665005 20762 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:45:18.665009 20762 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:45:18.687584 20762 net.cpp:124] Setting up fc6\n",
      "I0430 12:45:18.687607 20762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:45:18.687611 20762 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:45:18.687621 20762 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:45:18.687629 20762 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:45:18.687631 20762 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:45:18.687638 20762 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:45:18.687644 20762 net.cpp:124] Setting up relu6\n",
      "I0430 12:45:18.687645 20762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:45:18.687647 20762 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:45:18.687650 20762 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:45:18.687654 20762 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:45:18.687655 20762 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:45:18.687657 20762 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:45:18.687674 20762 net.cpp:124] Setting up drop6\n",
      "I0430 12:45:18.687677 20762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:45:18.687680 20762 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:45:18.687682 20762 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:45:18.687686 20762 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:45:18.687688 20762 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:45:18.687691 20762 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:45:18.697821 20762 net.cpp:124] Setting up fc7\n",
      "I0430 12:45:18.697842 20762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:45:18.697846 20762 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:45:18.697855 20762 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:45:18.697865 20762 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:45:18.697867 20762 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:45:18.697871 20762 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:45:18.697877 20762 net.cpp:124] Setting up relu7\n",
      "I0430 12:45:18.697880 20762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:45:18.697881 20762 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:45:18.697883 20762 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:45:18.697887 20762 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:45:18.697890 20762 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:45:18.697892 20762 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:45:18.697896 20762 net.cpp:124] Setting up drop7\n",
      "I0430 12:45:18.697908 20762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:45:18.697911 20762 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:45:18.697913 20762 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:45:18.697917 20762 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:45:18.697919 20762 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:45:18.697922 20762 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:45:18.698896 20762 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:45:18.698909 20762 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:45:18.698911 20762 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:45:18.698918 20762 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:45:18.698921 20762 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:45:18.698922 20762 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:45:18.698925 20762 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:45:18.698926 20762 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:45:18.698928 20762 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:45:18.698930 20762 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:45:18.698933 20762 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:45:18.698936 20762 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:45:18.698940 20762 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:45:18.698941 20762 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:45:18.698945 20762 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:45:18.698948 20762 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:45:18.698951 20762 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:45:18.698954 20762 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:45:18.698957 20762 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:45:18.698959 20762 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:45:18.698962 20762 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:45:18.698966 20762 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:45:18.698968 20762 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:45:18.698971 20762 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:45:18.698972 20762 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:45:18.698976 20762 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:45:18.698977 20762 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:45:18.698987 20762 net.cpp:257] Network initialization done.\n",
      "I0430 12:45:18.788866 20762 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:45:18.883195 20762 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:45:18.884414 20762 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:45:18.884428 20762 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:45:18.884434 20762 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/574706.jpg'}, '/tmp/tmpFvBmTJ.mat')\n",
      "Processed 1726 windows in 195.225 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.06258, -1.88325, -1.57456, -1.12655, -1.76...\n",
      "ymin                                                          0\n",
      "xmin                                                        213\n",
      "ymax                                                        309\n",
      "xmax                                                        326\n",
      "Name: /home/ambika/INF_project/data/car/574706.jpg, dtype: object\n",
      "prediction    [-1.70878, -2.06447, -1.80306, -2.35513, -1.73...\n",
      "ymin                                                        166\n",
      "xmin                                                        150\n",
      "ymax                                                        308\n",
      "xmax                                                        313\n",
      "Name: /home/ambika/INF_project/data/car/574706.jpg, dtype: object\n",
      "person\n",
      "213\t0\t326\t309\n",
      "dog\n",
      "150\t166\t313\t308\n",
      "574706\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:48:35.556772 20922 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:48:35.556799 20922 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:48:35.556802 20922 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:48:35.557977 20922 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:48:35.558146 20922 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:48:35.558153 20922 net.cpp:86] Creating Layer data\n",
      "I0430 12:48:35.558156 20922 net.cpp:382] data -> data\n",
      "I0430 12:48:35.558166 20922 net.cpp:124] Setting up data\n",
      "I0430 12:48:35.558171 20922 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:48:35.558173 20922 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:48:35.558176 20922 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:48:35.558182 20922 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:48:35.558184 20922 net.cpp:408] conv1 <- data\n",
      "I0430 12:48:35.558187 20922 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:48:35.558239 20922 net.cpp:124] Setting up conv1\n",
      "I0430 12:48:35.558244 20922 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:48:35.558246 20922 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:48:35.558254 20922 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:48:35.558257 20922 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:48:35.558260 20922 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:48:35.558264 20922 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:48:35.558267 20922 net.cpp:124] Setting up relu1\n",
      "I0430 12:48:35.558270 20922 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:48:35.558274 20922 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:48:35.558275 20922 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:48:35.558279 20922 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:48:35.558281 20922 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:48:35.558284 20922 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:48:35.558290 20922 net.cpp:124] Setting up pool1\n",
      "I0430 12:48:35.558293 20922 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:48:35.558296 20922 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:48:35.558298 20922 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:48:35.558305 20922 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:48:35.558306 20922 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:48:35.558310 20922 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:48:35.558315 20922 net.cpp:124] Setting up norm1\n",
      "I0430 12:48:35.558318 20922 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:48:35.558320 20922 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:48:35.558322 20922 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:48:35.558326 20922 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:48:35.558328 20922 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:48:35.558332 20922 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:48:35.558675 20922 net.cpp:124] Setting up conv2\n",
      "I0430 12:48:35.558679 20922 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:48:35.558681 20922 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:48:35.558686 20922 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:48:35.558691 20922 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:48:35.558693 20922 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:48:35.558696 20922 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:48:35.558699 20922 net.cpp:124] Setting up relu2\n",
      "I0430 12:48:35.558702 20922 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:48:35.558706 20922 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:48:35.558707 20922 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:48:35.558712 20922 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:48:35.558713 20922 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:48:35.558717 20922 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:48:35.558722 20922 net.cpp:124] Setting up pool2\n",
      "I0430 12:48:35.558725 20922 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:48:35.558727 20922 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:48:35.558729 20922 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:48:35.558733 20922 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:48:35.558737 20922 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:48:35.558738 20922 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:48:35.558743 20922 net.cpp:124] Setting up norm2\n",
      "I0430 12:48:35.558744 20922 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:48:35.558746 20922 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:48:35.558748 20922 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:48:35.558751 20922 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:48:35.558753 20922 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:48:35.558756 20922 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:48:35.559445 20922 net.cpp:124] Setting up conv3\n",
      "I0430 12:48:35.559455 20922 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:48:35.559459 20922 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:48:35.559466 20922 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:48:35.559471 20922 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:48:35.559473 20922 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:48:35.559478 20922 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:48:35.559483 20922 net.cpp:124] Setting up relu3\n",
      "I0430 12:48:35.559485 20922 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:48:35.559487 20922 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:48:35.559490 20922 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:48:35.559495 20922 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:48:35.559497 20922 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:48:35.559500 20922 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:48:35.560235 20922 net.cpp:124] Setting up conv4\n",
      "I0430 12:48:35.560243 20922 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:48:35.560245 20922 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:48:35.560250 20922 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:48:35.560255 20922 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:48:35.560257 20922 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:48:35.560261 20922 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:48:35.560264 20922 net.cpp:124] Setting up relu4\n",
      "I0430 12:48:35.560267 20922 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:48:35.560271 20922 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:48:35.560272 20922 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:48:35.560276 20922 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:48:35.560279 20922 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:48:35.560282 20922 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:48:35.560763 20922 net.cpp:124] Setting up conv5\n",
      "I0430 12:48:35.560770 20922 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:48:35.560772 20922 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:48:35.560780 20922 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:48:35.560782 20922 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:48:35.560786 20922 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:48:35.560789 20922 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:48:35.560793 20922 net.cpp:124] Setting up relu5\n",
      "I0430 12:48:35.560796 20922 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:48:35.560798 20922 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:48:35.560801 20922 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:48:35.560804 20922 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:48:35.560806 20922 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:48:35.560811 20922 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:48:35.560817 20922 net.cpp:124] Setting up pool5\n",
      "I0430 12:48:35.560819 20922 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:48:35.560822 20922 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:48:35.560824 20922 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:48:35.560832 20922 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:48:35.560833 20922 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:48:35.560837 20922 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:48:35.582051 20922 net.cpp:124] Setting up fc6\n",
      "I0430 12:48:35.582073 20922 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:48:35.582075 20922 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:48:35.582087 20922 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:48:35.582108 20922 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:48:35.582113 20922 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:48:35.582119 20922 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:48:35.582141 20922 net.cpp:124] Setting up relu6\n",
      "I0430 12:48:35.582147 20922 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:48:35.582151 20922 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:48:35.582155 20922 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:48:35.582164 20922 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:48:35.582166 20922 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:48:35.582170 20922 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:48:35.582176 20922 net.cpp:124] Setting up drop6\n",
      "I0430 12:48:35.582180 20922 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:48:35.582182 20922 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:48:35.582185 20922 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:48:35.582190 20922 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:48:35.582193 20922 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:48:35.582200 20922 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:48:35.592756 20922 net.cpp:124] Setting up fc7\n",
      "I0430 12:48:35.592779 20922 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:48:35.592782 20922 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:48:35.592792 20922 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:48:35.592803 20922 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:48:35.592808 20922 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:48:35.592814 20922 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:48:35.592823 20922 net.cpp:124] Setting up relu7\n",
      "I0430 12:48:35.592826 20922 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:48:35.592829 20922 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:48:35.592833 20922 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:48:35.592839 20922 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:48:35.592840 20922 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:48:35.592845 20922 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:48:35.592852 20922 net.cpp:124] Setting up drop7\n",
      "I0430 12:48:35.592855 20922 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:48:35.592857 20922 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:48:35.592860 20922 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:48:35.592866 20922 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:48:35.592869 20922 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:48:35.592872 20922 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:48:35.593859 20922 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:48:35.593875 20922 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:48:35.593878 20922 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:48:35.593888 20922 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:48:35.593891 20922 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:48:35.593894 20922 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:48:35.593896 20922 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:48:35.593901 20922 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:48:35.593904 20922 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:48:35.593907 20922 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:48:35.593910 20922 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:48:35.593914 20922 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:48:35.593916 20922 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:48:35.593920 20922 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:48:35.593924 20922 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:48:35.593926 20922 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:48:35.593930 20922 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:48:35.593932 20922 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:48:35.593935 20922 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:48:35.593938 20922 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:48:35.593941 20922 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:48:35.593945 20922 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:48:35.593948 20922 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:48:35.593951 20922 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:48:35.593955 20922 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:48:35.593957 20922 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:48:35.593961 20922 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:48:35.593971 20922 net.cpp:257] Network initialization done.\n",
      "I0430 12:48:35.674212 20922 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:48:35.765673 20922 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:48:35.766604 20922 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:48:35.766613 20922 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:48:35.766616 20922 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/51746.jpg'}, '/tmp/tmpaeLVxH.mat')\n",
      "Processed 2156 windows in 238.098 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.68234, -2.95554, -2.56451, -2.36035, -2.46...\n",
      "ymin                                                         12\n",
      "xmin                                                        302\n",
      "ymax                                                        292\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/cat/51746.jpg, dtype: object\n",
      "prediction    [-2.14464, -1.91601, -2.47036, -1.90695, -2.01...\n",
      "ymin                                                         84\n",
      "xmin                                                        372\n",
      "ymax                                                        159\n",
      "xmax                                                        467\n",
      "Name: /home/ambika/INF_project/data/cat/51746.jpg, dtype: object\n",
      "bookshelf\n",
      "302\t12\t500\t292\n",
      "tv or monitor\n",
      "372\t84\t467\t159\n",
      "51746\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:52:35.304762 21095 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:52:35.304781 21095 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:52:35.304783 21095 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:52:35.305877 21095 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:52:35.305965 21095 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:52:35.305975 21095 net.cpp:86] Creating Layer data\n",
      "I0430 12:52:35.305979 21095 net.cpp:382] data -> data\n",
      "I0430 12:52:35.305991 21095 net.cpp:124] Setting up data\n",
      "I0430 12:52:35.305996 21095 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:52:35.305999 21095 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:52:35.306002 21095 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:52:35.306008 21095 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:52:35.306010 21095 net.cpp:408] conv1 <- data\n",
      "I0430 12:52:35.306015 21095 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:52:35.306073 21095 net.cpp:124] Setting up conv1\n",
      "I0430 12:52:35.306077 21095 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:52:35.306080 21095 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:52:35.306087 21095 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:52:35.306092 21095 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:52:35.306094 21095 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:52:35.306097 21095 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:52:35.306103 21095 net.cpp:124] Setting up relu1\n",
      "I0430 12:52:35.306107 21095 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:52:35.306109 21095 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:52:35.306112 21095 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:52:35.306116 21095 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:52:35.306118 21095 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:52:35.306121 21095 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:52:35.306128 21095 net.cpp:124] Setting up pool1\n",
      "I0430 12:52:35.306131 21095 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:52:35.306134 21095 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:52:35.306136 21095 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:52:35.306141 21095 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:52:35.306143 21095 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:52:35.306147 21095 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:52:35.306152 21095 net.cpp:124] Setting up norm1\n",
      "I0430 12:52:35.306155 21095 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:52:35.306159 21095 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:52:35.306160 21095 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:52:35.306164 21095 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:52:35.306167 21095 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:52:35.306170 21095 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:52:35.306510 21095 net.cpp:124] Setting up conv2\n",
      "I0430 12:52:35.306515 21095 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:52:35.306519 21095 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:52:35.306524 21095 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:52:35.306529 21095 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:52:35.306530 21095 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:52:35.306535 21095 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:52:35.306540 21095 net.cpp:124] Setting up relu2\n",
      "I0430 12:52:35.306545 21095 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:52:35.306546 21095 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:52:35.306548 21095 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:52:35.306553 21095 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:52:35.306555 21095 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:52:35.306558 21095 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:52:35.306565 21095 net.cpp:124] Setting up pool2\n",
      "I0430 12:52:35.306567 21095 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:52:35.306569 21095 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:52:35.306571 21095 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:52:35.306576 21095 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:52:35.306578 21095 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:52:35.306581 21095 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:52:35.306586 21095 net.cpp:124] Setting up norm2\n",
      "I0430 12:52:35.306589 21095 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:52:35.306591 21095 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:52:35.306593 21095 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:52:35.306598 21095 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:52:35.306601 21095 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:52:35.306604 21095 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:52:35.307303 21095 net.cpp:124] Setting up conv3\n",
      "I0430 12:52:35.307313 21095 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:52:35.307317 21095 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:52:35.307324 21095 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:52:35.307332 21095 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:52:35.307334 21095 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:52:35.307338 21095 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:52:35.307343 21095 net.cpp:124] Setting up relu3\n",
      "I0430 12:52:35.307346 21095 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:52:35.307348 21095 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:52:35.307350 21095 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:52:35.307354 21095 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:52:35.307358 21095 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:52:35.307360 21095 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:52:35.308085 21095 net.cpp:124] Setting up conv4\n",
      "I0430 12:52:35.308094 21095 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:52:35.308097 21095 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:52:35.308102 21095 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:52:35.308107 21095 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:52:35.308110 21095 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:52:35.308115 21095 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:52:35.308118 21095 net.cpp:124] Setting up relu4\n",
      "I0430 12:52:35.308121 21095 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:52:35.308125 21095 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:52:35.308126 21095 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:52:35.308131 21095 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:52:35.308135 21095 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:52:35.308137 21095 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:52:35.308635 21095 net.cpp:124] Setting up conv5\n",
      "I0430 12:52:35.308641 21095 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:52:35.308645 21095 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:52:35.308653 21095 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:52:35.308657 21095 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:52:35.308660 21095 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:52:35.308665 21095 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:52:35.308668 21095 net.cpp:124] Setting up relu5\n",
      "I0430 12:52:35.308672 21095 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:52:35.308675 21095 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:52:35.308676 21095 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:52:35.308681 21095 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:52:35.308682 21095 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:52:35.308686 21095 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:52:35.308692 21095 net.cpp:124] Setting up pool5\n",
      "I0430 12:52:35.308696 21095 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:52:35.308698 21095 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:52:35.308701 21095 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:52:35.308706 21095 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:52:35.308709 21095 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:52:35.308712 21095 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:52:35.329833 21095 net.cpp:124] Setting up fc6\n",
      "I0430 12:52:35.329856 21095 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:52:35.329862 21095 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:52:35.329872 21095 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:52:35.329881 21095 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:52:35.329885 21095 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:52:35.329890 21095 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:52:35.329897 21095 net.cpp:124] Setting up relu6\n",
      "I0430 12:52:35.329900 21095 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:52:35.329903 21095 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:52:35.329905 21095 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:52:35.329910 21095 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:52:35.329912 21095 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:52:35.329916 21095 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:52:35.329921 21095 net.cpp:124] Setting up drop6\n",
      "I0430 12:52:35.329923 21095 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:52:35.329926 21095 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:52:35.329928 21095 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:52:35.329932 21095 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:52:35.329934 21095 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:52:35.329939 21095 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:52:35.339583 21095 net.cpp:124] Setting up fc7\n",
      "I0430 12:52:35.339602 21095 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:52:35.339606 21095 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:52:35.339612 21095 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:52:35.339618 21095 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:52:35.339622 21095 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:52:35.339627 21095 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:52:35.339632 21095 net.cpp:124] Setting up relu7\n",
      "I0430 12:52:35.339635 21095 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:52:35.339637 21095 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:52:35.339640 21095 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:52:35.339644 21095 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:52:35.339646 21095 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:52:35.339653 21095 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:52:35.339658 21095 net.cpp:124] Setting up drop7\n",
      "I0430 12:52:35.339660 21095 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:52:35.339663 21095 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:52:35.339665 21095 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:52:35.339669 21095 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:52:35.339671 21095 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:52:35.339674 21095 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:52:35.340286 21095 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:52:35.340301 21095 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:52:35.340303 21095 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:52:35.340311 21095 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:52:35.340319 21095 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:52:35.340323 21095 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:52:35.340327 21095 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:52:35.340330 21095 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:52:35.340333 21095 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:52:35.340337 21095 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:52:35.340340 21095 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:52:35.340344 21095 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:52:35.340351 21095 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:52:35.340358 21095 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:52:35.340361 21095 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:52:35.340364 21095 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:52:35.340369 21095 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:52:35.340373 21095 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:52:35.340378 21095 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:52:35.340381 21095 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:52:35.340384 21095 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:52:35.340387 21095 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:52:35.340390 21095 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:52:35.340394 21095 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:52:35.340396 21095 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:52:35.340399 21095 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:52:35.340401 21095 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:52:35.340411 21095 net.cpp:257] Network initialization done.\n",
      "I0430 12:52:35.418695 21095 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:52:35.509886 21095 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:52:35.510819 21095 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:52:35.510826 21095 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:52:35.510828 21095 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/92985.jpg'}, '/tmp/tmpXpqqlR.mat')\n",
      "Processed 1491 windows in 170.049 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.027 s.\n",
      "prediction    [-2.78091, -2.21898, -2.18382, -1.97822, -2.28...\n",
      "ymin                                                         48\n",
      "xmin                                                        147\n",
      "ymax                                                        319\n",
      "xmax                                                        332\n",
      "Name: /home/ambika/INF_project/data/couch/92985.jpg, dtype: object\n",
      "prediction    [-2.3837, -1.71528, -2.24794, -2.08032, -2.461...\n",
      "ymin                                                          0\n",
      "xmin                                                        372\n",
      "ymax                                                        150\n",
      "xmax                                                        463\n",
      "Name: /home/ambika/INF_project/data/couch/92985.jpg, dtype: object\n",
      "person\n",
      "147\t48\t332\t319\n",
      "tv or monitor\n",
      "372\t0\t463\t150\n",
      "92985\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 12:55:27.019460 21259 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 12:55:27.019503 21259 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 12:55:27.019507 21259 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 12:55:27.020637 21259 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 12:55:27.020766 21259 layer_factory.hpp:77] Creating layer data\n",
      "I0430 12:55:27.020773 21259 net.cpp:86] Creating Layer data\n",
      "I0430 12:55:27.020781 21259 net.cpp:382] data -> data\n",
      "I0430 12:55:27.020795 21259 net.cpp:124] Setting up data\n",
      "I0430 12:55:27.020800 21259 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 12:55:27.020803 21259 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 12:55:27.020807 21259 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 12:55:27.020812 21259 net.cpp:86] Creating Layer conv1\n",
      "I0430 12:55:27.020814 21259 net.cpp:408] conv1 <- data\n",
      "I0430 12:55:27.020820 21259 net.cpp:382] conv1 -> conv1\n",
      "I0430 12:55:27.020889 21259 net.cpp:124] Setting up conv1\n",
      "I0430 12:55:27.020895 21259 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:55:27.020897 21259 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 12:55:27.020905 21259 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 12:55:27.020910 21259 net.cpp:86] Creating Layer relu1\n",
      "I0430 12:55:27.020912 21259 net.cpp:408] relu1 <- conv1\n",
      "I0430 12:55:27.020915 21259 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 12:55:27.020920 21259 net.cpp:124] Setting up relu1\n",
      "I0430 12:55:27.020923 21259 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 12:55:27.020925 21259 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 12:55:27.020928 21259 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 12:55:27.020931 21259 net.cpp:86] Creating Layer pool1\n",
      "I0430 12:55:27.020934 21259 net.cpp:408] pool1 <- conv1\n",
      "I0430 12:55:27.020937 21259 net.cpp:382] pool1 -> pool1\n",
      "I0430 12:55:27.020943 21259 net.cpp:124] Setting up pool1\n",
      "I0430 12:55:27.020946 21259 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:55:27.020949 21259 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 12:55:27.020951 21259 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 12:55:27.020956 21259 net.cpp:86] Creating Layer norm1\n",
      "I0430 12:55:27.020957 21259 net.cpp:408] norm1 <- pool1\n",
      "I0430 12:55:27.020961 21259 net.cpp:382] norm1 -> norm1\n",
      "I0430 12:55:27.020967 21259 net.cpp:124] Setting up norm1\n",
      "I0430 12:55:27.020969 21259 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 12:55:27.020972 21259 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 12:55:27.020973 21259 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 12:55:27.020978 21259 net.cpp:86] Creating Layer conv2\n",
      "I0430 12:55:27.020982 21259 net.cpp:408] conv2 <- norm1\n",
      "I0430 12:55:27.020984 21259 net.cpp:382] conv2 -> conv2\n",
      "I0430 12:55:27.021348 21259 net.cpp:124] Setting up conv2\n",
      "I0430 12:55:27.021354 21259 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:55:27.021358 21259 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 12:55:27.021363 21259 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 12:55:27.021366 21259 net.cpp:86] Creating Layer relu2\n",
      "I0430 12:55:27.021369 21259 net.cpp:408] relu2 <- conv2\n",
      "I0430 12:55:27.021375 21259 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 12:55:27.021381 21259 net.cpp:124] Setting up relu2\n",
      "I0430 12:55:27.021386 21259 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 12:55:27.021389 21259 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 12:55:27.021394 21259 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 12:55:27.021400 21259 net.cpp:86] Creating Layer pool2\n",
      "I0430 12:55:27.021402 21259 net.cpp:408] pool2 <- conv2\n",
      "I0430 12:55:27.021406 21259 net.cpp:382] pool2 -> pool2\n",
      "I0430 12:55:27.021412 21259 net.cpp:124] Setting up pool2\n",
      "I0430 12:55:27.021415 21259 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:55:27.021419 21259 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 12:55:27.021420 21259 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 12:55:27.021426 21259 net.cpp:86] Creating Layer norm2\n",
      "I0430 12:55:27.021428 21259 net.cpp:408] norm2 <- pool2\n",
      "I0430 12:55:27.021431 21259 net.cpp:382] norm2 -> norm2\n",
      "I0430 12:55:27.021436 21259 net.cpp:124] Setting up norm2\n",
      "I0430 12:55:27.021440 21259 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:55:27.021442 21259 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 12:55:27.021445 21259 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 12:55:27.021448 21259 net.cpp:86] Creating Layer conv3\n",
      "I0430 12:55:27.021451 21259 net.cpp:408] conv3 <- norm2\n",
      "I0430 12:55:27.021455 21259 net.cpp:382] conv3 -> conv3\n",
      "I0430 12:55:27.022146 21259 net.cpp:124] Setting up conv3\n",
      "I0430 12:55:27.022167 21259 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:55:27.022171 21259 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 12:55:27.022181 21259 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 12:55:27.022189 21259 net.cpp:86] Creating Layer relu3\n",
      "I0430 12:55:27.022192 21259 net.cpp:408] relu3 <- conv3\n",
      "I0430 12:55:27.022197 21259 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 12:55:27.022202 21259 net.cpp:124] Setting up relu3\n",
      "I0430 12:55:27.022204 21259 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:55:27.022207 21259 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 12:55:27.022208 21259 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 12:55:27.022213 21259 net.cpp:86] Creating Layer conv4\n",
      "I0430 12:55:27.022215 21259 net.cpp:408] conv4 <- conv3\n",
      "I0430 12:55:27.022219 21259 net.cpp:382] conv4 -> conv4\n",
      "I0430 12:55:27.022953 21259 net.cpp:124] Setting up conv4\n",
      "I0430 12:55:27.022961 21259 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:55:27.022964 21259 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 12:55:27.022971 21259 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 12:55:27.022979 21259 net.cpp:86] Creating Layer relu4\n",
      "I0430 12:55:27.022982 21259 net.cpp:408] relu4 <- conv4\n",
      "I0430 12:55:27.022986 21259 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 12:55:27.022991 21259 net.cpp:124] Setting up relu4\n",
      "I0430 12:55:27.022994 21259 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 12:55:27.022996 21259 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 12:55:27.023000 21259 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 12:55:27.023003 21259 net.cpp:86] Creating Layer conv5\n",
      "I0430 12:55:27.023005 21259 net.cpp:408] conv5 <- conv4\n",
      "I0430 12:55:27.023010 21259 net.cpp:382] conv5 -> conv5\n",
      "I0430 12:55:27.023532 21259 net.cpp:124] Setting up conv5\n",
      "I0430 12:55:27.023540 21259 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:55:27.023542 21259 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 12:55:27.023553 21259 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 12:55:27.023560 21259 net.cpp:86] Creating Layer relu5\n",
      "I0430 12:55:27.023562 21259 net.cpp:408] relu5 <- conv5\n",
      "I0430 12:55:27.023566 21259 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 12:55:27.023571 21259 net.cpp:124] Setting up relu5\n",
      "I0430 12:55:27.023574 21259 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 12:55:27.023576 21259 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 12:55:27.023579 21259 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 12:55:27.023583 21259 net.cpp:86] Creating Layer pool5\n",
      "I0430 12:55:27.023586 21259 net.cpp:408] pool5 <- conv5\n",
      "I0430 12:55:27.023589 21259 net.cpp:382] pool5 -> pool5\n",
      "I0430 12:55:27.023596 21259 net.cpp:124] Setting up pool5\n",
      "I0430 12:55:27.023598 21259 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 12:55:27.023602 21259 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 12:55:27.023603 21259 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 12:55:27.023610 21259 net.cpp:86] Creating Layer fc6\n",
      "I0430 12:55:27.023612 21259 net.cpp:408] fc6 <- pool5\n",
      "I0430 12:55:27.023617 21259 net.cpp:382] fc6 -> fc6\n",
      "I0430 12:55:27.044981 21259 net.cpp:124] Setting up fc6\n",
      "I0430 12:55:27.045009 21259 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:55:27.045014 21259 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 12:55:27.045027 21259 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 12:55:27.045076 21259 net.cpp:86] Creating Layer relu6\n",
      "I0430 12:55:27.045080 21259 net.cpp:408] relu6 <- fc6\n",
      "I0430 12:55:27.045085 21259 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 12:55:27.045092 21259 net.cpp:124] Setting up relu6\n",
      "I0430 12:55:27.045094 21259 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:55:27.045096 21259 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 12:55:27.045099 21259 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 12:55:27.045104 21259 net.cpp:86] Creating Layer drop6\n",
      "I0430 12:55:27.045109 21259 net.cpp:408] drop6 <- fc6\n",
      "I0430 12:55:27.045111 21259 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 12:55:27.045116 21259 net.cpp:124] Setting up drop6\n",
      "I0430 12:55:27.045120 21259 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:55:27.045121 21259 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 12:55:27.045125 21259 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 12:55:27.045128 21259 net.cpp:86] Creating Layer fc7\n",
      "I0430 12:55:27.045130 21259 net.cpp:408] fc7 <- fc6\n",
      "I0430 12:55:27.045135 21259 net.cpp:382] fc7 -> fc7\n",
      "I0430 12:55:27.054898 21259 net.cpp:124] Setting up fc7\n",
      "I0430 12:55:27.054921 21259 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:55:27.054925 21259 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 12:55:27.054936 21259 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 12:55:27.054946 21259 net.cpp:86] Creating Layer relu7\n",
      "I0430 12:55:27.054951 21259 net.cpp:408] relu7 <- fc7\n",
      "I0430 12:55:27.054958 21259 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 12:55:27.054967 21259 net.cpp:124] Setting up relu7\n",
      "I0430 12:55:27.054972 21259 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:55:27.054975 21259 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 12:55:27.054980 21259 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 12:55:27.054986 21259 net.cpp:86] Creating Layer drop7\n",
      "I0430 12:55:27.054989 21259 net.cpp:408] drop7 <- fc7\n",
      "I0430 12:55:27.054996 21259 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 12:55:27.055002 21259 net.cpp:124] Setting up drop7\n",
      "I0430 12:55:27.055007 21259 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 12:55:27.055011 21259 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 12:55:27.055013 21259 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 12:55:27.055019 21259 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 12:55:27.055023 21259 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 12:55:27.055028 21259 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 12:55:27.055882 21259 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 12:55:27.055899 21259 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 12:55:27.055903 21259 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 12:55:27.055912 21259 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 12:55:27.055917 21259 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 12:55:27.055920 21259 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 12:55:27.055923 21259 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 12:55:27.055927 21259 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 12:55:27.055930 21259 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 12:55:27.055933 21259 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 12:55:27.055938 21259 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 12:55:27.055943 21259 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 12:55:27.055946 21259 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 12:55:27.055950 21259 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 12:55:27.055953 21259 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 12:55:27.055958 21259 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 12:55:27.055961 21259 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 12:55:27.055964 21259 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 12:55:27.055969 21259 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 12:55:27.055974 21259 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 12:55:27.055977 21259 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 12:55:27.055981 21259 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 12:55:27.055985 21259 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 12:55:27.055989 21259 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 12:55:27.055992 21259 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 12:55:27.055996 21259 net.cpp:202] data does not need backward computation.\n",
      "I0430 12:55:27.055999 21259 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 12:55:27.056013 21259 net.cpp:257] Network initialization done.\n",
      "I0430 12:55:27.138063 21259 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:55:27.229629 21259 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 12:55:27.230572 21259 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 12:55:27.230579 21259 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 12:55:27.230581 21259 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/261758.jpg'}, '/tmp/tmpIRIHs6.mat')\n",
      "Processed 2701 windows in 305.160 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-2.1911, -1.92041, -1.93925, -2.24021, -1.837...\n",
      "ymin                                                    231.128\n",
      "xmin                                                          0\n",
      "ymax                                                    396.456\n",
      "xmax                                                     204.74\n",
      "Name: /home/ambika/INF_project/data/dog/261758.jpg, dtype: object\n",
      "prediction    [-2.2014, -1.95801, -1.86617, -2.14158, -1.675...\n",
      "ymin                                                      4.008\n",
      "xmin                                                          0\n",
      "ymax                                                     40.412\n",
      "xmax                                                    334.332\n",
      "Name: /home/ambika/INF_project/data/dog/261758.jpg, dtype: object\n",
      "dog\n",
      "0.0\t231.128\t204.74\t396.456\n",
      "screwdriver\n",
      "0.0\t4.008\t334.332\t40.412\n",
      "261758\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:00:33.854426 21447 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:00:33.854455 21447 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:00:33.854461 21447 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:00:33.855592 21447 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:00:33.855695 21447 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:00:33.855703 21447 net.cpp:86] Creating Layer data\n",
      "I0430 13:00:33.855708 21447 net.cpp:382] data -> data\n",
      "I0430 13:00:33.855721 21447 net.cpp:124] Setting up data\n",
      "I0430 13:00:33.855726 21447 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:00:33.855729 21447 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:00:33.855733 21447 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:00:33.855741 21447 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:00:33.855742 21447 net.cpp:408] conv1 <- data\n",
      "I0430 13:00:33.855748 21447 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:00:33.855808 21447 net.cpp:124] Setting up conv1\n",
      "I0430 13:00:33.855813 21447 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:00:33.855815 21447 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:00:33.855826 21447 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:00:33.855834 21447 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:00:33.855837 21447 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:00:33.855842 21447 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:00:33.855849 21447 net.cpp:124] Setting up relu1\n",
      "I0430 13:00:33.855854 21447 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:00:33.855857 21447 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:00:33.855860 21447 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:00:33.855866 21447 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:00:33.855870 21447 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:00:33.855875 21447 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:00:33.855883 21447 net.cpp:124] Setting up pool1\n",
      "I0430 13:00:33.855888 21447 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:00:33.855890 21447 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:00:33.855893 21447 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:00:33.855900 21447 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:00:33.855902 21447 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:00:33.855906 21447 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:00:33.855914 21447 net.cpp:124] Setting up norm1\n",
      "I0430 13:00:33.855918 21447 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:00:33.855921 21447 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:00:33.855923 21447 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:00:33.855929 21447 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:00:33.855932 21447 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:00:33.855937 21447 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:00:33.856292 21447 net.cpp:124] Setting up conv2\n",
      "I0430 13:00:33.856300 21447 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:00:33.856304 21447 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:00:33.856312 21447 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:00:33.856318 21447 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:00:33.856322 21447 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:00:33.856326 21447 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:00:33.856331 21447 net.cpp:124] Setting up relu2\n",
      "I0430 13:00:33.856335 21447 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:00:33.856338 21447 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:00:33.856340 21447 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:00:33.856345 21447 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:00:33.856348 21447 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:00:33.856353 21447 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:00:33.856359 21447 net.cpp:124] Setting up pool2\n",
      "I0430 13:00:33.856362 21447 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:00:33.856364 21447 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:00:33.856367 21447 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:00:33.856374 21447 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:00:33.856375 21447 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:00:33.856379 21447 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:00:33.856385 21447 net.cpp:124] Setting up norm2\n",
      "I0430 13:00:33.856389 21447 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:00:33.856391 21447 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:00:33.856395 21447 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:00:33.856400 21447 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:00:33.856403 21447 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:00:33.856408 21447 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:00:33.857097 21447 net.cpp:124] Setting up conv3\n",
      "I0430 13:00:33.857110 21447 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:00:33.857113 21447 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:00:33.857123 21447 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:00:33.857131 21447 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:00:33.857137 21447 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:00:33.857142 21447 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:00:33.857148 21447 net.cpp:124] Setting up relu3\n",
      "I0430 13:00:33.857152 21447 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:00:33.857154 21447 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:00:33.857158 21447 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:00:33.857163 21447 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:00:33.857167 21447 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:00:33.857170 21447 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:00:33.857913 21447 net.cpp:124] Setting up conv4\n",
      "I0430 13:00:33.857923 21447 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:00:33.857928 21447 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:00:33.857934 21447 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:00:33.857944 21447 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:00:33.857947 21447 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:00:33.857951 21447 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:00:33.857956 21447 net.cpp:124] Setting up relu4\n",
      "I0430 13:00:33.857960 21447 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:00:33.857964 21447 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:00:33.857966 21447 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:00:33.857971 21447 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:00:33.857973 21447 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:00:33.857978 21447 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:00:33.858472 21447 net.cpp:124] Setting up conv5\n",
      "I0430 13:00:33.858481 21447 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:00:33.858484 21447 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:00:33.858495 21447 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:00:33.858502 21447 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:00:33.858505 21447 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:00:33.858510 21447 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:00:33.858515 21447 net.cpp:124] Setting up relu5\n",
      "I0430 13:00:33.858518 21447 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:00:33.858521 21447 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:00:33.858525 21447 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:00:33.858530 21447 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:00:33.858531 21447 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:00:33.858537 21447 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:00:33.858544 21447 net.cpp:124] Setting up pool5\n",
      "I0430 13:00:33.858548 21447 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:00:33.858551 21447 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:00:33.858553 21447 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:00:33.858563 21447 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:00:33.858566 21447 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:00:33.858572 21447 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:00:33.879843 21447 net.cpp:124] Setting up fc6\n",
      "I0430 13:00:33.879864 21447 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:00:33.879868 21447 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:00:33.879878 21447 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:00:33.879887 21447 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:00:33.879891 21447 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:00:33.879897 21447 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:00:33.879906 21447 net.cpp:124] Setting up relu6\n",
      "I0430 13:00:33.879911 21447 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:00:33.879914 21447 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:00:33.879917 21447 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:00:33.879930 21447 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:00:33.879932 21447 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:00:33.879936 21447 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:00:33.879945 21447 net.cpp:124] Setting up drop6\n",
      "I0430 13:00:33.879947 21447 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:00:33.879951 21447 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:00:33.879953 21447 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:00:33.879967 21447 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:00:33.879971 21447 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:00:33.879976 21447 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:00:33.890108 21447 net.cpp:124] Setting up fc7\n",
      "I0430 13:00:33.890137 21447 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:00:33.890143 21447 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:00:33.890166 21447 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:00:33.890182 21447 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:00:33.890187 21447 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:00:33.890192 21447 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:00:33.890202 21447 net.cpp:124] Setting up relu7\n",
      "I0430 13:00:33.890205 21447 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:00:33.890208 21447 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:00:33.890213 21447 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:00:33.890219 21447 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:00:33.890223 21447 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:00:33.890228 21447 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:00:33.890234 21447 net.cpp:124] Setting up drop7\n",
      "I0430 13:00:33.890239 21447 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:00:33.890241 21447 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:00:33.890245 21447 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:00:33.890250 21447 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:00:33.890254 21447 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:00:33.890260 21447 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:00:33.891330 21447 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:00:33.891350 21447 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:00:33.891355 21447 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:00:33.891365 21447 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:00:33.891369 21447 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:00:33.891372 21447 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:00:33.891376 21447 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:00:33.891386 21447 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:00:33.891391 21447 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:00:33.891393 21447 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:00:33.891397 21447 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:00:33.891400 21447 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:00:33.891403 21447 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:00:33.891407 21447 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:00:33.891410 21447 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:00:33.891413 21447 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:00:33.891417 21447 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:00:33.891422 21447 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:00:33.891424 21447 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:00:33.891427 21447 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:00:33.891430 21447 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:00:33.891433 21447 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:00:33.891438 21447 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:00:33.891440 21447 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:00:33.891443 21447 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:00:33.891446 21447 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:00:33.891449 21447 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:00:33.891461 21447 net.cpp:257] Network initialization done.\n",
      "I0430 13:00:33.971379 21447 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:00:34.063415 21447 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:00:34.064345 21447 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:00:34.064355 21447 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:00:34.064360 21447 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/359925.jpg'}, '/tmp/tmpgGPdTG.mat')\n",
      "Processed 4149 windows in 461.987 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.092 s.\n",
      "prediction    [-2.24726, -1.16034, -2.24703, -2.66483, -1.96...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                    447.208\n",
      "xmax                                                    332.336\n",
      "Name: /home/ambika/INF_project/data/horse/359925.jpg, dtype: object\n",
      "prediction    [-2.85942, -3.07297, -2.18649, -2.23579, -2.00...\n",
      "ymin                                                    114.208\n",
      "xmin                                                     51.128\n",
      "ymax                                                    311.752\n",
      "xmax                                                     153.72\n",
      "Name: /home/ambika/INF_project/data/horse/359925.jpg, dtype: object\n",
      "cart\n",
      "0.0\t0.0\t332.336\t447.208\n",
      "person\n",
      "51.128\t114.208\t153.72\t311.752\n",
      "359925\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:08:18.205590 21704 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:08:18.205613 21704 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:08:18.205617 21704 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:08:18.207314 21704 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:08:18.207626 21704 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:08:18.207638 21704 net.cpp:86] Creating Layer data\n",
      "I0430 13:08:18.207641 21704 net.cpp:382] data -> data\n",
      "I0430 13:08:18.207654 21704 net.cpp:124] Setting up data\n",
      "I0430 13:08:18.207676 21704 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:08:18.207680 21704 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:08:18.207684 21704 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:08:18.207693 21704 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:08:18.207697 21704 net.cpp:408] conv1 <- data\n",
      "I0430 13:08:18.207705 21704 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:08:18.207769 21704 net.cpp:124] Setting up conv1\n",
      "I0430 13:08:18.207774 21704 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:08:18.207777 21704 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:08:18.207783 21704 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:08:18.207788 21704 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:08:18.207792 21704 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:08:18.207794 21704 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:08:18.207803 21704 net.cpp:124] Setting up relu1\n",
      "I0430 13:08:18.207805 21704 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:08:18.207808 21704 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:08:18.207810 21704 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:08:18.207814 21704 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:08:18.207816 21704 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:08:18.207820 21704 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:08:18.207826 21704 net.cpp:124] Setting up pool1\n",
      "I0430 13:08:18.207829 21704 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:08:18.207832 21704 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:08:18.207834 21704 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:08:18.207839 21704 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:08:18.207841 21704 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:08:18.207844 21704 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:08:18.207849 21704 net.cpp:124] Setting up norm1\n",
      "I0430 13:08:18.207852 21704 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:08:18.207854 21704 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:08:18.207857 21704 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:08:18.207868 21704 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:08:18.207872 21704 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:08:18.207878 21704 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:08:18.208232 21704 net.cpp:124] Setting up conv2\n",
      "I0430 13:08:18.208240 21704 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:08:18.208242 21704 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:08:18.208250 21704 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:08:18.208256 21704 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:08:18.208259 21704 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:08:18.208262 21704 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:08:18.208267 21704 net.cpp:124] Setting up relu2\n",
      "I0430 13:08:18.208271 21704 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:08:18.208272 21704 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:08:18.208276 21704 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:08:18.208278 21704 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:08:18.208281 21704 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:08:18.208284 21704 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:08:18.208289 21704 net.cpp:124] Setting up pool2\n",
      "I0430 13:08:18.208292 21704 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:08:18.208295 21704 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:08:18.208297 21704 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:08:18.208302 21704 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:08:18.208305 21704 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:08:18.208308 21704 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:08:18.208313 21704 net.cpp:124] Setting up norm2\n",
      "I0430 13:08:18.208317 21704 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:08:18.208318 21704 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:08:18.208320 21704 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:08:18.208324 21704 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:08:18.208328 21704 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:08:18.208330 21704 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:08:18.209295 21704 net.cpp:124] Setting up conv3\n",
      "I0430 13:08:18.209306 21704 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:08:18.209311 21704 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:08:18.209321 21704 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:08:18.209327 21704 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:08:18.209331 21704 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:08:18.209336 21704 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:08:18.209342 21704 net.cpp:124] Setting up relu3\n",
      "I0430 13:08:18.209345 21704 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:08:18.209348 21704 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:08:18.209352 21704 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:08:18.209358 21704 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:08:18.209362 21704 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:08:18.209367 21704 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:08:18.209887 21704 net.cpp:124] Setting up conv4\n",
      "I0430 13:08:18.209897 21704 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:08:18.209900 21704 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:08:18.209906 21704 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:08:18.209913 21704 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:08:18.209915 21704 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:08:18.209920 21704 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:08:18.209926 21704 net.cpp:124] Setting up relu4\n",
      "I0430 13:08:18.209930 21704 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:08:18.209933 21704 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:08:18.209936 21704 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:08:18.209942 21704 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:08:18.209945 21704 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:08:18.209950 21704 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:08:18.210451 21704 net.cpp:124] Setting up conv5\n",
      "I0430 13:08:18.210464 21704 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:08:18.210469 21704 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:08:18.210477 21704 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:08:18.210484 21704 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:08:18.210486 21704 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:08:18.210491 21704 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:08:18.210496 21704 net.cpp:124] Setting up relu5\n",
      "I0430 13:08:18.210500 21704 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:08:18.210503 21704 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:08:18.210506 21704 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:08:18.210511 21704 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:08:18.210513 21704 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:08:18.210520 21704 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:08:18.210526 21704 net.cpp:124] Setting up pool5\n",
      "I0430 13:08:18.210530 21704 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:08:18.210533 21704 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:08:18.210536 21704 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:08:18.210543 21704 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:08:18.210546 21704 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:08:18.210551 21704 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:08:18.231979 21704 net.cpp:124] Setting up fc6\n",
      "I0430 13:08:18.232000 21704 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:08:18.232004 21704 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:08:18.232014 21704 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:08:18.232024 21704 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:08:18.232028 21704 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:08:18.232033 21704 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:08:18.232041 21704 net.cpp:124] Setting up relu6\n",
      "I0430 13:08:18.232044 21704 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:08:18.232049 21704 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:08:18.232058 21704 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:08:18.232064 21704 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:08:18.232066 21704 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:08:18.232070 21704 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:08:18.232076 21704 net.cpp:124] Setting up drop6\n",
      "I0430 13:08:18.232080 21704 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:08:18.232082 21704 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:08:18.232085 21704 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:08:18.232090 21704 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:08:18.232094 21704 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:08:18.232100 21704 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:08:18.241768 21704 net.cpp:124] Setting up fc7\n",
      "I0430 13:08:18.241792 21704 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:08:18.241798 21704 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:08:18.241808 21704 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:08:18.241816 21704 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:08:18.241821 21704 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:08:18.241825 21704 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:08:18.241834 21704 net.cpp:124] Setting up relu7\n",
      "I0430 13:08:18.241837 21704 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:08:18.241839 21704 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:08:18.241878 21704 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:08:18.241885 21704 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:08:18.241888 21704 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:08:18.241894 21704 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:08:18.241899 21704 net.cpp:124] Setting up drop7\n",
      "I0430 13:08:18.241904 21704 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:08:18.241905 21704 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:08:18.241909 21704 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:08:18.241914 21704 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:08:18.241916 21704 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:08:18.241921 21704 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:08:18.242825 21704 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:08:18.242835 21704 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:08:18.242839 21704 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:08:18.242846 21704 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:08:18.242851 21704 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:08:18.242852 21704 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:08:18.242856 21704 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:08:18.242861 21704 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:08:18.242863 21704 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:08:18.242866 21704 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:08:18.242869 21704 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:08:18.242873 21704 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:08:18.242877 21704 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:08:18.242879 21704 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:08:18.242882 21704 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:08:18.242887 21704 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:08:18.242889 21704 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:08:18.242892 21704 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:08:18.242895 21704 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:08:18.242899 21704 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:08:18.242902 21704 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:08:18.242905 21704 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:08:18.242908 21704 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:08:18.242913 21704 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:08:18.242914 21704 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:08:18.242918 21704 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:08:18.242920 21704 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:08:18.242933 21704 net.cpp:257] Network initialization done.\n",
      "I0430 13:08:18.493216 21704 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:08:18.596194 21704 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:08:18.597318 21704 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:08:18.597327 21704 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:08:18.597331 21704 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/559778.jpg'}, '/tmp/tmp7sapR6.mat')\n",
      "Processed 2020 windows in 229.099 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-1.96137, -2.17346, -1.79643, -2.25966, -2.13...\n",
      "ymin                                                          0\n",
      "xmin                                                        178\n",
      "ymax                                                        243\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/person/559778.jpg, dtype: object\n",
      "prediction    [-2.20724, -2.18402, -2.20491, -1.06118, -2.23...\n",
      "ymin                                                        147\n",
      "xmin                                                        105\n",
      "ymax                                                        309\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/person/559778.jpg, dtype: object\n",
      "dog\n",
      "178\t0\t500\t243\n",
      "domestic cat\n",
      "105\t147\t500\t309\n",
      "559778\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:12:09.239233 21862 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:12:09.239253 21862 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:12:09.239255 21862 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:12:09.240341 21862 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:12:09.240497 21862 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:12:09.240509 21862 net.cpp:86] Creating Layer data\n",
      "I0430 13:12:09.240512 21862 net.cpp:382] data -> data\n",
      "I0430 13:12:09.240526 21862 net.cpp:124] Setting up data\n",
      "I0430 13:12:09.240532 21862 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:12:09.240536 21862 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:12:09.240541 21862 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:12:09.240550 21862 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:12:09.240553 21862 net.cpp:408] conv1 <- data\n",
      "I0430 13:12:09.240559 21862 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:12:09.240628 21862 net.cpp:124] Setting up conv1\n",
      "I0430 13:12:09.240635 21862 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:12:09.240638 21862 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:12:09.240646 21862 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:12:09.240651 21862 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:12:09.240654 21862 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:12:09.240659 21862 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:12:09.240664 21862 net.cpp:124] Setting up relu1\n",
      "I0430 13:12:09.240669 21862 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:12:09.240670 21862 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:12:09.240674 21862 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:12:09.240679 21862 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:12:09.240681 21862 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:12:09.240685 21862 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:12:09.240692 21862 net.cpp:124] Setting up pool1\n",
      "I0430 13:12:09.240697 21862 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:12:09.240700 21862 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:12:09.240702 21862 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:12:09.240708 21862 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:12:09.240710 21862 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:12:09.240715 21862 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:12:09.240720 21862 net.cpp:124] Setting up norm1\n",
      "I0430 13:12:09.240725 21862 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:12:09.240727 21862 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:12:09.240731 21862 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:12:09.240736 21862 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:12:09.240739 21862 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:12:09.240744 21862 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:12:09.241102 21862 net.cpp:124] Setting up conv2\n",
      "I0430 13:12:09.241111 21862 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:12:09.241114 21862 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:12:09.241122 21862 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:12:09.241128 21862 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:12:09.241132 21862 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:12:09.241135 21862 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:12:09.241140 21862 net.cpp:124] Setting up relu2\n",
      "I0430 13:12:09.241144 21862 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:12:09.241147 21862 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:12:09.241150 21862 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:12:09.241154 21862 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:12:09.241158 21862 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:12:09.241163 21862 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:12:09.241168 21862 net.cpp:124] Setting up pool2\n",
      "I0430 13:12:09.241173 21862 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:12:09.241174 21862 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:12:09.241178 21862 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:12:09.241184 21862 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:12:09.241188 21862 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:12:09.241192 21862 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:12:09.241197 21862 net.cpp:124] Setting up norm2\n",
      "I0430 13:12:09.241201 21862 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:12:09.241204 21862 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:12:09.241207 21862 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:12:09.241214 21862 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:12:09.241215 21862 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:12:09.241220 21862 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:12:09.241926 21862 net.cpp:124] Setting up conv3\n",
      "I0430 13:12:09.241937 21862 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:12:09.241941 21862 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:12:09.241950 21862 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:12:09.241956 21862 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:12:09.241960 21862 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:12:09.241966 21862 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:12:09.241971 21862 net.cpp:124] Setting up relu3\n",
      "I0430 13:12:09.241974 21862 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:12:09.241977 21862 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:12:09.241981 21862 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:12:09.241987 21862 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:12:09.241991 21862 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:12:09.241996 21862 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:12:09.242748 21862 net.cpp:124] Setting up conv4\n",
      "I0430 13:12:09.242758 21862 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:12:09.242761 21862 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:12:09.242769 21862 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:12:09.242775 21862 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:12:09.242779 21862 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:12:09.242782 21862 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:12:09.242787 21862 net.cpp:124] Setting up relu4\n",
      "I0430 13:12:09.242790 21862 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:12:09.242792 21862 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:12:09.242794 21862 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:12:09.242801 21862 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:12:09.242804 21862 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:12:09.242806 21862 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:12:09.243376 21862 net.cpp:124] Setting up conv5\n",
      "I0430 13:12:09.243384 21862 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:12:09.243387 21862 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:12:09.243401 21862 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:12:09.243407 21862 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:12:09.243410 21862 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:12:09.243417 21862 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:12:09.243422 21862 net.cpp:124] Setting up relu5\n",
      "I0430 13:12:09.243425 21862 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:12:09.243427 21862 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:12:09.243429 21862 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:12:09.243433 21862 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:12:09.243435 21862 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:12:09.243439 21862 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:12:09.243445 21862 net.cpp:124] Setting up pool5\n",
      "I0430 13:12:09.243448 21862 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:12:09.243450 21862 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:12:09.243453 21862 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:12:09.243460 21862 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:12:09.243463 21862 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:12:09.243466 21862 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:12:09.264437 21862 net.cpp:124] Setting up fc6\n",
      "I0430 13:12:09.264459 21862 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:12:09.264461 21862 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:12:09.264472 21862 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:12:09.264485 21862 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:12:09.264489 21862 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:12:09.264494 21862 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:12:09.264500 21862 net.cpp:124] Setting up relu6\n",
      "I0430 13:12:09.264503 21862 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:12:09.264505 21862 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:12:09.264508 21862 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:12:09.264511 21862 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:12:09.264513 21862 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:12:09.264515 21862 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:12:09.264519 21862 net.cpp:124] Setting up drop6\n",
      "I0430 13:12:09.264521 21862 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:12:09.264533 21862 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:12:09.264535 21862 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:12:09.264539 21862 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:12:09.264541 21862 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:12:09.264545 21862 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:12:09.274000 21862 net.cpp:124] Setting up fc7\n",
      "I0430 13:12:09.274019 21862 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:12:09.274021 21862 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:12:09.274027 21862 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:12:09.274036 21862 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:12:09.274054 21862 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:12:09.274060 21862 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:12:09.274067 21862 net.cpp:124] Setting up relu7\n",
      "I0430 13:12:09.274071 21862 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:12:09.274075 21862 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:12:09.274078 21862 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:12:09.274085 21862 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:12:09.274086 21862 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:12:09.274092 21862 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:12:09.274098 21862 net.cpp:124] Setting up drop7\n",
      "I0430 13:12:09.274101 21862 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:12:09.274104 21862 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:12:09.274107 21862 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:12:09.274113 21862 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:12:09.274116 21862 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:12:09.274121 21862 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:12:09.275009 21862 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:12:09.275019 21862 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:12:09.275022 21862 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:12:09.275030 21862 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:12:09.275033 21862 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:12:09.275038 21862 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:12:09.275040 21862 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:12:09.275044 21862 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:12:09.275048 21862 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:12:09.275050 21862 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:12:09.275054 21862 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:12:09.275058 21862 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:12:09.275060 21862 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:12:09.275064 21862 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:12:09.275068 21862 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:12:09.275071 21862 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:12:09.275074 21862 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:12:09.275077 21862 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:12:09.275081 21862 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:12:09.275084 21862 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:12:09.275089 21862 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:12:09.275091 21862 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:12:09.275095 21862 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:12:09.275099 21862 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:12:09.275102 21862 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:12:09.275105 21862 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:12:09.275108 21862 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:12:09.275120 21862 net.cpp:257] Network initialization done.\n",
      "I0430 13:12:09.359632 21862 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:12:09.451133 21862 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:12:09.452083 21862 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:12:09.452092 21862 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:12:09.452096 21862 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/85381.jpg'}, '/tmp/tmpydD7zL.mat')\n",
      "Processed 2672 windows in 300.075 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.35202, -2.39288, -1.97744, -2.14359, -1.99...\n",
      "ymin                                                        201\n",
      "xmin                                                        240\n",
      "ymax                                                        291\n",
      "xmax                                                        285\n",
      "Name: /home/ambika/INF_project/data/train/85381.jpg, dtype: object\n",
      "prediction    [-2.39486, -1.60273, -2.03164, -2.57214, -2.01...\n",
      "ymin                                                        131\n",
      "xmin                                                        254\n",
      "ymax                                                        272\n",
      "xmax                                                        482\n",
      "Name: /home/ambika/INF_project/data/train/85381.jpg, dtype: object\n",
      "person\n",
      "240\t201\t285\t291\n",
      "bus\n",
      "254\t131\t482\t272\n",
      "85381\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:17:11.056586 22064 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:17:11.056607 22064 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:17:11.056609 22064 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:17:11.057807 22064 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:17:11.057904 22064 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:17:11.057917 22064 net.cpp:86] Creating Layer data\n",
      "I0430 13:17:11.057924 22064 net.cpp:382] data -> data\n",
      "I0430 13:17:11.057940 22064 net.cpp:124] Setting up data\n",
      "I0430 13:17:11.057946 22064 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:17:11.057950 22064 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:17:11.057952 22064 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:17:11.057960 22064 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:17:11.057965 22064 net.cpp:408] conv1 <- data\n",
      "I0430 13:17:11.057970 22064 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:17:11.058050 22064 net.cpp:124] Setting up conv1\n",
      "I0430 13:17:11.058058 22064 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:17:11.058061 22064 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:17:11.058071 22064 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:17:11.058078 22064 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:17:11.058080 22064 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:17:11.058084 22064 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:17:11.058090 22064 net.cpp:124] Setting up relu1\n",
      "I0430 13:17:11.058094 22064 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:17:11.058096 22064 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:17:11.058099 22064 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:17:11.058104 22064 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:17:11.058106 22064 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:17:11.058110 22064 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:17:11.058120 22064 net.cpp:124] Setting up pool1\n",
      "I0430 13:17:11.058123 22064 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:17:11.058126 22064 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:17:11.058130 22064 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:17:11.058135 22064 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:17:11.058136 22064 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:17:11.058140 22064 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:17:11.058146 22064 net.cpp:124] Setting up norm1\n",
      "I0430 13:17:11.058151 22064 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:17:11.058153 22064 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:17:11.058156 22064 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:17:11.058161 22064 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:17:11.058163 22064 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:17:11.058167 22064 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:17:11.058625 22064 net.cpp:124] Setting up conv2\n",
      "I0430 13:17:11.058636 22064 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:17:11.058640 22064 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:17:11.058648 22064 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:17:11.058656 22064 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:17:11.058660 22064 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:17:11.058665 22064 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:17:11.058670 22064 net.cpp:124] Setting up relu2\n",
      "I0430 13:17:11.058675 22064 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:17:11.058677 22064 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:17:11.058681 22064 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:17:11.058686 22064 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:17:11.058688 22064 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:17:11.058692 22064 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:17:11.058701 22064 net.cpp:124] Setting up pool2\n",
      "I0430 13:17:11.058706 22064 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:17:11.058708 22064 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:17:11.058712 22064 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:17:11.058719 22064 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:17:11.058723 22064 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:17:11.058727 22064 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:17:11.058734 22064 net.cpp:124] Setting up norm2\n",
      "I0430 13:17:11.058739 22064 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:17:11.058743 22064 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:17:11.058745 22064 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:17:11.058753 22064 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:17:11.058755 22064 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:17:11.058759 22064 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:17:11.059954 22064 net.cpp:124] Setting up conv3\n",
      "I0430 13:17:11.059974 22064 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:17:11.059978 22064 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:17:11.059989 22064 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:17:11.059998 22064 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:17:11.060001 22064 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:17:11.060008 22064 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:17:11.060014 22064 net.cpp:124] Setting up relu3\n",
      "I0430 13:17:11.060019 22064 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:17:11.060021 22064 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:17:11.060025 22064 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:17:11.060032 22064 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:17:11.060035 22064 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:17:11.060040 22064 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:17:11.060791 22064 net.cpp:124] Setting up conv4\n",
      "I0430 13:17:11.060801 22064 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:17:11.060804 22064 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:17:11.060811 22064 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:17:11.060818 22064 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:17:11.060822 22064 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:17:11.060827 22064 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:17:11.060832 22064 net.cpp:124] Setting up relu4\n",
      "I0430 13:17:11.060837 22064 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:17:11.060839 22064 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:17:11.060842 22064 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:17:11.060850 22064 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:17:11.060853 22064 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:17:11.060858 22064 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:17:11.061363 22064 net.cpp:124] Setting up conv5\n",
      "I0430 13:17:11.061372 22064 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:17:11.061377 22064 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:17:11.061388 22064 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:17:11.061393 22064 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:17:11.061398 22064 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:17:11.061403 22064 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:17:11.061408 22064 net.cpp:124] Setting up relu5\n",
      "I0430 13:17:11.061413 22064 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:17:11.061414 22064 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:17:11.061419 22064 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:17:11.061424 22064 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:17:11.061425 22064 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:17:11.061430 22064 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:17:11.061437 22064 net.cpp:124] Setting up pool5\n",
      "I0430 13:17:11.061442 22064 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:17:11.061444 22064 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:17:11.061447 22064 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:17:11.061455 22064 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:17:11.061458 22064 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:17:11.061463 22064 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:17:11.082449 22064 net.cpp:124] Setting up fc6\n",
      "I0430 13:17:11.082468 22064 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:17:11.082473 22064 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:17:11.082482 22064 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:17:11.082492 22064 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:17:11.082496 22064 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:17:11.082504 22064 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:17:11.082511 22064 net.cpp:124] Setting up relu6\n",
      "I0430 13:17:11.082515 22064 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:17:11.082527 22064 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:17:11.082531 22064 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:17:11.082536 22064 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:17:11.082540 22064 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:17:11.082545 22064 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:17:11.082550 22064 net.cpp:124] Setting up drop6\n",
      "I0430 13:17:11.082553 22064 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:17:11.082556 22064 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:17:11.082559 22064 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:17:11.082564 22064 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:17:11.082567 22064 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:17:11.082573 22064 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:17:11.092110 22064 net.cpp:124] Setting up fc7\n",
      "I0430 13:17:11.092131 22064 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:17:11.092136 22064 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:17:11.092146 22064 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:17:11.092154 22064 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:17:11.092159 22064 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:17:11.092164 22064 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:17:11.092172 22064 net.cpp:124] Setting up relu7\n",
      "I0430 13:17:11.092176 22064 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:17:11.092178 22064 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:17:11.092181 22064 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:17:11.092200 22064 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:17:11.092202 22064 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:17:11.092208 22064 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:17:11.092213 22064 net.cpp:124] Setting up drop7\n",
      "I0430 13:17:11.092217 22064 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:17:11.092219 22064 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:17:11.092223 22064 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:17:11.092228 22064 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:17:11.092231 22064 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:17:11.092236 22064 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:17:11.093142 22064 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:17:11.093152 22064 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:17:11.093156 22064 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:17:11.093163 22064 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:17:11.093168 22064 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:17:11.093171 22064 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:17:11.093175 22064 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:17:11.093180 22064 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:17:11.093183 22064 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:17:11.093186 22064 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:17:11.093190 22064 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:17:11.093194 22064 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:17:11.093196 22064 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:17:11.093200 22064 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:17:11.093204 22064 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:17:11.093206 22064 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:17:11.093209 22064 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:17:11.093214 22064 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:17:11.093216 22064 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:17:11.093219 22064 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:17:11.093222 22064 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:17:11.093226 22064 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:17:11.093230 22064 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:17:11.093232 22064 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:17:11.093235 22064 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:17:11.093238 22064 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:17:11.093241 22064 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:17:11.093251 22064 net.cpp:257] Network initialization done.\n",
      "I0430 13:17:11.175509 22064 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:17:11.266136 22064 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:17:11.267053 22064 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:17:11.267061 22064 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:17:11.267065 22064 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/326582.jpg'}, '/tmp/tmpOCXaU4.mat')\n",
      "Processed 767 windows in 90.135 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.027 s.\n",
      "prediction    [-1.81014, -0.0802622, -1.68107, -1.27942, -1....\n",
      "ymin                                                        206\n",
      "xmin                                                         33\n",
      "ymax                                                        265\n",
      "xmax                                                        268\n",
      "Name: /home/ambika/INF_project/data/airplane/326582.jpg, dtype: object\n",
      "prediction    [-1.69894, -0.42193, -1.88011, -1.54177, -1.76...\n",
      "ymin                                                        206\n",
      "xmin                                                         33\n",
      "ymax                                                        254\n",
      "xmax                                                        268\n",
      "Name: /home/ambika/INF_project/data/airplane/326582.jpg, dtype: object\n",
      "airplane\n",
      "33\t206\t268\t265\n",
      "corkscrew\n",
      "33\t206\t268\t254\n",
      "326582\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:18:42.857376 22201 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:18:42.857398 22201 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:18:42.857400 22201 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:18:42.858517 22201 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:18:42.858698 22201 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:18:42.858707 22201 net.cpp:86] Creating Layer data\n",
      "I0430 13:18:42.858712 22201 net.cpp:382] data -> data\n",
      "I0430 13:18:42.858727 22201 net.cpp:124] Setting up data\n",
      "I0430 13:18:42.858734 22201 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:18:42.858738 22201 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:18:42.858743 22201 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:18:42.858750 22201 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:18:42.858754 22201 net.cpp:408] conv1 <- data\n",
      "I0430 13:18:42.858759 22201 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:18:42.858820 22201 net.cpp:124] Setting up conv1\n",
      "I0430 13:18:42.858825 22201 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:18:42.858829 22201 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:18:42.858837 22201 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:18:42.858842 22201 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:18:42.858845 22201 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:18:42.858850 22201 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:18:42.858855 22201 net.cpp:124] Setting up relu1\n",
      "I0430 13:18:42.858860 22201 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:18:42.858861 22201 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:18:42.858865 22201 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:18:42.858870 22201 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:18:42.858872 22201 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:18:42.858877 22201 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:18:42.858893 22201 net.cpp:124] Setting up pool1\n",
      "I0430 13:18:42.858899 22201 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:18:42.858902 22201 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:18:42.858906 22201 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:18:42.858911 22201 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:18:42.858914 22201 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:18:42.858918 22201 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:18:42.858925 22201 net.cpp:124] Setting up norm1\n",
      "I0430 13:18:42.858930 22201 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:18:42.858933 22201 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:18:42.858937 22201 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:18:42.858942 22201 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:18:42.858944 22201 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:18:42.858949 22201 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:18:42.859338 22201 net.cpp:124] Setting up conv2\n",
      "I0430 13:18:42.859345 22201 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:18:42.859349 22201 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:18:42.859357 22201 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:18:42.859364 22201 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:18:42.859366 22201 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:18:42.859371 22201 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:18:42.859376 22201 net.cpp:124] Setting up relu2\n",
      "I0430 13:18:42.859381 22201 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:18:42.859383 22201 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:18:42.859386 22201 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:18:42.859391 22201 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:18:42.859395 22201 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:18:42.859398 22201 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:18:42.859405 22201 net.cpp:124] Setting up pool2\n",
      "I0430 13:18:42.859410 22201 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:18:42.859412 22201 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:18:42.859416 22201 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:18:42.859421 22201 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:18:42.859424 22201 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:18:42.859428 22201 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:18:42.859434 22201 net.cpp:124] Setting up norm2\n",
      "I0430 13:18:42.859438 22201 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:18:42.859441 22201 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:18:42.859444 22201 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:18:42.859449 22201 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:18:42.859452 22201 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:18:42.859457 22201 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:18:42.860424 22201 net.cpp:124] Setting up conv3\n",
      "I0430 13:18:42.860435 22201 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:18:42.860438 22201 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:18:42.860448 22201 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:18:42.860456 22201 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:18:42.860460 22201 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:18:42.860465 22201 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:18:42.860471 22201 net.cpp:124] Setting up relu3\n",
      "I0430 13:18:42.860476 22201 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:18:42.860478 22201 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:18:42.860481 22201 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:18:42.860487 22201 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:18:42.860491 22201 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:18:42.860496 22201 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:18:42.861238 22201 net.cpp:124] Setting up conv4\n",
      "I0430 13:18:42.861248 22201 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:18:42.861251 22201 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:18:42.861258 22201 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:18:42.861265 22201 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:18:42.861269 22201 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:18:42.861274 22201 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:18:42.861279 22201 net.cpp:124] Setting up relu4\n",
      "I0430 13:18:42.861284 22201 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:18:42.861286 22201 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:18:42.861289 22201 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:18:42.861296 22201 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:18:42.861299 22201 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:18:42.861304 22201 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:18:42.861817 22201 net.cpp:124] Setting up conv5\n",
      "I0430 13:18:42.861825 22201 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:18:42.861829 22201 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:18:42.861838 22201 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:18:42.861845 22201 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:18:42.861850 22201 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:18:42.861855 22201 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:18:42.861860 22201 net.cpp:124] Setting up relu5\n",
      "I0430 13:18:42.861863 22201 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:18:42.861866 22201 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:18:42.861870 22201 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:18:42.861874 22201 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:18:42.861877 22201 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:18:42.861882 22201 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:18:42.861891 22201 net.cpp:124] Setting up pool5\n",
      "I0430 13:18:42.861896 22201 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:18:42.861897 22201 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:18:42.861901 22201 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:18:42.861908 22201 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:18:42.861912 22201 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:18:42.861915 22201 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:18:42.883026 22201 net.cpp:124] Setting up fc6\n",
      "I0430 13:18:42.883051 22201 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:18:42.883056 22201 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:18:42.883066 22201 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:18:42.883077 22201 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:18:42.883080 22201 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:18:42.883086 22201 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:18:42.883093 22201 net.cpp:124] Setting up relu6\n",
      "I0430 13:18:42.883097 22201 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:18:42.883100 22201 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:18:42.883101 22201 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:18:42.883106 22201 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:18:42.883121 22201 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:18:42.883126 22201 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:18:42.883131 22201 net.cpp:124] Setting up drop6\n",
      "I0430 13:18:42.883136 22201 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:18:42.883138 22201 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:18:42.883142 22201 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:18:42.883147 22201 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:18:42.883150 22201 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:18:42.883157 22201 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:18:42.892606 22201 net.cpp:124] Setting up fc7\n",
      "I0430 13:18:42.892629 22201 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:18:42.892634 22201 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:18:42.892644 22201 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:18:42.892652 22201 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:18:42.892657 22201 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:18:42.892662 22201 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:18:42.892668 22201 net.cpp:124] Setting up relu7\n",
      "I0430 13:18:42.892673 22201 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:18:42.892674 22201 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:18:42.892691 22201 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:18:42.892696 22201 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:18:42.892699 22201 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:18:42.892705 22201 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:18:42.892711 22201 net.cpp:124] Setting up drop7\n",
      "I0430 13:18:42.892715 22201 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:18:42.892719 22201 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:18:42.892721 22201 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:18:42.892726 22201 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:18:42.892729 22201 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:18:42.892735 22201 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:18:42.893393 22201 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:18:42.893402 22201 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:18:42.893406 22201 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:18:42.893414 22201 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:18:42.893416 22201 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:18:42.893420 22201 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:18:42.893424 22201 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:18:42.893427 22201 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:18:42.893430 22201 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:18:42.893434 22201 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:18:42.893437 22201 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:18:42.893440 22201 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:18:42.893443 22201 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:18:42.893447 22201 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:18:42.893450 22201 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:18:42.893453 22201 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:18:42.893456 22201 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:18:42.893460 22201 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:18:42.893463 22201 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:18:42.893467 22201 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:18:42.893471 22201 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:18:42.893473 22201 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:18:42.893477 22201 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:18:42.893481 22201 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:18:42.893483 22201 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:18:42.893486 22201 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:18:42.893489 22201 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:18:42.893501 22201 net.cpp:257] Network initialization done.\n",
      "I0430 13:18:42.974768 22201 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:18:43.065125 22201 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:18:43.066031 22201 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:18:43.066040 22201 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:18:43.066045 22201 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/60456.jpg'}, '/tmp/tmpY7zxzq.mat')\n",
      "Processed 652 windows in 78.996 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.028 s.\n",
      "prediction    [-2.01628, -2.65849, -1.72562, -1.61401, -1.69...\n",
      "ymin                                                         52\n",
      "xmin                                                         31\n",
      "ymax                                                        322\n",
      "xmax                                                        137\n",
      "Name: /home/ambika/INF_project/data/bird/60456.jpg, dtype: object\n",
      "prediction    [-1.94756, -2.99653, -2.06446, -2.58254, -2.17...\n",
      "ymin                                                        232\n",
      "xmin                                                        385\n",
      "ymax                                                        321\n",
      "xmax                                                        457\n",
      "Name: /home/ambika/INF_project/data/bird/60456.jpg, dtype: object\n",
      "person\n",
      "31\t52\t137\t322\n",
      "bird\n",
      "385\t232\t457\t321\n",
      "60456\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:20:03.452658 22322 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:20:03.452687 22322 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:20:03.452690 22322 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:20:03.454365 22322 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:20:03.454543 22322 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:20:03.454556 22322 net.cpp:86] Creating Layer data\n",
      "I0430 13:20:03.454566 22322 net.cpp:382] data -> data\n",
      "I0430 13:20:03.454587 22322 net.cpp:124] Setting up data\n",
      "I0430 13:20:03.454596 22322 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:20:03.454599 22322 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:20:03.454603 22322 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:20:03.454612 22322 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:20:03.454617 22322 net.cpp:408] conv1 <- data\n",
      "I0430 13:20:03.454622 22322 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:20:03.454706 22322 net.cpp:124] Setting up conv1\n",
      "I0430 13:20:03.454717 22322 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:20:03.454721 22322 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:20:03.454731 22322 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:20:03.454738 22322 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:20:03.454742 22322 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:20:03.454748 22322 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:20:03.454754 22322 net.cpp:124] Setting up relu1\n",
      "I0430 13:20:03.454761 22322 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:20:03.454763 22322 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:20:03.454767 22322 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:20:03.454773 22322 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:20:03.454777 22322 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:20:03.454782 22322 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:20:03.454790 22322 net.cpp:124] Setting up pool1\n",
      "I0430 13:20:03.454795 22322 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:20:03.454798 22322 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:20:03.454802 22322 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:20:03.454808 22322 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:20:03.454813 22322 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:20:03.454818 22322 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:20:03.454824 22322 net.cpp:124] Setting up norm1\n",
      "I0430 13:20:03.454829 22322 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:20:03.454833 22322 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:20:03.454836 22322 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:20:03.454843 22322 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:20:03.454846 22322 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:20:03.454851 22322 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:20:03.455327 22322 net.cpp:124] Setting up conv2\n",
      "I0430 13:20:03.455346 22322 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:20:03.455351 22322 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:20:03.455363 22322 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:20:03.455370 22322 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:20:03.455375 22322 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:20:03.455381 22322 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:20:03.455389 22322 net.cpp:124] Setting up relu2\n",
      "I0430 13:20:03.455394 22322 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:20:03.455397 22322 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:20:03.455401 22322 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:20:03.455407 22322 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:20:03.455411 22322 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:20:03.455416 22322 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:20:03.455426 22322 net.cpp:124] Setting up pool2\n",
      "I0430 13:20:03.455432 22322 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:20:03.455436 22322 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:20:03.455440 22322 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:20:03.455448 22322 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:20:03.455452 22322 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:20:03.455457 22322 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:20:03.455466 22322 net.cpp:124] Setting up norm2\n",
      "I0430 13:20:03.455471 22322 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:20:03.455474 22322 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:20:03.455478 22322 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:20:03.455487 22322 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:20:03.455492 22322 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:20:03.455497 22322 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:20:03.456789 22322 net.cpp:124] Setting up conv3\n",
      "I0430 13:20:03.456815 22322 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:20:03.456820 22322 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:20:03.456833 22322 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:20:03.456843 22322 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:20:03.456848 22322 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:20:03.456856 22322 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:20:03.456863 22322 net.cpp:124] Setting up relu3\n",
      "I0430 13:20:03.456869 22322 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:20:03.456873 22322 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:20:03.456876 22322 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:20:03.456887 22322 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:20:03.456890 22322 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:20:03.456895 22322 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:20:03.457620 22322 net.cpp:124] Setting up conv4\n",
      "I0430 13:20:03.457638 22322 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:20:03.457643 22322 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:20:03.457653 22322 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:20:03.457660 22322 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:20:03.457664 22322 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:20:03.457671 22322 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:20:03.457679 22322 net.cpp:124] Setting up relu4\n",
      "I0430 13:20:03.457684 22322 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:20:03.457689 22322 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:20:03.457691 22322 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:20:03.457700 22322 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:20:03.457703 22322 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:20:03.457710 22322 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:20:03.458370 22322 net.cpp:124] Setting up conv5\n",
      "I0430 13:20:03.458380 22322 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:20:03.458385 22322 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:20:03.458397 22322 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:20:03.458405 22322 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:20:03.458408 22322 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:20:03.458415 22322 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:20:03.458421 22322 net.cpp:124] Setting up relu5\n",
      "I0430 13:20:03.458426 22322 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:20:03.458431 22322 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:20:03.458434 22322 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:20:03.458441 22322 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:20:03.458444 22322 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:20:03.458449 22322 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:20:03.458459 22322 net.cpp:124] Setting up pool5\n",
      "I0430 13:20:03.458464 22322 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:20:03.458468 22322 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:20:03.458472 22322 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:20:03.458482 22322 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:20:03.458485 22322 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:20:03.458490 22322 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:20:03.480453 22322 net.cpp:124] Setting up fc6\n",
      "I0430 13:20:03.480479 22322 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:20:03.480481 22322 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:20:03.480489 22322 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:20:03.480499 22322 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:20:03.480504 22322 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:20:03.480509 22322 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:20:03.480515 22322 net.cpp:124] Setting up relu6\n",
      "I0430 13:20:03.480518 22322 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:20:03.480520 22322 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:20:03.480523 22322 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:20:03.480528 22322 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:20:03.480530 22322 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:20:03.480533 22322 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:20:03.480538 22322 net.cpp:124] Setting up drop6\n",
      "I0430 13:20:03.480541 22322 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:20:03.480543 22322 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:20:03.480545 22322 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:20:03.480550 22322 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:20:03.480552 22322 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:20:03.480556 22322 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:20:03.490583 22322 net.cpp:124] Setting up fc7\n",
      "I0430 13:20:03.490610 22322 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:20:03.490617 22322 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:20:03.490629 22322 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:20:03.490641 22322 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:20:03.490646 22322 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:20:03.490654 22322 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:20:03.490664 22322 net.cpp:124] Setting up relu7\n",
      "I0430 13:20:03.490679 22322 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:20:03.490682 22322 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:20:03.490686 22322 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:20:03.490694 22322 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:20:03.490697 22322 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:20:03.490703 22322 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:20:03.490711 22322 net.cpp:124] Setting up drop7\n",
      "I0430 13:20:03.490716 22322 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:20:03.490720 22322 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:20:03.490723 22322 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:20:03.490731 22322 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:20:03.490734 22322 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:20:03.490739 22322 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:20:03.491371 22322 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:20:03.491384 22322 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:20:03.491387 22322 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:20:03.491395 22322 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:20:03.491410 22322 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:20:03.491412 22322 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:20:03.491415 22322 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:20:03.491420 22322 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:20:03.491422 22322 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:20:03.491426 22322 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:20:03.491431 22322 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:20:03.491436 22322 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:20:03.491438 22322 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:20:03.491442 22322 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:20:03.491446 22322 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:20:03.491449 22322 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:20:03.491452 22322 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:20:03.491456 22322 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:20:03.491459 22322 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:20:03.491462 22322 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:20:03.491466 22322 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:20:03.491469 22322 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:20:03.491473 22322 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:20:03.491477 22322 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:20:03.491479 22322 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:20:03.491483 22322 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:20:03.491487 22322 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:20:03.491497 22322 net.cpp:257] Network initialization done.\n",
      "I0430 13:20:03.572788 22322 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:20:03.664158 22322 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:20:03.665020 22322 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:20:03.665027 22322 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:20:03.665032 22322 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/263664.jpg'}, '/tmp/tmpnsuxHG.mat')\n",
      "Processed 2837 windows in 317.877 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-1.22592, -1.06844, -1.8793, -2.21618, -1.791...\n",
      "ymin                                                         14\n",
      "xmin                                                          0\n",
      "ymax                                                        288\n",
      "xmax                                                        299\n",
      "Name: /home/ambika/INF_project/data/bus/263664.jpg, dtype: object\n",
      "prediction    [-1.83058, -2.31796, -1.82413, -1.52742, -1.83...\n",
      "ymin                                                        175\n",
      "xmin                                                        374\n",
      "ymax                                                        375\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/bus/263664.jpg, dtype: object\n",
      "bus\n",
      "0\t14\t299\t288\n",
      "person\n",
      "374\t175\t500\t375\n",
      "263664\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:25:23.175232 22509 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:25:23.175261 22509 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:25:23.175266 22509 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:25:23.176398 22509 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:25:23.176539 22509 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:25:23.176548 22509 net.cpp:86] Creating Layer data\n",
      "I0430 13:25:23.176550 22509 net.cpp:382] data -> data\n",
      "I0430 13:25:23.176560 22509 net.cpp:124] Setting up data\n",
      "I0430 13:25:23.176564 22509 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:25:23.176568 22509 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:25:23.176570 22509 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:25:23.176576 22509 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:25:23.176580 22509 net.cpp:408] conv1 <- data\n",
      "I0430 13:25:23.176585 22509 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:25:23.176654 22509 net.cpp:124] Setting up conv1\n",
      "I0430 13:25:23.176661 22509 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:25:23.176662 22509 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:25:23.176669 22509 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:25:23.176674 22509 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:25:23.176676 22509 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:25:23.176681 22509 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:25:23.176684 22509 net.cpp:124] Setting up relu1\n",
      "I0430 13:25:23.176687 22509 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:25:23.176689 22509 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:25:23.176692 22509 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:25:23.176695 22509 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:25:23.176698 22509 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:25:23.176702 22509 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:25:23.176707 22509 net.cpp:124] Setting up pool1\n",
      "I0430 13:25:23.176710 22509 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:25:23.176713 22509 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:25:23.176715 22509 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:25:23.176719 22509 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:25:23.176723 22509 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:25:23.176725 22509 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:25:23.176733 22509 net.cpp:124] Setting up norm1\n",
      "I0430 13:25:23.176735 22509 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:25:23.176738 22509 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:25:23.176740 22509 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:25:23.176744 22509 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:25:23.176746 22509 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:25:23.176750 22509 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:25:23.177140 22509 net.cpp:124] Setting up conv2\n",
      "I0430 13:25:23.177151 22509 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:25:23.177155 22509 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:25:23.177165 22509 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:25:23.177172 22509 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:25:23.177176 22509 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:25:23.177181 22509 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:25:23.177186 22509 net.cpp:124] Setting up relu2\n",
      "I0430 13:25:23.177188 22509 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:25:23.177191 22509 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:25:23.177193 22509 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:25:23.177196 22509 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:25:23.177199 22509 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:25:23.177202 22509 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:25:23.177207 22509 net.cpp:124] Setting up pool2\n",
      "I0430 13:25:23.177211 22509 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:25:23.177213 22509 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:25:23.177215 22509 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:25:23.177222 22509 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:25:23.177223 22509 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:25:23.177227 22509 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:25:23.177232 22509 net.cpp:124] Setting up norm2\n",
      "I0430 13:25:23.177234 22509 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:25:23.177237 22509 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:25:23.177239 22509 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:25:23.177243 22509 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:25:23.177247 22509 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:25:23.177249 22509 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:25:23.177950 22509 net.cpp:124] Setting up conv3\n",
      "I0430 13:25:23.177961 22509 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:25:23.177964 22509 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:25:23.177974 22509 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:25:23.177983 22509 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:25:23.177986 22509 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:25:23.177990 22509 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:25:23.177995 22509 net.cpp:124] Setting up relu3\n",
      "I0430 13:25:23.177999 22509 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:25:23.178001 22509 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:25:23.178004 22509 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:25:23.178009 22509 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:25:23.178011 22509 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:25:23.178015 22509 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:25:23.178759 22509 net.cpp:124] Setting up conv4\n",
      "I0430 13:25:23.178768 22509 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:25:23.178771 22509 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:25:23.178778 22509 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:25:23.178784 22509 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:25:23.178788 22509 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:25:23.178791 22509 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:25:23.178797 22509 net.cpp:124] Setting up relu4\n",
      "I0430 13:25:23.178799 22509 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:25:23.178802 22509 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:25:23.178804 22509 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:25:23.178809 22509 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:25:23.178812 22509 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:25:23.178815 22509 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:25:23.179344 22509 net.cpp:124] Setting up conv5\n",
      "I0430 13:25:23.179352 22509 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:25:23.179355 22509 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:25:23.179365 22509 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:25:23.179370 22509 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:25:23.179374 22509 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:25:23.179378 22509 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:25:23.179381 22509 net.cpp:124] Setting up relu5\n",
      "I0430 13:25:23.179385 22509 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:25:23.179388 22509 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:25:23.179389 22509 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:25:23.179394 22509 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:25:23.179395 22509 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:25:23.179399 22509 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:25:23.179406 22509 net.cpp:124] Setting up pool5\n",
      "I0430 13:25:23.179409 22509 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:25:23.179411 22509 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:25:23.179414 22509 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:25:23.179420 22509 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:25:23.179422 22509 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:25:23.179426 22509 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:25:23.201091 22509 net.cpp:124] Setting up fc6\n",
      "I0430 13:25:23.201117 22509 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:25:23.201122 22509 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:25:23.201148 22509 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:25:23.201159 22509 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:25:23.201164 22509 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:25:23.201170 22509 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:25:23.201179 22509 net.cpp:124] Setting up relu6\n",
      "I0430 13:25:23.201182 22509 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:25:23.201184 22509 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:25:23.201186 22509 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:25:23.201190 22509 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:25:23.201194 22509 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:25:23.201196 22509 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:25:23.201201 22509 net.cpp:124] Setting up drop6\n",
      "I0430 13:25:23.201203 22509 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:25:23.201205 22509 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:25:23.201208 22509 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:25:23.201212 22509 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:25:23.201215 22509 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:25:23.201218 22509 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:25:23.210831 22509 net.cpp:124] Setting up fc7\n",
      "I0430 13:25:23.210850 22509 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:25:23.210855 22509 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:25:23.210876 22509 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:25:23.210886 22509 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:25:23.210891 22509 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:25:23.210896 22509 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:25:23.210903 22509 net.cpp:124] Setting up relu7\n",
      "I0430 13:25:23.210908 22509 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:25:23.210911 22509 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:25:23.210913 22509 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:25:23.210917 22509 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:25:23.210921 22509 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:25:23.210924 22509 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:25:23.210929 22509 net.cpp:124] Setting up drop7\n",
      "I0430 13:25:23.210932 22509 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:25:23.210934 22509 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:25:23.210937 22509 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:25:23.210942 22509 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:25:23.210943 22509 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:25:23.210948 22509 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:25:23.211866 22509 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:25:23.211876 22509 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:25:23.211880 22509 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:25:23.211889 22509 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:25:23.211892 22509 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:25:23.211896 22509 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:25:23.211900 22509 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:25:23.211905 22509 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:25:23.211907 22509 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:25:23.211911 22509 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:25:23.211915 22509 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:25:23.211917 22509 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:25:23.211920 22509 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:25:23.211922 22509 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:25:23.211925 22509 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:25:23.211928 22509 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:25:23.211930 22509 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:25:23.211933 22509 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:25:23.211936 22509 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:25:23.211938 22509 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:25:23.211941 22509 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:25:23.211944 22509 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:25:23.211947 22509 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:25:23.211949 22509 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:25:23.211952 22509 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:25:23.211954 22509 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:25:23.211957 22509 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:25:23.211967 22509 net.cpp:257] Network initialization done.\n",
      "I0430 13:25:23.294031 22509 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:25:23.385289 22509 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:25:23.386265 22509 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:25:23.386273 22509 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:25:23.386276 22509 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/232121.jpg'}, '/tmp/tmp2scwWk.mat')\n",
      "Processed 1941 windows in 224.505 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-2.36083, -2.09541, -1.88236, -1.96531, -1.88...\n",
      "ymin                                                        197\n",
      "xmin                                                         99\n",
      "ymax                                                        276\n",
      "xmax                                                        353\n",
      "Name: /home/ambika/INF_project/data/car/232121.jpg, dtype: object\n",
      "prediction    [-1.68523, -2.14607, -2.2738, -2.15013, -2.031...\n",
      "ymin                                                          0\n",
      "xmin                                                         43\n",
      "ymax                                                        375\n",
      "xmax                                                        365\n",
      "Name: /home/ambika/INF_project/data/car/232121.jpg, dtype: object\n",
      "computer keyboard\n",
      "99\t197\t353\t276\n",
      "laptop\n",
      "43\t0\t365\t375\n",
      "232121\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:29:09.461102 22695 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:29:09.461125 22695 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:29:09.461128 22695 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:29:09.462807 22695 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:29:09.463431 22695 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:29:09.463449 22695 net.cpp:86] Creating Layer data\n",
      "I0430 13:29:09.463457 22695 net.cpp:382] data -> data\n",
      "I0430 13:29:09.463476 22695 net.cpp:124] Setting up data\n",
      "I0430 13:29:09.463487 22695 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:29:09.463493 22695 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:29:09.463500 22695 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:29:09.463511 22695 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:29:09.463518 22695 net.cpp:408] conv1 <- data\n",
      "I0430 13:29:09.463526 22695 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:29:09.463610 22695 net.cpp:124] Setting up conv1\n",
      "I0430 13:29:09.463624 22695 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:29:09.463629 22695 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:29:09.463646 22695 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:29:09.463656 22695 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:29:09.463662 22695 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:29:09.463670 22695 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:29:09.463678 22695 net.cpp:124] Setting up relu1\n",
      "I0430 13:29:09.463686 22695 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:29:09.463692 22695 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:29:09.463697 22695 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:29:09.463706 22695 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:29:09.463711 22695 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:29:09.463717 22695 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:29:09.463729 22695 net.cpp:124] Setting up pool1\n",
      "I0430 13:29:09.463737 22695 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:29:09.463742 22695 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:29:09.463748 22695 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:29:09.463757 22695 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:29:09.463764 22695 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:29:09.463771 22695 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:29:09.463783 22695 net.cpp:124] Setting up norm1\n",
      "I0430 13:29:09.463790 22695 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:29:09.463796 22695 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:29:09.463802 22695 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:29:09.463811 22695 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:29:09.463817 22695 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:29:09.463825 22695 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:29:09.464283 22695 net.cpp:124] Setting up conv2\n",
      "I0430 13:29:09.464294 22695 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:29:09.464296 22695 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:29:09.464304 22695 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:29:09.464309 22695 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:29:09.464313 22695 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:29:09.464316 22695 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:29:09.464323 22695 net.cpp:124] Setting up relu2\n",
      "I0430 13:29:09.464328 22695 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:29:09.464331 22695 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:29:09.464334 22695 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:29:09.464340 22695 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:29:09.464344 22695 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:29:09.464349 22695 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:29:09.464356 22695 net.cpp:124] Setting up pool2\n",
      "I0430 13:29:09.464361 22695 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:29:09.464365 22695 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:29:09.464368 22695 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:29:09.464375 22695 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:29:09.464380 22695 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:29:09.464385 22695 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:29:09.464391 22695 net.cpp:124] Setting up norm2\n",
      "I0430 13:29:09.464396 22695 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:29:09.464399 22695 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:29:09.464403 22695 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:29:09.464409 22695 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:29:09.464413 22695 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:29:09.464418 22695 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:29:09.465729 22695 net.cpp:124] Setting up conv3\n",
      "I0430 13:29:09.465745 22695 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:29:09.465749 22695 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:29:09.465760 22695 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:29:09.465770 22695 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:29:09.465775 22695 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:29:09.465781 22695 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:29:09.465788 22695 net.cpp:124] Setting up relu3\n",
      "I0430 13:29:09.465795 22695 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:29:09.465797 22695 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:29:09.465801 22695 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:29:09.465808 22695 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:29:09.465812 22695 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:29:09.465817 22695 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:29:09.466428 22695 net.cpp:124] Setting up conv4\n",
      "I0430 13:29:09.466439 22695 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:29:09.466441 22695 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:29:09.466449 22695 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:29:09.466456 22695 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:29:09.466460 22695 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:29:09.466466 22695 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:29:09.466472 22695 net.cpp:124] Setting up relu4\n",
      "I0430 13:29:09.466477 22695 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:29:09.466480 22695 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:29:09.466485 22695 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:29:09.466491 22695 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:29:09.466495 22695 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:29:09.466501 22695 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:29:09.467278 22695 net.cpp:124] Setting up conv5\n",
      "I0430 13:29:09.467288 22695 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:29:09.467291 22695 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:29:09.467304 22695 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:29:09.467311 22695 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:29:09.467316 22695 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:29:09.467322 22695 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:29:09.467329 22695 net.cpp:124] Setting up relu5\n",
      "I0430 13:29:09.467334 22695 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:29:09.467337 22695 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:29:09.467341 22695 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:29:09.467347 22695 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:29:09.467350 22695 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:29:09.467356 22695 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:29:09.467365 22695 net.cpp:124] Setting up pool5\n",
      "I0430 13:29:09.467370 22695 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:29:09.467375 22695 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:29:09.467377 22695 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:29:09.467387 22695 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:29:09.467391 22695 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:29:09.467397 22695 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:29:09.495795 22695 net.cpp:124] Setting up fc6\n",
      "I0430 13:29:09.495822 22695 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:29:09.495827 22695 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:29:09.495837 22695 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:29:09.495849 22695 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:29:09.495854 22695 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:29:09.495862 22695 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:29:09.495870 22695 net.cpp:124] Setting up relu6\n",
      "I0430 13:29:09.495875 22695 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:29:09.495878 22695 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:29:09.495882 22695 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:29:09.495888 22695 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:29:09.495893 22695 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:29:09.495898 22695 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:29:09.495904 22695 net.cpp:124] Setting up drop6\n",
      "I0430 13:29:09.495908 22695 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:29:09.495911 22695 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:29:09.495915 22695 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:29:09.495921 22695 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:29:09.495925 22695 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:29:09.495932 22695 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:29:09.508642 22695 net.cpp:124] Setting up fc7\n",
      "I0430 13:29:09.508673 22695 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:29:09.508678 22695 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:29:09.508688 22695 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:29:09.508700 22695 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:29:09.508703 22695 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:29:09.508710 22695 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:29:09.508719 22695 net.cpp:124] Setting up relu7\n",
      "I0430 13:29:09.508723 22695 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:29:09.508728 22695 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:29:09.508733 22695 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:29:09.508739 22695 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:29:09.508744 22695 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:29:09.508749 22695 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:29:09.508757 22695 net.cpp:124] Setting up drop7\n",
      "I0430 13:29:09.508764 22695 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:29:09.508767 22695 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:29:09.508771 22695 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:29:09.508777 22695 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:29:09.508781 22695 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:29:09.508787 22695 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:29:09.509994 22695 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:29:09.510009 22695 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:29:09.510011 22695 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:29:09.510020 22695 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:29:09.510023 22695 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:29:09.510025 22695 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:29:09.510028 22695 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:29:09.510032 22695 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:29:09.510035 22695 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:29:09.510041 22695 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:29:09.510057 22695 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:29:09.510061 22695 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:29:09.510066 22695 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:29:09.510069 22695 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:29:09.510073 22695 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:29:09.510077 22695 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:29:09.510080 22695 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:29:09.510085 22695 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:29:09.510089 22695 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:29:09.510093 22695 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:29:09.510097 22695 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:29:09.510102 22695 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:29:09.510104 22695 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:29:09.510109 22695 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:29:09.510113 22695 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:29:09.510116 22695 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:29:09.510119 22695 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:29:09.510134 22695 net.cpp:257] Network initialization done.\n",
      "I0430 13:29:09.593593 22695 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:29:09.688963 22695 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:29:09.689916 22695 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:29:09.689924 22695 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:29:09.689925 22695 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/166277.jpg'}, '/tmp/tmpqUruKr.mat')\n",
      "Processed 2686 windows in 305.998 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-1.9692, -2.70623, -1.89013, -1.95749, -2.606...\n",
      "ymin                                                      103.5\n",
      "xmin                                                      118.5\n",
      "ymax                                                      356.5\n",
      "xmax                                                        316\n",
      "Name: /home/ambika/INF_project/data/cat/166277.jpg, dtype: object\n",
      "prediction    [-2.20008, -2.73286, -2.02927, -2.18571, -2.22...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                        307\n",
      "xmax                                                        280\n",
      "Name: /home/ambika/INF_project/data/cat/166277.jpg, dtype: object\n",
      "domestic cat\n",
      "118.5\t103.5\t316.0\t356.5\n",
      "dog\n",
      "0.0\t0.0\t280.0\t307.0\n",
      "166277\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:34:17.185148 22908 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:34:17.185173 22908 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:34:17.185175 22908 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:34:17.186305 22908 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:34:17.186570 22908 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:34:17.186584 22908 net.cpp:86] Creating Layer data\n",
      "I0430 13:34:17.186591 22908 net.cpp:382] data -> data\n",
      "I0430 13:34:17.186605 22908 net.cpp:124] Setting up data\n",
      "I0430 13:34:17.186611 22908 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:34:17.186614 22908 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:34:17.186617 22908 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:34:17.186625 22908 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:34:17.186627 22908 net.cpp:408] conv1 <- data\n",
      "I0430 13:34:17.186632 22908 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:34:17.186704 22908 net.cpp:124] Setting up conv1\n",
      "I0430 13:34:17.186712 22908 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:34:17.186715 22908 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:34:17.186727 22908 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:34:17.186733 22908 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:34:17.186738 22908 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:34:17.186743 22908 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:34:17.186748 22908 net.cpp:124] Setting up relu1\n",
      "I0430 13:34:17.186753 22908 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:34:17.186755 22908 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:34:17.186758 22908 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:34:17.186764 22908 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:34:17.186765 22908 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:34:17.186770 22908 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:34:17.186779 22908 net.cpp:124] Setting up pool1\n",
      "I0430 13:34:17.186782 22908 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:34:17.186784 22908 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:34:17.186787 22908 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:34:17.186794 22908 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:34:17.186795 22908 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:34:17.186800 22908 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:34:17.186806 22908 net.cpp:124] Setting up norm1\n",
      "I0430 13:34:17.186810 22908 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:34:17.186813 22908 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:34:17.186816 22908 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:34:17.186821 22908 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:34:17.186823 22908 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:34:17.186828 22908 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:34:17.187181 22908 net.cpp:124] Setting up conv2\n",
      "I0430 13:34:17.187188 22908 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:34:17.187192 22908 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:34:17.187201 22908 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:34:17.187240 22908 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:34:17.187244 22908 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:34:17.187249 22908 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:34:17.187254 22908 net.cpp:124] Setting up relu2\n",
      "I0430 13:34:17.187258 22908 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:34:17.187261 22908 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:34:17.187264 22908 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:34:17.187268 22908 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:34:17.187271 22908 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:34:17.187276 22908 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:34:17.187283 22908 net.cpp:124] Setting up pool2\n",
      "I0430 13:34:17.187286 22908 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:34:17.187289 22908 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:34:17.187292 22908 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:34:17.187299 22908 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:34:17.187301 22908 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:34:17.187306 22908 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:34:17.187311 22908 net.cpp:124] Setting up norm2\n",
      "I0430 13:34:17.187315 22908 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:34:17.187319 22908 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:34:17.187321 22908 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:34:17.187327 22908 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:34:17.187330 22908 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:34:17.187335 22908 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:34:17.188050 22908 net.cpp:124] Setting up conv3\n",
      "I0430 13:34:17.188061 22908 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:34:17.188066 22908 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:34:17.188076 22908 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:34:17.188083 22908 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:34:17.188087 22908 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:34:17.188092 22908 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:34:17.188098 22908 net.cpp:124] Setting up relu3\n",
      "I0430 13:34:17.188102 22908 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:34:17.188105 22908 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:34:17.188108 22908 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:34:17.188115 22908 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:34:17.188117 22908 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:34:17.188122 22908 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:34:17.188870 22908 net.cpp:124] Setting up conv4\n",
      "I0430 13:34:17.188880 22908 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:34:17.188884 22908 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:34:17.188891 22908 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:34:17.188897 22908 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:34:17.188901 22908 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:34:17.188907 22908 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:34:17.188912 22908 net.cpp:124] Setting up relu4\n",
      "I0430 13:34:17.188916 22908 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:34:17.188920 22908 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:34:17.188922 22908 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:34:17.188930 22908 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:34:17.188931 22908 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:34:17.188936 22908 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:34:17.189446 22908 net.cpp:124] Setting up conv5\n",
      "I0430 13:34:17.189453 22908 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:34:17.189457 22908 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:34:17.189468 22908 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:34:17.189473 22908 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:34:17.189476 22908 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:34:17.189481 22908 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:34:17.189486 22908 net.cpp:124] Setting up relu5\n",
      "I0430 13:34:17.189491 22908 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:34:17.189493 22908 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:34:17.189496 22908 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:34:17.189502 22908 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:34:17.189503 22908 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:34:17.189508 22908 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:34:17.189515 22908 net.cpp:124] Setting up pool5\n",
      "I0430 13:34:17.189519 22908 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:34:17.189522 22908 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:34:17.189525 22908 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:34:17.189533 22908 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:34:17.189537 22908 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:34:17.189541 22908 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:34:17.210712 22908 net.cpp:124] Setting up fc6\n",
      "I0430 13:34:17.210736 22908 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:34:17.210741 22908 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:34:17.210749 22908 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:34:17.210759 22908 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:34:17.210764 22908 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:34:17.210770 22908 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:34:17.210778 22908 net.cpp:124] Setting up relu6\n",
      "I0430 13:34:17.210783 22908 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:34:17.210785 22908 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:34:17.210788 22908 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:34:17.210793 22908 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:34:17.210805 22908 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:34:17.210809 22908 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:34:17.210815 22908 net.cpp:124] Setting up drop6\n",
      "I0430 13:34:17.210819 22908 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:34:17.210821 22908 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:34:17.210824 22908 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:34:17.210830 22908 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:34:17.210834 22908 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:34:17.210839 22908 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:34:17.221196 22908 net.cpp:124] Setting up fc7\n",
      "I0430 13:34:17.221225 22908 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:34:17.221230 22908 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:34:17.221256 22908 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:34:17.221266 22908 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:34:17.221269 22908 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:34:17.221276 22908 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:34:17.221282 22908 net.cpp:124] Setting up relu7\n",
      "I0430 13:34:17.221287 22908 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:34:17.221289 22908 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:34:17.221292 22908 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:34:17.221297 22908 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:34:17.221300 22908 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:34:17.221307 22908 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:34:17.221312 22908 net.cpp:124] Setting up drop7\n",
      "I0430 13:34:17.221315 22908 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:34:17.221318 22908 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:34:17.221321 22908 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:34:17.221326 22908 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:34:17.221328 22908 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:34:17.221333 22908 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:34:17.222224 22908 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:34:17.222235 22908 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:34:17.222239 22908 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:34:17.222245 22908 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:34:17.222249 22908 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:34:17.222251 22908 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:34:17.222254 22908 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:34:17.222256 22908 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:34:17.222259 22908 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:34:17.222261 22908 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:34:17.222265 22908 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:34:17.222268 22908 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:34:17.222271 22908 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:34:17.222275 22908 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:34:17.222278 22908 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:34:17.222282 22908 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:34:17.222285 22908 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:34:17.222290 22908 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:34:17.222292 22908 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:34:17.222295 22908 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:34:17.222299 22908 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:34:17.222302 22908 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:34:17.222306 22908 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:34:17.222309 22908 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:34:17.222312 22908 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:34:17.222316 22908 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:34:17.222319 22908 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:34:17.222329 22908 net.cpp:257] Network initialization done.\n",
      "I0430 13:34:17.302356 22908 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:34:17.393599 22908 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:34:17.394546 22908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:34:17.394556 22908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:34:17.394560 22908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/398489.jpg'}, '/tmp/tmpisKR6i.mat')\n",
      "Processed 2418 windows in 272.054 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-1.67751, -2.55763, -1.67844, -1.65901, -2.15...\n",
      "ymin                                                          7\n",
      "xmin                                                         98\n",
      "ymax                                                        375\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/couch/398489.jpg, dtype: object\n",
      "prediction    [-1.47155, -2.04816, -1.68233, -1.89691, -1.91...\n",
      "ymin                                                        166\n",
      "xmin                                                         98\n",
      "ymax                                                        365\n",
      "xmax                                                        418\n",
      "Name: /home/ambika/INF_project/data/couch/398489.jpg, dtype: object\n",
      "domestic cat\n",
      "98\t7\t500\t375\n",
      "dog\n",
      "98\t166\t418\t365\n",
      "398489\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:38:50.917924 23112 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:38:50.917945 23112 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:38:50.917949 23112 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:38:50.919066 23112 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:38:50.919266 23112 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:38:50.919275 23112 net.cpp:86] Creating Layer data\n",
      "I0430 13:38:50.919277 23112 net.cpp:382] data -> data\n",
      "I0430 13:38:50.919288 23112 net.cpp:124] Setting up data\n",
      "I0430 13:38:50.919293 23112 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:38:50.919296 23112 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:38:50.919297 23112 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:38:50.919302 23112 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:38:50.919304 23112 net.cpp:408] conv1 <- data\n",
      "I0430 13:38:50.919308 23112 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:38:50.919368 23112 net.cpp:124] Setting up conv1\n",
      "I0430 13:38:50.919373 23112 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:38:50.919376 23112 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:38:50.919384 23112 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:38:50.919389 23112 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:38:50.919392 23112 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:38:50.919396 23112 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:38:50.919401 23112 net.cpp:124] Setting up relu1\n",
      "I0430 13:38:50.919406 23112 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:38:50.919409 23112 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:38:50.919411 23112 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:38:50.919416 23112 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:38:50.919420 23112 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:38:50.919423 23112 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:38:50.919430 23112 net.cpp:124] Setting up pool1\n",
      "I0430 13:38:50.919435 23112 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:38:50.919437 23112 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:38:50.919440 23112 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:38:50.919446 23112 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:38:50.919450 23112 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:38:50.919456 23112 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:38:50.919461 23112 net.cpp:124] Setting up norm1\n",
      "I0430 13:38:50.919466 23112 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:38:50.919468 23112 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:38:50.919471 23112 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:38:50.919476 23112 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:38:50.919479 23112 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:38:50.919483 23112 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:38:50.919821 23112 net.cpp:124] Setting up conv2\n",
      "I0430 13:38:50.919827 23112 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:38:50.919831 23112 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:38:50.919837 23112 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:38:50.919845 23112 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:38:50.919848 23112 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:38:50.919853 23112 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:38:50.919857 23112 net.cpp:124] Setting up relu2\n",
      "I0430 13:38:50.919862 23112 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:38:50.919864 23112 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:38:50.919867 23112 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:38:50.919872 23112 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:38:50.919874 23112 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:38:50.919878 23112 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:38:50.919884 23112 net.cpp:124] Setting up pool2\n",
      "I0430 13:38:50.919888 23112 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:38:50.919891 23112 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:38:50.919894 23112 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:38:50.919900 23112 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:38:50.919903 23112 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:38:50.919908 23112 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:38:50.919912 23112 net.cpp:124] Setting up norm2\n",
      "I0430 13:38:50.919917 23112 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:38:50.919919 23112 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:38:50.919922 23112 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:38:50.919929 23112 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:38:50.919931 23112 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:38:50.919936 23112 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:38:50.920627 23112 net.cpp:124] Setting up conv3\n",
      "I0430 13:38:50.920639 23112 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:38:50.920642 23112 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:38:50.920651 23112 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:38:50.920657 23112 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:38:50.920660 23112 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:38:50.920665 23112 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:38:50.920671 23112 net.cpp:124] Setting up relu3\n",
      "I0430 13:38:50.920675 23112 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:38:50.920678 23112 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:38:50.920681 23112 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:38:50.920688 23112 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:38:50.920691 23112 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:38:50.920696 23112 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:38:50.921509 23112 net.cpp:124] Setting up conv4\n",
      "I0430 13:38:50.921526 23112 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:38:50.921530 23112 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:38:50.921536 23112 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:38:50.921543 23112 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:38:50.921546 23112 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:38:50.921552 23112 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:38:50.921558 23112 net.cpp:124] Setting up relu4\n",
      "I0430 13:38:50.921562 23112 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:38:50.921564 23112 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:38:50.921568 23112 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:38:50.921576 23112 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:38:50.921577 23112 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:38:50.921582 23112 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:38:50.922070 23112 net.cpp:124] Setting up conv5\n",
      "I0430 13:38:50.922076 23112 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:38:50.922080 23112 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:38:50.922087 23112 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:38:50.922092 23112 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:38:50.922096 23112 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:38:50.922101 23112 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:38:50.922106 23112 net.cpp:124] Setting up relu5\n",
      "I0430 13:38:50.922109 23112 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:38:50.922111 23112 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:38:50.922116 23112 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:38:50.922124 23112 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:38:50.922127 23112 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:38:50.922132 23112 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:38:50.922139 23112 net.cpp:124] Setting up pool5\n",
      "I0430 13:38:50.922143 23112 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:38:50.922147 23112 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:38:50.922149 23112 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:38:50.922157 23112 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:38:50.922159 23112 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:38:50.922164 23112 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:38:50.943431 23112 net.cpp:124] Setting up fc6\n",
      "I0430 13:38:50.943455 23112 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:38:50.943459 23112 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:38:50.943470 23112 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:38:50.943480 23112 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:38:50.943485 23112 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:38:50.943490 23112 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:38:50.943498 23112 net.cpp:124] Setting up relu6\n",
      "I0430 13:38:50.943502 23112 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:38:50.943506 23112 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:38:50.943508 23112 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:38:50.943514 23112 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:38:50.943517 23112 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:38:50.943521 23112 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:38:50.943527 23112 net.cpp:124] Setting up drop6\n",
      "I0430 13:38:50.943531 23112 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:38:50.943533 23112 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:38:50.943536 23112 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:38:50.943542 23112 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:38:50.943544 23112 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:38:50.943550 23112 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:38:50.955315 23112 net.cpp:124] Setting up fc7\n",
      "I0430 13:38:50.955338 23112 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:38:50.955343 23112 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:38:50.955353 23112 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:38:50.955363 23112 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:38:50.955366 23112 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:38:50.955373 23112 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:38:50.955380 23112 net.cpp:124] Setting up relu7\n",
      "I0430 13:38:50.955384 23112 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:38:50.955386 23112 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:38:50.955389 23112 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:38:50.955396 23112 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:38:50.955399 23112 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:38:50.955404 23112 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:38:50.955410 23112 net.cpp:124] Setting up drop7\n",
      "I0430 13:38:50.955412 23112 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:38:50.955415 23112 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:38:50.955418 23112 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:38:50.955423 23112 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:38:50.955426 23112 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:38:50.955431 23112 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:38:50.956341 23112 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:38:50.956359 23112 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:38:50.956363 23112 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:38:50.956370 23112 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:38:50.956373 23112 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:38:50.956377 23112 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:38:50.956380 23112 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:38:50.956383 23112 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:38:50.956387 23112 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:38:50.956389 23112 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:38:50.956393 23112 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:38:50.956395 23112 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:38:50.956398 23112 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:38:50.956401 23112 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:38:50.956404 23112 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:38:50.956408 23112 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:38:50.956411 23112 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:38:50.956414 23112 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:38:50.956418 23112 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:38:50.956421 23112 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:38:50.956424 23112 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:38:50.956428 23112 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:38:50.956430 23112 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:38:50.956434 23112 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:38:50.956436 23112 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:38:50.956439 23112 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:38:50.956442 23112 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:38:50.956454 23112 net.cpp:257] Network initialization done.\n",
      "I0430 13:38:51.035511 23112 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:38:51.125736 23112 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:38:51.126595 23112 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:38:51.126602 23112 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:38:51.126606 23112 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/101312.jpg'}, '/tmp/tmp5klrLs.mat')\n",
      "Processed 2735 windows in 312.076 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-1.90417, -2.20869, -1.63718, -1.58435, -1.71...\n",
      "ymin                                                       97.5\n",
      "xmin                                                     296.25\n",
      "ymax                                                     343.75\n",
      "xmax                                                     375.25\n",
      "Name: /home/ambika/INF_project/data/dog/101312.jpg, dtype: object\n",
      "prediction    [-2.06801, -2.00604, -2.05269, -2.10695, -2.00...\n",
      "ymin                                                          0\n",
      "xmin                                                          0\n",
      "ymax                                                      500.5\n",
      "xmax                                                     375.25\n",
      "Name: /home/ambika/INF_project/data/dog/101312.jpg, dtype: object\n",
      "chair\n",
      "296.25\t97.5\t375.25\t343.75\n",
      "person\n",
      "0.0\t0.0\t375.25\t500.5\n",
      "101312\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:44:04.705929 23358 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:44:04.705950 23358 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:44:04.705953 23358 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:44:04.707089 23358 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:44:04.707334 23358 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:44:04.707343 23358 net.cpp:86] Creating Layer data\n",
      "I0430 13:44:04.707351 23358 net.cpp:382] data -> data\n",
      "I0430 13:44:04.707368 23358 net.cpp:124] Setting up data\n",
      "I0430 13:44:04.707375 23358 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:44:04.707377 23358 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:44:04.707381 23358 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:44:04.707388 23358 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:44:04.707391 23358 net.cpp:408] conv1 <- data\n",
      "I0430 13:44:04.707396 23358 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:44:04.707463 23358 net.cpp:124] Setting up conv1\n",
      "I0430 13:44:04.707468 23358 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:44:04.707473 23358 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:44:04.707481 23358 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:44:04.707487 23358 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:44:04.707491 23358 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:44:04.707495 23358 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:44:04.707501 23358 net.cpp:124] Setting up relu1\n",
      "I0430 13:44:04.707506 23358 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:44:04.707509 23358 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:44:04.707512 23358 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:44:04.707517 23358 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:44:04.707520 23358 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:44:04.707525 23358 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:44:04.707532 23358 net.cpp:124] Setting up pool1\n",
      "I0430 13:44:04.707537 23358 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:44:04.707540 23358 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:44:04.707542 23358 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:44:04.707548 23358 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:44:04.707551 23358 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:44:04.707556 23358 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:44:04.707561 23358 net.cpp:124] Setting up norm1\n",
      "I0430 13:44:04.707566 23358 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:44:04.707568 23358 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:44:04.707571 23358 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:44:04.707576 23358 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:44:04.707578 23358 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:44:04.707583 23358 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:44:04.707940 23358 net.cpp:124] Setting up conv2\n",
      "I0430 13:44:04.707947 23358 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:44:04.707950 23358 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:44:04.707958 23358 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:44:04.707964 23358 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:44:04.707967 23358 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:44:04.707972 23358 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:44:04.707978 23358 net.cpp:124] Setting up relu2\n",
      "I0430 13:44:04.707981 23358 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:44:04.707983 23358 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:44:04.707986 23358 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:44:04.707991 23358 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:44:04.707994 23358 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:44:04.707998 23358 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:44:04.708004 23358 net.cpp:124] Setting up pool2\n",
      "I0430 13:44:04.708009 23358 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:44:04.708011 23358 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:44:04.708014 23358 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:44:04.708021 23358 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:44:04.708024 23358 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:44:04.708029 23358 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:44:04.708034 23358 net.cpp:124] Setting up norm2\n",
      "I0430 13:44:04.708039 23358 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:44:04.708040 23358 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:44:04.708043 23358 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:44:04.708050 23358 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:44:04.708052 23358 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:44:04.708056 23358 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:44:04.708755 23358 net.cpp:124] Setting up conv3\n",
      "I0430 13:44:04.708766 23358 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:44:04.708770 23358 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:44:04.708780 23358 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:44:04.708786 23358 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:44:04.708788 23358 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:44:04.708793 23358 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:44:04.708798 23358 net.cpp:124] Setting up relu3\n",
      "I0430 13:44:04.708803 23358 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:44:04.708806 23358 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:44:04.708808 23358 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:44:04.708816 23358 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:44:04.708818 23358 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:44:04.708822 23358 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:44:04.709563 23358 net.cpp:124] Setting up conv4\n",
      "I0430 13:44:04.709573 23358 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:44:04.709576 23358 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:44:04.709583 23358 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:44:04.709589 23358 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:44:04.709592 23358 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:44:04.709597 23358 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:44:04.709602 23358 net.cpp:124] Setting up relu4\n",
      "I0430 13:44:04.709606 23358 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:44:04.709609 23358 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:44:04.709611 23358 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:44:04.709619 23358 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:44:04.709622 23358 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:44:04.709626 23358 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:44:04.710134 23358 net.cpp:124] Setting up conv5\n",
      "I0430 13:44:04.710144 23358 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:44:04.710147 23358 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:44:04.710157 23358 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:44:04.710163 23358 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:44:04.710166 23358 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:44:04.710170 23358 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:44:04.710175 23358 net.cpp:124] Setting up relu5\n",
      "I0430 13:44:04.710180 23358 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:44:04.710182 23358 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:44:04.710186 23358 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:44:04.710191 23358 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:44:04.710192 23358 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:44:04.710198 23358 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:44:04.710206 23358 net.cpp:124] Setting up pool5\n",
      "I0430 13:44:04.710209 23358 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:44:04.710212 23358 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:44:04.710216 23358 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:44:04.710222 23358 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:44:04.710225 23358 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:44:04.710229 23358 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:44:04.731789 23358 net.cpp:124] Setting up fc6\n",
      "I0430 13:44:04.731813 23358 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:44:04.731817 23358 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:44:04.731827 23358 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:44:04.731835 23358 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:44:04.731839 23358 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:44:04.731844 23358 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:44:04.731853 23358 net.cpp:124] Setting up relu6\n",
      "I0430 13:44:04.731855 23358 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:44:04.731858 23358 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:44:04.731892 23358 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:44:04.731899 23358 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:44:04.731900 23358 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:44:04.731905 23358 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:44:04.731911 23358 net.cpp:124] Setting up drop6\n",
      "I0430 13:44:04.731914 23358 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:44:04.731917 23358 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:44:04.731920 23358 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:44:04.731926 23358 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:44:04.731930 23358 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:44:04.731935 23358 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:44:04.741442 23358 net.cpp:124] Setting up fc7\n",
      "I0430 13:44:04.741466 23358 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:44:04.741472 23358 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:44:04.741480 23358 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:44:04.741489 23358 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:44:04.741493 23358 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:44:04.741498 23358 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:44:04.741504 23358 net.cpp:124] Setting up relu7\n",
      "I0430 13:44:04.741508 23358 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:44:04.741510 23358 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:44:04.741513 23358 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:44:04.741533 23358 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:44:04.741536 23358 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:44:04.741541 23358 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:44:04.741547 23358 net.cpp:124] Setting up drop7\n",
      "I0430 13:44:04.741550 23358 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:44:04.741554 23358 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:44:04.741556 23358 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:44:04.741561 23358 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:44:04.741564 23358 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:44:04.741569 23358 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:44:04.742241 23358 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:44:04.742254 23358 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:44:04.742257 23358 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:44:04.742265 23358 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:44:04.742269 23358 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:44:04.742272 23358 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:44:04.742276 23358 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:44:04.742280 23358 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:44:04.742282 23358 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:44:04.742285 23358 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:44:04.742290 23358 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:44:04.742292 23358 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:44:04.742295 23358 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:44:04.742298 23358 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:44:04.742303 23358 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:44:04.742310 23358 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:44:04.742313 23358 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:44:04.742319 23358 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:44:04.742326 23358 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:44:04.742328 23358 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:44:04.742331 23358 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:44:04.742334 23358 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:44:04.742337 23358 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:44:04.742341 23358 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:44:04.742344 23358 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:44:04.742347 23358 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:44:04.742350 23358 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:44:04.742362 23358 net.cpp:257] Network initialization done.\n",
      "I0430 13:44:04.823882 23358 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:44:04.916540 23358 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:44:04.917526 23358 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:44:04.917534 23358 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:44:04.917538 23358 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/391933.jpg'}, '/tmp/tmpZvBMXO.mat')\n",
      "Processed 2951 windows in 336.544 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.28608, -2.73572, -1.60026, -1.9508, -1.905...\n",
      "ymin                                                         74\n",
      "xmin                                                        182\n",
      "ymax                                                        166\n",
      "xmax                                                        249\n",
      "Name: /home/ambika/INF_project/data/horse/391933.jpg, dtype: object\n",
      "prediction    [-2.05163, -2.33899, -1.85158, -2.23381, -1.57...\n",
      "ymin                                                         98\n",
      "xmin                                                        165\n",
      "ymax                                                        310\n",
      "xmax                                                        292\n",
      "Name: /home/ambika/INF_project/data/horse/391933.jpg, dtype: object\n",
      "person\n",
      "182\t74\t249\t166\n",
      "dog\n",
      "165\t98\t292\t310\n",
      "391933\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:49:42.941838 23589 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:49:42.941857 23589 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:49:42.941861 23589 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:49:42.942951 23589 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:49:42.943107 23589 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:49:42.943119 23589 net.cpp:86] Creating Layer data\n",
      "I0430 13:49:42.943122 23589 net.cpp:382] data -> data\n",
      "I0430 13:49:42.943136 23589 net.cpp:124] Setting up data\n",
      "I0430 13:49:42.943142 23589 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:49:42.943145 23589 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:49:42.943148 23589 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:49:42.943156 23589 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:49:42.943158 23589 net.cpp:408] conv1 <- data\n",
      "I0430 13:49:42.943163 23589 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:49:42.943236 23589 net.cpp:124] Setting up conv1\n",
      "I0430 13:49:42.943243 23589 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:49:42.943246 23589 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:49:42.943254 23589 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:49:42.943259 23589 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:49:42.943262 23589 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:49:42.943267 23589 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:49:42.943272 23589 net.cpp:124] Setting up relu1\n",
      "I0430 13:49:42.943276 23589 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:49:42.943279 23589 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:49:42.943281 23589 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:49:42.943286 23589 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:49:42.943289 23589 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:49:42.943294 23589 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:49:42.943300 23589 net.cpp:124] Setting up pool1\n",
      "I0430 13:49:42.943305 23589 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:49:42.943307 23589 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:49:42.943310 23589 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:49:42.943315 23589 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:49:42.943318 23589 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:49:42.943322 23589 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:49:42.943328 23589 net.cpp:124] Setting up norm1\n",
      "I0430 13:49:42.943332 23589 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:49:42.943336 23589 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:49:42.943338 23589 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:49:42.943343 23589 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:49:42.943346 23589 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:49:42.943351 23589 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:49:42.943688 23589 net.cpp:124] Setting up conv2\n",
      "I0430 13:49:42.943696 23589 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:49:42.943698 23589 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:49:42.943704 23589 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:49:42.943709 23589 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:49:42.943712 23589 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:49:42.943717 23589 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:49:42.943722 23589 net.cpp:124] Setting up relu2\n",
      "I0430 13:49:42.943727 23589 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:49:42.943729 23589 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:49:42.943732 23589 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:49:42.943738 23589 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:49:42.943742 23589 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:49:42.943745 23589 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:49:42.943752 23589 net.cpp:124] Setting up pool2\n",
      "I0430 13:49:42.943756 23589 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:49:42.943758 23589 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:49:42.943761 23589 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:49:42.943766 23589 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:49:42.943768 23589 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:49:42.943773 23589 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:49:42.943778 23589 net.cpp:124] Setting up norm2\n",
      "I0430 13:49:42.943783 23589 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:49:42.943785 23589 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:49:42.943789 23589 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:49:42.943794 23589 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:49:42.943797 23589 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:49:42.943802 23589 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:49:42.944470 23589 net.cpp:124] Setting up conv3\n",
      "I0430 13:49:42.944481 23589 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:49:42.944485 23589 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:49:42.944494 23589 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:49:42.944499 23589 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:49:42.944502 23589 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:49:42.944506 23589 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:49:42.944511 23589 net.cpp:124] Setting up relu3\n",
      "I0430 13:49:42.944515 23589 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:49:42.944519 23589 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:49:42.944521 23589 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:49:42.944527 23589 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:49:42.944530 23589 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:49:42.944535 23589 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:49:42.945264 23589 net.cpp:124] Setting up conv4\n",
      "I0430 13:49:42.945276 23589 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:49:42.945278 23589 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:49:42.945286 23589 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:49:42.945291 23589 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:49:42.945294 23589 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:49:42.945299 23589 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:49:42.945303 23589 net.cpp:124] Setting up relu4\n",
      "I0430 13:49:42.945308 23589 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:49:42.945310 23589 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:49:42.945313 23589 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:49:42.945318 23589 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:49:42.945322 23589 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:49:42.945325 23589 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:49:42.945827 23589 net.cpp:124] Setting up conv5\n",
      "I0430 13:49:42.945834 23589 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:49:42.945838 23589 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:49:42.945847 23589 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:49:42.945852 23589 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:49:42.945855 23589 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:49:42.945859 23589 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:49:42.945863 23589 net.cpp:124] Setting up relu5\n",
      "I0430 13:49:42.945868 23589 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:49:42.945870 23589 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:49:42.945873 23589 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:49:42.945878 23589 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:49:42.945880 23589 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:49:42.945886 23589 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:49:42.945894 23589 net.cpp:124] Setting up pool5\n",
      "I0430 13:49:42.945897 23589 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:49:42.945899 23589 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:49:42.945902 23589 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:49:42.945910 23589 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:49:42.945914 23589 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:49:42.945917 23589 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:49:42.967094 23589 net.cpp:124] Setting up fc6\n",
      "I0430 13:49:42.967114 23589 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:49:42.967118 23589 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:49:42.967128 23589 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:49:42.967140 23589 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:49:42.967144 23589 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:49:42.967149 23589 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:49:42.967155 23589 net.cpp:124] Setting up relu6\n",
      "I0430 13:49:42.967159 23589 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:49:42.967160 23589 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:49:42.967162 23589 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:49:42.967166 23589 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:49:42.967167 23589 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:49:42.967170 23589 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:49:42.967175 23589 net.cpp:124] Setting up drop6\n",
      "I0430 13:49:42.967185 23589 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:49:42.967188 23589 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:49:42.967190 23589 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:49:42.967196 23589 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:49:42.967198 23589 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:49:42.967202 23589 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:49:42.976985 23589 net.cpp:124] Setting up fc7\n",
      "I0430 13:49:42.977005 23589 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:49:42.977007 23589 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:49:42.977015 23589 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:49:42.977021 23589 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:49:42.977023 23589 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:49:42.977028 23589 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:49:42.977035 23589 net.cpp:124] Setting up relu7\n",
      "I0430 13:49:42.977036 23589 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:49:42.977038 23589 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:49:42.977041 23589 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:49:42.977044 23589 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:49:42.977046 23589 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:49:42.977048 23589 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:49:42.977052 23589 net.cpp:124] Setting up drop7\n",
      "I0430 13:49:42.977056 23589 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:49:42.977056 23589 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:49:42.977058 23589 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:49:42.977061 23589 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:49:42.977063 23589 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:49:42.977066 23589 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:49:42.978034 23589 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:49:42.978049 23589 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:49:42.978052 23589 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:49:42.978062 23589 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:49:42.978067 23589 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:49:42.978071 23589 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:49:42.978075 23589 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:49:42.978078 23589 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:49:42.978082 23589 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:49:42.978085 23589 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:49:42.978091 23589 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:49:42.978093 23589 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:49:42.978096 23589 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:49:42.978099 23589 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:49:42.978102 23589 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:49:42.978106 23589 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:49:42.978109 23589 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:49:42.978112 23589 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:49:42.978116 23589 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:49:42.978118 23589 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:49:42.978121 23589 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:49:42.978126 23589 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:49:42.978128 23589 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:49:42.978132 23589 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:49:42.978134 23589 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:49:42.978137 23589 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:49:42.978140 23589 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:49:42.978152 23589 net.cpp:257] Network initialization done.\n",
      "I0430 13:49:43.058607 23589 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:49:43.151396 23589 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:49:43.152285 23589 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:49:43.152294 23589 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:49:43.152298 23589 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/199610.jpg'}, '/tmp/tmpw835Xu.mat')\n",
      "Processed 2552 windows in 286.116 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.032 s.\n",
      "prediction    [-2.00059, -2.32019, -2.09378, -3.09258, -1.07...\n",
      "ymin                                                        126\n",
      "xmin                                                         88\n",
      "ymax                                                        333\n",
      "xmax                                                        205\n",
      "Name: /home/ambika/INF_project/data/person/199610.jpg, dtype: object\n",
      "prediction    [-2.18249, -1.9999, -1.68281, -2.1745, -1.9819...\n",
      "ymin                                                         27\n",
      "xmin                                                        471\n",
      "ymax                                                         84\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/person/199610.jpg, dtype: object\n",
      "sheep\n",
      "88\t126\t205\t333\n",
      "person\n",
      "471\t27\t500\t84\n",
      "199610\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:54:30.864606 23812 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:54:30.864635 23812 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:54:30.864641 23812 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:54:30.865804 23812 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:54:30.865978 23812 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:54:30.865990 23812 net.cpp:86] Creating Layer data\n",
      "I0430 13:54:30.865998 23812 net.cpp:382] data -> data\n",
      "I0430 13:54:30.866013 23812 net.cpp:124] Setting up data\n",
      "I0430 13:54:30.866019 23812 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:54:30.866022 23812 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:54:30.866025 23812 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:54:30.866032 23812 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:54:30.866035 23812 net.cpp:408] conv1 <- data\n",
      "I0430 13:54:30.866041 23812 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:54:30.866109 23812 net.cpp:124] Setting up conv1\n",
      "I0430 13:54:30.866117 23812 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:54:30.866119 23812 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:54:30.866128 23812 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:54:30.866133 23812 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:54:30.866137 23812 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:54:30.866142 23812 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:54:30.866147 23812 net.cpp:124] Setting up relu1\n",
      "I0430 13:54:30.866152 23812 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:54:30.866153 23812 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:54:30.866158 23812 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:54:30.866163 23812 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:54:30.866164 23812 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:54:30.866169 23812 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:54:30.866178 23812 net.cpp:124] Setting up pool1\n",
      "I0430 13:54:30.866183 23812 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:54:30.866184 23812 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:54:30.866188 23812 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:54:30.866194 23812 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:54:30.866196 23812 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:54:30.866200 23812 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:54:30.866206 23812 net.cpp:124] Setting up norm1\n",
      "I0430 13:54:30.866211 23812 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:54:30.866214 23812 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:54:30.866216 23812 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:54:30.866222 23812 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:54:30.866225 23812 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:54:30.866230 23812 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:54:30.866614 23812 net.cpp:124] Setting up conv2\n",
      "I0430 13:54:30.866626 23812 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:54:30.866629 23812 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:54:30.866638 23812 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:54:30.866644 23812 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:54:30.866648 23812 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:54:30.866653 23812 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:54:30.866660 23812 net.cpp:124] Setting up relu2\n",
      "I0430 13:54:30.866664 23812 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:54:30.866667 23812 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:54:30.866670 23812 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:54:30.866680 23812 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:54:30.866683 23812 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:54:30.866689 23812 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:54:30.866696 23812 net.cpp:124] Setting up pool2\n",
      "I0430 13:54:30.866701 23812 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:54:30.866703 23812 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:54:30.866706 23812 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:54:30.866713 23812 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:54:30.866715 23812 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:54:30.866720 23812 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:54:30.866726 23812 net.cpp:124] Setting up norm2\n",
      "I0430 13:54:30.866731 23812 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:54:30.866734 23812 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:54:30.866736 23812 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:54:30.866744 23812 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:54:30.866746 23812 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:54:30.866751 23812 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:54:30.867483 23812 net.cpp:124] Setting up conv3\n",
      "I0430 13:54:30.867501 23812 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:54:30.867506 23812 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:54:30.867516 23812 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:54:30.867527 23812 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:54:30.867532 23812 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:54:30.867537 23812 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:54:30.867544 23812 net.cpp:124] Setting up relu3\n",
      "I0430 13:54:30.867550 23812 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:54:30.867552 23812 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:54:30.867557 23812 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:54:30.867570 23812 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:54:30.867573 23812 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:54:30.867578 23812 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:54:30.868345 23812 net.cpp:124] Setting up conv4\n",
      "I0430 13:54:30.868363 23812 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:54:30.868366 23812 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:54:30.868373 23812 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:54:30.868382 23812 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:54:30.868386 23812 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:54:30.868391 23812 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:54:30.868397 23812 net.cpp:124] Setting up relu4\n",
      "I0430 13:54:30.868402 23812 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:54:30.868404 23812 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:54:30.868408 23812 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:54:30.868415 23812 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:54:30.868418 23812 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:54:30.868423 23812 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:54:30.868962 23812 net.cpp:124] Setting up conv5\n",
      "I0430 13:54:30.868973 23812 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:54:30.868975 23812 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:54:30.868988 23812 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:54:30.868995 23812 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:54:30.868998 23812 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:54:30.869004 23812 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:54:30.869009 23812 net.cpp:124] Setting up relu5\n",
      "I0430 13:54:30.869014 23812 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:54:30.869016 23812 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:54:30.869020 23812 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:54:30.869025 23812 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:54:30.869029 23812 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:54:30.869033 23812 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:54:30.869041 23812 net.cpp:124] Setting up pool5\n",
      "I0430 13:54:30.869045 23812 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:54:30.869048 23812 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:54:30.869051 23812 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:54:30.869060 23812 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:54:30.869065 23812 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:54:30.869069 23812 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:54:30.892808 23812 net.cpp:124] Setting up fc6\n",
      "I0430 13:54:30.892832 23812 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:54:30.892838 23812 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:54:30.892848 23812 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:54:30.892858 23812 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:54:30.892861 23812 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:54:30.892868 23812 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:54:30.892874 23812 net.cpp:124] Setting up relu6\n",
      "I0430 13:54:30.892879 23812 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:54:30.892884 23812 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:54:30.892889 23812 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:54:30.892895 23812 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:54:30.892899 23812 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:54:30.892904 23812 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:54:30.892909 23812 net.cpp:124] Setting up drop6\n",
      "I0430 13:54:30.892911 23812 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:54:30.892913 23812 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:54:30.892916 23812 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:54:30.892920 23812 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:54:30.892922 23812 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:54:30.892927 23812 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:54:30.902969 23812 net.cpp:124] Setting up fc7\n",
      "I0430 13:54:30.903012 23812 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:54:30.903017 23812 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:54:30.903028 23812 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:54:30.903036 23812 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:54:30.903041 23812 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:54:30.903048 23812 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:54:30.903056 23812 net.cpp:124] Setting up relu7\n",
      "I0430 13:54:30.903061 23812 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:54:30.903064 23812 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:54:30.903069 23812 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:54:30.903075 23812 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:54:30.903077 23812 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:54:30.903082 23812 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:54:30.903087 23812 net.cpp:124] Setting up drop7\n",
      "I0430 13:54:30.903090 23812 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:54:30.903092 23812 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:54:30.903095 23812 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:54:30.903100 23812 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:54:30.903102 23812 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:54:30.903105 23812 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:54:30.904038 23812 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:54:30.904057 23812 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:54:30.904060 23812 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:54:30.904072 23812 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:54:30.904078 23812 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:54:30.904079 23812 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:54:30.904081 23812 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:54:30.904084 23812 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:54:30.904088 23812 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:54:30.904089 23812 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:54:30.904093 23812 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:54:30.904095 23812 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:54:30.904109 23812 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:54:30.904112 23812 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:54:30.904115 23812 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:54:30.904119 23812 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:54:30.904124 23812 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:54:30.904126 23812 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:54:30.904130 23812 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:54:30.904134 23812 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:54:30.904137 23812 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:54:30.904140 23812 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:54:30.904144 23812 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:54:30.904147 23812 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:54:30.904150 23812 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:54:30.904152 23812 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:54:30.904155 23812 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:54:30.904167 23812 net.cpp:257] Network initialization done.\n",
      "I0430 13:54:31.000955 23812 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:54:31.094943 23812 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:54:31.096825 23812 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:54:31.096842 23812 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:54:31.096845 23812 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/528142.jpg'}, '/tmp/tmpjNMlK5.mat')\n",
      "Processed 2171 windows in 244.516 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.45806, -3.06616, -1.83217, -2.344, -1.7720...\n",
      "ymin                                                        146\n",
      "xmin                                                        264\n",
      "ymax                                                        242\n",
      "xmax                                                        337\n",
      "Name: /home/ambika/INF_project/data/train/528142.jpg, dtype: object\n",
      "prediction    [-2.24095, -1.01694, -2.39483, -2.6185, -1.929...\n",
      "ymin                                                          0\n",
      "xmin                                                        231\n",
      "ymax                                                        269\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/train/528142.jpg, dtype: object\n",
      "person\n",
      "264\t146\t337\t242\n",
      "train\n",
      "231\t0\t500\t269\n",
      "528142\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 13:58:37.098449 24013 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 13:58:37.098471 24013 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 13:58:37.098474 24013 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 13:58:37.099668 24013 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 13:58:37.099838 24013 layer_factory.hpp:77] Creating layer data\n",
      "I0430 13:58:37.099845 24013 net.cpp:86] Creating Layer data\n",
      "I0430 13:58:37.099848 24013 net.cpp:382] data -> data\n",
      "I0430 13:58:37.099862 24013 net.cpp:124] Setting up data\n",
      "I0430 13:58:37.099870 24013 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 13:58:37.099874 24013 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 13:58:37.099875 24013 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 13:58:37.099880 24013 net.cpp:86] Creating Layer conv1\n",
      "I0430 13:58:37.099882 24013 net.cpp:408] conv1 <- data\n",
      "I0430 13:58:37.099886 24013 net.cpp:382] conv1 -> conv1\n",
      "I0430 13:58:37.099944 24013 net.cpp:124] Setting up conv1\n",
      "I0430 13:58:37.099949 24013 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:58:37.099951 24013 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 13:58:37.099958 24013 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 13:58:37.099963 24013 net.cpp:86] Creating Layer relu1\n",
      "I0430 13:58:37.099966 24013 net.cpp:408] relu1 <- conv1\n",
      "I0430 13:58:37.099969 24013 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 13:58:37.099973 24013 net.cpp:124] Setting up relu1\n",
      "I0430 13:58:37.099977 24013 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 13:58:37.099979 24013 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 13:58:37.099982 24013 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 13:58:37.099985 24013 net.cpp:86] Creating Layer pool1\n",
      "I0430 13:58:37.099987 24013 net.cpp:408] pool1 <- conv1\n",
      "I0430 13:58:37.099992 24013 net.cpp:382] pool1 -> pool1\n",
      "I0430 13:58:37.099997 24013 net.cpp:124] Setting up pool1\n",
      "I0430 13:58:37.100000 24013 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:58:37.100003 24013 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 13:58:37.100005 24013 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 13:58:37.100009 24013 net.cpp:86] Creating Layer norm1\n",
      "I0430 13:58:37.100011 24013 net.cpp:408] norm1 <- pool1\n",
      "I0430 13:58:37.100015 24013 net.cpp:382] norm1 -> norm1\n",
      "I0430 13:58:37.100023 24013 net.cpp:124] Setting up norm1\n",
      "I0430 13:58:37.100026 24013 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 13:58:37.100028 24013 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 13:58:37.100030 24013 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 13:58:37.100034 24013 net.cpp:86] Creating Layer conv2\n",
      "I0430 13:58:37.100038 24013 net.cpp:408] conv2 <- norm1\n",
      "I0430 13:58:37.100040 24013 net.cpp:382] conv2 -> conv2\n",
      "I0430 13:58:37.100378 24013 net.cpp:124] Setting up conv2\n",
      "I0430 13:58:37.100383 24013 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:58:37.100386 24013 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 13:58:37.100391 24013 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 13:58:37.100395 24013 net.cpp:86] Creating Layer relu2\n",
      "I0430 13:58:37.100397 24013 net.cpp:408] relu2 <- conv2\n",
      "I0430 13:58:37.100400 24013 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 13:58:37.100404 24013 net.cpp:124] Setting up relu2\n",
      "I0430 13:58:37.100407 24013 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 13:58:37.100409 24013 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 13:58:37.100412 24013 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 13:58:37.100416 24013 net.cpp:86] Creating Layer pool2\n",
      "I0430 13:58:37.100419 24013 net.cpp:408] pool2 <- conv2\n",
      "I0430 13:58:37.100422 24013 net.cpp:382] pool2 -> pool2\n",
      "I0430 13:58:37.100427 24013 net.cpp:124] Setting up pool2\n",
      "I0430 13:58:37.100430 24013 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:58:37.100432 24013 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 13:58:37.100433 24013 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 13:58:37.100437 24013 net.cpp:86] Creating Layer norm2\n",
      "I0430 13:58:37.100438 24013 net.cpp:408] norm2 <- pool2\n",
      "I0430 13:58:37.100441 24013 net.cpp:382] norm2 -> norm2\n",
      "I0430 13:58:37.100445 24013 net.cpp:124] Setting up norm2\n",
      "I0430 13:58:37.100447 24013 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:58:37.100450 24013 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 13:58:37.100451 24013 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 13:58:37.100457 24013 net.cpp:86] Creating Layer conv3\n",
      "I0430 13:58:37.100459 24013 net.cpp:408] conv3 <- norm2\n",
      "I0430 13:58:37.100462 24013 net.cpp:382] conv3 -> conv3\n",
      "I0430 13:58:37.101142 24013 net.cpp:124] Setting up conv3\n",
      "I0430 13:58:37.101150 24013 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:58:37.101153 24013 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 13:58:37.101160 24013 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 13:58:37.101164 24013 net.cpp:86] Creating Layer relu3\n",
      "I0430 13:58:37.101166 24013 net.cpp:408] relu3 <- conv3\n",
      "I0430 13:58:37.101171 24013 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 13:58:37.101176 24013 net.cpp:124] Setting up relu3\n",
      "I0430 13:58:37.101178 24013 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:58:37.101181 24013 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 13:58:37.101182 24013 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 13:58:37.101188 24013 net.cpp:86] Creating Layer conv4\n",
      "I0430 13:58:37.101191 24013 net.cpp:408] conv4 <- conv3\n",
      "I0430 13:58:37.101193 24013 net.cpp:382] conv4 -> conv4\n",
      "I0430 13:58:37.101972 24013 net.cpp:124] Setting up conv4\n",
      "I0430 13:58:37.101989 24013 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:58:37.101994 24013 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 13:58:37.102004 24013 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 13:58:37.102012 24013 net.cpp:86] Creating Layer relu4\n",
      "I0430 13:58:37.102017 24013 net.cpp:408] relu4 <- conv4\n",
      "I0430 13:58:37.102022 24013 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 13:58:37.102030 24013 net.cpp:124] Setting up relu4\n",
      "I0430 13:58:37.102032 24013 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 13:58:37.102035 24013 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 13:58:37.102036 24013 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 13:58:37.102041 24013 net.cpp:86] Creating Layer conv5\n",
      "I0430 13:58:37.102044 24013 net.cpp:408] conv5 <- conv4\n",
      "I0430 13:58:37.102049 24013 net.cpp:382] conv5 -> conv5\n",
      "I0430 13:58:37.102702 24013 net.cpp:124] Setting up conv5\n",
      "I0430 13:58:37.102715 24013 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:58:37.102718 24013 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 13:58:37.102731 24013 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 13:58:37.102737 24013 net.cpp:86] Creating Layer relu5\n",
      "I0430 13:58:37.102741 24013 net.cpp:408] relu5 <- conv5\n",
      "I0430 13:58:37.102747 24013 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 13:58:37.102754 24013 net.cpp:124] Setting up relu5\n",
      "I0430 13:58:37.102759 24013 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 13:58:37.102763 24013 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 13:58:37.102766 24013 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 13:58:37.102773 24013 net.cpp:86] Creating Layer pool5\n",
      "I0430 13:58:37.102777 24013 net.cpp:408] pool5 <- conv5\n",
      "I0430 13:58:37.102782 24013 net.cpp:382] pool5 -> pool5\n",
      "I0430 13:58:37.102792 24013 net.cpp:124] Setting up pool5\n",
      "I0430 13:58:37.102797 24013 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 13:58:37.102800 24013 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 13:58:37.102804 24013 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 13:58:37.102813 24013 net.cpp:86] Creating Layer fc6\n",
      "I0430 13:58:37.102816 24013 net.cpp:408] fc6 <- pool5\n",
      "I0430 13:58:37.102823 24013 net.cpp:382] fc6 -> fc6\n",
      "I0430 13:58:37.124213 24013 net.cpp:124] Setting up fc6\n",
      "I0430 13:58:37.124239 24013 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:58:37.124241 24013 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 13:58:37.124253 24013 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 13:58:37.124265 24013 net.cpp:86] Creating Layer relu6\n",
      "I0430 13:58:37.124269 24013 net.cpp:408] relu6 <- fc6\n",
      "I0430 13:58:37.124276 24013 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 13:58:37.124284 24013 net.cpp:124] Setting up relu6\n",
      "I0430 13:58:37.124286 24013 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:58:37.124287 24013 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 13:58:37.124289 24013 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 13:58:37.124294 24013 net.cpp:86] Creating Layer drop6\n",
      "I0430 13:58:37.124294 24013 net.cpp:408] drop6 <- fc6\n",
      "I0430 13:58:37.124297 24013 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 13:58:37.124301 24013 net.cpp:124] Setting up drop6\n",
      "I0430 13:58:37.124315 24013 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:58:37.124316 24013 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 13:58:37.124318 24013 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 13:58:37.124322 24013 net.cpp:86] Creating Layer fc7\n",
      "I0430 13:58:37.124325 24013 net.cpp:408] fc7 <- fc6\n",
      "I0430 13:58:37.124328 24013 net.cpp:382] fc7 -> fc7\n",
      "I0430 13:58:37.133904 24013 net.cpp:124] Setting up fc7\n",
      "I0430 13:58:37.133929 24013 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:58:37.133930 24013 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 13:58:37.133939 24013 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 13:58:37.133949 24013 net.cpp:86] Creating Layer relu7\n",
      "I0430 13:58:37.133951 24013 net.cpp:408] relu7 <- fc7\n",
      "I0430 13:58:37.133956 24013 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 13:58:37.133962 24013 net.cpp:124] Setting up relu7\n",
      "I0430 13:58:37.133965 24013 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:58:37.133966 24013 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 13:58:37.133968 24013 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 13:58:37.133972 24013 net.cpp:86] Creating Layer drop7\n",
      "I0430 13:58:37.133975 24013 net.cpp:408] drop7 <- fc7\n",
      "I0430 13:58:37.133976 24013 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 13:58:37.133983 24013 net.cpp:124] Setting up drop7\n",
      "I0430 13:58:37.133986 24013 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 13:58:37.134001 24013 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 13:58:37.134002 24013 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 13:58:37.134006 24013 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 13:58:37.134009 24013 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 13:58:37.134012 24013 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 13:58:37.134654 24013 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 13:58:37.134663 24013 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 13:58:37.134668 24013 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 13:58:37.134688 24013 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 13:58:37.134692 24013 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 13:58:37.134694 24013 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 13:58:37.134697 24013 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 13:58:37.134699 24013 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 13:58:37.134702 24013 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 13:58:37.134704 24013 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 13:58:37.134707 24013 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 13:58:37.134709 24013 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 13:58:37.134712 24013 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 13:58:37.134716 24013 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 13:58:37.134717 24013 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 13:58:37.134721 24013 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 13:58:37.134722 24013 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 13:58:37.134726 24013 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 13:58:37.134729 24013 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 13:58:37.134732 24013 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 13:58:37.134734 24013 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 13:58:37.134737 24013 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 13:58:37.134740 24013 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 13:58:37.134742 24013 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 13:58:37.134745 24013 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 13:58:37.134747 24013 net.cpp:202] data does not need backward computation.\n",
      "I0430 13:58:37.134749 24013 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 13:58:37.134759 24013 net.cpp:257] Network initialization done.\n",
      "I0430 13:58:37.216337 24013 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:58:37.307449 24013 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 13:58:37.308447 24013 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 13:58:37.308459 24013 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 13:58:37.308464 24013 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/527783.jpg'}, '/tmp/tmp6G4bFp.mat')\n",
      "Processed 1061 windows in 121.251 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.026 s.\n",
      "prediction    [-2.64513, 3.46429, -2.77442, -2.09013, -2.357...\n",
      "ymin                                                         64\n",
      "xmin                                                          0\n",
      "ymax                                                        221\n",
      "xmax                                                        259\n",
      "Name: /home/ambika/INF_project/data/airplane/527783.jpg, dtype: object\n",
      "prediction    [-2.22693, -0.940158, -2.67566, -2.01753, -2.4...\n",
      "ymin                                                        111\n",
      "xmin                                                         61\n",
      "ymax                                                        178\n",
      "xmax                                                        128\n",
      "Name: /home/ambika/INF_project/data/airplane/527783.jpg, dtype: object\n",
      "airplane\n",
      "0\t64\t259\t221\n",
      "volleyball\n",
      "61\t111\t128\t178\n",
      "527783\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:00:39.959494 24155 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:00:39.959517 24155 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:00:39.959520 24155 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:00:39.960712 24155 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:00:39.960907 24155 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:00:39.960917 24155 net.cpp:86] Creating Layer data\n",
      "I0430 14:00:39.960922 24155 net.cpp:382] data -> data\n",
      "I0430 14:00:39.960939 24155 net.cpp:124] Setting up data\n",
      "I0430 14:00:39.960947 24155 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:00:39.960950 24155 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:00:39.960954 24155 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:00:39.960963 24155 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:00:39.960966 24155 net.cpp:408] conv1 <- data\n",
      "I0430 14:00:39.960973 24155 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:00:39.961040 24155 net.cpp:124] Setting up conv1\n",
      "I0430 14:00:39.961045 24155 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:00:39.961048 24155 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:00:39.961055 24155 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:00:39.961061 24155 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:00:39.961062 24155 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:00:39.961066 24155 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:00:39.961071 24155 net.cpp:124] Setting up relu1\n",
      "I0430 14:00:39.961074 24155 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:00:39.961076 24155 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:00:39.961078 24155 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:00:39.961083 24155 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:00:39.961086 24155 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:00:39.961088 24155 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:00:39.961096 24155 net.cpp:124] Setting up pool1\n",
      "I0430 14:00:39.961099 24155 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:00:39.961102 24155 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:00:39.961103 24155 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:00:39.961108 24155 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:00:39.961110 24155 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:00:39.961114 24155 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:00:39.961119 24155 net.cpp:124] Setting up norm1\n",
      "I0430 14:00:39.961122 24155 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:00:39.961125 24155 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:00:39.961128 24155 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:00:39.961135 24155 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:00:39.961138 24155 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:00:39.961144 24155 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:00:39.961518 24155 net.cpp:124] Setting up conv2\n",
      "I0430 14:00:39.961525 24155 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:00:39.961529 24155 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:00:39.961536 24155 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:00:39.961542 24155 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:00:39.961545 24155 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:00:39.961549 24155 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:00:39.961555 24155 net.cpp:124] Setting up relu2\n",
      "I0430 14:00:39.961557 24155 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:00:39.961560 24155 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:00:39.961562 24155 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:00:39.961567 24155 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:00:39.961570 24155 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:00:39.961572 24155 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:00:39.961578 24155 net.cpp:124] Setting up pool2\n",
      "I0430 14:00:39.961581 24155 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:00:39.961585 24155 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:00:39.961586 24155 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:00:39.961592 24155 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:00:39.961596 24155 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:00:39.961598 24155 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:00:39.961604 24155 net.cpp:124] Setting up norm2\n",
      "I0430 14:00:39.961607 24155 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:00:39.961609 24155 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:00:39.961612 24155 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:00:39.961616 24155 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:00:39.961618 24155 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:00:39.961622 24155 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:00:39.962352 24155 net.cpp:124] Setting up conv3\n",
      "I0430 14:00:39.962366 24155 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:00:39.962369 24155 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:00:39.962380 24155 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:00:39.962389 24155 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:00:39.962393 24155 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:00:39.962396 24155 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:00:39.962402 24155 net.cpp:124] Setting up relu3\n",
      "I0430 14:00:39.962405 24155 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:00:39.962407 24155 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:00:39.962409 24155 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:00:39.962414 24155 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:00:39.962417 24155 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:00:39.962420 24155 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:00:39.963173 24155 net.cpp:124] Setting up conv4\n",
      "I0430 14:00:39.963182 24155 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:00:39.963186 24155 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:00:39.963193 24155 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:00:39.963201 24155 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:00:39.963203 24155 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:00:39.963224 24155 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:00:39.963228 24155 net.cpp:124] Setting up relu4\n",
      "I0430 14:00:39.963232 24155 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:00:39.963234 24155 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:00:39.963237 24155 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:00:39.963241 24155 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:00:39.963243 24155 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:00:39.963246 24155 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:00:39.963763 24155 net.cpp:124] Setting up conv5\n",
      "I0430 14:00:39.963770 24155 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:00:39.963773 24155 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:00:39.963784 24155 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:00:39.963789 24155 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:00:39.963793 24155 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:00:39.963796 24155 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:00:39.963801 24155 net.cpp:124] Setting up relu5\n",
      "I0430 14:00:39.963804 24155 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:00:39.963806 24155 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:00:39.963809 24155 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:00:39.963812 24155 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:00:39.963815 24155 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:00:39.963819 24155 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:00:39.963825 24155 net.cpp:124] Setting up pool5\n",
      "I0430 14:00:39.963829 24155 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:00:39.963831 24155 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:00:39.963834 24155 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:00:39.963840 24155 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:00:39.963843 24155 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:00:39.963846 24155 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:00:39.984941 24155 net.cpp:124] Setting up fc6\n",
      "I0430 14:00:39.984964 24155 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:00:39.984968 24155 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:00:39.984978 24155 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:00:39.985000 24155 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:00:39.985005 24155 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:00:39.985013 24155 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:00:39.985020 24155 net.cpp:124] Setting up relu6\n",
      "I0430 14:00:39.985023 24155 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:00:39.985028 24155 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:00:39.985030 24155 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:00:39.985038 24155 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:00:39.985039 24155 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:00:39.985044 24155 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:00:39.985049 24155 net.cpp:124] Setting up drop6\n",
      "I0430 14:00:39.985052 24155 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:00:39.985055 24155 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:00:39.985059 24155 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:00:39.985064 24155 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:00:39.985066 24155 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:00:39.985071 24155 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:00:39.995146 24155 net.cpp:124] Setting up fc7\n",
      "I0430 14:00:39.995169 24155 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:00:39.995172 24155 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:00:39.995182 24155 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:00:39.995194 24155 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:00:39.995198 24155 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:00:39.995204 24155 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:00:39.995221 24155 net.cpp:124] Setting up relu7\n",
      "I0430 14:00:39.995225 24155 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:00:39.995227 24155 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:00:39.995231 24155 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:00:39.995239 24155 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:00:39.995244 24155 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:00:39.995249 24155 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:00:39.995256 24155 net.cpp:124] Setting up drop7\n",
      "I0430 14:00:39.995261 24155 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:00:39.995265 24155 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:00:39.995268 24155 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:00:39.995275 24155 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:00:39.995277 24155 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:00:39.995283 24155 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:00:39.996417 24155 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:00:39.996436 24155 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:00:39.996440 24155 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:00:39.996449 24155 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:00:39.996454 24155 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:00:39.996459 24155 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:00:39.996461 24155 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:00:39.996465 24155 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:00:39.996469 24155 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:00:39.996472 24155 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:00:39.996475 24155 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:00:39.996481 24155 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:00:39.996485 24155 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:00:39.996490 24155 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:00:39.996493 24155 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:00:39.996496 24155 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:00:39.996500 24155 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:00:39.996505 24155 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:00:39.996508 24155 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:00:39.996512 24155 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:00:39.996516 24155 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:00:39.996520 24155 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:00:39.996523 24155 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:00:39.996527 24155 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:00:39.996531 24155 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:00:39.996534 24155 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:00:39.996537 24155 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:00:39.996551 24155 net.cpp:257] Network initialization done.\n",
      "I0430 14:00:40.076723 24155 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:00:40.168114 24155 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:00:40.168995 24155 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:00:40.169003 24155 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:00:40.169003 24155 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/314034.jpg'}, '/tmp/tmpJshLyM.mat')\n",
      "Processed 2185 windows in 254.226 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-1.98631, -2.097, -2.32856, -1.03326, -2.4362...\n",
      "ymin                                                        145\n",
      "xmin                                                        175\n",
      "ymax                                                        219\n",
      "xmax                                                        237\n",
      "Name: /home/ambika/INF_project/data/bird/314034.jpg, dtype: object\n",
      "prediction    [-1.85102, -2.30846, -1.89977, 0.678718, -2.22...\n",
      "ymin                                                        153\n",
      "xmin                                                        376\n",
      "ymax                                                        214\n",
      "xmax                                                        446\n",
      "Name: /home/ambika/INF_project/data/bird/314034.jpg, dtype: object\n",
      "cattle\n",
      "175\t145\t237\t219\n",
      "antelope\n",
      "376\t153\t446\t214\n",
      "314034\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:04:55.991228 24366 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:04:55.991255 24366 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:04:55.991259 24366 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:04:55.992571 24366 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:04:55.992782 24366 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:04:55.992797 24366 net.cpp:86] Creating Layer data\n",
      "I0430 14:04:55.992804 24366 net.cpp:382] data -> data\n",
      "I0430 14:04:55.992822 24366 net.cpp:124] Setting up data\n",
      "I0430 14:04:55.992831 24366 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:04:55.992836 24366 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:04:55.992841 24366 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:04:55.992851 24366 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:04:55.992853 24366 net.cpp:408] conv1 <- data\n",
      "I0430 14:04:55.992858 24366 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:04:55.992930 24366 net.cpp:124] Setting up conv1\n",
      "I0430 14:04:55.992935 24366 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:04:55.992938 24366 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:04:55.992946 24366 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:04:55.992951 24366 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:04:55.992955 24366 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:04:55.992959 24366 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:04:55.992964 24366 net.cpp:124] Setting up relu1\n",
      "I0430 14:04:55.992967 24366 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:04:55.992970 24366 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:04:55.992974 24366 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:04:55.992979 24366 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:04:55.992980 24366 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:04:55.992985 24366 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:04:55.992992 24366 net.cpp:124] Setting up pool1\n",
      "I0430 14:04:55.992998 24366 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:04:55.993001 24366 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:04:55.993005 24366 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:04:55.993012 24366 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:04:55.993016 24366 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:04:55.993023 24366 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:04:55.993032 24366 net.cpp:124] Setting up norm1\n",
      "I0430 14:04:55.993037 24366 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:04:55.993041 24366 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:04:55.993043 24366 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:04:55.993048 24366 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:04:55.993052 24366 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:04:55.993055 24366 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:04:55.993460 24366 net.cpp:124] Setting up conv2\n",
      "I0430 14:04:55.993470 24366 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:04:55.993474 24366 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:04:55.993484 24366 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:04:55.993491 24366 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:04:55.993495 24366 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:04:55.993500 24366 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:04:55.993506 24366 net.cpp:124] Setting up relu2\n",
      "I0430 14:04:55.993510 24366 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:04:55.993513 24366 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:04:55.993517 24366 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:04:55.993525 24366 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:04:55.993527 24366 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:04:55.993532 24366 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:04:55.993540 24366 net.cpp:124] Setting up pool2\n",
      "I0430 14:04:55.993543 24366 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:04:55.993546 24366 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:04:55.993551 24366 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:04:55.993556 24366 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:04:55.993559 24366 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:04:55.993563 24366 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:04:55.993569 24366 net.cpp:124] Setting up norm2\n",
      "I0430 14:04:55.993574 24366 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:04:55.993577 24366 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:04:55.993580 24366 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:04:55.993587 24366 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:04:55.993590 24366 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:04:55.993595 24366 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:04:55.994379 24366 net.cpp:124] Setting up conv3\n",
      "I0430 14:04:55.994398 24366 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:04:55.994401 24366 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:04:55.994413 24366 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:04:55.994423 24366 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:04:55.994428 24366 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:04:55.994433 24366 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:04:55.994441 24366 net.cpp:124] Setting up relu3\n",
      "I0430 14:04:55.994446 24366 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:04:55.994448 24366 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:04:55.994452 24366 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:04:55.994458 24366 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:04:55.994462 24366 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:04:55.994467 24366 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:04:55.995340 24366 net.cpp:124] Setting up conv4\n",
      "I0430 14:04:55.995358 24366 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:04:55.995362 24366 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:04:55.995370 24366 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:04:55.995379 24366 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:04:55.995383 24366 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:04:55.995390 24366 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:04:55.995398 24366 net.cpp:124] Setting up relu4\n",
      "I0430 14:04:55.995403 24366 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:04:55.995405 24366 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:04:55.995409 24366 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:04:55.995416 24366 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:04:55.995419 24366 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:04:55.995424 24366 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:04:55.996006 24366 net.cpp:124] Setting up conv5\n",
      "I0430 14:04:55.996018 24366 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:04:55.996022 24366 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:04:55.996037 24366 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:04:55.996042 24366 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:04:55.996047 24366 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:04:55.996052 24366 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:04:55.996059 24366 net.cpp:124] Setting up relu5\n",
      "I0430 14:04:55.996063 24366 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:04:55.996067 24366 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:04:55.996069 24366 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:04:55.996075 24366 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:04:55.996078 24366 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:04:55.996083 24366 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:04:55.996091 24366 net.cpp:124] Setting up pool5\n",
      "I0430 14:04:55.996096 24366 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:04:55.996099 24366 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:04:55.996103 24366 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:04:55.996111 24366 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:04:55.996114 24366 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:04:55.996119 24366 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:04:56.021559 24366 net.cpp:124] Setting up fc6\n",
      "I0430 14:04:56.021587 24366 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:04:56.021595 24366 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:04:56.021607 24366 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:04:56.021620 24366 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:04:56.021625 24366 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:04:56.021632 24366 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:04:56.021643 24366 net.cpp:124] Setting up relu6\n",
      "I0430 14:04:56.021649 24366 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:04:56.021653 24366 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:04:56.021657 24366 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:04:56.021663 24366 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:04:56.021667 24366 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:04:56.021669 24366 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:04:56.021675 24366 net.cpp:124] Setting up drop6\n",
      "I0430 14:04:56.021678 24366 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:04:56.021682 24366 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:04:56.021684 24366 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:04:56.021689 24366 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:04:56.021692 24366 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:04:56.021697 24366 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:04:56.032542 24366 net.cpp:124] Setting up fc7\n",
      "I0430 14:04:56.032564 24366 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:04:56.032569 24366 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:04:56.032582 24366 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:04:56.032601 24366 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:04:56.032608 24366 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:04:56.032620 24366 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:04:56.032630 24366 net.cpp:124] Setting up relu7\n",
      "I0430 14:04:56.032635 24366 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:04:56.032639 24366 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:04:56.032644 24366 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:04:56.032649 24366 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:04:56.032654 24366 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:04:56.032658 24366 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:04:56.032675 24366 net.cpp:124] Setting up drop7\n",
      "I0430 14:04:56.032680 24366 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:04:56.032682 24366 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:04:56.032686 24366 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:04:56.032692 24366 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:04:56.032696 24366 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:04:56.032701 24366 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:04:56.033746 24366 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:04:56.033766 24366 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:04:56.033771 24366 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:04:56.033783 24366 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:04:56.033788 24366 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:04:56.033792 24366 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:04:56.033795 24366 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:04:56.033802 24366 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:04:56.033805 24366 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:04:56.033809 24366 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:04:56.033812 24366 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:04:56.033816 24366 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:04:56.033820 24366 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:04:56.033824 24366 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:04:56.033828 24366 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:04:56.033831 24366 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:04:56.033835 24366 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:04:56.033839 24366 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:04:56.033843 24366 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:04:56.033848 24366 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:04:56.033851 24366 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:04:56.033855 24366 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:04:56.033859 24366 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:04:56.033862 24366 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:04:56.033865 24366 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:04:56.033869 24366 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:04:56.033872 24366 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:04:56.033885 24366 net.cpp:257] Network initialization done.\n",
      "I0430 14:04:56.133801 24366 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:04:56.247545 24366 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:04:56.248785 24366 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:04:56.248805 24366 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:04:56.248811 24366 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/187144.jpg'}, '/tmp/tmp5CREYq.mat')\n",
      "Processed 1840 windows in 217.427 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.041 s.\n",
      "prediction    [-1.95973, -2.09318, -2.1389, -1.79365, -1.888...\n",
      "ymin                                                        191\n",
      "xmin                                                        308\n",
      "ymax                                                        254\n",
      "xmax                                                        348\n",
      "Name: /home/ambika/INF_project/data/bus/187144.jpg, dtype: object\n",
      "prediction    [-2.91639, -0.0223292, -2.62083, -3.0249, -2.2...\n",
      "ymin                                                         98\n",
      "xmin                                                        127\n",
      "ymax                                                        207\n",
      "xmax                                                        412\n",
      "Name: /home/ambika/INF_project/data/bus/187144.jpg, dtype: object\n",
      "person\n",
      "308\t191\t348\t254\n",
      "airplane\n",
      "127\t98\t412\t207\n",
      "187144\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:08:35.326942 24540 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:08:35.326969 24540 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:08:35.326973 24540 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:08:35.328646 24540 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:08:35.328853 24540 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:08:35.328866 24540 net.cpp:86] Creating Layer data\n",
      "I0430 14:08:35.328872 24540 net.cpp:382] data -> data\n",
      "I0430 14:08:35.328888 24540 net.cpp:124] Setting up data\n",
      "I0430 14:08:35.328899 24540 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:08:35.328903 24540 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:08:35.328907 24540 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:08:35.328917 24540 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:08:35.328920 24540 net.cpp:408] conv1 <- data\n",
      "I0430 14:08:35.328927 24540 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:08:35.329008 24540 net.cpp:124] Setting up conv1\n",
      "I0430 14:08:35.329017 24540 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:08:35.329021 24540 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:08:35.329031 24540 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:08:35.329040 24540 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:08:35.329043 24540 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:08:35.329047 24540 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:08:35.329053 24540 net.cpp:124] Setting up relu1\n",
      "I0430 14:08:35.329058 24540 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:08:35.329061 24540 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:08:35.329064 24540 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:08:35.329069 24540 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:08:35.329073 24540 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:08:35.329078 24540 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:08:35.329089 24540 net.cpp:124] Setting up pool1\n",
      "I0430 14:08:35.329095 24540 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:08:35.329098 24540 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:08:35.329102 24540 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:08:35.329109 24540 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:08:35.329113 24540 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:08:35.329119 24540 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:08:35.329128 24540 net.cpp:124] Setting up norm1\n",
      "I0430 14:08:35.329133 24540 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:08:35.329136 24540 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:08:35.329140 24540 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:08:35.329149 24540 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:08:35.329152 24540 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:08:35.329159 24540 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:08:35.329613 24540 net.cpp:124] Setting up conv2\n",
      "I0430 14:08:35.329627 24540 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:08:35.329630 24540 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:08:35.329640 24540 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:08:35.329648 24540 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:08:35.329651 24540 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:08:35.329656 24540 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:08:35.329663 24540 net.cpp:124] Setting up relu2\n",
      "I0430 14:08:35.329668 24540 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:08:35.329672 24540 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:08:35.329676 24540 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:08:35.329684 24540 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:08:35.329687 24540 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:08:35.329692 24540 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:08:35.329700 24540 net.cpp:124] Setting up pool2\n",
      "I0430 14:08:35.329705 24540 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:08:35.329710 24540 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:08:35.329713 24540 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:08:35.329720 24540 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:08:35.329725 24540 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:08:35.329730 24540 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:08:35.329737 24540 net.cpp:124] Setting up norm2\n",
      "I0430 14:08:35.329742 24540 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:08:35.329746 24540 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:08:35.329749 24540 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:08:35.329757 24540 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:08:35.329761 24540 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:08:35.329767 24540 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:08:35.330730 24540 net.cpp:124] Setting up conv3\n",
      "I0430 14:08:35.330755 24540 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:08:35.330759 24540 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:08:35.330770 24540 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:08:35.330778 24540 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:08:35.330782 24540 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:08:35.330787 24540 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:08:35.330796 24540 net.cpp:124] Setting up relu3\n",
      "I0430 14:08:35.330799 24540 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:08:35.330802 24540 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:08:35.330806 24540 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:08:35.330813 24540 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:08:35.330816 24540 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:08:35.330821 24540 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:08:35.331828 24540 net.cpp:124] Setting up conv4\n",
      "I0430 14:08:35.331848 24540 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:08:35.331852 24540 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:08:35.331861 24540 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:08:35.331872 24540 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:08:35.331876 24540 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:08:35.331883 24540 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:08:35.331892 24540 net.cpp:124] Setting up relu4\n",
      "I0430 14:08:35.331897 24540 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:08:35.331899 24540 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:08:35.331902 24540 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:08:35.331910 24540 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:08:35.331913 24540 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:08:35.331919 24540 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:08:35.332593 24540 net.cpp:124] Setting up conv5\n",
      "I0430 14:08:35.332612 24540 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:08:35.332615 24540 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:08:35.332630 24540 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:08:35.332638 24540 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:08:35.332643 24540 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:08:35.332649 24540 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:08:35.332657 24540 net.cpp:124] Setting up relu5\n",
      "I0430 14:08:35.332661 24540 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:08:35.332664 24540 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:08:35.332667 24540 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:08:35.332674 24540 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:08:35.332676 24540 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:08:35.332680 24540 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:08:35.332690 24540 net.cpp:124] Setting up pool5\n",
      "I0430 14:08:35.332695 24540 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:08:35.332697 24540 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:08:35.332700 24540 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:08:35.332710 24540 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:08:35.332713 24540 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:08:35.332717 24540 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:08:35.363170 24540 net.cpp:124] Setting up fc6\n",
      "I0430 14:08:35.363204 24540 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:08:35.363229 24540 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:08:35.363241 24540 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:08:35.363255 24540 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:08:35.363258 24540 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:08:35.363265 24540 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:08:35.363273 24540 net.cpp:124] Setting up relu6\n",
      "I0430 14:08:35.363279 24540 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:08:35.363286 24540 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:08:35.363291 24540 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:08:35.363297 24540 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:08:35.363301 24540 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:08:35.363307 24540 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:08:35.363314 24540 net.cpp:124] Setting up drop6\n",
      "I0430 14:08:35.363320 24540 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:08:35.363323 24540 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:08:35.363327 24540 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:08:35.363333 24540 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:08:35.363337 24540 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:08:35.363344 24540 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:08:35.374883 24540 net.cpp:124] Setting up fc7\n",
      "I0430 14:08:35.374910 24540 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:08:35.374914 24540 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:08:35.374923 24540 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:08:35.374930 24540 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:08:35.374933 24540 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:08:35.374938 24540 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:08:35.374943 24540 net.cpp:124] Setting up relu7\n",
      "I0430 14:08:35.374946 24540 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:08:35.374948 24540 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:08:35.374949 24540 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:08:35.374953 24540 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:08:35.374955 24540 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:08:35.374958 24540 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:08:35.374963 24540 net.cpp:124] Setting up drop7\n",
      "I0430 14:08:35.374966 24540 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:08:35.374969 24540 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:08:35.374971 24540 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:08:35.374975 24540 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:08:35.374977 24540 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:08:35.374981 24540 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:08:35.375905 24540 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:08:35.375918 24540 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:08:35.375921 24540 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:08:35.375926 24540 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:08:35.375928 24540 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:08:35.375931 24540 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:08:35.375933 24540 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:08:35.375936 24540 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:08:35.375937 24540 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:08:35.375938 24540 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:08:35.375941 24540 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:08:35.375944 24540 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:08:35.375947 24540 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:08:35.375950 24540 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:08:35.375953 24540 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:08:35.375957 24540 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:08:35.375959 24540 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:08:35.375962 24540 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:08:35.375965 24540 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:08:35.375968 24540 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:08:35.375972 24540 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:08:35.375973 24540 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:08:35.375977 24540 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:08:35.375979 24540 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:08:35.375983 24540 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:08:35.375986 24540 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:08:35.375990 24540 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:08:35.376001 24540 net.cpp:257] Network initialization done.\n",
      "I0430 14:08:35.465925 24540 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:08:35.570485 24540 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:08:35.571528 24540 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:08:35.571538 24540 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:08:35.571542 24540 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/571636.jpg'}, '/tmp/tmpWK77gK.mat')\n",
      "Processed 2227 windows in 249.238 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.19248, -2.02367, -1.77266, -2.29842, -2.18...\n",
      "ymin                                                        114\n",
      "xmin                                                        354\n",
      "ymax                                                        166\n",
      "xmax                                                        400\n",
      "Name: /home/ambika/INF_project/data/car/571636.jpg, dtype: object\n",
      "prediction    [-1.86741, -1.78956, -1.94838, -1.41215, -1.84...\n",
      "ymin                                                         77\n",
      "xmin                                                        264\n",
      "ymax                                                        335\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/car/571636.jpg, dtype: object\n",
      "person\n",
      "354\t114\t400\t166\n",
      "car\n",
      "264\t77\t500\t335\n",
      "571636\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:12:46.318500 24730 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:12:46.318526 24730 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:12:46.318531 24730 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:12:46.319676 24730 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:12:46.319845 24730 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:12:46.319852 24730 net.cpp:86] Creating Layer data\n",
      "I0430 14:12:46.319855 24730 net.cpp:382] data -> data\n",
      "I0430 14:12:46.319865 24730 net.cpp:124] Setting up data\n",
      "I0430 14:12:46.319870 24730 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:12:46.319872 24730 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:12:46.319875 24730 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:12:46.319881 24730 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:12:46.319883 24730 net.cpp:408] conv1 <- data\n",
      "I0430 14:12:46.319890 24730 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:12:46.319957 24730 net.cpp:124] Setting up conv1\n",
      "I0430 14:12:46.319962 24730 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:12:46.319965 24730 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:12:46.319972 24730 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:12:46.319977 24730 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:12:46.319979 24730 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:12:46.319983 24730 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:12:46.319988 24730 net.cpp:124] Setting up relu1\n",
      "I0430 14:12:46.319990 24730 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:12:46.319993 24730 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:12:46.319994 24730 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:12:46.319998 24730 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:12:46.320000 24730 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:12:46.320004 24730 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:12:46.320010 24730 net.cpp:124] Setting up pool1\n",
      "I0430 14:12:46.320013 24730 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:12:46.320015 24730 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:12:46.320017 24730 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:12:46.320022 24730 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:12:46.320024 24730 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:12:46.320027 24730 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:12:46.320032 24730 net.cpp:124] Setting up norm1\n",
      "I0430 14:12:46.320035 24730 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:12:46.320039 24730 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:12:46.320040 24730 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:12:46.320044 24730 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:12:46.320046 24730 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:12:46.320050 24730 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:12:46.320418 24730 net.cpp:124] Setting up conv2\n",
      "I0430 14:12:46.320425 24730 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:12:46.320427 24730 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:12:46.320433 24730 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:12:46.320441 24730 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:12:46.320444 24730 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:12:46.320449 24730 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:12:46.320456 24730 net.cpp:124] Setting up relu2\n",
      "I0430 14:12:46.320461 24730 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:12:46.320464 24730 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:12:46.320467 24730 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:12:46.320472 24730 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:12:46.320473 24730 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:12:46.320477 24730 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:12:46.320482 24730 net.cpp:124] Setting up pool2\n",
      "I0430 14:12:46.320485 24730 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:12:46.320487 24730 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:12:46.320490 24730 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:12:46.320495 24730 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:12:46.320498 24730 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:12:46.320502 24730 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:12:46.320507 24730 net.cpp:124] Setting up norm2\n",
      "I0430 14:12:46.320509 24730 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:12:46.320511 24730 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:12:46.320514 24730 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:12:46.320519 24730 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:12:46.320523 24730 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:12:46.320525 24730 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:12:46.321221 24730 net.cpp:124] Setting up conv3\n",
      "I0430 14:12:46.321233 24730 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:12:46.321235 24730 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:12:46.321246 24730 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:12:46.321254 24730 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:12:46.321256 24730 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:12:46.321259 24730 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:12:46.321264 24730 net.cpp:124] Setting up relu3\n",
      "I0430 14:12:46.321267 24730 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:12:46.321269 24730 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:12:46.321272 24730 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:12:46.321279 24730 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:12:46.321280 24730 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:12:46.321285 24730 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:12:46.322032 24730 net.cpp:124] Setting up conv4\n",
      "I0430 14:12:46.322041 24730 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:12:46.322046 24730 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:12:46.322052 24730 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:12:46.322058 24730 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:12:46.322062 24730 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:12:46.322065 24730 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:12:46.322069 24730 net.cpp:124] Setting up relu4\n",
      "I0430 14:12:46.322073 24730 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:12:46.322075 24730 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:12:46.322077 24730 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:12:46.322083 24730 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:12:46.322085 24730 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:12:46.322089 24730 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:12:46.322585 24730 net.cpp:124] Setting up conv5\n",
      "I0430 14:12:46.322592 24730 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:12:46.322595 24730 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:12:46.322605 24730 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:12:46.322612 24730 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:12:46.322613 24730 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:12:46.322618 24730 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:12:46.322621 24730 net.cpp:124] Setting up relu5\n",
      "I0430 14:12:46.322624 24730 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:12:46.322626 24730 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:12:46.322629 24730 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:12:46.322633 24730 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:12:46.322634 24730 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:12:46.322638 24730 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:12:46.322645 24730 net.cpp:124] Setting up pool5\n",
      "I0430 14:12:46.322649 24730 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:12:46.322650 24730 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:12:46.322652 24730 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:12:46.322659 24730 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:12:46.322661 24730 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:12:46.322664 24730 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:12:46.343804 24730 net.cpp:124] Setting up fc6\n",
      "I0430 14:12:46.343825 24730 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:12:46.343829 24730 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:12:46.343844 24730 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:12:46.343854 24730 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:12:46.343858 24730 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:12:46.343863 24730 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:12:46.343868 24730 net.cpp:124] Setting up relu6\n",
      "I0430 14:12:46.343871 24730 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:12:46.343873 24730 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:12:46.343874 24730 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:12:46.343879 24730 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:12:46.343880 24730 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:12:46.343883 24730 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:12:46.343886 24730 net.cpp:124] Setting up drop6\n",
      "I0430 14:12:46.343900 24730 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:12:46.343902 24730 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:12:46.343905 24730 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:12:46.343910 24730 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:12:46.343914 24730 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:12:46.343919 24730 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:12:46.354619 24730 net.cpp:124] Setting up fc7\n",
      "I0430 14:12:46.354645 24730 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:12:46.354651 24730 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:12:46.354663 24730 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:12:46.354673 24730 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:12:46.354676 24730 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:12:46.354681 24730 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:12:46.354687 24730 net.cpp:124] Setting up relu7\n",
      "I0430 14:12:46.354689 24730 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:12:46.354691 24730 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:12:46.354693 24730 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:12:46.354697 24730 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:12:46.354698 24730 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:12:46.354702 24730 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:12:46.354707 24730 net.cpp:124] Setting up drop7\n",
      "I0430 14:12:46.354709 24730 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:12:46.354712 24730 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:12:46.354715 24730 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:12:46.354720 24730 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:12:46.354723 24730 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:12:46.354728 24730 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:12:46.355638 24730 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:12:46.355650 24730 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:12:46.355654 24730 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:12:46.355661 24730 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:12:46.355664 24730 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:12:46.355669 24730 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:12:46.355671 24730 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:12:46.355675 24730 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:12:46.355679 24730 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:12:46.355681 24730 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:12:46.355685 24730 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:12:46.355689 24730 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:12:46.355691 24730 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:12:46.355695 24730 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:12:46.355698 24730 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:12:46.355701 24730 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:12:46.355705 24730 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:12:46.355708 24730 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:12:46.355712 24730 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:12:46.355715 24730 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:12:46.355718 24730 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:12:46.355722 24730 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:12:46.355726 24730 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:12:46.355729 24730 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:12:46.355732 24730 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:12:46.355736 24730 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:12:46.355738 24730 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:12:46.355751 24730 net.cpp:257] Network initialization done.\n",
      "I0430 14:12:46.435024 24730 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:12:46.526115 24730 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:12:46.526975 24730 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:12:46.526983 24730 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:12:46.526988 24730 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/549410.jpg'}, '/tmp/tmp3JhYKB.mat')\n",
      "Processed 1422 windows in 162.896 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.027 s.\n",
      "prediction    [-1.91188, -2.57496, -1.61707, -2.53181, -2.29...\n",
      "ymin                                                         72\n",
      "xmin                                                          0\n",
      "ymax                                                        280\n",
      "xmax                                                        473\n",
      "Name: /home/ambika/INF_project/data/cat/549410.jpg, dtype: object\n",
      "prediction    [-1.78294, -2.4231, -1.53157, -2.58253, -2.429...\n",
      "ymin                                                        136\n",
      "xmin                                                          0\n",
      "ymax                                                        279\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/cat/549410.jpg, dtype: object\n",
      "domestic cat\n",
      "0\t72\t473\t280\n",
      "lion\n",
      "0\t136\t500\t279\n",
      "549410\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:15:30.893120 24878 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:15:30.893146 24878 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:15:30.893148 24878 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:15:30.894268 24878 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:15:30.894446 24878 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:15:30.894455 24878 net.cpp:86] Creating Layer data\n",
      "I0430 14:15:30.894459 24878 net.cpp:382] data -> data\n",
      "I0430 14:15:30.894470 24878 net.cpp:124] Setting up data\n",
      "I0430 14:15:30.894476 24878 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:15:30.894479 24878 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:15:30.894484 24878 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:15:30.894490 24878 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:15:30.894493 24878 net.cpp:408] conv1 <- data\n",
      "I0430 14:15:30.894498 24878 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:15:30.894556 24878 net.cpp:124] Setting up conv1\n",
      "I0430 14:15:30.894562 24878 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:15:30.894564 24878 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:15:30.894573 24878 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:15:30.894578 24878 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:15:30.894582 24878 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:15:30.894587 24878 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:15:30.894592 24878 net.cpp:124] Setting up relu1\n",
      "I0430 14:15:30.894595 24878 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:15:30.894598 24878 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:15:30.894601 24878 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:15:30.894606 24878 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:15:30.894609 24878 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:15:30.894614 24878 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:15:30.894621 24878 net.cpp:124] Setting up pool1\n",
      "I0430 14:15:30.894626 24878 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:15:30.894629 24878 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:15:30.894631 24878 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:15:30.894637 24878 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:15:30.894640 24878 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:15:30.894645 24878 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:15:30.894650 24878 net.cpp:124] Setting up norm1\n",
      "I0430 14:15:30.894655 24878 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:15:30.894659 24878 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:15:30.894661 24878 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:15:30.894666 24878 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:15:30.894670 24878 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:15:30.894675 24878 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:15:30.895015 24878 net.cpp:124] Setting up conv2\n",
      "I0430 14:15:30.895020 24878 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:15:30.895023 24878 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:15:30.895030 24878 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:15:30.895035 24878 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:15:30.895038 24878 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:15:30.895043 24878 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:15:30.895047 24878 net.cpp:124] Setting up relu2\n",
      "I0430 14:15:30.895051 24878 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:15:30.895054 24878 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:15:30.895057 24878 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:15:30.895062 24878 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:15:30.895066 24878 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:15:30.895071 24878 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:15:30.895076 24878 net.cpp:124] Setting up pool2\n",
      "I0430 14:15:30.895081 24878 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:15:30.895083 24878 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:15:30.895087 24878 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:15:30.895092 24878 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:15:30.895095 24878 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:15:30.895100 24878 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:15:30.895105 24878 net.cpp:124] Setting up norm2\n",
      "I0430 14:15:30.895109 24878 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:15:30.895112 24878 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:15:30.895115 24878 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:15:30.895122 24878 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:15:30.895124 24878 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:15:30.895129 24878 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:15:30.895814 24878 net.cpp:124] Setting up conv3\n",
      "I0430 14:15:30.895825 24878 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:15:30.895829 24878 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:15:30.895839 24878 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:15:30.895845 24878 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:15:30.895848 24878 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:15:30.895854 24878 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:15:30.895860 24878 net.cpp:124] Setting up relu3\n",
      "I0430 14:15:30.895864 24878 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:15:30.895866 24878 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:15:30.895870 24878 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:15:30.895877 24878 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:15:30.895880 24878 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:15:30.895885 24878 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:15:30.896610 24878 net.cpp:124] Setting up conv4\n",
      "I0430 14:15:30.896620 24878 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:15:30.896625 24878 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:15:30.896631 24878 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:15:30.896636 24878 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:15:30.896639 24878 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:15:30.896646 24878 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:15:30.896651 24878 net.cpp:124] Setting up relu4\n",
      "I0430 14:15:30.896654 24878 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:15:30.896657 24878 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:15:30.896661 24878 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:15:30.896667 24878 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:15:30.896670 24878 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:15:30.896675 24878 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:15:30.897167 24878 net.cpp:124] Setting up conv5\n",
      "I0430 14:15:30.897176 24878 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:15:30.897179 24878 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:15:30.897189 24878 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:15:30.897194 24878 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:15:30.897197 24878 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:15:30.897203 24878 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:15:30.897208 24878 net.cpp:124] Setting up relu5\n",
      "I0430 14:15:30.897212 24878 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:15:30.897215 24878 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:15:30.897218 24878 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:15:30.897223 24878 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:15:30.897227 24878 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:15:30.897231 24878 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:15:30.897238 24878 net.cpp:124] Setting up pool5\n",
      "I0430 14:15:30.897243 24878 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:15:30.897245 24878 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:15:30.897248 24878 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:15:30.897259 24878 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:15:30.897263 24878 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:15:30.897267 24878 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:15:30.919131 24878 net.cpp:124] Setting up fc6\n",
      "I0430 14:15:30.919162 24878 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:15:30.919164 24878 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:15:30.919173 24878 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:15:30.919184 24878 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:15:30.919188 24878 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:15:30.919193 24878 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:15:30.919201 24878 net.cpp:124] Setting up relu6\n",
      "I0430 14:15:30.919214 24878 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:15:30.919217 24878 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:15:30.919220 24878 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:15:30.919226 24878 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:15:30.919229 24878 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:15:30.919232 24878 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:15:30.919239 24878 net.cpp:124] Setting up drop6\n",
      "I0430 14:15:30.919244 24878 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:15:30.919245 24878 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:15:30.919248 24878 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:15:30.919253 24878 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:15:30.919256 24878 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:15:30.919262 24878 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:15:30.928855 24878 net.cpp:124] Setting up fc7\n",
      "I0430 14:15:30.928879 24878 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:15:30.928882 24878 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:15:30.928911 24878 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:15:30.928923 24878 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:15:30.928927 24878 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:15:30.928936 24878 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:15:30.928944 24878 net.cpp:124] Setting up relu7\n",
      "I0430 14:15:30.928951 24878 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:15:30.928953 24878 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:15:30.928956 24878 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:15:30.928967 24878 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:15:30.928977 24878 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:15:30.928983 24878 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:15:30.928989 24878 net.cpp:124] Setting up drop7\n",
      "I0430 14:15:30.928993 24878 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:15:30.928995 24878 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:15:30.928998 24878 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:15:30.929004 24878 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:15:30.929006 24878 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:15:30.929011 24878 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:15:30.929644 24878 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:15:30.929656 24878 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:15:30.929659 24878 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:15:30.929667 24878 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:15:30.929672 24878 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:15:30.929674 24878 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:15:30.929677 24878 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:15:30.929682 24878 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:15:30.929685 24878 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:15:30.929688 24878 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:15:30.929692 24878 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:15:30.929695 24878 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:15:30.929698 24878 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:15:30.929702 24878 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:15:30.929704 24878 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:15:30.929708 24878 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:15:30.929711 24878 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:15:30.929714 24878 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:15:30.929718 24878 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:15:30.929721 24878 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:15:30.929724 24878 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:15:30.929728 24878 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:15:30.929731 24878 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:15:30.929734 24878 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:15:30.929738 24878 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:15:30.929740 24878 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:15:30.929744 24878 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:15:30.929754 24878 net.cpp:257] Network initialization done.\n",
      "I0430 14:15:31.010283 24878 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:15:31.101554 24878 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:15:31.102535 24878 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:15:31.102545 24878 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:15:31.102550 24878 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/334416.jpg'}, '/tmp/tmpIuf2Z5.mat')\n",
      "Processed 2209 windows in 245.598 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.22471, -2.15201, -1.92475, -2.07032, -1.69...\n",
      "ymin                                                        126\n",
      "xmin                                                        214\n",
      "ymax                                                        322\n",
      "xmax                                                        282\n",
      "Name: /home/ambika/INF_project/data/couch/334416.jpg, dtype: object\n",
      "prediction    [-2.24864, -1.81582, -2.38656, -2.20158, -2.39...\n",
      "ymin                                                        149\n",
      "xmin                                                        301\n",
      "ymax                                                        333\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/couch/334416.jpg, dtype: object\n",
      "person\n",
      "214\t126\t282\t322\n",
      "sofa\n",
      "301\t149\t500\t333\n",
      "334416\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:19:38.229949 25103 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:19:38.229970 25103 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:19:38.229974 25103 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:19:38.231173 25103 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:19:38.231287 25103 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:19:38.231295 25103 net.cpp:86] Creating Layer data\n",
      "I0430 14:19:38.231299 25103 net.cpp:382] data -> data\n",
      "I0430 14:19:38.231313 25103 net.cpp:124] Setting up data\n",
      "I0430 14:19:38.231318 25103 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:19:38.231322 25103 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:19:38.231325 25103 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:19:38.231331 25103 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:19:38.231334 25103 net.cpp:408] conv1 <- data\n",
      "I0430 14:19:38.231339 25103 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:19:38.231400 25103 net.cpp:124] Setting up conv1\n",
      "I0430 14:19:38.231406 25103 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:19:38.231410 25103 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:19:38.231420 25103 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:19:38.231425 25103 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:19:38.231427 25103 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:19:38.231432 25103 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:19:38.231438 25103 net.cpp:124] Setting up relu1\n",
      "I0430 14:19:38.231442 25103 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:19:38.231446 25103 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:19:38.231448 25103 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:19:38.231452 25103 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:19:38.231456 25103 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:19:38.231461 25103 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:19:38.231468 25103 net.cpp:124] Setting up pool1\n",
      "I0430 14:19:38.231472 25103 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:19:38.231474 25103 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:19:38.231477 25103 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:19:38.231483 25103 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:19:38.231487 25103 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:19:38.231490 25103 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:19:38.231497 25103 net.cpp:124] Setting up norm1\n",
      "I0430 14:19:38.231500 25103 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:19:38.231503 25103 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:19:38.231505 25103 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:19:38.231510 25103 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:19:38.231513 25103 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:19:38.231518 25103 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:19:38.231876 25103 net.cpp:124] Setting up conv2\n",
      "I0430 14:19:38.231884 25103 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:19:38.231887 25103 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:19:38.231895 25103 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:19:38.231901 25103 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:19:38.231904 25103 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:19:38.231909 25103 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:19:38.231914 25103 net.cpp:124] Setting up relu2\n",
      "I0430 14:19:38.231917 25103 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:19:38.231920 25103 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:19:38.231923 25103 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:19:38.231927 25103 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:19:38.231930 25103 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:19:38.231935 25103 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:19:38.231940 25103 net.cpp:124] Setting up pool2\n",
      "I0430 14:19:38.231945 25103 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:19:38.231947 25103 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:19:38.231950 25103 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:19:38.231956 25103 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:19:38.231958 25103 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:19:38.231963 25103 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:19:38.231968 25103 net.cpp:124] Setting up norm2\n",
      "I0430 14:19:38.231972 25103 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:19:38.231976 25103 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:19:38.231977 25103 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:19:38.231983 25103 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:19:38.231986 25103 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:19:38.231990 25103 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:19:38.232981 25103 net.cpp:124] Setting up conv3\n",
      "I0430 14:19:38.232995 25103 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:19:38.232998 25103 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:19:38.233009 25103 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:19:38.233016 25103 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:19:38.233021 25103 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:19:38.233026 25103 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:19:38.233031 25103 net.cpp:124] Setting up relu3\n",
      "I0430 14:19:38.233036 25103 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:19:38.233038 25103 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:19:38.233042 25103 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:19:38.233049 25103 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:19:38.233052 25103 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:19:38.233057 25103 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:19:38.233572 25103 net.cpp:124] Setting up conv4\n",
      "I0430 14:19:38.233584 25103 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:19:38.233587 25103 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:19:38.233595 25103 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:19:38.233602 25103 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:19:38.233603 25103 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:19:38.233609 25103 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:19:38.233614 25103 net.cpp:124] Setting up relu4\n",
      "I0430 14:19:38.233619 25103 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:19:38.233621 25103 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:19:38.233624 25103 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:19:38.233631 25103 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:19:38.233633 25103 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:19:38.233639 25103 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:19:38.234143 25103 net.cpp:124] Setting up conv5\n",
      "I0430 14:19:38.234153 25103 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:19:38.234156 25103 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:19:38.234167 25103 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:19:38.234174 25103 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:19:38.234176 25103 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:19:38.234182 25103 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:19:38.234187 25103 net.cpp:124] Setting up relu5\n",
      "I0430 14:19:38.234191 25103 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:19:38.234194 25103 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:19:38.234197 25103 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:19:38.234202 25103 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:19:38.234205 25103 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:19:38.234210 25103 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:19:38.234217 25103 net.cpp:124] Setting up pool5\n",
      "I0430 14:19:38.234221 25103 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:19:38.234223 25103 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:19:38.234226 25103 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:19:38.234235 25103 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:19:38.234237 25103 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:19:38.234242 25103 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:19:38.255447 25103 net.cpp:124] Setting up fc6\n",
      "I0430 14:19:38.255470 25103 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:19:38.255473 25103 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:19:38.255483 25103 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:19:38.255493 25103 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:19:38.255496 25103 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:19:38.255502 25103 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:19:38.255511 25103 net.cpp:124] Setting up relu6\n",
      "I0430 14:19:38.255514 25103 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:19:38.255517 25103 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:19:38.255527 25103 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:19:38.255532 25103 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:19:38.255535 25103 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:19:38.255539 25103 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:19:38.255545 25103 net.cpp:124] Setting up drop6\n",
      "I0430 14:19:38.255549 25103 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:19:38.255551 25103 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:19:38.255555 25103 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:19:38.255560 25103 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:19:38.255563 25103 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:19:38.255569 25103 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:19:38.266508 25103 net.cpp:124] Setting up fc7\n",
      "I0430 14:19:38.266533 25103 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:19:38.266536 25103 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:19:38.266547 25103 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:19:38.266558 25103 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:19:38.266562 25103 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:19:38.266568 25103 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:19:38.266577 25103 net.cpp:124] Setting up relu7\n",
      "I0430 14:19:38.266584 25103 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:19:38.266587 25103 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:19:38.266592 25103 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:19:38.266597 25103 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:19:38.266599 25103 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:19:38.266604 25103 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:19:38.266610 25103 net.cpp:124] Setting up drop7\n",
      "I0430 14:19:38.266614 25103 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:19:38.266616 25103 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:19:38.266619 25103 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:19:38.266625 25103 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:19:38.266628 25103 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:19:38.266633 25103 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:19:38.267277 25103 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:19:38.267287 25103 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:19:38.267290 25103 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:19:38.267298 25103 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:19:38.267302 25103 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:19:38.267304 25103 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:19:38.267307 25103 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:19:38.267310 25103 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:19:38.267314 25103 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:19:38.267318 25103 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:19:38.267323 25103 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:19:38.267325 25103 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:19:38.267328 25103 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:19:38.267331 25103 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:19:38.267334 25103 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:19:38.267338 25103 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:19:38.267340 25103 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:19:38.267344 25103 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:19:38.267348 25103 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:19:38.267350 25103 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:19:38.267354 25103 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:19:38.267356 25103 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:19:38.267359 25103 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:19:38.267364 25103 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:19:38.267366 25103 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:19:38.267369 25103 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:19:38.267371 25103 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:19:38.267381 25103 net.cpp:257] Network initialization done.\n",
      "I0430 14:19:38.348176 25103 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:19:38.439407 25103 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:19:38.440299 25103 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:19:38.440307 25103 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:19:38.440312 25103 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/384007.jpg'}, '/tmp/tmp0VHFpn.mat')\n",
      "Processed 2109 windows in 239.098 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.035 s.\n",
      "prediction    [-1.76186, -1.13846, -1.76459, -1.62773, -1.87...\n",
      "ymin                                                        147\n",
      "xmin                                                      83.25\n",
      "ymax                                                      179.5\n",
      "xmax                                                        112\n",
      "Name: /home/ambika/INF_project/data/dog/384007.jpg, dtype: object\n",
      "prediction    [-1.39226, -2.42164, -1.57788, -2.02174, -1.53...\n",
      "ymin                                                      310.5\n",
      "xmin                                                      193.5\n",
      "ymax                                                     409.75\n",
      "xmax                                                     250.75\n",
      "Name: /home/ambika/INF_project/data/dog/384007.jpg, dtype: object\n",
      "cattle\n",
      "83.25\t147.0\t112.0\t179.5\n",
      "dog\n",
      "193.5\t310.5\t250.75\t409.75\n",
      "384007\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:23:39.010844 25293 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:23:39.010869 25293 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:23:39.010882 25293 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:23:39.012058 25293 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:23:39.012217 25293 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:23:39.012226 25293 net.cpp:86] Creating Layer data\n",
      "I0430 14:23:39.012230 25293 net.cpp:382] data -> data\n",
      "I0430 14:23:39.012244 25293 net.cpp:124] Setting up data\n",
      "I0430 14:23:39.012250 25293 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:23:39.012253 25293 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:23:39.012257 25293 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:23:39.012264 25293 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:23:39.012269 25293 net.cpp:408] conv1 <- data\n",
      "I0430 14:23:39.012274 25293 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:23:39.012346 25293 net.cpp:124] Setting up conv1\n",
      "I0430 14:23:39.012352 25293 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:23:39.012356 25293 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:23:39.012363 25293 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:23:39.012369 25293 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:23:39.012372 25293 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:23:39.012377 25293 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:23:39.012382 25293 net.cpp:124] Setting up relu1\n",
      "I0430 14:23:39.012387 25293 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:23:39.012389 25293 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:23:39.012392 25293 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:23:39.012398 25293 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:23:39.012400 25293 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:23:39.012404 25293 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:23:39.012411 25293 net.cpp:124] Setting up pool1\n",
      "I0430 14:23:39.012415 25293 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:23:39.012418 25293 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:23:39.012421 25293 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:23:39.012426 25293 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:23:39.012429 25293 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:23:39.012434 25293 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:23:39.012439 25293 net.cpp:124] Setting up norm1\n",
      "I0430 14:23:39.012444 25293 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:23:39.012445 25293 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:23:39.012449 25293 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:23:39.012454 25293 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:23:39.012456 25293 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:23:39.012460 25293 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:23:39.012812 25293 net.cpp:124] Setting up conv2\n",
      "I0430 14:23:39.012820 25293 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:23:39.012822 25293 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:23:39.012830 25293 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:23:39.012836 25293 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:23:39.012840 25293 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:23:39.012845 25293 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:23:39.012850 25293 net.cpp:124] Setting up relu2\n",
      "I0430 14:23:39.012854 25293 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:23:39.012857 25293 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:23:39.012861 25293 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:23:39.012866 25293 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:23:39.012868 25293 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:23:39.012872 25293 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:23:39.012879 25293 net.cpp:124] Setting up pool2\n",
      "I0430 14:23:39.012883 25293 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:23:39.012886 25293 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:23:39.012888 25293 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:23:39.012895 25293 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:23:39.012898 25293 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:23:39.012903 25293 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:23:39.012908 25293 net.cpp:124] Setting up norm2\n",
      "I0430 14:23:39.012912 25293 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:23:39.012915 25293 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:23:39.012917 25293 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:23:39.012923 25293 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:23:39.012926 25293 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:23:39.012930 25293 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:23:39.013628 25293 net.cpp:124] Setting up conv3\n",
      "I0430 14:23:39.013640 25293 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:23:39.013643 25293 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:23:39.013653 25293 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:23:39.013660 25293 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:23:39.013664 25293 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:23:39.013669 25293 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:23:39.013674 25293 net.cpp:124] Setting up relu3\n",
      "I0430 14:23:39.013677 25293 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:23:39.013680 25293 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:23:39.013684 25293 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:23:39.013690 25293 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:23:39.013692 25293 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:23:39.013697 25293 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:23:39.014453 25293 net.cpp:124] Setting up conv4\n",
      "I0430 14:23:39.014464 25293 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:23:39.014468 25293 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:23:39.014474 25293 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:23:39.014482 25293 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:23:39.014498 25293 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:23:39.014503 25293 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:23:39.014508 25293 net.cpp:124] Setting up relu4\n",
      "I0430 14:23:39.014510 25293 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:23:39.014513 25293 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:23:39.014515 25293 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:23:39.014521 25293 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:23:39.014523 25293 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:23:39.014528 25293 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:23:39.015033 25293 net.cpp:124] Setting up conv5\n",
      "I0430 14:23:39.015049 25293 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:23:39.015058 25293 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:23:39.015070 25293 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:23:39.015075 25293 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:23:39.015079 25293 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:23:39.015084 25293 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:23:39.015089 25293 net.cpp:124] Setting up relu5\n",
      "I0430 14:23:39.015092 25293 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:23:39.015095 25293 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:23:39.015099 25293 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:23:39.015103 25293 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:23:39.015105 25293 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:23:39.015110 25293 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:23:39.015117 25293 net.cpp:124] Setting up pool5\n",
      "I0430 14:23:39.015121 25293 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:23:39.015123 25293 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:23:39.015126 25293 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:23:39.015135 25293 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:23:39.015137 25293 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:23:39.015142 25293 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:23:39.037184 25293 net.cpp:124] Setting up fc6\n",
      "I0430 14:23:39.037205 25293 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:23:39.037210 25293 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:23:39.037233 25293 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:23:39.037250 25293 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:23:39.037255 25293 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:23:39.037261 25293 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:23:39.037271 25293 net.cpp:124] Setting up relu6\n",
      "I0430 14:23:39.037276 25293 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:23:39.037278 25293 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:23:39.037282 25293 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:23:39.037288 25293 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:23:39.037291 25293 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:23:39.037295 25293 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:23:39.037300 25293 net.cpp:124] Setting up drop6\n",
      "I0430 14:23:39.037304 25293 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:23:39.037307 25293 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:23:39.037309 25293 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:23:39.037314 25293 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:23:39.037317 25293 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:23:39.037323 25293 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:23:39.048422 25293 net.cpp:124] Setting up fc7\n",
      "I0430 14:23:39.048447 25293 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:23:39.048454 25293 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:23:39.048463 25293 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:23:39.048472 25293 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:23:39.048475 25293 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:23:39.048481 25293 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:23:39.048490 25293 net.cpp:124] Setting up relu7\n",
      "I0430 14:23:39.048493 25293 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:23:39.048496 25293 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:23:39.048511 25293 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:23:39.048516 25293 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:23:39.048519 25293 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:23:39.048526 25293 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:23:39.048532 25293 net.cpp:124] Setting up drop7\n",
      "I0430 14:23:39.048535 25293 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:23:39.048537 25293 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:23:39.048540 25293 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:23:39.048547 25293 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:23:39.048548 25293 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:23:39.048553 25293 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:23:39.049463 25293 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:23:39.049476 25293 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:23:39.049479 25293 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:23:39.049487 25293 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:23:39.049491 25293 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:23:39.049494 25293 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:23:39.049497 25293 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:23:39.049501 25293 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:23:39.049504 25293 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:23:39.049507 25293 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:23:39.049510 25293 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:23:39.049513 25293 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:23:39.049516 25293 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:23:39.049520 25293 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:23:39.049523 25293 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:23:39.049526 25293 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:23:39.049530 25293 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:23:39.049532 25293 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:23:39.049535 25293 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:23:39.049540 25293 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:23:39.049542 25293 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:23:39.049546 25293 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:23:39.049548 25293 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:23:39.049551 25293 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:23:39.049554 25293 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:23:39.049558 25293 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:23:39.049561 25293 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:23:39.049572 25293 net.cpp:257] Network initialization done.\n",
      "I0430 14:23:39.129719 25293 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:23:39.221316 25293 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:23:39.222292 25293 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:23:39.222301 25293 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:23:39.222306 25293 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/horse/334713.jpg'}, '/tmp/tmp6tiT8M.mat')\n",
      "Processed 4209 windows in 465.885 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.101 s.\n",
      "prediction    [-2.37753, -2.53224, -1.7141, -1.74493, -1.722...\n",
      "ymin                                                    252.414\n",
      "xmin                                                          0\n",
      "ymax                                                     460.54\n",
      "xmax                                                    186.148\n",
      "Name: /home/ambika/INF_project/data/horse/334713.jpg, dtype: object\n",
      "prediction    [-2.91042, -2.58696, -2.61814, -2.86609, -2.21...\n",
      "ymin                                                    161.172\n",
      "xmin                                                    143.856\n",
      "ymax                                                    405.262\n",
      "xmax                                                    246.088\n",
      "Name: /home/ambika/INF_project/data/horse/334713.jpg, dtype: object\n",
      "person\n",
      "0.0\t252.414\t186.148\t460.54\n",
      "horse\n",
      "143.856\t161.172\t246.088\t405.262\n",
      "334713\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:31:27.157461 25541 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:31:27.157485 25541 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:31:27.157488 25541 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:31:27.159005 25541 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:31:27.159274 25541 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:31:27.159284 25541 net.cpp:86] Creating Layer data\n",
      "I0430 14:31:27.159288 25541 net.cpp:382] data -> data\n",
      "I0430 14:31:27.159302 25541 net.cpp:124] Setting up data\n",
      "I0430 14:31:27.159322 25541 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:31:27.159325 25541 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:31:27.159330 25541 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:31:27.159337 25541 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:31:27.159340 25541 net.cpp:408] conv1 <- data\n",
      "I0430 14:31:27.159346 25541 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:31:27.159409 25541 net.cpp:124] Setting up conv1\n",
      "I0430 14:31:27.159415 25541 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:31:27.159418 25541 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:31:27.159435 25541 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:31:27.159442 25541 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:31:27.159446 25541 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:31:27.159451 25541 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:31:27.159457 25541 net.cpp:124] Setting up relu1\n",
      "I0430 14:31:27.159461 25541 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:31:27.159464 25541 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:31:27.159467 25541 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:31:27.159472 25541 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:31:27.159476 25541 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:31:27.159481 25541 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:31:27.159487 25541 net.cpp:124] Setting up pool1\n",
      "I0430 14:31:27.159492 25541 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:31:27.159494 25541 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:31:27.159497 25541 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:31:27.159503 25541 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:31:27.159507 25541 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:31:27.159510 25541 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:31:27.159517 25541 net.cpp:124] Setting up norm1\n",
      "I0430 14:31:27.159521 25541 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:31:27.159523 25541 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:31:27.159526 25541 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:31:27.159533 25541 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:31:27.159535 25541 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:31:27.159539 25541 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:31:27.159920 25541 net.cpp:124] Setting up conv2\n",
      "I0430 14:31:27.159929 25541 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:31:27.159934 25541 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:31:27.159941 25541 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:31:27.159948 25541 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:31:27.159951 25541 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:31:27.159956 25541 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:31:27.159961 25541 net.cpp:124] Setting up relu2\n",
      "I0430 14:31:27.159965 25541 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:31:27.159968 25541 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:31:27.159971 25541 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:31:27.159976 25541 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:31:27.159978 25541 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:31:27.159983 25541 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:31:27.159989 25541 net.cpp:124] Setting up pool2\n",
      "I0430 14:31:27.159994 25541 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:31:27.159996 25541 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:31:27.159999 25541 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:31:27.160006 25541 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:31:27.160009 25541 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:31:27.160014 25541 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:31:27.160020 25541 net.cpp:124] Setting up norm2\n",
      "I0430 14:31:27.160024 25541 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:31:27.160027 25541 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:31:27.160030 25541 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:31:27.160035 25541 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:31:27.160038 25541 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:31:27.160043 25541 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:31:27.160754 25541 net.cpp:124] Setting up conv3\n",
      "I0430 14:31:27.160765 25541 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:31:27.160769 25541 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:31:27.160779 25541 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:31:27.160787 25541 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:31:27.160790 25541 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:31:27.160795 25541 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:31:27.160800 25541 net.cpp:124] Setting up relu3\n",
      "I0430 14:31:27.160804 25541 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:31:27.160806 25541 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:31:27.160809 25541 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:31:27.160814 25541 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:31:27.160815 25541 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:31:27.160820 25541 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:31:27.161567 25541 net.cpp:124] Setting up conv4\n",
      "I0430 14:31:27.161578 25541 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:31:27.161581 25541 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:31:27.161588 25541 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:31:27.161594 25541 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:31:27.161598 25541 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:31:27.161604 25541 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:31:27.161610 25541 net.cpp:124] Setting up relu4\n",
      "I0430 14:31:27.161614 25541 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:31:27.161617 25541 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:31:27.161620 25541 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:31:27.161628 25541 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:31:27.161630 25541 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:31:27.161635 25541 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:31:27.162147 25541 net.cpp:124] Setting up conv5\n",
      "I0430 14:31:27.162154 25541 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:31:27.162158 25541 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:31:27.162169 25541 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:31:27.162174 25541 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:31:27.162178 25541 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:31:27.162183 25541 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:31:27.162189 25541 net.cpp:124] Setting up relu5\n",
      "I0430 14:31:27.162192 25541 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:31:27.162195 25541 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:31:27.162199 25541 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:31:27.162204 25541 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:31:27.162206 25541 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:31:27.162211 25541 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:31:27.162219 25541 net.cpp:124] Setting up pool5\n",
      "I0430 14:31:27.162223 25541 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:31:27.162225 25541 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:31:27.162228 25541 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:31:27.162237 25541 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:31:27.162240 25541 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:31:27.162245 25541 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:31:27.184078 25541 net.cpp:124] Setting up fc6\n",
      "I0430 14:31:27.184100 25541 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:31:27.184105 25541 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:31:27.184116 25541 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:31:27.184126 25541 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:31:27.184130 25541 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:31:27.184136 25541 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:31:27.184145 25541 net.cpp:124] Setting up relu6\n",
      "I0430 14:31:27.184150 25541 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:31:27.184154 25541 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:31:27.184156 25541 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:31:27.184161 25541 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:31:27.184175 25541 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:31:27.184178 25541 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:31:27.184185 25541 net.cpp:124] Setting up drop6\n",
      "I0430 14:31:27.184188 25541 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:31:27.184190 25541 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:31:27.184193 25541 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:31:27.184200 25541 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:31:27.184201 25541 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:31:27.184206 25541 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:31:27.193724 25541 net.cpp:124] Setting up fc7\n",
      "I0430 14:31:27.193743 25541 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:31:27.193747 25541 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:31:27.193756 25541 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:31:27.193768 25541 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:31:27.193771 25541 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:31:27.193778 25541 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:31:27.193785 25541 net.cpp:124] Setting up relu7\n",
      "I0430 14:31:27.193789 25541 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:31:27.193792 25541 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:31:27.193795 25541 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:31:27.193801 25541 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:31:27.193810 25541 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:31:27.193816 25541 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:31:27.193822 25541 net.cpp:124] Setting up drop7\n",
      "I0430 14:31:27.193825 25541 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:31:27.193828 25541 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:31:27.193831 25541 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:31:27.193836 25541 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:31:27.193840 25541 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:31:27.193845 25541 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:31:27.194501 25541 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:31:27.194512 25541 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:31:27.194515 25541 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:31:27.194525 25541 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:31:27.194528 25541 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:31:27.194532 25541 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:31:27.194535 25541 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:31:27.194538 25541 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:31:27.194541 25541 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:31:27.194545 25541 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:31:27.194548 25541 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:31:27.194551 25541 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:31:27.194555 25541 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:31:27.194560 25541 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:31:27.194563 25541 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:31:27.194566 25541 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:31:27.194569 25541 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:31:27.194572 25541 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:31:27.194576 25541 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:31:27.194578 25541 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:31:27.194582 25541 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:31:27.194586 25541 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:31:27.194588 25541 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:31:27.194591 25541 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:31:27.194594 25541 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:31:27.194598 25541 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:31:27.194600 25541 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:31:27.194610 25541 net.cpp:257] Network initialization done.\n",
      "I0430 14:31:27.437116 25541 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:31:27.544411 25541 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:31:27.545413 25541 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:31:27.545423 25541 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:31:27.545433 25541 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/person/533123.jpg'}, '/tmp/tmpHvCa15.mat')\n",
      "Processed 2619 windows in 293.354 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-2.36755, -2.26143, -2.1013, -2.16632, -1.879...\n",
      "ymin                                                    142.284\n",
      "xmin                                                          0\n",
      "ymax                                                    500.664\n",
      "xmax                                                    292.916\n",
      "Name: /home/ambika/INF_project/data/person/533123.jpg, dtype: object\n",
      "prediction    [-2.57002, -2.53611, -1.83354, -1.808, -2.0087...\n",
      "ymin                                                    258.516\n",
      "xmin                                                          0\n",
      "ymax                                                    500.664\n",
      "xmax                                                    334.332\n",
      "Name: /home/ambika/INF_project/data/person/533123.jpg, dtype: object\n",
      "person\n",
      "0.0\t142.284\t292.916\t500.664\n",
      "chair\n",
      "0.0\t258.516\t334.332\t500.664\n",
      "533123\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:36:22.454193 25762 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:36:22.454211 25762 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:36:22.454216 25762 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:36:22.455366 25762 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:36:22.455513 25762 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:36:22.455524 25762 net.cpp:86] Creating Layer data\n",
      "I0430 14:36:22.455528 25762 net.cpp:382] data -> data\n",
      "I0430 14:36:22.455540 25762 net.cpp:124] Setting up data\n",
      "I0430 14:36:22.455545 25762 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:36:22.455549 25762 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:36:22.455554 25762 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:36:22.455561 25762 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:36:22.455566 25762 net.cpp:408] conv1 <- data\n",
      "I0430 14:36:22.455571 25762 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:36:22.455636 25762 net.cpp:124] Setting up conv1\n",
      "I0430 14:36:22.455641 25762 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:36:22.455643 25762 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:36:22.455651 25762 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:36:22.455655 25762 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:36:22.455658 25762 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:36:22.455662 25762 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:36:22.455667 25762 net.cpp:124] Setting up relu1\n",
      "I0430 14:36:22.455669 25762 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:36:22.455672 25762 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:36:22.455674 25762 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:36:22.455678 25762 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:36:22.455680 25762 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:36:22.455683 25762 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:36:22.455690 25762 net.cpp:124] Setting up pool1\n",
      "I0430 14:36:22.455693 25762 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:36:22.455695 25762 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:36:22.455698 25762 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:36:22.455703 25762 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:36:22.455704 25762 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:36:22.455708 25762 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:36:22.455713 25762 net.cpp:124] Setting up norm1\n",
      "I0430 14:36:22.455716 25762 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:36:22.455718 25762 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:36:22.455720 25762 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:36:22.455724 25762 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:36:22.455727 25762 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:36:22.455730 25762 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:36:22.456077 25762 net.cpp:124] Setting up conv2\n",
      "I0430 14:36:22.456084 25762 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:36:22.456086 25762 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:36:22.456094 25762 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:36:22.456101 25762 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:36:22.456105 25762 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:36:22.456110 25762 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:36:22.456116 25762 net.cpp:124] Setting up relu2\n",
      "I0430 14:36:22.456122 25762 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:36:22.456125 25762 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:36:22.456127 25762 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:36:22.456131 25762 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:36:22.456133 25762 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:36:22.456137 25762 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:36:22.456142 25762 net.cpp:124] Setting up pool2\n",
      "I0430 14:36:22.456146 25762 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:36:22.456148 25762 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:36:22.456151 25762 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:36:22.456156 25762 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:36:22.456158 25762 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:36:22.456161 25762 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:36:22.456166 25762 net.cpp:124] Setting up norm2\n",
      "I0430 14:36:22.456169 25762 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:36:22.456171 25762 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:36:22.456174 25762 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:36:22.456179 25762 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:36:22.456182 25762 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:36:22.456185 25762 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:36:22.456885 25762 net.cpp:124] Setting up conv3\n",
      "I0430 14:36:22.456897 25762 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:36:22.456900 25762 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:36:22.456909 25762 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:36:22.456918 25762 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:36:22.456923 25762 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:36:22.456926 25762 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:36:22.456931 25762 net.cpp:124] Setting up relu3\n",
      "I0430 14:36:22.456934 25762 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:36:22.456938 25762 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:36:22.456939 25762 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:36:22.456945 25762 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:36:22.456948 25762 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:36:22.456951 25762 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:36:22.457703 25762 net.cpp:124] Setting up conv4\n",
      "I0430 14:36:22.457715 25762 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:36:22.457717 25762 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:36:22.457725 25762 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:36:22.457731 25762 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:36:22.457736 25762 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:36:22.457739 25762 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:36:22.457744 25762 net.cpp:124] Setting up relu4\n",
      "I0430 14:36:22.457747 25762 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:36:22.457751 25762 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:36:22.457752 25762 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:36:22.457758 25762 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:36:22.457761 25762 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:36:22.457763 25762 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:36:22.458274 25762 net.cpp:124] Setting up conv5\n",
      "I0430 14:36:22.458281 25762 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:36:22.458286 25762 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:36:22.458295 25762 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:36:22.458304 25762 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:36:22.458307 25762 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:36:22.458310 25762 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:36:22.458315 25762 net.cpp:124] Setting up relu5\n",
      "I0430 14:36:22.458318 25762 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:36:22.458320 25762 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:36:22.458323 25762 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:36:22.458328 25762 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:36:22.458329 25762 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:36:22.458333 25762 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:36:22.458340 25762 net.cpp:124] Setting up pool5\n",
      "I0430 14:36:22.458344 25762 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:36:22.458346 25762 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:36:22.458349 25762 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:36:22.458355 25762 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:36:22.458358 25762 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:36:22.458361 25762 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:36:22.479756 25762 net.cpp:124] Setting up fc6\n",
      "I0430 14:36:22.479779 25762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:36:22.479782 25762 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:36:22.479802 25762 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:36:22.479811 25762 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:36:22.479816 25762 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:36:22.479822 25762 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:36:22.479830 25762 net.cpp:124] Setting up relu6\n",
      "I0430 14:36:22.479835 25762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:36:22.479837 25762 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:36:22.479840 25762 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:36:22.479845 25762 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:36:22.479847 25762 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:36:22.479851 25762 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:36:22.479856 25762 net.cpp:124] Setting up drop6\n",
      "I0430 14:36:22.479858 25762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:36:22.479861 25762 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:36:22.479862 25762 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:36:22.479868 25762 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:36:22.479871 25762 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:36:22.479873 25762 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:36:22.490244 25762 net.cpp:124] Setting up fc7\n",
      "I0430 14:36:22.490270 25762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:36:22.490274 25762 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:36:22.490286 25762 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:36:22.490303 25762 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:36:22.490309 25762 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:36:22.490314 25762 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:36:22.490324 25762 net.cpp:124] Setting up relu7\n",
      "I0430 14:36:22.490329 25762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:36:22.490331 25762 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:36:22.490334 25762 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:36:22.490340 25762 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:36:22.490342 25762 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:36:22.490345 25762 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:36:22.490350 25762 net.cpp:124] Setting up drop7\n",
      "I0430 14:36:22.490353 25762 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:36:22.490356 25762 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:36:22.490358 25762 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:36:22.490363 25762 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:36:22.490365 25762 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:36:22.490370 25762 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:36:22.491303 25762 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:36:22.491314 25762 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:36:22.491317 25762 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:36:22.491324 25762 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:36:22.491329 25762 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:36:22.491333 25762 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:36:22.491336 25762 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:36:22.491340 25762 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:36:22.491343 25762 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:36:22.491345 25762 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:36:22.491348 25762 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:36:22.491350 25762 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:36:22.491353 25762 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:36:22.491355 25762 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:36:22.491358 25762 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:36:22.491361 25762 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:36:22.491364 25762 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:36:22.491367 25762 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:36:22.491369 25762 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:36:22.491372 25762 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:36:22.491375 25762 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:36:22.491379 25762 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:36:22.491381 25762 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:36:22.491384 25762 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:36:22.491386 25762 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:36:22.491389 25762 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:36:22.491391 25762 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:36:22.491401 25762 net.cpp:257] Network initialization done.\n",
      "I0430 14:36:22.574338 25762 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:36:22.666353 25762 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:36:22.667439 25762 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:36:22.667453 25762 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:36:22.667456 25762 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/train/423804.jpg'}, '/tmp/tmp05C_XK.mat')\n",
      "Processed 2508 windows in 286.239 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.031 s.\n",
      "prediction    [-3.21274, -2.42958, -1.9906, -2.47797, -1.767...\n",
      "ymin                                                        279\n",
      "xmin                                                        187\n",
      "ymax                                                        317\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/train/423804.jpg, dtype: object\n",
      "prediction    [-2.37494, -1.84493, -1.83881, -2.54421, -1.92...\n",
      "ymin                                                         97\n",
      "xmin                                                        310\n",
      "ymax                                                        200\n",
      "xmax                                                        494\n",
      "Name: /home/ambika/INF_project/data/train/423804.jpg, dtype: object\n",
      "horizontal bar\n",
      "187\t279\t500\t317\n",
      "train\n",
      "310\t97\t494\t200\n",
      "423804\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:41:10.424280 25986 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:41:10.424296 25986 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:41:10.424299 25986 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:41:10.425424 25986 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:41:10.425532 25986 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:41:10.425544 25986 net.cpp:86] Creating Layer data\n",
      "I0430 14:41:10.425549 25986 net.cpp:382] data -> data\n",
      "I0430 14:41:10.425562 25986 net.cpp:124] Setting up data\n",
      "I0430 14:41:10.425567 25986 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:41:10.425570 25986 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:41:10.425575 25986 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:41:10.425581 25986 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:41:10.425585 25986 net.cpp:408] conv1 <- data\n",
      "I0430 14:41:10.425590 25986 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:41:10.425647 25986 net.cpp:124] Setting up conv1\n",
      "I0430 14:41:10.425653 25986 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:41:10.425657 25986 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:41:10.425667 25986 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:41:10.425673 25986 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:41:10.425675 25986 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:41:10.425680 25986 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:41:10.425686 25986 net.cpp:124] Setting up relu1\n",
      "I0430 14:41:10.425690 25986 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:41:10.425694 25986 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:41:10.425698 25986 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:41:10.425703 25986 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:41:10.425704 25986 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:41:10.425709 25986 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:41:10.425716 25986 net.cpp:124] Setting up pool1\n",
      "I0430 14:41:10.425721 25986 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:41:10.425724 25986 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:41:10.425726 25986 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:41:10.425732 25986 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:41:10.425734 25986 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:41:10.425740 25986 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:41:10.425745 25986 net.cpp:124] Setting up norm1\n",
      "I0430 14:41:10.425750 25986 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:41:10.425751 25986 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:41:10.425755 25986 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:41:10.425760 25986 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:41:10.425762 25986 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:41:10.425766 25986 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:41:10.426126 25986 net.cpp:124] Setting up conv2\n",
      "I0430 14:41:10.426132 25986 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:41:10.426136 25986 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:41:10.426143 25986 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:41:10.426149 25986 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:41:10.426152 25986 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:41:10.426156 25986 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:41:10.426162 25986 net.cpp:124] Setting up relu2\n",
      "I0430 14:41:10.426165 25986 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:41:10.426168 25986 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:41:10.426172 25986 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:41:10.426177 25986 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:41:10.426180 25986 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:41:10.426184 25986 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:41:10.426192 25986 net.cpp:124] Setting up pool2\n",
      "I0430 14:41:10.426195 25986 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:41:10.426198 25986 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:41:10.426200 25986 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:41:10.426206 25986 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:41:10.426208 25986 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:41:10.426213 25986 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:41:10.426218 25986 net.cpp:124] Setting up norm2\n",
      "I0430 14:41:10.426223 25986 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:41:10.426225 25986 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:41:10.426229 25986 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:41:10.426235 25986 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:41:10.426239 25986 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:41:10.426242 25986 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:41:10.426940 25986 net.cpp:124] Setting up conv3\n",
      "I0430 14:41:10.426952 25986 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:41:10.426955 25986 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:41:10.426964 25986 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:41:10.426971 25986 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:41:10.426975 25986 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:41:10.426980 25986 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:41:10.426986 25986 net.cpp:124] Setting up relu3\n",
      "I0430 14:41:10.426991 25986 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:41:10.426993 25986 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:41:10.426996 25986 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:41:10.427002 25986 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:41:10.427006 25986 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:41:10.427009 25986 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:41:10.427811 25986 net.cpp:124] Setting up conv4\n",
      "I0430 14:41:10.427825 25986 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:41:10.427829 25986 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:41:10.427834 25986 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:41:10.427841 25986 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:41:10.427845 25986 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:41:10.427850 25986 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:41:10.427857 25986 net.cpp:124] Setting up relu4\n",
      "I0430 14:41:10.427861 25986 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:41:10.427863 25986 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:41:10.427867 25986 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:41:10.427873 25986 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:41:10.427875 25986 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:41:10.427881 25986 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:41:10.428385 25986 net.cpp:124] Setting up conv5\n",
      "I0430 14:41:10.428393 25986 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:41:10.428396 25986 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:41:10.428407 25986 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:41:10.428413 25986 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:41:10.428416 25986 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:41:10.428421 25986 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:41:10.428426 25986 net.cpp:124] Setting up relu5\n",
      "I0430 14:41:10.428431 25986 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:41:10.428432 25986 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:41:10.428436 25986 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:41:10.428442 25986 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:41:10.428444 25986 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:41:10.428449 25986 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:41:10.428457 25986 net.cpp:124] Setting up pool5\n",
      "I0430 14:41:10.428462 25986 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:41:10.428463 25986 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:41:10.428467 25986 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:41:10.428474 25986 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:41:10.428478 25986 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:41:10.428483 25986 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:41:10.449508 25986 net.cpp:124] Setting up fc6\n",
      "I0430 14:41:10.449532 25986 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:41:10.449535 25986 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:41:10.449548 25986 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:41:10.449558 25986 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:41:10.449563 25986 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:41:10.449569 25986 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:41:10.449578 25986 net.cpp:124] Setting up relu6\n",
      "I0430 14:41:10.449580 25986 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:41:10.449584 25986 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:41:10.449585 25986 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:41:10.449591 25986 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:41:10.449606 25986 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:41:10.449611 25986 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:41:10.449617 25986 net.cpp:124] Setting up drop6\n",
      "I0430 14:41:10.449620 25986 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:41:10.449623 25986 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:41:10.449626 25986 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:41:10.449631 25986 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:41:10.449635 25986 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:41:10.449640 25986 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:41:10.459302 25986 net.cpp:124] Setting up fc7\n",
      "I0430 14:41:10.459326 25986 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:41:10.459333 25986 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:41:10.459343 25986 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:41:10.459352 25986 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:41:10.459357 25986 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:41:10.459362 25986 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:41:10.459369 25986 net.cpp:124] Setting up relu7\n",
      "I0430 14:41:10.459373 25986 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:41:10.459375 25986 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:41:10.459378 25986 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:41:10.459383 25986 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:41:10.459398 25986 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:41:10.459403 25986 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:41:10.459410 25986 net.cpp:124] Setting up drop7\n",
      "I0430 14:41:10.459414 25986 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:41:10.459416 25986 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:41:10.459419 25986 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:41:10.459425 25986 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:41:10.459427 25986 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:41:10.459434 25986 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:41:10.460074 25986 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:41:10.460085 25986 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:41:10.460089 25986 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:41:10.460096 25986 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:41:10.460100 25986 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:41:10.460103 25986 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:41:10.460106 25986 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:41:10.460109 25986 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:41:10.460114 25986 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:41:10.460116 25986 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:41:10.460119 25986 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:41:10.460122 25986 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:41:10.460125 25986 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:41:10.460129 25986 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:41:10.460132 25986 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:41:10.460137 25986 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:41:10.460140 25986 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:41:10.460144 25986 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:41:10.460147 25986 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:41:10.460150 25986 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:41:10.460153 25986 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:41:10.460156 25986 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:41:10.460160 25986 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:41:10.460163 25986 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:41:10.460166 25986 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:41:10.460170 25986 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:41:10.460171 25986 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:41:10.460182 25986 net.cpp:257] Network initialization done.\n",
      "I0430 14:41:10.541488 25986 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:41:10.633967 25986 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:41:10.634956 25986 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:41:10.634965 25986 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:41:10.634970 25986 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/airplane/133279.jpg'}, '/tmp/tmpdDFfw8.mat')\n",
      "Processed 1377 windows in 156.344 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.029 s.\n",
      "prediction    [-1.86669, -1.98592, -1.907, -1.48245, -1.9578...\n",
      "ymin                                                        134\n",
      "xmin                                                        146\n",
      "ymax                                                        231\n",
      "xmax                                                        343\n",
      "Name: /home/ambika/INF_project/data/airplane/133279.jpg, dtype: object\n",
      "prediction    [-2.10952, -1.94958, -1.96916, -1.67039, -1.86...\n",
      "ymin                                                        118\n",
      "xmin                                                        147\n",
      "ymax                                                        232\n",
      "xmax                                                        343\n",
      "Name: /home/ambika/INF_project/data/airplane/133279.jpg, dtype: object\n",
      "car\n",
      "146\t134\t343\t231\n",
      "golfcart\n",
      "147\t118\t343\t232\n",
      "133279\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:43:48.483975 26148 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:43:48.484001 26148 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:43:48.484005 26148 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:43:48.485144 26148 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:43:48.485302 26148 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:43:48.485312 26148 net.cpp:86] Creating Layer data\n",
      "I0430 14:43:48.485316 26148 net.cpp:382] data -> data\n",
      "I0430 14:43:48.485328 26148 net.cpp:124] Setting up data\n",
      "I0430 14:43:48.485333 26148 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:43:48.485337 26148 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:43:48.485339 26148 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:43:48.485345 26148 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:43:48.485348 26148 net.cpp:408] conv1 <- data\n",
      "I0430 14:43:48.485352 26148 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:43:48.485420 26148 net.cpp:124] Setting up conv1\n",
      "I0430 14:43:48.485425 26148 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:43:48.485427 26148 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:43:48.485435 26148 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:43:48.485438 26148 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:43:48.485441 26148 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:43:48.485445 26148 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:43:48.485450 26148 net.cpp:124] Setting up relu1\n",
      "I0430 14:43:48.485452 26148 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:43:48.485455 26148 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:43:48.485458 26148 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:43:48.485461 26148 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:43:48.485465 26148 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:43:48.485467 26148 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:43:48.485474 26148 net.cpp:124] Setting up pool1\n",
      "I0430 14:43:48.485477 26148 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:43:48.485479 26148 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:43:48.485482 26148 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:43:48.485486 26148 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:43:48.485489 26148 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:43:48.485492 26148 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:43:48.485497 26148 net.cpp:124] Setting up norm1\n",
      "I0430 14:43:48.485501 26148 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:43:48.485503 26148 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:43:48.485507 26148 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:43:48.485510 26148 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:43:48.485512 26148 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:43:48.485515 26148 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:43:48.485854 26148 net.cpp:124] Setting up conv2\n",
      "I0430 14:43:48.485860 26148 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:43:48.485862 26148 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:43:48.485867 26148 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:43:48.485872 26148 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:43:48.485874 26148 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:43:48.485877 26148 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:43:48.485882 26148 net.cpp:124] Setting up relu2\n",
      "I0430 14:43:48.485884 26148 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:43:48.485887 26148 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:43:48.485888 26148 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:43:48.485893 26148 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:43:48.485894 26148 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:43:48.485898 26148 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:43:48.485903 26148 net.cpp:124] Setting up pool2\n",
      "I0430 14:43:48.485908 26148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:43:48.485908 26148 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:43:48.485910 26148 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:43:48.485913 26148 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:43:48.485915 26148 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:43:48.485918 26148 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:43:48.485921 26148 net.cpp:124] Setting up norm2\n",
      "I0430 14:43:48.485924 26148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:43:48.485925 26148 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:43:48.485927 26148 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:43:48.485932 26148 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:43:48.485935 26148 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:43:48.485939 26148 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:43:48.486662 26148 net.cpp:124] Setting up conv3\n",
      "I0430 14:43:48.486673 26148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:43:48.486677 26148 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:43:48.486685 26148 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:43:48.486690 26148 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:43:48.486692 26148 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:43:48.486696 26148 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:43:48.486701 26148 net.cpp:124] Setting up relu3\n",
      "I0430 14:43:48.486704 26148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:43:48.486706 26148 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:43:48.486708 26148 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:43:48.486714 26148 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:43:48.486717 26148 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:43:48.486721 26148 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:43:48.487501 26148 net.cpp:124] Setting up conv4\n",
      "I0430 14:43:48.487517 26148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:43:48.487521 26148 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:43:48.487529 26148 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:43:48.487535 26148 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:43:48.487538 26148 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:43:48.487543 26148 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:43:48.487548 26148 net.cpp:124] Setting up relu4\n",
      "I0430 14:43:48.487551 26148 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:43:48.487553 26148 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:43:48.487555 26148 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:43:48.487561 26148 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:43:48.487563 26148 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:43:48.487570 26148 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:43:48.488052 26148 net.cpp:124] Setting up conv5\n",
      "I0430 14:43:48.488057 26148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:43:48.488061 26148 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:43:48.488090 26148 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:43:48.488095 26148 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:43:48.488097 26148 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:43:48.488101 26148 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:43:48.488106 26148 net.cpp:124] Setting up relu5\n",
      "I0430 14:43:48.488108 26148 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:43:48.488111 26148 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:43:48.488112 26148 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:43:48.488117 26148 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:43:48.488119 26148 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:43:48.488123 26148 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:43:48.488129 26148 net.cpp:124] Setting up pool5\n",
      "I0430 14:43:48.488132 26148 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:43:48.488134 26148 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:43:48.488137 26148 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:43:48.488143 26148 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:43:48.488145 26148 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:43:48.488149 26148 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:43:48.509477 26148 net.cpp:124] Setting up fc6\n",
      "I0430 14:43:48.509497 26148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:43:48.509501 26148 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:43:48.509512 26148 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:43:48.509531 26148 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:43:48.509534 26148 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:43:48.509542 26148 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:43:48.509551 26148 net.cpp:124] Setting up relu6\n",
      "I0430 14:43:48.509553 26148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:43:48.509557 26148 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:43:48.509560 26148 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:43:48.509567 26148 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:43:48.509568 26148 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:43:48.509572 26148 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:43:48.509578 26148 net.cpp:124] Setting up drop6\n",
      "I0430 14:43:48.509582 26148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:43:48.509584 26148 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:43:48.509588 26148 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:43:48.509593 26148 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:43:48.509595 26148 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:43:48.509600 26148 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:43:48.519150 26148 net.cpp:124] Setting up fc7\n",
      "I0430 14:43:48.519166 26148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:43:48.519170 26148 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:43:48.519196 26148 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:43:48.519203 26148 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:43:48.519212 26148 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:43:48.519219 26148 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:43:48.519227 26148 net.cpp:124] Setting up relu7\n",
      "I0430 14:43:48.519230 26148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:43:48.519232 26148 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:43:48.519235 26148 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:43:48.519240 26148 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:43:48.519243 26148 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:43:48.519248 26148 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:43:48.519253 26148 net.cpp:124] Setting up drop7\n",
      "I0430 14:43:48.519256 26148 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:43:48.519259 26148 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:43:48.519263 26148 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:43:48.519268 26148 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:43:48.519270 26148 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:43:48.519275 26148 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:43:48.519932 26148 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:43:48.519942 26148 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:43:48.519945 26148 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:43:48.519953 26148 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:43:48.519955 26148 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:43:48.519958 26148 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:43:48.519963 26148 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:43:48.519965 26148 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:43:48.519968 26148 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:43:48.519971 26148 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:43:48.519974 26148 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:43:48.519978 26148 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:43:48.519980 26148 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:43:48.519984 26148 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:43:48.519987 26148 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:43:48.519991 26148 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:43:48.519994 26148 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:43:48.519997 26148 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:43:48.520000 26148 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:43:48.520005 26148 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:43:48.520009 26148 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:43:48.520012 26148 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:43:48.520015 26148 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:43:48.520018 26148 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:43:48.520021 26148 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:43:48.520025 26148 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:43:48.520027 26148 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:43:48.520038 26148 net.cpp:257] Network initialization done.\n",
      "I0430 14:43:48.601832 26148 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:43:48.693804 26148 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:43:48.694741 26148 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:43:48.694747 26148 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:43:48.694752 26148 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bird/160661.jpg'}, '/tmp/tmpbX_TTF.mat')\n",
      "Processed 2241 windows in 258.485 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.030 s.\n",
      "prediction    [-2.49776, -2.61212, -2.93314, -2.25424, -1.38...\n",
      "ymin                                                          0\n",
      "xmin                                                        152\n",
      "ymax                                                        346\n",
      "xmax                                                        415\n",
      "Name: /home/ambika/INF_project/data/bird/160661.jpg, dtype: object\n",
      "prediction    [-1.58625, -1.27455, -1.87206, -1.96353, -2.14...\n",
      "ymin                                                          2\n",
      "xmin                                                        267\n",
      "ymax                                                        135\n",
      "xmax                                                        411\n",
      "Name: /home/ambika/INF_project/data/bird/160661.jpg, dtype: object\n",
      "butterfly\n",
      "152\t0\t415\t346\n",
      "goldfish\n",
      "267\t2\t411\t135\n",
      "160661\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:48:08.659943 26313 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:48:08.659966 26313 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:48:08.659970 26313 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:48:08.661237 26313 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:48:08.661378 26313 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:48:08.661386 26313 net.cpp:86] Creating Layer data\n",
      "I0430 14:48:08.661389 26313 net.cpp:382] data -> data\n",
      "I0430 14:48:08.661401 26313 net.cpp:124] Setting up data\n",
      "I0430 14:48:08.661404 26313 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:48:08.661407 26313 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:48:08.661411 26313 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:48:08.661417 26313 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:48:08.661418 26313 net.cpp:408] conv1 <- data\n",
      "I0430 14:48:08.661423 26313 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:48:08.661491 26313 net.cpp:124] Setting up conv1\n",
      "I0430 14:48:08.661497 26313 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:48:08.661500 26313 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:48:08.661507 26313 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:48:08.661512 26313 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:48:08.661514 26313 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:48:08.661519 26313 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:48:08.661522 26313 net.cpp:124] Setting up relu1\n",
      "I0430 14:48:08.661526 26313 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:48:08.661528 26313 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:48:08.661530 26313 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:48:08.661535 26313 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:48:08.661537 26313 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:48:08.661540 26313 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:48:08.661546 26313 net.cpp:124] Setting up pool1\n",
      "I0430 14:48:08.661550 26313 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:48:08.661552 26313 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:48:08.661554 26313 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:48:08.661558 26313 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:48:08.661561 26313 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:48:08.661564 26313 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:48:08.661569 26313 net.cpp:124] Setting up norm1\n",
      "I0430 14:48:08.661572 26313 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:48:08.661576 26313 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:48:08.661577 26313 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:48:08.661581 26313 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:48:08.661583 26313 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:48:08.661587 26313 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:48:08.661948 26313 net.cpp:124] Setting up conv2\n",
      "I0430 14:48:08.661955 26313 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:48:08.661957 26313 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:48:08.661963 26313 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:48:08.661967 26313 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:48:08.661970 26313 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:48:08.661973 26313 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:48:08.661978 26313 net.cpp:124] Setting up relu2\n",
      "I0430 14:48:08.661981 26313 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:48:08.661983 26313 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:48:08.661986 26313 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:48:08.661991 26313 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:48:08.661995 26313 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:48:08.662001 26313 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:48:08.662009 26313 net.cpp:124] Setting up pool2\n",
      "I0430 14:48:08.662015 26313 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:48:08.662019 26313 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:48:08.662020 26313 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:48:08.662026 26313 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:48:08.662029 26313 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:48:08.662034 26313 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:48:08.662039 26313 net.cpp:124] Setting up norm2\n",
      "I0430 14:48:08.662041 26313 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:48:08.662044 26313 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:48:08.662045 26313 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:48:08.662051 26313 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:48:08.662055 26313 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:48:08.662057 26313 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:48:08.662760 26313 net.cpp:124] Setting up conv3\n",
      "I0430 14:48:08.662770 26313 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:48:08.662775 26313 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:48:08.662784 26313 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:48:08.662792 26313 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:48:08.662794 26313 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:48:08.662799 26313 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:48:08.662804 26313 net.cpp:124] Setting up relu3\n",
      "I0430 14:48:08.662807 26313 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:48:08.662811 26313 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:48:08.662812 26313 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:48:08.662818 26313 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:48:08.662822 26313 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:48:08.662825 26313 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:48:08.663573 26313 net.cpp:124] Setting up conv4\n",
      "I0430 14:48:08.663583 26313 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:48:08.663586 26313 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:48:08.663594 26313 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:48:08.663601 26313 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:48:08.663604 26313 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:48:08.663609 26313 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:48:08.663614 26313 net.cpp:124] Setting up relu4\n",
      "I0430 14:48:08.663616 26313 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:48:08.663619 26313 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:48:08.663621 26313 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:48:08.663626 26313 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:48:08.663628 26313 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:48:08.663632 26313 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:48:08.664142 26313 net.cpp:124] Setting up conv5\n",
      "I0430 14:48:08.664149 26313 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:48:08.664152 26313 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:48:08.664165 26313 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:48:08.664170 26313 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:48:08.664171 26313 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:48:08.664175 26313 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:48:08.664180 26313 net.cpp:124] Setting up relu5\n",
      "I0430 14:48:08.664185 26313 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:48:08.664186 26313 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:48:08.664188 26313 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:48:08.664193 26313 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:48:08.664196 26313 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:48:08.664199 26313 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:48:08.664206 26313 net.cpp:124] Setting up pool5\n",
      "I0430 14:48:08.664209 26313 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:48:08.664211 26313 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:48:08.664213 26313 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:48:08.664221 26313 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:48:08.664222 26313 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:48:08.664227 26313 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:48:08.685593 26313 net.cpp:124] Setting up fc6\n",
      "I0430 14:48:08.685618 26313 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:48:08.685621 26313 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:48:08.685632 26313 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:48:08.685673 26313 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:48:08.685678 26313 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:48:08.685684 26313 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:48:08.685693 26313 net.cpp:124] Setting up relu6\n",
      "I0430 14:48:08.685696 26313 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:48:08.685700 26313 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:48:08.685703 26313 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:48:08.685708 26313 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:48:08.685709 26313 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:48:08.685714 26313 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:48:08.685717 26313 net.cpp:124] Setting up drop6\n",
      "I0430 14:48:08.685720 26313 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:48:08.685722 26313 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:48:08.685725 26313 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:48:08.685729 26313 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:48:08.685732 26313 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:48:08.685735 26313 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:48:08.695441 26313 net.cpp:124] Setting up fc7\n",
      "I0430 14:48:08.695464 26313 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:48:08.695468 26313 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:48:08.695478 26313 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:48:08.695493 26313 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:48:08.695498 26313 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:48:08.695504 26313 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:48:08.695513 26313 net.cpp:124] Setting up relu7\n",
      "I0430 14:48:08.695518 26313 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:48:08.695520 26313 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:48:08.695523 26313 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:48:08.695528 26313 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:48:08.695530 26313 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:48:08.695538 26313 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:48:08.695543 26313 net.cpp:124] Setting up drop7\n",
      "I0430 14:48:08.695545 26313 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:48:08.695547 26313 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:48:08.695549 26313 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:48:08.695554 26313 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:48:08.695555 26313 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:48:08.695559 26313 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:48:08.696476 26313 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:48:08.696487 26313 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:48:08.696491 26313 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:48:08.696498 26313 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:48:08.696502 26313 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:48:08.696506 26313 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:48:08.696509 26313 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:48:08.696512 26313 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:48:08.696516 26313 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:48:08.696517 26313 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:48:08.696521 26313 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:48:08.696523 26313 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:48:08.696526 26313 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:48:08.696530 26313 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:48:08.696532 26313 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:48:08.696535 26313 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:48:08.696538 26313 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:48:08.696540 26313 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:48:08.696543 26313 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:48:08.696547 26313 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:48:08.696548 26313 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:48:08.696552 26313 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:48:08.696554 26313 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:48:08.696557 26313 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:48:08.696559 26313 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:48:08.696563 26313 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:48:08.696564 26313 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:48:08.696573 26313 net.cpp:257] Network initialization done.\n",
      "I0430 14:48:08.777541 26313 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:48:08.868877 26313 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:48:08.869746 26313 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:48:08.869753 26313 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:48:08.869755 26313 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/bus/278237.jpg'}, '/tmp/tmpm3BbPK.mat')\n",
      "Processed 2506 windows in 284.261 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.049 s.\n",
      "prediction    [-2.02144, -2.39067, -1.89141, -1.83043, -1.68...\n",
      "ymin                                                        192\n",
      "xmin                                                         50\n",
      "ymax                                                        330\n",
      "xmax                                                        420\n",
      "Name: /home/ambika/INF_project/data/bus/278237.jpg, dtype: object\n",
      "prediction    [-1.75219, -2.19979, -1.72934, -2.07237, -2.02...\n",
      "ymin                                                        147\n",
      "xmin                                                        329\n",
      "ymax                                                        239\n",
      "xmax                                                        402\n",
      "Name: /home/ambika/INF_project/data/bus/278237.jpg, dtype: object\n",
      "car\n",
      "50\t192\t420\t330\n",
      "bus\n",
      "329\t147\t402\t239\n",
      "278237\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:52:54.717339 26522 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:52:54.717358 26522 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:52:54.717361 26522 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:52:54.718456 26522 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:52:54.718646 26522 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:52:54.718653 26522 net.cpp:86] Creating Layer data\n",
      "I0430 14:52:54.718658 26522 net.cpp:382] data -> data\n",
      "I0430 14:52:54.718674 26522 net.cpp:124] Setting up data\n",
      "I0430 14:52:54.718682 26522 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:52:54.718684 26522 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:52:54.718688 26522 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:52:54.718695 26522 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:52:54.718700 26522 net.cpp:408] conv1 <- data\n",
      "I0430 14:52:54.718705 26522 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:52:54.718766 26522 net.cpp:124] Setting up conv1\n",
      "I0430 14:52:54.718772 26522 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:52:54.718775 26522 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:52:54.718783 26522 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:52:54.718789 26522 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:52:54.718791 26522 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:52:54.718796 26522 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:52:54.718801 26522 net.cpp:124] Setting up relu1\n",
      "I0430 14:52:54.718806 26522 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:52:54.718808 26522 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:52:54.718811 26522 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:52:54.718816 26522 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:52:54.718818 26522 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:52:54.718823 26522 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:52:54.718830 26522 net.cpp:124] Setting up pool1\n",
      "I0430 14:52:54.718834 26522 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:52:54.718837 26522 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:52:54.718840 26522 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:52:54.718845 26522 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:52:54.718849 26522 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:52:54.718853 26522 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:52:54.718861 26522 net.cpp:124] Setting up norm1\n",
      "I0430 14:52:54.718865 26522 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:52:54.718868 26522 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:52:54.718871 26522 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:52:54.718878 26522 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:52:54.718881 26522 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:52:54.718885 26522 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:52:54.719298 26522 net.cpp:124] Setting up conv2\n",
      "I0430 14:52:54.719307 26522 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:52:54.719310 26522 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:52:54.719319 26522 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:52:54.719326 26522 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:52:54.719328 26522 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:52:54.719333 26522 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:52:54.719338 26522 net.cpp:124] Setting up relu2\n",
      "I0430 14:52:54.719342 26522 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:52:54.719346 26522 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:52:54.719348 26522 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:52:54.719353 26522 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:52:54.719355 26522 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:52:54.719360 26522 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:52:54.719367 26522 net.cpp:124] Setting up pool2\n",
      "I0430 14:52:54.719370 26522 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:52:54.719373 26522 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:52:54.719377 26522 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:52:54.719383 26522 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:52:54.719386 26522 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:52:54.719390 26522 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:52:54.719396 26522 net.cpp:124] Setting up norm2\n",
      "I0430 14:52:54.719400 26522 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:52:54.719403 26522 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:52:54.719406 26522 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:52:54.719413 26522 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:52:54.719416 26522 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:52:54.719420 26522 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:52:54.720140 26522 net.cpp:124] Setting up conv3\n",
      "I0430 14:52:54.720157 26522 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:52:54.720160 26522 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:52:54.720170 26522 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:52:54.720177 26522 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:52:54.720180 26522 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:52:54.720186 26522 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:52:54.720192 26522 net.cpp:124] Setting up relu3\n",
      "I0430 14:52:54.720197 26522 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:52:54.720199 26522 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:52:54.720203 26522 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:52:54.720209 26522 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:52:54.720212 26522 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:52:54.720217 26522 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:52:54.720954 26522 net.cpp:124] Setting up conv4\n",
      "I0430 14:52:54.720970 26522 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:52:54.720979 26522 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:52:54.720986 26522 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:52:54.720993 26522 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:52:54.720998 26522 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:52:54.721002 26522 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:52:54.721006 26522 net.cpp:124] Setting up relu4\n",
      "I0430 14:52:54.721009 26522 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:52:54.721012 26522 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:52:54.721014 26522 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:52:54.721020 26522 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:52:54.721022 26522 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:52:54.721025 26522 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:52:54.721523 26522 net.cpp:124] Setting up conv5\n",
      "I0430 14:52:54.721529 26522 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:52:54.721532 26522 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:52:54.721544 26522 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:52:54.721549 26522 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:52:54.721551 26522 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:52:54.721555 26522 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:52:54.721560 26522 net.cpp:124] Setting up relu5\n",
      "I0430 14:52:54.721562 26522 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:52:54.721565 26522 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:52:54.721567 26522 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:52:54.721572 26522 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:52:54.721575 26522 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:52:54.721578 26522 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:52:54.721585 26522 net.cpp:124] Setting up pool5\n",
      "I0430 14:52:54.721588 26522 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:52:54.721590 26522 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:52:54.721592 26522 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:52:54.721599 26522 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:52:54.721601 26522 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:52:54.721606 26522 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:52:54.743456 26522 net.cpp:124] Setting up fc6\n",
      "I0430 14:52:54.743481 26522 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:52:54.743485 26522 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:52:54.743496 26522 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:52:54.743507 26522 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:52:54.743512 26522 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:52:54.743520 26522 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:52:54.743530 26522 net.cpp:124] Setting up relu6\n",
      "I0430 14:52:54.743535 26522 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:52:54.743538 26522 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:52:54.743542 26522 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:52:54.743549 26522 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:52:54.743552 26522 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:52:54.743556 26522 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:52:54.743561 26522 net.cpp:124] Setting up drop6\n",
      "I0430 14:52:54.743564 26522 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:52:54.743567 26522 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:52:54.743569 26522 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:52:54.743574 26522 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:52:54.743577 26522 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:52:54.743580 26522 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:52:54.753075 26522 net.cpp:124] Setting up fc7\n",
      "I0430 14:52:54.753098 26522 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:52:54.753100 26522 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:52:54.753110 26522 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:52:54.753130 26522 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:52:54.753135 26522 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:52:54.753142 26522 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:52:54.753149 26522 net.cpp:124] Setting up relu7\n",
      "I0430 14:52:54.753154 26522 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:52:54.753156 26522 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:52:54.753160 26522 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:52:54.753166 26522 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:52:54.753168 26522 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:52:54.753175 26522 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:52:54.753180 26522 net.cpp:124] Setting up drop7\n",
      "I0430 14:52:54.753183 26522 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:52:54.753186 26522 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:52:54.753190 26522 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:52:54.753195 26522 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:52:54.753197 26522 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:52:54.753201 26522 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:52:54.753864 26522 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:52:54.753872 26522 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:52:54.753875 26522 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:52:54.753882 26522 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:52:54.753886 26522 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:52:54.753890 26522 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:52:54.753892 26522 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:52:54.753896 26522 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:52:54.753900 26522 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:52:54.753902 26522 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:52:54.753906 26522 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:52:54.753908 26522 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:52:54.753912 26522 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:52:54.753916 26522 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:52:54.753918 26522 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:52:54.753922 26522 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:52:54.753926 26522 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:52:54.753931 26522 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:52:54.753933 26522 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:52:54.753937 26522 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:52:54.753940 26522 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:52:54.753944 26522 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:52:54.753947 26522 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:52:54.753950 26522 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:52:54.753953 26522 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:52:54.753957 26522 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:52:54.753959 26522 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:52:54.753970 26522 net.cpp:257] Network initialization done.\n",
      "I0430 14:52:54.834209 26522 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:52:54.925503 26522 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:52:54.926501 26522 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:52:54.926511 26522 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:52:54.926514 26522 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/car/273579.jpg'}, '/tmp/tmpgL4dYj.mat')\n",
      "Processed 2333 windows in 277.702 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.033 s.\n",
      "prediction    [-2.20525, -1.85225, -1.95209, -2.76442, -1.69...\n",
      "ymin                                                        151\n",
      "xmin                                                        243\n",
      "ymax                                                        375\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/car/273579.jpg, dtype: object\n",
      "prediction    [-2.52162, -2.58263, -1.98388, -1.58026, -1.60...\n",
      "ymin                                                        184\n",
      "xmin                                                          0\n",
      "ymax                                                        375\n",
      "xmax                                                        167\n",
      "Name: /home/ambika/INF_project/data/car/273579.jpg, dtype: object\n",
      "elephant\n",
      "243\t151\t500\t375\n",
      "person\n",
      "0\t184\t167\t375\n",
      "273579\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 14:57:34.514907 26743 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 14:57:34.514933 26743 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 14:57:34.514937 26743 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 14:57:34.516732 26743 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 14:57:34.516973 26743 layer_factory.hpp:77] Creating layer data\n",
      "I0430 14:57:34.516985 26743 net.cpp:86] Creating Layer data\n",
      "I0430 14:57:34.516990 26743 net.cpp:382] data -> data\n",
      "I0430 14:57:34.517006 26743 net.cpp:124] Setting up data\n",
      "I0430 14:57:34.517014 26743 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 14:57:34.517019 26743 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 14:57:34.517024 26743 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 14:57:34.517031 26743 net.cpp:86] Creating Layer conv1\n",
      "I0430 14:57:34.517035 26743 net.cpp:408] conv1 <- data\n",
      "I0430 14:57:34.517041 26743 net.cpp:382] conv1 -> conv1\n",
      "I0430 14:57:34.517132 26743 net.cpp:124] Setting up conv1\n",
      "I0430 14:57:34.517143 26743 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:57:34.517146 26743 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 14:57:34.517158 26743 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 14:57:34.517164 26743 net.cpp:86] Creating Layer relu1\n",
      "I0430 14:57:34.517168 26743 net.cpp:408] relu1 <- conv1\n",
      "I0430 14:57:34.517174 26743 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 14:57:34.517180 26743 net.cpp:124] Setting up relu1\n",
      "I0430 14:57:34.517186 26743 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 14:57:34.517190 26743 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 14:57:34.517194 26743 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 14:57:34.517200 26743 net.cpp:86] Creating Layer pool1\n",
      "I0430 14:57:34.517204 26743 net.cpp:408] pool1 <- conv1\n",
      "I0430 14:57:34.517210 26743 net.cpp:382] pool1 -> pool1\n",
      "I0430 14:57:34.517221 26743 net.cpp:124] Setting up pool1\n",
      "I0430 14:57:34.517228 26743 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:57:34.517232 26743 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 14:57:34.517236 26743 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 14:57:34.517243 26743 net.cpp:86] Creating Layer norm1\n",
      "I0430 14:57:34.517247 26743 net.cpp:408] norm1 <- pool1\n",
      "I0430 14:57:34.517253 26743 net.cpp:382] norm1 -> norm1\n",
      "I0430 14:57:34.517263 26743 net.cpp:124] Setting up norm1\n",
      "I0430 14:57:34.517269 26743 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 14:57:34.517273 26743 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 14:57:34.517277 26743 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 14:57:34.517285 26743 net.cpp:86] Creating Layer conv2\n",
      "I0430 14:57:34.517289 26743 net.cpp:408] conv2 <- norm1\n",
      "I0430 14:57:34.517295 26743 net.cpp:382] conv2 -> conv2\n",
      "I0430 14:57:34.517786 26743 net.cpp:124] Setting up conv2\n",
      "I0430 14:57:34.517801 26743 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:57:34.517805 26743 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 14:57:34.517817 26743 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 14:57:34.517824 26743 net.cpp:86] Creating Layer relu2\n",
      "I0430 14:57:34.517828 26743 net.cpp:408] relu2 <- conv2\n",
      "I0430 14:57:34.517835 26743 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 14:57:34.517844 26743 net.cpp:124] Setting up relu2\n",
      "I0430 14:57:34.517849 26743 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 14:57:34.517853 26743 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 14:57:34.517856 26743 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 14:57:34.517865 26743 net.cpp:86] Creating Layer pool2\n",
      "I0430 14:57:34.517869 26743 net.cpp:408] pool2 <- conv2\n",
      "I0430 14:57:34.517875 26743 net.cpp:382] pool2 -> pool2\n",
      "I0430 14:57:34.517885 26743 net.cpp:124] Setting up pool2\n",
      "I0430 14:57:34.517891 26743 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:57:34.517894 26743 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 14:57:34.517899 26743 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 14:57:34.517910 26743 net.cpp:86] Creating Layer norm2\n",
      "I0430 14:57:34.517913 26743 net.cpp:408] norm2 <- pool2\n",
      "I0430 14:57:34.517920 26743 net.cpp:382] norm2 -> norm2\n",
      "I0430 14:57:34.517928 26743 net.cpp:124] Setting up norm2\n",
      "I0430 14:57:34.517935 26743 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:57:34.517938 26743 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 14:57:34.517942 26743 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 14:57:34.517949 26743 net.cpp:86] Creating Layer conv3\n",
      "I0430 14:57:34.517953 26743 net.cpp:408] conv3 <- norm2\n",
      "I0430 14:57:34.517961 26743 net.cpp:382] conv3 -> conv3\n",
      "I0430 14:57:34.518918 26743 net.cpp:124] Setting up conv3\n",
      "I0430 14:57:34.518944 26743 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:57:34.518950 26743 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 14:57:34.518963 26743 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 14:57:34.518976 26743 net.cpp:86] Creating Layer relu3\n",
      "I0430 14:57:34.518982 26743 net.cpp:408] relu3 <- conv3\n",
      "I0430 14:57:34.518990 26743 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 14:57:34.518999 26743 net.cpp:124] Setting up relu3\n",
      "I0430 14:57:34.519006 26743 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:57:34.519009 26743 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 14:57:34.519013 26743 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 14:57:34.519022 26743 net.cpp:86] Creating Layer conv4\n",
      "I0430 14:57:34.519027 26743 net.cpp:408] conv4 <- conv3\n",
      "I0430 14:57:34.519034 26743 net.cpp:382] conv4 -> conv4\n",
      "I0430 14:57:34.520068 26743 net.cpp:124] Setting up conv4\n",
      "I0430 14:57:34.520089 26743 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:57:34.520094 26743 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 14:57:34.520104 26743 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 14:57:34.520113 26743 net.cpp:86] Creating Layer relu4\n",
      "I0430 14:57:34.520118 26743 net.cpp:408] relu4 <- conv4\n",
      "I0430 14:57:34.520125 26743 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 14:57:34.520134 26743 net.cpp:124] Setting up relu4\n",
      "I0430 14:57:34.520140 26743 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 14:57:34.520144 26743 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 14:57:34.520148 26743 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 14:57:34.520157 26743 net.cpp:86] Creating Layer conv5\n",
      "I0430 14:57:34.520161 26743 net.cpp:408] conv5 <- conv4\n",
      "I0430 14:57:34.520167 26743 net.cpp:382] conv5 -> conv5\n",
      "I0430 14:57:34.520865 26743 net.cpp:124] Setting up conv5\n",
      "I0430 14:57:34.520880 26743 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:57:34.520885 26743 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 14:57:34.520900 26743 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 14:57:34.520908 26743 net.cpp:86] Creating Layer relu5\n",
      "I0430 14:57:34.520915 26743 net.cpp:408] relu5 <- conv5\n",
      "I0430 14:57:34.520922 26743 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 14:57:34.520931 26743 net.cpp:124] Setting up relu5\n",
      "I0430 14:57:34.520936 26743 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 14:57:34.520941 26743 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 14:57:34.520944 26743 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 14:57:34.520951 26743 net.cpp:86] Creating Layer pool5\n",
      "I0430 14:57:34.520956 26743 net.cpp:408] pool5 <- conv5\n",
      "I0430 14:57:34.520961 26743 net.cpp:382] pool5 -> pool5\n",
      "I0430 14:57:34.520972 26743 net.cpp:124] Setting up pool5\n",
      "I0430 14:57:34.520979 26743 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 14:57:34.520983 26743 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 14:57:34.520987 26743 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 14:57:34.520999 26743 net.cpp:86] Creating Layer fc6\n",
      "I0430 14:57:34.521004 26743 net.cpp:408] fc6 <- pool5\n",
      "I0430 14:57:34.521010 26743 net.cpp:382] fc6 -> fc6\n",
      "I0430 14:57:34.550817 26743 net.cpp:124] Setting up fc6\n",
      "I0430 14:57:34.550848 26743 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:57:34.550851 26743 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 14:57:34.550863 26743 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 14:57:34.550874 26743 net.cpp:86] Creating Layer relu6\n",
      "I0430 14:57:34.550880 26743 net.cpp:408] relu6 <- fc6\n",
      "I0430 14:57:34.550889 26743 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 14:57:34.550900 26743 net.cpp:124] Setting up relu6\n",
      "I0430 14:57:34.550905 26743 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:57:34.550907 26743 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 14:57:34.550911 26743 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 14:57:34.550917 26743 net.cpp:86] Creating Layer drop6\n",
      "I0430 14:57:34.550920 26743 net.cpp:408] drop6 <- fc6\n",
      "I0430 14:57:34.550925 26743 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 14:57:34.550931 26743 net.cpp:124] Setting up drop6\n",
      "I0430 14:57:34.550938 26743 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:57:34.550942 26743 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 14:57:34.550946 26743 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 14:57:34.550953 26743 net.cpp:86] Creating Layer fc7\n",
      "I0430 14:57:34.550957 26743 net.cpp:408] fc7 <- fc6\n",
      "I0430 14:57:34.550966 26743 net.cpp:382] fc7 -> fc7\n",
      "I0430 14:57:34.563421 26743 net.cpp:124] Setting up fc7\n",
      "I0430 14:57:34.563447 26743 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:57:34.563452 26743 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 14:57:34.563459 26743 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 14:57:34.563467 26743 net.cpp:86] Creating Layer relu7\n",
      "I0430 14:57:34.563470 26743 net.cpp:408] relu7 <- fc7\n",
      "I0430 14:57:34.563474 26743 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 14:57:34.563482 26743 net.cpp:124] Setting up relu7\n",
      "I0430 14:57:34.563484 26743 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:57:34.563485 26743 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 14:57:34.563488 26743 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 14:57:34.563493 26743 net.cpp:86] Creating Layer drop7\n",
      "I0430 14:57:34.563494 26743 net.cpp:408] drop7 <- fc7\n",
      "I0430 14:57:34.563498 26743 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 14:57:34.563503 26743 net.cpp:124] Setting up drop7\n",
      "I0430 14:57:34.563505 26743 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 14:57:34.563506 26743 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 14:57:34.563508 26743 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 14:57:34.563513 26743 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 14:57:34.563514 26743 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 14:57:34.563519 26743 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 14:57:34.564565 26743 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 14:57:34.564579 26743 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 14:57:34.564582 26743 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 14:57:34.564589 26743 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 14:57:34.564591 26743 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 14:57:34.564594 26743 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 14:57:34.564595 26743 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 14:57:34.564599 26743 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 14:57:34.564599 26743 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 14:57:34.564602 26743 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 14:57:34.564605 26743 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 14:57:34.564610 26743 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 14:57:34.564612 26743 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 14:57:34.564615 26743 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 14:57:34.564618 26743 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 14:57:34.564621 26743 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 14:57:34.564625 26743 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 14:57:34.564628 26743 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 14:57:34.564631 26743 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 14:57:34.564635 26743 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 14:57:34.564637 26743 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 14:57:34.564640 26743 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 14:57:34.564643 26743 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 14:57:34.564646 26743 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 14:57:34.564649 26743 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 14:57:34.564652 26743 net.cpp:202] data does not need backward computation.\n",
      "I0430 14:57:34.564654 26743 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 14:57:34.564663 26743 net.cpp:257] Network initialization done.\n",
      "I0430 14:57:34.658882 26743 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:57:34.770640 26743 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 14:57:34.771641 26743 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 14:57:34.771653 26743 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 14:57:34.771656 26743 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/cat/38438.jpg'}, '/tmp/tmpLrAlj9.mat')\n",
      "Processed 3384 windows in 435.364 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.061 s.\n",
      "prediction    [-1.23461, -2.49087, -1.96224, -2.2093, -1.538...\n",
      "ymin                                                      93.75\n",
      "xmin                                                          0\n",
      "ymax                                                      500.5\n",
      "xmax                                                     375.25\n",
      "Name: /home/ambika/INF_project/data/cat/38438.jpg, dtype: object\n",
      "prediction    [-2.05083, -2.64663, -1.39407, -2.84266, -1.93...\n",
      "ymin                                                         60\n",
      "xmin                                                          0\n",
      "ymax                                                     147.25\n",
      "xmax                                                      122.5\n",
      "Name: /home/ambika/INF_project/data/cat/38438.jpg, dtype: object\n",
      "person\n",
      "0.0\t93.75\t375.25\t500.5\n",
      "lobster\n",
      "0.0\t60.0\t122.5\t147.25\n",
      "38438\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 15:04:52.302811 27005 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 15:04:52.302840 27005 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 15:04:52.302847 27005 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 15:04:52.304595 27005 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 15:04:52.305269 27005 layer_factory.hpp:77] Creating layer data\n",
      "I0430 15:04:52.305284 27005 net.cpp:86] Creating Layer data\n",
      "I0430 15:04:52.305292 27005 net.cpp:382] data -> data\n",
      "I0430 15:04:52.305310 27005 net.cpp:124] Setting up data\n",
      "I0430 15:04:52.305321 27005 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 15:04:52.305327 27005 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 15:04:52.305335 27005 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 15:04:52.305346 27005 net.cpp:86] Creating Layer conv1\n",
      "I0430 15:04:52.305352 27005 net.cpp:408] conv1 <- data\n",
      "I0430 15:04:52.305361 27005 net.cpp:382] conv1 -> conv1\n",
      "I0430 15:04:52.305447 27005 net.cpp:124] Setting up conv1\n",
      "I0430 15:04:52.305459 27005 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 15:04:52.305465 27005 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 15:04:52.305480 27005 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 15:04:52.305490 27005 net.cpp:86] Creating Layer relu1\n",
      "I0430 15:04:52.305495 27005 net.cpp:408] relu1 <- conv1\n",
      "I0430 15:04:52.305503 27005 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 15:04:52.305512 27005 net.cpp:124] Setting up relu1\n",
      "I0430 15:04:52.305521 27005 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 15:04:52.305526 27005 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 15:04:52.305532 27005 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 15:04:52.305541 27005 net.cpp:86] Creating Layer pool1\n",
      "I0430 15:04:52.305547 27005 net.cpp:408] pool1 <- conv1\n",
      "I0430 15:04:52.305554 27005 net.cpp:382] pool1 -> pool1\n",
      "I0430 15:04:52.305567 27005 net.cpp:124] Setting up pool1\n",
      "I0430 15:04:52.305575 27005 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 15:04:52.305582 27005 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 15:04:52.305588 27005 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 15:04:52.305596 27005 net.cpp:86] Creating Layer norm1\n",
      "I0430 15:04:52.305603 27005 net.cpp:408] norm1 <- pool1\n",
      "I0430 15:04:52.305610 27005 net.cpp:382] norm1 -> norm1\n",
      "I0430 15:04:52.305621 27005 net.cpp:124] Setting up norm1\n",
      "I0430 15:04:52.305629 27005 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 15:04:52.305634 27005 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 15:04:52.305641 27005 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 15:04:52.305655 27005 net.cpp:86] Creating Layer conv2\n",
      "I0430 15:04:52.305661 27005 net.cpp:408] conv2 <- norm1\n",
      "I0430 15:04:52.305670 27005 net.cpp:382] conv2 -> conv2\n",
      "I0430 15:04:52.306135 27005 net.cpp:124] Setting up conv2\n",
      "I0430 15:04:52.306152 27005 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 15:04:52.306159 27005 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 15:04:52.306172 27005 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 15:04:52.306181 27005 net.cpp:86] Creating Layer relu2\n",
      "I0430 15:04:52.306188 27005 net.cpp:408] relu2 <- conv2\n",
      "I0430 15:04:52.306196 27005 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 15:04:52.306205 27005 net.cpp:124] Setting up relu2\n",
      "I0430 15:04:52.306212 27005 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 15:04:52.306218 27005 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 15:04:52.306224 27005 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 15:04:52.306236 27005 net.cpp:86] Creating Layer pool2\n",
      "I0430 15:04:52.306243 27005 net.cpp:408] pool2 <- conv2\n",
      "I0430 15:04:52.306252 27005 net.cpp:382] pool2 -> pool2\n",
      "I0430 15:04:52.306263 27005 net.cpp:124] Setting up pool2\n",
      "I0430 15:04:52.306272 27005 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 15:04:52.306277 27005 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 15:04:52.306283 27005 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 15:04:52.306295 27005 net.cpp:86] Creating Layer norm2\n",
      "I0430 15:04:52.306301 27005 net.cpp:408] norm2 <- pool2\n",
      "I0430 15:04:52.306309 27005 net.cpp:382] norm2 -> norm2\n",
      "I0430 15:04:52.306319 27005 net.cpp:124] Setting up norm2\n",
      "I0430 15:04:52.306329 27005 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 15:04:52.306334 27005 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 15:04:52.306341 27005 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 15:04:52.306351 27005 net.cpp:86] Creating Layer conv3\n",
      "I0430 15:04:52.306357 27005 net.cpp:408] conv3 <- norm2\n",
      "I0430 15:04:52.306366 27005 net.cpp:382] conv3 -> conv3\n",
      "I0430 15:04:52.307350 27005 net.cpp:124] Setting up conv3\n",
      "I0430 15:04:52.307379 27005 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 15:04:52.307385 27005 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 15:04:52.307421 27005 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 15:04:52.307436 27005 net.cpp:86] Creating Layer relu3\n",
      "I0430 15:04:52.307445 27005 net.cpp:408] relu3 <- conv3\n",
      "I0430 15:04:52.307454 27005 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 15:04:52.307466 27005 net.cpp:124] Setting up relu3\n",
      "I0430 15:04:52.307474 27005 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 15:04:52.307479 27005 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 15:04:52.307485 27005 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 15:04:52.307495 27005 net.cpp:86] Creating Layer conv4\n",
      "I0430 15:04:52.307500 27005 net.cpp:408] conv4 <- conv3\n",
      "I0430 15:04:52.307509 27005 net.cpp:382] conv4 -> conv4\n",
      "I0430 15:04:52.308502 27005 net.cpp:124] Setting up conv4\n",
      "I0430 15:04:52.308531 27005 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 15:04:52.308537 27005 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 15:04:52.308549 27005 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 15:04:52.308562 27005 net.cpp:86] Creating Layer relu4\n",
      "I0430 15:04:52.308568 27005 net.cpp:408] relu4 <- conv4\n",
      "I0430 15:04:52.308576 27005 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 15:04:52.308588 27005 net.cpp:124] Setting up relu4\n",
      "I0430 15:04:52.308595 27005 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 15:04:52.308600 27005 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 15:04:52.308606 27005 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 15:04:52.308619 27005 net.cpp:86] Creating Layer conv5\n",
      "I0430 15:04:52.308625 27005 net.cpp:408] conv5 <- conv4\n",
      "I0430 15:04:52.308634 27005 net.cpp:382] conv5 -> conv5\n",
      "I0430 15:04:52.309289 27005 net.cpp:124] Setting up conv5\n",
      "I0430 15:04:52.309309 27005 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 15:04:52.309316 27005 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 15:04:52.309331 27005 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 15:04:52.309341 27005 net.cpp:86] Creating Layer relu5\n",
      "I0430 15:04:52.309348 27005 net.cpp:408] relu5 <- conv5\n",
      "I0430 15:04:52.309357 27005 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 15:04:52.309367 27005 net.cpp:124] Setting up relu5\n",
      "I0430 15:04:52.309375 27005 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 15:04:52.309381 27005 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 15:04:52.309386 27005 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 15:04:52.309394 27005 net.cpp:86] Creating Layer pool5\n",
      "I0430 15:04:52.309401 27005 net.cpp:408] pool5 <- conv5\n",
      "I0430 15:04:52.309407 27005 net.cpp:382] pool5 -> pool5\n",
      "I0430 15:04:52.309420 27005 net.cpp:124] Setting up pool5\n",
      "I0430 15:04:52.309428 27005 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 15:04:52.309433 27005 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 15:04:52.309439 27005 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 15:04:52.309453 27005 net.cpp:86] Creating Layer fc6\n",
      "I0430 15:04:52.309460 27005 net.cpp:408] fc6 <- pool5\n",
      "I0430 15:04:52.309468 27005 net.cpp:382] fc6 -> fc6\n",
      "I0430 15:04:52.337785 27005 net.cpp:124] Setting up fc6\n",
      "I0430 15:04:52.337828 27005 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:04:52.337836 27005 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 15:04:52.337849 27005 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 15:04:52.337865 27005 net.cpp:86] Creating Layer relu6\n",
      "I0430 15:04:52.337873 27005 net.cpp:408] relu6 <- fc6\n",
      "I0430 15:04:52.337884 27005 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 15:04:52.337896 27005 net.cpp:124] Setting up relu6\n",
      "I0430 15:04:52.337903 27005 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:04:52.337909 27005 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 15:04:52.337915 27005 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 15:04:52.337924 27005 net.cpp:86] Creating Layer drop6\n",
      "I0430 15:04:52.337930 27005 net.cpp:408] drop6 <- fc6\n",
      "I0430 15:04:52.337937 27005 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 15:04:52.337946 27005 net.cpp:124] Setting up drop6\n",
      "I0430 15:04:52.337954 27005 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:04:52.337960 27005 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 15:04:52.337966 27005 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 15:04:52.337975 27005 net.cpp:86] Creating Layer fc7\n",
      "I0430 15:04:52.337980 27005 net.cpp:408] fc7 <- fc6\n",
      "I0430 15:04:52.337990 27005 net.cpp:382] fc7 -> fc7\n",
      "I0430 15:04:52.350770 27005 net.cpp:124] Setting up fc7\n",
      "I0430 15:04:52.350811 27005 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:04:52.350817 27005 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 15:04:52.350831 27005 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 15:04:52.350845 27005 net.cpp:86] Creating Layer relu7\n",
      "I0430 15:04:52.350853 27005 net.cpp:408] relu7 <- fc7\n",
      "I0430 15:04:52.350862 27005 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 15:04:52.350872 27005 net.cpp:124] Setting up relu7\n",
      "I0430 15:04:52.350880 27005 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:04:52.350886 27005 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 15:04:52.350891 27005 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 15:04:52.350900 27005 net.cpp:86] Creating Layer drop7\n",
      "I0430 15:04:52.350906 27005 net.cpp:408] drop7 <- fc7\n",
      "I0430 15:04:52.350915 27005 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 15:04:52.350924 27005 net.cpp:124] Setting up drop7\n",
      "I0430 15:04:52.350932 27005 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:04:52.350937 27005 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 15:04:52.350944 27005 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 15:04:52.350951 27005 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 15:04:52.350958 27005 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 15:04:52.350966 27005 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 15:04:52.351845 27005 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 15:04:52.351874 27005 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 15:04:52.351881 27005 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 15:04:52.351894 27005 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 15:04:52.351902 27005 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 15:04:52.351907 27005 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 15:04:52.351913 27005 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 15:04:52.351919 27005 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 15:04:52.351925 27005 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 15:04:52.351932 27005 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 15:04:52.351939 27005 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 15:04:52.351945 27005 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 15:04:52.351951 27005 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 15:04:52.351958 27005 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 15:04:52.351963 27005 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 15:04:52.351970 27005 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 15:04:52.351976 27005 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 15:04:52.351982 27005 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 15:04:52.351989 27005 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 15:04:52.351995 27005 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 15:04:52.352001 27005 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 15:04:52.352007 27005 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 15:04:52.352013 27005 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 15:04:52.352020 27005 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 15:04:52.352025 27005 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 15:04:52.352030 27005 net.cpp:202] data does not need backward computation.\n",
      "I0430 15:04:52.352036 27005 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 15:04:52.352053 27005 net.cpp:257] Network initialization done.\n",
      "I0430 15:04:52.449455 27005 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 15:04:52.549496 27005 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 15:04:52.550781 27005 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 15:04:52.550796 27005 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 15:04:52.550801 27005 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/couch/559778.jpg'}, '/tmp/tmpKyX24D.mat')\n",
      "Processed 2020 windows in 252.294 s.\n",
      "/home/ambika/.local/lib/python2.7/site-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['prediction']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Saved to /home/ambika/INF_project/_temp/det_output.h5 in 0.044 s.\n",
      "prediction    [-1.96137, -2.17346, -1.79643, -2.25966, -2.13...\n",
      "ymin                                                          0\n",
      "xmin                                                        178\n",
      "ymax                                                        243\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/couch/559778.jpg, dtype: object\n",
      "prediction    [-2.20724, -2.18402, -2.20491, -1.06118, -2.23...\n",
      "ymin                                                        147\n",
      "xmin                                                        105\n",
      "ymax                                                        309\n",
      "xmax                                                        500\n",
      "Name: /home/ambika/INF_project/data/couch/559778.jpg, dtype: object\n",
      "dog\n",
      "178\t0\t500\t243\n",
      "domestic cat\n",
      "105\t147\t500\t309\n",
      "559778\n",
      "CPU mode\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "W0430 15:09:06.600950 27211 _caffe.cpp:135] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0430 15:09:06.600976 27211 _caffe.cpp:136] Use this instead (with the named \"weights\" parameter):\n",
      "W0430 15:09:06.600981 27211 _caffe.cpp:138] Net('/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt', 1, weights='/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel')\n",
      "I0430 15:09:06.602375 27211 net.cpp:53] Initializing net from parameters: \n",
      "name: \"R-CNN-ilsvrc13\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc-rcnn\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc-rcnn\"\n",
      "  inner_product_param {\n",
      "    num_output: 200\n",
      "  }\n",
      "}\n",
      "I0430 15:09:06.602566 27211 layer_factory.hpp:77] Creating layer data\n",
      "I0430 15:09:06.602581 27211 net.cpp:86] Creating Layer data\n",
      "I0430 15:09:06.602588 27211 net.cpp:382] data -> data\n",
      "I0430 15:09:06.602608 27211 net.cpp:124] Setting up data\n",
      "I0430 15:09:06.602617 27211 net.cpp:131] Top shape: 10 3 227 227 (1545870)\n",
      "I0430 15:09:06.602622 27211 net.cpp:139] Memory required for data: 6183480\n",
      "I0430 15:09:06.602627 27211 layer_factory.hpp:77] Creating layer conv1\n",
      "I0430 15:09:06.602635 27211 net.cpp:86] Creating Layer conv1\n",
      "I0430 15:09:06.602638 27211 net.cpp:408] conv1 <- data\n",
      "I0430 15:09:06.602643 27211 net.cpp:382] conv1 -> conv1\n",
      "I0430 15:09:06.602712 27211 net.cpp:124] Setting up conv1\n",
      "I0430 15:09:06.602717 27211 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 15:09:06.602720 27211 net.cpp:139] Memory required for data: 17799480\n",
      "I0430 15:09:06.602728 27211 layer_factory.hpp:77] Creating layer relu1\n",
      "I0430 15:09:06.602735 27211 net.cpp:86] Creating Layer relu1\n",
      "I0430 15:09:06.602737 27211 net.cpp:408] relu1 <- conv1\n",
      "I0430 15:09:06.602741 27211 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0430 15:09:06.602746 27211 net.cpp:124] Setting up relu1\n",
      "I0430 15:09:06.602751 27211 net.cpp:131] Top shape: 10 96 55 55 (2904000)\n",
      "I0430 15:09:06.602753 27211 net.cpp:139] Memory required for data: 29415480\n",
      "I0430 15:09:06.602756 27211 layer_factory.hpp:77] Creating layer pool1\n",
      "I0430 15:09:06.602761 27211 net.cpp:86] Creating Layer pool1\n",
      "I0430 15:09:06.602763 27211 net.cpp:408] pool1 <- conv1\n",
      "I0430 15:09:06.602767 27211 net.cpp:382] pool1 -> pool1\n",
      "I0430 15:09:06.602776 27211 net.cpp:124] Setting up pool1\n",
      "I0430 15:09:06.602782 27211 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 15:09:06.602785 27211 net.cpp:139] Memory required for data: 32214840\n",
      "I0430 15:09:06.602790 27211 layer_factory.hpp:77] Creating layer norm1\n",
      "I0430 15:09:06.602797 27211 net.cpp:86] Creating Layer norm1\n",
      "I0430 15:09:06.602802 27211 net.cpp:408] norm1 <- pool1\n",
      "I0430 15:09:06.602808 27211 net.cpp:382] norm1 -> norm1\n",
      "I0430 15:09:06.602818 27211 net.cpp:124] Setting up norm1\n",
      "I0430 15:09:06.602823 27211 net.cpp:131] Top shape: 10 96 27 27 (699840)\n",
      "I0430 15:09:06.602826 27211 net.cpp:139] Memory required for data: 35014200\n",
      "I0430 15:09:06.602829 27211 layer_factory.hpp:77] Creating layer conv2\n",
      "I0430 15:09:06.602834 27211 net.cpp:86] Creating Layer conv2\n",
      "I0430 15:09:06.602838 27211 net.cpp:408] conv2 <- norm1\n",
      "I0430 15:09:06.602841 27211 net.cpp:382] conv2 -> conv2\n",
      "I0430 15:09:06.603257 27211 net.cpp:124] Setting up conv2\n",
      "I0430 15:09:06.603266 27211 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 15:09:06.603271 27211 net.cpp:139] Memory required for data: 42479160\n",
      "I0430 15:09:06.603281 27211 layer_factory.hpp:77] Creating layer relu2\n",
      "I0430 15:09:06.603287 27211 net.cpp:86] Creating Layer relu2\n",
      "I0430 15:09:06.603291 27211 net.cpp:408] relu2 <- conv2\n",
      "I0430 15:09:06.603294 27211 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0430 15:09:06.603299 27211 net.cpp:124] Setting up relu2\n",
      "I0430 15:09:06.603303 27211 net.cpp:131] Top shape: 10 256 27 27 (1866240)\n",
      "I0430 15:09:06.603307 27211 net.cpp:139] Memory required for data: 49944120\n",
      "I0430 15:09:06.603309 27211 layer_factory.hpp:77] Creating layer pool2\n",
      "I0430 15:09:06.603314 27211 net.cpp:86] Creating Layer pool2\n",
      "I0430 15:09:06.603317 27211 net.cpp:408] pool2 <- conv2\n",
      "I0430 15:09:06.603322 27211 net.cpp:382] pool2 -> pool2\n",
      "I0430 15:09:06.603328 27211 net.cpp:124] Setting up pool2\n",
      "I0430 15:09:06.603340 27211 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 15:09:06.603343 27211 net.cpp:139] Memory required for data: 51674680\n",
      "I0430 15:09:06.603346 27211 layer_factory.hpp:77] Creating layer norm2\n",
      "I0430 15:09:06.603355 27211 net.cpp:86] Creating Layer norm2\n",
      "I0430 15:09:06.603358 27211 net.cpp:408] norm2 <- pool2\n",
      "I0430 15:09:06.603363 27211 net.cpp:382] norm2 -> norm2\n",
      "I0430 15:09:06.603371 27211 net.cpp:124] Setting up norm2\n",
      "I0430 15:09:06.603375 27211 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 15:09:06.603379 27211 net.cpp:139] Memory required for data: 53405240\n",
      "I0430 15:09:06.603381 27211 layer_factory.hpp:77] Creating layer conv3\n",
      "I0430 15:09:06.603387 27211 net.cpp:86] Creating Layer conv3\n",
      "I0430 15:09:06.603390 27211 net.cpp:408] conv3 <- norm2\n",
      "I0430 15:09:06.603394 27211 net.cpp:382] conv3 -> conv3\n",
      "I0430 15:09:06.604192 27211 net.cpp:124] Setting up conv3\n",
      "I0430 15:09:06.604210 27211 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 15:09:06.604215 27211 net.cpp:139] Memory required for data: 56001080\n",
      "I0430 15:09:06.604228 27211 layer_factory.hpp:77] Creating layer relu3\n",
      "I0430 15:09:06.604239 27211 net.cpp:86] Creating Layer relu3\n",
      "I0430 15:09:06.604243 27211 net.cpp:408] relu3 <- conv3\n",
      "I0430 15:09:06.604250 27211 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0430 15:09:06.604256 27211 net.cpp:124] Setting up relu3\n",
      "I0430 15:09:06.604260 27211 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 15:09:06.604264 27211 net.cpp:139] Memory required for data: 58596920\n",
      "I0430 15:09:06.604266 27211 layer_factory.hpp:77] Creating layer conv4\n",
      "I0430 15:09:06.604272 27211 net.cpp:86] Creating Layer conv4\n",
      "I0430 15:09:06.604275 27211 net.cpp:408] conv4 <- conv3\n",
      "I0430 15:09:06.604279 27211 net.cpp:382] conv4 -> conv4\n",
      "I0430 15:09:06.605132 27211 net.cpp:124] Setting up conv4\n",
      "I0430 15:09:06.605147 27211 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 15:09:06.605151 27211 net.cpp:139] Memory required for data: 61192760\n",
      "I0430 15:09:06.605159 27211 layer_factory.hpp:77] Creating layer relu4\n",
      "I0430 15:09:06.605170 27211 net.cpp:86] Creating Layer relu4\n",
      "I0430 15:09:06.605175 27211 net.cpp:408] relu4 <- conv4\n",
      "I0430 15:09:06.605180 27211 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0430 15:09:06.605185 27211 net.cpp:124] Setting up relu4\n",
      "I0430 15:09:06.605188 27211 net.cpp:131] Top shape: 10 384 13 13 (648960)\n",
      "I0430 15:09:06.605191 27211 net.cpp:139] Memory required for data: 63788600\n",
      "I0430 15:09:06.605195 27211 layer_factory.hpp:77] Creating layer conv5\n",
      "I0430 15:09:06.605199 27211 net.cpp:86] Creating Layer conv5\n",
      "I0430 15:09:06.605206 27211 net.cpp:408] conv5 <- conv4\n",
      "I0430 15:09:06.605209 27211 net.cpp:382] conv5 -> conv5\n",
      "I0430 15:09:06.605796 27211 net.cpp:124] Setting up conv5\n",
      "I0430 15:09:06.605805 27211 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 15:09:06.605809 27211 net.cpp:139] Memory required for data: 65519160\n",
      "I0430 15:09:06.605823 27211 layer_factory.hpp:77] Creating layer relu5\n",
      "I0430 15:09:06.605829 27211 net.cpp:86] Creating Layer relu5\n",
      "I0430 15:09:06.605834 27211 net.cpp:408] relu5 <- conv5\n",
      "I0430 15:09:06.605837 27211 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0430 15:09:06.605842 27211 net.cpp:124] Setting up relu5\n",
      "I0430 15:09:06.605846 27211 net.cpp:131] Top shape: 10 256 13 13 (432640)\n",
      "I0430 15:09:06.605849 27211 net.cpp:139] Memory required for data: 67249720\n",
      "I0430 15:09:06.605852 27211 layer_factory.hpp:77] Creating layer pool5\n",
      "I0430 15:09:06.605857 27211 net.cpp:86] Creating Layer pool5\n",
      "I0430 15:09:06.605860 27211 net.cpp:408] pool5 <- conv5\n",
      "I0430 15:09:06.605865 27211 net.cpp:382] pool5 -> pool5\n",
      "I0430 15:09:06.605872 27211 net.cpp:124] Setting up pool5\n",
      "I0430 15:09:06.605876 27211 net.cpp:131] Top shape: 10 256 6 6 (92160)\n",
      "I0430 15:09:06.605880 27211 net.cpp:139] Memory required for data: 67618360\n",
      "I0430 15:09:06.605882 27211 layer_factory.hpp:77] Creating layer fc6\n",
      "I0430 15:09:06.605890 27211 net.cpp:86] Creating Layer fc6\n",
      "I0430 15:09:06.605892 27211 net.cpp:408] fc6 <- pool5\n",
      "I0430 15:09:06.605896 27211 net.cpp:382] fc6 -> fc6\n",
      "I0430 15:09:06.630807 27211 net.cpp:124] Setting up fc6\n",
      "I0430 15:09:06.630833 27211 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:09:06.630839 27211 net.cpp:139] Memory required for data: 67782200\n",
      "I0430 15:09:06.630851 27211 layer_factory.hpp:77] Creating layer relu6\n",
      "I0430 15:09:06.630862 27211 net.cpp:86] Creating Layer relu6\n",
      "I0430 15:09:06.630867 27211 net.cpp:408] relu6 <- fc6\n",
      "I0430 15:09:06.630872 27211 net.cpp:369] relu6 -> fc6 (in-place)\n",
      "I0430 15:09:06.630880 27211 net.cpp:124] Setting up relu6\n",
      "I0430 15:09:06.630884 27211 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:09:06.630887 27211 net.cpp:139] Memory required for data: 67946040\n",
      "I0430 15:09:06.630890 27211 layer_factory.hpp:77] Creating layer drop6\n",
      "I0430 15:09:06.630897 27211 net.cpp:86] Creating Layer drop6\n",
      "I0430 15:09:06.630901 27211 net.cpp:408] drop6 <- fc6\n",
      "I0430 15:09:06.630908 27211 net.cpp:369] drop6 -> fc6 (in-place)\n",
      "I0430 15:09:06.630975 27211 net.cpp:124] Setting up drop6\n",
      "I0430 15:09:06.630978 27211 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:09:06.630981 27211 net.cpp:139] Memory required for data: 68109880\n",
      "I0430 15:09:06.630985 27211 layer_factory.hpp:77] Creating layer fc7\n",
      "I0430 15:09:06.630991 27211 net.cpp:86] Creating Layer fc7\n",
      "I0430 15:09:06.630995 27211 net.cpp:408] fc7 <- fc6\n",
      "I0430 15:09:06.630998 27211 net.cpp:382] fc7 -> fc7\n",
      "I0430 15:09:06.641927 27211 net.cpp:124] Setting up fc7\n",
      "I0430 15:09:06.641947 27211 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:09:06.641950 27211 net.cpp:139] Memory required for data: 68273720\n",
      "I0430 15:09:06.641963 27211 layer_factory.hpp:77] Creating layer relu7\n",
      "I0430 15:09:06.641973 27211 net.cpp:86] Creating Layer relu7\n",
      "I0430 15:09:06.641976 27211 net.cpp:408] relu7 <- fc7\n",
      "I0430 15:09:06.641984 27211 net.cpp:369] relu7 -> fc7 (in-place)\n",
      "I0430 15:09:06.641993 27211 net.cpp:124] Setting up relu7\n",
      "I0430 15:09:06.641996 27211 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:09:06.642009 27211 net.cpp:139] Memory required for data: 68437560\n",
      "I0430 15:09:06.642012 27211 layer_factory.hpp:77] Creating layer drop7\n",
      "I0430 15:09:06.642019 27211 net.cpp:86] Creating Layer drop7\n",
      "I0430 15:09:06.642022 27211 net.cpp:408] drop7 <- fc7\n",
      "I0430 15:09:06.642027 27211 net.cpp:369] drop7 -> fc7 (in-place)\n",
      "I0430 15:09:06.642033 27211 net.cpp:124] Setting up drop7\n",
      "I0430 15:09:06.642038 27211 net.cpp:131] Top shape: 10 4096 (40960)\n",
      "I0430 15:09:06.642041 27211 net.cpp:139] Memory required for data: 68601400\n",
      "I0430 15:09:06.642045 27211 layer_factory.hpp:77] Creating layer fc-rcnn\n",
      "I0430 15:09:06.642050 27211 net.cpp:86] Creating Layer fc-rcnn\n",
      "I0430 15:09:06.642053 27211 net.cpp:408] fc-rcnn <- fc7\n",
      "I0430 15:09:06.642058 27211 net.cpp:382] fc-rcnn -> fc-rcnn\n",
      "I0430 15:09:06.642803 27211 net.cpp:124] Setting up fc-rcnn\n",
      "I0430 15:09:06.642822 27211 net.cpp:131] Top shape: 10 200 (2000)\n",
      "I0430 15:09:06.642825 27211 net.cpp:139] Memory required for data: 68609400\n",
      "I0430 15:09:06.642834 27211 net.cpp:202] fc-rcnn does not need backward computation.\n",
      "I0430 15:09:06.642839 27211 net.cpp:202] drop7 does not need backward computation.\n",
      "I0430 15:09:06.642841 27211 net.cpp:202] relu7 does not need backward computation.\n",
      "I0430 15:09:06.642844 27211 net.cpp:202] fc7 does not need backward computation.\n",
      "I0430 15:09:06.642848 27211 net.cpp:202] drop6 does not need backward computation.\n",
      "I0430 15:09:06.642853 27211 net.cpp:202] relu6 does not need backward computation.\n",
      "I0430 15:09:06.642856 27211 net.cpp:202] fc6 does not need backward computation.\n",
      "I0430 15:09:06.642860 27211 net.cpp:202] pool5 does not need backward computation.\n",
      "I0430 15:09:06.642864 27211 net.cpp:202] relu5 does not need backward computation.\n",
      "I0430 15:09:06.642868 27211 net.cpp:202] conv5 does not need backward computation.\n",
      "I0430 15:09:06.642871 27211 net.cpp:202] relu4 does not need backward computation.\n",
      "I0430 15:09:06.642875 27211 net.cpp:202] conv4 does not need backward computation.\n",
      "I0430 15:09:06.642879 27211 net.cpp:202] relu3 does not need backward computation.\n",
      "I0430 15:09:06.642884 27211 net.cpp:202] conv3 does not need backward computation.\n",
      "I0430 15:09:06.642887 27211 net.cpp:202] norm2 does not need backward computation.\n",
      "I0430 15:09:06.642890 27211 net.cpp:202] pool2 does not need backward computation.\n",
      "I0430 15:09:06.642894 27211 net.cpp:202] relu2 does not need backward computation.\n",
      "I0430 15:09:06.642899 27211 net.cpp:202] conv2 does not need backward computation.\n",
      "I0430 15:09:06.642902 27211 net.cpp:202] norm1 does not need backward computation.\n",
      "I0430 15:09:06.642905 27211 net.cpp:202] pool1 does not need backward computation.\n",
      "I0430 15:09:06.642910 27211 net.cpp:202] relu1 does not need backward computation.\n",
      "I0430 15:09:06.642913 27211 net.cpp:202] conv1 does not need backward computation.\n",
      "I0430 15:09:06.642916 27211 net.cpp:202] data does not need backward computation.\n",
      "I0430 15:09:06.642920 27211 net.cpp:244] This network produces output fc-rcnn\n",
      "I0430 15:09:06.642933 27211 net.cpp:257] Network initialization done.\n",
      "I0430 15:09:06.732970 27211 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 15:09:06.835386 27211 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0430 15:09:06.836453 27211 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: /home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel\n",
      "I0430 15:09:06.836467 27211 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.\n",
      "W0430 15:09:06.836472 27211 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.\n",
      "Loading input...\n",
      "selective_search_rcnn({'/home/ambika/INF_project/data/dog/132389.jpg'}, '/tmp/tmpk2feff.mat')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "final_path='/home/ambika/INF_project/final_image_paths.txt'\n",
    "image_list = np.loadtxt(final_path, str)\n",
    "\n",
    "filename='detection_results.txt'\n",
    "b = open(filename, 'wb') \n",
    "a = csv.writer(b)\n",
    "\n",
    "for p in range(0,1000):\n",
    "    !mkdir -p _temp\n",
    "    !echo ''{image_list[p]}'' > _temp/det_input.txt\n",
    "\n",
    "    !/home/ambika/caffe/python/detect.py --crop_mode=selective_search --pretrained_model=/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel --model_def=/home/ambika/caffe/models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt --raw_scale=255 /home/ambika/INF_project/_temp/det_input.txt /home/ambika/INF_project/_temp/det_output.h5    \n",
    "\n",
    "    df = pd.read_hdf('/home/ambika/INF_project/_temp/det_output.h5', 'df')\n",
    "#print(df.shape)\n",
    "#print(df.iloc[0])\n",
    "#print(df.iloc[1])\n",
    "\n",
    "    with open('/home/ambika/caffe/data/ilsvrc12/det_synset_words.txt') as f:\n",
    "        labels_df = pd.DataFrame([\n",
    "            {\n",
    "                'synset_id': l.strip().split(' ')[0],\n",
    "                'name': ' '.join(l.strip().split(' ')[1:]).split(',')[0]\n",
    "            }\n",
    "            for l in f.readlines()\n",
    "        ])\n",
    "    labels_df.sort('synset_id')\n",
    "    predictions_df = pd.DataFrame(np.vstack(df.prediction.values), columns=labels_df['name'])\n",
    "#print(predictions_df.iloc[0])\n",
    "\n",
    "    max_s = predictions_df.max(0)\n",
    "    max_s.sort(ascending=False)\n",
    "#print(max_s[:10])\n",
    "#print(max_s[:1])\n",
    "    x=max_s.axes\n",
    "    y=x[0][0]\n",
    "#print y\n",
    "    y2=x[0][1]\n",
    "#print y2\n",
    "\n",
    "# Find, print, and display the top detections: person and bicycle.\n",
    "    i = predictions_df[y].argmax()\n",
    "    j = predictions_df[y2].argmax()\n",
    "\n",
    "# Show top predictions for top detection.\n",
    "    f = pd.Series(df['prediction'].iloc[i], index=labels_df['name'])\n",
    "#print('Top detection:')\n",
    "#print(f.order(ascending=False)[:2])\n",
    "    f1=f.order(ascending=False)[:2]\n",
    "    f_ind1=f1.axes\n",
    "#print f_ind1[0][0]\n",
    "#print f1[0]\n",
    "#print('')\n",
    "\n",
    "# Show top predictions for second-best detection.\n",
    "    f = pd.Series(df['prediction'].iloc[j], index=labels_df['name'])\n",
    "#print('Second-best detection:')\n",
    "#print(f.order(ascending=False)[:2])\n",
    "    f2=f.order(ascending=False)[:2]\n",
    "    f_ind2=f2.axes\n",
    "#print f_ind2[0][0]\n",
    "#print f2[0]\n",
    "\n",
    "# Show top detection in red, second-best top detection in blue.\n",
    "    im = plt.imread(image_list[p])\n",
    "    plt.imshow(im)\n",
    "    currentAxis = plt.gca()\n",
    "\n",
    "    det1 = df.iloc[i]\n",
    "    print det1\n",
    "#coords = (det1['xmin'], det1['ymin']), det1['xmax'] - det1['xmin'], det1['ymax'] - det1['ymin']\n",
    "#currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor='r', linewidth=5))\n",
    "\n",
    "    det2 = df.iloc[j]\n",
    "    print det2\n",
    "#coords = (det2['xmin'], det2['ymin']), det2['xmax'] - det2['xmin'], det2['ymax'] - det2['ymin']\n",
    "#currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor='b', linewidth=5))\n",
    "\n",
    "#if (det1['xmin']<=det2['xmin'] and det1['ymin']<=det2['ymin'] and det1['xmax']>=det2['xmax'] and det1['ymax']>=det2['ymax']):\n",
    "#    coords = (det1['xmin'], det1['ymin']), det1['xmax'] - det1['xmin'], det1['ymax'] - det1['ymin']\n",
    "#    currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor='r', linewidth=5))\n",
    "#    print y\n",
    "#    print str(det1['xmin'])+'\\t'+str(det1['ymin'])+'\\t'+str(det1['xmax'])+'\\t'+str(det1['ymax'])\n",
    "#elif (det2['xmin']<=det1['xmin'] and det2['ymin']<=det1['ymin'] and det2['xmax']>=det1['xmax'] and det2['ymax']>=det1['ymax']):\n",
    "#    coords = (det2['xmin'], det2['ymin']), det2['xmax'] - det2['xmin'], det2['ymax'] - det2['ymin']\n",
    "#    currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor='b', linewidth=5))\n",
    "#    print y2\n",
    "#    print str(det2['xmin'])+'\\t'+str(det2['ymin'])+'\\t'+str(det2['xmax'])+'\\t'+str(det2['ymax'])\n",
    "#else:\n",
    "    coords1 = (det1['xmin'], det1['ymin']), det1['xmax'] - det1['xmin'], det1['ymax'] - det1['ymin']\n",
    "    currentAxis.add_patch(plt.Rectangle(*coords1, fill=False, edgecolor='r', linewidth=5))\n",
    "    coords2 = (det2['xmin'], det2['ymin']), det2['xmax'] - det2['xmin'], det2['ymax'] - det2['ymin']\n",
    "    currentAxis.add_patch(plt.Rectangle(*coords2, fill=False, edgecolor='b', linewidth=5))\n",
    "    print y\n",
    "    print str(det1['xmin'])+'\\t'+str(det1['ymin'])+'\\t'+str(det1['xmax'])+'\\t'+str(det1['ymax'])\n",
    "    print y2\n",
    "    print str(det2['xmin'])+'\\t'+str(det2['ymin'])+'\\t'+str(det2['xmax'])+'\\t'+str(det2['ymax'])\n",
    "    \n",
    "    x_init=''\n",
    "    for q in range(0,len(image_list[0])):\n",
    "        #print q\n",
    "        #print lines[1][q]\n",
    "        if image_list[p][q]=='.':\n",
    "            break\n",
    "        elif (image_list[p][q]=='1' or image_list[p][q]=='2' or image_list[p][q]=='3' or image_list[p][q]=='4' or image_list[p][q]=='5' or image_list[p][q]=='6' or image_list[p][q]=='7' or image_list[p][q]=='8' or image_list[p][q]=='9' or image_list[p][q]=='0'):\n",
    "            x_init+=image_list[p][q]\n",
    "    x_init=x_init\n",
    "    print x_init\n",
    "    \n",
    "    var=str(x_init)+'\\t'+f_ind1[0][0]+'\\t'+str(f1[0])+'\\t'+str(det1['xmin'])+'\\t'+str(det1['ymin'])+'\\t'+str(det1['xmax'])+'\\t'+str(det1['ymax'])+'\\t'+f_ind2[0][0]+'\\t'+str(f2[0])+'\\t'+str(det2['xmin'])+'\\t'+str(det2['ymin'])+'\\t'+str(det2['xmax'])+'\\t'+str(det2['ymax'])\n",
    "    a.writerows([[var]])\n",
    "    \n",
    "    !rm -rf _temp\n",
    "    \n",
    "b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['144114' 'airplane' '1.57993' '75' '152' '345' '288' 'airplane' '0.93291'\n",
      " '20' '151' '500' '285']\n"
     ]
    }
   ],
   "source": [
    "path='/home/ambika/INF_project/detection_results.txt'\n",
    "d = np.loadtxt(path, str)\n",
    "\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
